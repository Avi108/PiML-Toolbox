{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Robustness:  Regression\n\nEvaluate model robustness\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom piml import Experiment\nfrom piml.models import FIGSRegressor\nfrom piml.models import ReluDNNRegressor\nfrom piml.models import GLMRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Data preparation and model instantiation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exp=Experiment()\nexp.data_loader(data=\"BikeSharing\")\nexp.data_prepare(target='cnt', task_type='Regression')\ntrain_x , train_y,_ = exp.get_data(train= True)\ntest_x , test_y,_= exp.get_data(test=True)\nfeature_names = exp.get_feature_names()\ntarget_names = exp.get_target_name()\nmodel_A = FIGSRegressor(max_iter=100, max_depth=None, random_state=None)\nmodel_B = ReluDNNRegressor(hidden_layer_sizes=(20, 30), batch_size=1000, learning_rate=0.001)\nexp.model_train(model=model_A, name=\"FIGS\")\nexp.model_train(model=model_B, name=\"ReluDNN\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model performance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exp.model_diagnose(model=\"ReluDNN\", show='robustness',\n                   perturb_features='All Features', alpha=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare models' under worst case.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exp.model_compare(models=[\"FIGS\",\"ReluDNN\"], show='robustness_perf_worst',\n                  alpha=0.3, figsize=(5,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comapre model Robustness : the perturbation step  size is 0.1\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exp.model_compare(models=[\"FIGS\",\"ReluDNN\"], show='robustness_perf', figsize=(5,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Comapre model Robustness : the perturbation step  size is 0.01\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exp.model_compare(models=[\"FIGS\",\"ReluDNN\"], show='robustness_perf',\n                  perturb_size=0.01, figsize=(5,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train models under different regularizations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model_list = []\nregularization_grid = np.logspace(-5, -3, 3)\nfor reg in regularization_grid:\n    name = \"GLM_{}\".format(reg)\n    exp.model_train(model=GLMRegressor(l1_regularzation=reg),name=name)\n    model_list.append(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare models (worst case) under different regularizations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exp.model_compare(models=model_list, show='robustness_perf_worst', \n                  figsize=(5,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We may not only compare the Robustness performance under the worst-case scenario. For general robustness, set show to robustness_perf as follows.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exp.model_compare(models=model_list, show='robustness_perf',\n                  alpha=0.3, figsize=(5,4))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}