Search.setIndex({"docnames": ["auto_examples/0_data/index", "auto_examples/0_data/plot_0_data_loader_builtin", "auto_examples/0_data/plot_0_data_loader_dataframe", "auto_examples/0_data/plot_0_data_loader_spark", "auto_examples/0_data/plot_1_data_summary", "auto_examples/0_data/plot_2_data_eda", "auto_examples/0_data/plot_3_data_prepare", "auto_examples/0_data/plot_4_data_quality", "auto_examples/0_data/plot_5_feature_select", "auto_examples/0_data/sg_execution_times", "auto_examples/1_model_train/index", "auto_examples/1_model_train/plot_0_model_train", "auto_examples/1_model_train/plot_1_hpo_grid", "auto_examples/1_model_train/plot_1_hpo_random", "auto_examples/1_model_train/plot_2_register_arbitrary", "auto_examples/1_model_train/plot_2_register_h2o", "auto_examples/1_model_train/plot_2_register_sklearn", "auto_examples/1_model_train/sg_execution_times", "auto_examples/1_train/index", "auto_examples/1_train/plot_0_model_train", "auto_examples/1_train/plot_1_hpo_grid", "auto_examples/1_train/plot_1_hpo_random", "auto_examples/1_train/plot_2_register_0_sklearn", "auto_examples/1_train/plot_2_register_1_h2o", "auto_examples/1_train/plot_2_register_2_arbitrary", "auto_examples/1_train/sg_execution_times", "auto_examples/2_explain/index", "auto_examples/2_explain/plot_0_pfi", "auto_examples/2_explain/plot_1_pdp", "auto_examples/2_explain/plot_1_pdp_hstats", "auto_examples/2_explain/plot_2_ice", "auto_examples/2_explain/plot_3_ale", "auto_examples/2_explain/plot_4_lime", "auto_examples/2_explain/plot_5_shap", "auto_examples/2_explain/plot_6_data_dependent_explain", "auto_examples/2_explain/sg_execution_times", "auto_examples/3_models/index", "auto_examples/3_models/plot_0_glm_cls", "auto_examples/3_models/plot_0_glm_reg", "auto_examples/3_models/plot_1_gam_cls", "auto_examples/3_models/plot_1_gam_reg", "auto_examples/3_models/plot_2_tree_cls", "auto_examples/3_models/plot_2_tree_reg", "auto_examples/3_models/plot_3_figs_cls", "auto_examples/3_models/plot_3_figs_reg", "auto_examples/3_models/plot_4_xgb1_cls", "auto_examples/3_models/plot_4_xgb1_reg", "auto_examples/3_models/plot_5_xgb2_cls", "auto_examples/3_models/plot_5_xgb2_reg", "auto_examples/3_models/plot_6_ebm_cls", "auto_examples/3_models/plot_6_ebm_reg", "auto_examples/3_models/plot_7_gaminet_cls", "auto_examples/3_models/plot_7_gaminet_reg", "auto_examples/3_models/plot_8_reludnn_cls", "auto_examples/3_models/plot_8_reludnn_reg", "auto_examples/3_models/sg_execution_times", "auto_examples/4_testing/index", "auto_examples/4_testing/plot_0_accuracy_cls", "auto_examples/4_testing/plot_0_accuracy_reg", "auto_examples/4_testing/plot_1_weakspot_cls", "auto_examples/4_testing/plot_1_weakspot_reg", "auto_examples/4_testing/plot_2_overfit_cls", "auto_examples/4_testing/plot_2_overfit_reg", "auto_examples/4_testing/plot_3_reliability_cls", "auto_examples/4_testing/plot_3_reliability_reg", "auto_examples/4_testing/plot_4_robustness_cls", "auto_examples/4_testing/plot_4_robustness_reg", "auto_examples/4_testing/plot_5_resilience_cls", "auto_examples/4_testing/plot_5_resilience_reg", "auto_examples/4_testing/plot_6_fairness", "auto_examples/4_testing/plot_7_segmented_cls", "auto_examples/4_testing/plot_7_segmented_reg", "auto_examples/4_testing/plot_8_scored_test_cls", "auto_examples/4_testing/plot_8_scored_test_reg", "auto_examples/4_testing/sg_execution_times", "auto_examples/5_compare/index", "auto_examples/5_compare/plot_0_compare_classification", "auto_examples/5_compare/plot_0_compare_regression", "auto_examples/5_compare/plot_1_compare_fairness", "auto_examples/5_compare/sg_execution_times", "auto_examples/index", "contents", "faq", "guides/cases", "guides/cases/Example_BikeSharing", "guides/cases/Example_CaliforniaHousing", "guides/cases/Example_Fairness_SimuStudy1", "guides/cases/Example_Fairness_SimuStudy2", "guides/cases/Example_TaiwanCredit", "guides/compare", "guides/compare/compare_classification", "guides/compare/compare_fairness", "guides/compare/compare_regression", "guides/data", "guides/data/data_eda", "guides/data/data_load", "guides/data/data_prepare", "guides/data/data_quality_drift", "guides/data/data_quality_integrity", "guides/data/data_quality_outlier", "guides/data/data_summary", "guides/data/feature_select", "guides/explain", "guides/explain/ale", "guides/explain/hstats", "guides/explain/ice", "guides/explain/lime", "guides/explain/pdp", "guides/explain/pfi", "guides/explain/shap", "guides/introduction", "guides/models", "guides/models/ebm", "guides/models/figs", "guides/models/gam", "guides/models/gaminet", "guides/models/glm", "guides/models/reludnn", "guides/models/tree", "guides/models/xgb1", "guides/models/xgb2", "guides/testing", "guides/testing/accuracy", "guides/testing/fairness", "guides/testing/overfit", "guides/testing/reliability", "guides/testing/resilience", "guides/testing/robustness", "guides/testing/scored_test", "guides/testing/segmented_diagnose", "guides/testing/weakspot", "guides/train", "guides/train/arbitrary", "guides/train/h2o", "guides/train/hpo", "guides/train/sklearn", "install", "modules/classes", "modules/generated/piml.Experiment", "modules/generated/piml.data.outlier_detection.CBLOF", "modules/generated/piml.data.outlier_detection.ECOD", "modules/generated/piml.data.outlier_detection.HBOS", "modules/generated/piml.data.outlier_detection.IsolationForest", "modules/generated/piml.data.outlier_detection.KMeansTree", "modules/generated/piml.data.outlier_detection.KNN", "modules/generated/piml.data.outlier_detection.OneClassSVM", "modules/generated/piml.data.outlier_detection.PCA", "modules/generated/piml.models.ExplainableBoostingClassifier", "modules/generated/piml.models.ExplainableBoostingRegressor", "modules/generated/piml.models.FIGSClassifier", "modules/generated/piml.models.FIGSRegressor", "modules/generated/piml.models.GAMClassifier", "modules/generated/piml.models.GAMINetClassifier", "modules/generated/piml.models.GAMINetRegressor", "modules/generated/piml.models.GAMRegressor", "modules/generated/piml.models.GLMClassifier", "modules/generated/piml.models.GLMRegressor", "modules/generated/piml.models.ReluDNNClassifier", "modules/generated/piml.models.ReluDNNRegressor", "modules/generated/piml.models.TreeClassifier", "modules/generated/piml.models.TreeRegressor", "modules/generated/piml.models.XGB1Classifier", "modules/generated/piml.models.XGB1Regressor", "modules/generated/piml.models.XGB2Classifier", "modules/generated/piml.models.XGB2Regressor", "modules/generated/piml.scored_test.test_accuracy_plot", "modules/generated/piml.scored_test.test_accuracy_residual", "modules/generated/piml.scored_test.test_accuracy_table", "modules/generated/piml.scored_test.test_overfit", "modules/generated/piml.scored_test.test_reliability_calibration", "modules/generated/piml.scored_test.test_reliability_distance", "modules/generated/piml.scored_test.test_reliability_marginal", "modules/generated/piml.scored_test.test_reliability_perf", "modules/generated/piml.scored_test.test_reliability_table", "modules/generated/piml.scored_test.test_resilience_distance", "modules/generated/piml.scored_test.test_resilience_perf", "modules/generated/piml.scored_test.test_resilience_shift_density", "modules/generated/piml.scored_test.test_resilience_shift_histogram", "modules/generated/piml.scored_test.test_weakspot", "preface", "tune_toc", "user_guide"], "filenames": ["auto_examples\\0_data\\index.rst", "auto_examples\\0_data\\plot_0_data_loader_builtin.rst", "auto_examples\\0_data\\plot_0_data_loader_dataframe.rst", "auto_examples\\0_data\\plot_0_data_loader_spark.rst", "auto_examples\\0_data\\plot_1_data_summary.rst", "auto_examples\\0_data\\plot_2_data_eda.rst", "auto_examples\\0_data\\plot_3_data_prepare.rst", "auto_examples\\0_data\\plot_4_data_quality.rst", "auto_examples\\0_data\\plot_5_feature_select.rst", "auto_examples\\0_data\\sg_execution_times.rst", "auto_examples\\1_model_train\\index.rst", "auto_examples\\1_model_train\\plot_0_model_train.rst", "auto_examples\\1_model_train\\plot_1_hpo_grid.rst", "auto_examples\\1_model_train\\plot_1_hpo_random.rst", "auto_examples\\1_model_train\\plot_2_register_arbitrary.rst", "auto_examples\\1_model_train\\plot_2_register_h2o.rst", "auto_examples\\1_model_train\\plot_2_register_sklearn.rst", "auto_examples\\1_model_train\\sg_execution_times.rst", "auto_examples\\1_train\\index.rst", "auto_examples\\1_train\\plot_0_model_train.rst", "auto_examples\\1_train\\plot_1_hpo_grid.rst", "auto_examples\\1_train\\plot_1_hpo_random.rst", "auto_examples\\1_train\\plot_2_register_0_sklearn.rst", "auto_examples\\1_train\\plot_2_register_1_h2o.rst", "auto_examples\\1_train\\plot_2_register_2_arbitrary.rst", "auto_examples\\1_train\\sg_execution_times.rst", "auto_examples\\2_explain\\index.rst", "auto_examples\\2_explain\\plot_0_pfi.rst", "auto_examples\\2_explain\\plot_1_pdp.rst", "auto_examples\\2_explain\\plot_1_pdp_hstats.rst", "auto_examples\\2_explain\\plot_2_ice.rst", "auto_examples\\2_explain\\plot_3_ale.rst", "auto_examples\\2_explain\\plot_4_lime.rst", "auto_examples\\2_explain\\plot_5_shap.rst", "auto_examples\\2_explain\\plot_6_data_dependent_explain.rst", "auto_examples\\2_explain\\sg_execution_times.rst", "auto_examples\\3_models\\index.rst", "auto_examples\\3_models\\plot_0_glm_cls.rst", "auto_examples\\3_models\\plot_0_glm_reg.rst", "auto_examples\\3_models\\plot_1_gam_cls.rst", "auto_examples\\3_models\\plot_1_gam_reg.rst", "auto_examples\\3_models\\plot_2_tree_cls.rst", "auto_examples\\3_models\\plot_2_tree_reg.rst", "auto_examples\\3_models\\plot_3_figs_cls.rst", "auto_examples\\3_models\\plot_3_figs_reg.rst", "auto_examples\\3_models\\plot_4_xgb1_cls.rst", "auto_examples\\3_models\\plot_4_xgb1_reg.rst", "auto_examples\\3_models\\plot_5_xgb2_cls.rst", "auto_examples\\3_models\\plot_5_xgb2_reg.rst", "auto_examples\\3_models\\plot_6_ebm_cls.rst", "auto_examples\\3_models\\plot_6_ebm_reg.rst", "auto_examples\\3_models\\plot_7_gaminet_cls.rst", "auto_examples\\3_models\\plot_7_gaminet_reg.rst", "auto_examples\\3_models\\plot_8_reludnn_cls.rst", "auto_examples\\3_models\\plot_8_reludnn_reg.rst", "auto_examples\\3_models\\sg_execution_times.rst", "auto_examples\\4_testing\\index.rst", "auto_examples\\4_testing\\plot_0_accuracy_cls.rst", "auto_examples\\4_testing\\plot_0_accuracy_reg.rst", "auto_examples\\4_testing\\plot_1_weakspot_cls.rst", "auto_examples\\4_testing\\plot_1_weakspot_reg.rst", "auto_examples\\4_testing\\plot_2_overfit_cls.rst", "auto_examples\\4_testing\\plot_2_overfit_reg.rst", "auto_examples\\4_testing\\plot_3_reliability_cls.rst", "auto_examples\\4_testing\\plot_3_reliability_reg.rst", "auto_examples\\4_testing\\plot_4_robustness_cls.rst", "auto_examples\\4_testing\\plot_4_robustness_reg.rst", "auto_examples\\4_testing\\plot_5_resilience_cls.rst", "auto_examples\\4_testing\\plot_5_resilience_reg.rst", "auto_examples\\4_testing\\plot_6_fairness.rst", "auto_examples\\4_testing\\plot_7_segmented_cls.rst", "auto_examples\\4_testing\\plot_7_segmented_reg.rst", "auto_examples\\4_testing\\plot_8_scored_test_cls.rst", "auto_examples\\4_testing\\plot_8_scored_test_reg.rst", "auto_examples\\4_testing\\sg_execution_times.rst", "auto_examples\\5_compare\\index.rst", "auto_examples\\5_compare\\plot_0_compare_classification.rst", "auto_examples\\5_compare\\plot_0_compare_regression.rst", "auto_examples\\5_compare\\plot_1_compare_fairness.rst", "auto_examples\\5_compare\\sg_execution_times.rst", "auto_examples\\index.rst", "contents.rst", "faq.rst", "guides\\cases.rst", "guides\\cases\\Example_BikeSharing.ipynb", "guides\\cases\\Example_CaliforniaHousing.ipynb", "guides\\cases\\Example_Fairness_SimuStudy1.ipynb", "guides\\cases\\Example_Fairness_SimuStudy2.ipynb", "guides\\cases\\Example_TaiwanCredit.ipynb", "guides\\compare.rst", "guides\\compare\\compare_classification.rst", "guides\\compare\\compare_fairness.rst", "guides\\compare\\compare_regression.rst", "guides\\data.rst", "guides\\data\\data_eda.rst", "guides\\data\\data_load.rst", "guides\\data\\data_prepare.rst", "guides\\data\\data_quality_drift.rst", "guides\\data\\data_quality_integrity.rst", "guides\\data\\data_quality_outlier.rst", "guides\\data\\data_summary.rst", "guides\\data\\feature_select.rst", "guides\\explain.rst", "guides\\explain\\ale.rst", "guides\\explain\\hstats.rst", "guides\\explain\\ice.rst", "guides\\explain\\lime.rst", "guides\\explain\\pdp.rst", "guides\\explain\\pfi.rst", "guides\\explain\\shap.rst", "guides\\introduction.rst", "guides\\models.rst", "guides\\models\\ebm.rst", "guides\\models\\figs.rst", "guides\\models\\gam.rst", "guides\\models\\gaminet.rst", "guides\\models\\glm.rst", "guides\\models\\reludnn.rst", "guides\\models\\tree.rst", "guides\\models\\xgb1.rst", "guides\\models\\xgb2.rst", "guides\\testing.rst", "guides\\testing\\accuracy.rst", "guides\\testing\\fairness.rst", "guides\\testing\\overfit.rst", "guides\\testing\\reliability.rst", "guides\\testing\\resilience.rst", "guides\\testing\\robustness.rst", "guides\\testing\\scored_test.rst", "guides\\testing\\segmented_diagnose.rst", "guides\\testing\\weakspot.rst", "guides\\train.rst", "guides\\train\\arbitrary.rst", "guides\\train\\h2o.rst", "guides\\train\\hpo.rst", "guides\\train\\sklearn.rst", "install.rst", "modules\\classes.rst", "modules\\generated\\piml.Experiment.rst", "modules\\generated\\piml.data.outlier_detection.CBLOF.rst", "modules\\generated\\piml.data.outlier_detection.ECOD.rst", "modules\\generated\\piml.data.outlier_detection.HBOS.rst", "modules\\generated\\piml.data.outlier_detection.IsolationForest.rst", "modules\\generated\\piml.data.outlier_detection.KMeansTree.rst", "modules\\generated\\piml.data.outlier_detection.KNN.rst", "modules\\generated\\piml.data.outlier_detection.OneClassSVM.rst", "modules\\generated\\piml.data.outlier_detection.PCA.rst", "modules\\generated\\piml.models.ExplainableBoostingClassifier.rst", "modules\\generated\\piml.models.ExplainableBoostingRegressor.rst", "modules\\generated\\piml.models.FIGSClassifier.rst", "modules\\generated\\piml.models.FIGSRegressor.rst", "modules\\generated\\piml.models.GAMClassifier.rst", "modules\\generated\\piml.models.GAMINetClassifier.rst", "modules\\generated\\piml.models.GAMINetRegressor.rst", "modules\\generated\\piml.models.GAMRegressor.rst", "modules\\generated\\piml.models.GLMClassifier.rst", "modules\\generated\\piml.models.GLMRegressor.rst", "modules\\generated\\piml.models.ReluDNNClassifier.rst", "modules\\generated\\piml.models.ReluDNNRegressor.rst", "modules\\generated\\piml.models.TreeClassifier.rst", "modules\\generated\\piml.models.TreeRegressor.rst", "modules\\generated\\piml.models.XGB1Classifier.rst", "modules\\generated\\piml.models.XGB1Regressor.rst", "modules\\generated\\piml.models.XGB2Classifier.rst", "modules\\generated\\piml.models.XGB2Regressor.rst", "modules\\generated\\piml.scored_test.test_accuracy_plot.rst", "modules\\generated\\piml.scored_test.test_accuracy_residual.rst", "modules\\generated\\piml.scored_test.test_accuracy_table.rst", "modules\\generated\\piml.scored_test.test_overfit.rst", "modules\\generated\\piml.scored_test.test_reliability_calibration.rst", "modules\\generated\\piml.scored_test.test_reliability_distance.rst", "modules\\generated\\piml.scored_test.test_reliability_marginal.rst", "modules\\generated\\piml.scored_test.test_reliability_perf.rst", "modules\\generated\\piml.scored_test.test_reliability_table.rst", "modules\\generated\\piml.scored_test.test_resilience_distance.rst", "modules\\generated\\piml.scored_test.test_resilience_perf.rst", "modules\\generated\\piml.scored_test.test_resilience_shift_density.rst", "modules\\generated\\piml.scored_test.test_resilience_shift_histogram.rst", "modules\\generated\\piml.scored_test.test_weakspot.rst", "preface.rst", "tune_toc.rst", "user_guide.rst"], "titles": ["Data Pipeline", "Data Load (Built-in Dataset)", "Data Load (Pandas DataFrame)", "Data Load (Spark)", "Data Summary", "EDA", "Data Preparation", "Data Quality Check", "Feature Selection", "Computation times", "Model Train and Tune", "Train External Models", "HPO - XGB - Grid Search (Bike Sharing)", "HPO - GLM - Random Search (SimuCredit)", "Registering Arbitrary Models", "Registering H2O Models", "Registering sklearn Style Models", "Computation times", "Model Train and Tune", "Train Models", "HPO - Grid Search", "HPO - Random Search", "Register sklearn Style Models", "Register H2O Models", "Register Arbitrary Models", "Computation times", "Post hoc Explainability", "Permutation Feature Importance", "Partial Dependence Plot", "H-statistics", "Individual Conditional Expectation", "Accumulated Local Effects", "Local Interpretable Model-Agnostic Explanation", "SHapley Additive exPlanations", "Data Dependent Explanation", "Computation times", "Interpretable Models", "GLM Logistic Regression (Taiwan Credit)", "GLM Linear Regression (Bike Sharing)", "GAM Classification (CoCircles)", "GAM Regression (California Housing)", "Tree Classification (TaiwanCredit)", "Tree Regression (California Housing)", "FIGS Classification (Taiwan Credit)", "FIGS Regression (California Housing)", "XGB-1 Classification (CoCircles)", "XGB-1 Regression (California Housing)", "XGB-2 Classification (Taiwan Credit)", "XGB-2 Regression (Bike Sharing)", "EBM Classification (Taiwan Credit)", "EBM Regression (Bike Sharing)", "GAMI-Net Classification (Taiwan Credit)", "GAMI-Net Regression (Bike Sharing)", "ReLU DNN Classification (Taiwan Credit)", "ReLU DNN Regression (Friedman)", "Computation times", "Outcome Testing", "Accuracy: Classification", "Accuracy: Regression", "WeakSpot: Classification", "WeakSpot: Regression", "Overfit: Classification", "Overfit: Regression", "Reliability: Classification", "Reliability: Regression", "Robustness: Classification", "Robustness:  Regression", "Resilience:  Classification", "Resilience - Regression", "Fairness Test: XGB2", "Segmented Diagnose (Classification)", "Segmented Diagnose (Regression)", "Scored Test: Classification", "Scored Test: Regression", "Computation times", "Model Comparison", "Model Comparison: Classification", "Model Comparison: Regression", "Fairness Comparison", "Computation times", "Examples", "Table Of Contents", "Frequently Asked Questions", "<span class=\"section-number\">8. </span>Case Studies", "<span class=\"section-number\">8.1. </span>BikeSharing Data", "<span class=\"section-number\">8.2. </span>CaliforniaHousing Data", "<span class=\"section-number\">8.4. </span>Fairness Simulation Study 1", "<span class=\"section-number\">8.5. </span>Fairness Simulation Study 2", "<span class=\"section-number\">8.3. </span>TaiwanCredit Data", "<span class=\"section-number\">7. </span>Model Comparison", "<span class=\"section-number\">7.2. </span>Comparison for Classification", "<span class=\"section-number\">7.3. </span>Fairness Comparison", "<span class=\"section-number\">7.1. </span>Comparison for Regression", "<span class=\"section-number\">2. </span>Data Pipeline", "<span class=\"section-number\">2.4. </span>Exploratory Analysis", "<span class=\"section-number\">2.1. </span>Data Load", "<span class=\"section-number\">2.3. </span>Data Preparation", "<span class=\"section-number\">2.7. </span>Data Quality (Drift Test)", "<span class=\"section-number\">2.5. </span>Data Quality (Integrity Check)", "<span class=\"section-number\">2.6. </span>Data Quality (Outlier Detection)", "<span class=\"section-number\">2.2. </span>Data Summary", "<span class=\"section-number\">2.8. </span>Feature Selection", "<span class=\"section-number\">4. </span>Post-hoc Explainability", "<span class=\"section-number\">4.5. </span>ALE (Accumulated Local Effects)", "<span class=\"section-number\">4.3. </span>Hstats (Friedman\u2019s H-statistic)", "<span class=\"section-number\">4.4. </span>ICE (Individual Conditional Expectation)", "<span class=\"section-number\">4.6. </span>LIME (Local Interpretable Model-Agnostic Explanation)", "<span class=\"section-number\">4.2. </span>PDP (Partial Dependence Plot)", "<span class=\"section-number\">4.1. </span>PFI (Permutation Feature Importance)", "<span class=\"section-number\">4.7. </span>SHAP (SHapley Additive exPlanations)", "<span class=\"section-number\">1. </span>Introduction", "<span class=\"section-number\">5. </span>Interpretable Models", "<span class=\"section-number\">5.7. </span>Explainable Boosting Machines", "<span class=\"section-number\">5.4. </span>Fast Interpretable Greedy-tree Sums", "<span class=\"section-number\">5.2. </span>Generalized Additive Model", "<span class=\"section-number\">5.8. </span>GAMI-Net", "<span class=\"section-number\">5.1. </span>Generalized Linear Models", "<span class=\"section-number\">5.9. </span>ReLU Neural Network", "<span class=\"section-number\">5.3. </span>Decision Tree", "<span class=\"section-number\">5.5. </span>XGBoost Depth 1", "<span class=\"section-number\">5.6. </span>XGBoost Depth 2", "<span class=\"section-number\">6. </span>Diagnostic Suite", "<span class=\"section-number\">6.1. </span>Accuracy", "<span class=\"section-number\">6.7. </span>Fairness", "<span class=\"section-number\">6.3. </span>Overfit", "<span class=\"section-number\">6.4. </span>Reliability", "<span class=\"section-number\">6.6. </span>Resilience", "<span class=\"section-number\">6.5. </span>Robustness", "<span class=\"section-number\">6.9. </span>Scored Test", "<span class=\"section-number\">6.8. </span>Segmented", "<span class=\"section-number\">6.2. </span>WeakSpot", "<span class=\"section-number\">3. </span>Model Train and Tune", "<span class=\"section-number\">3.3. </span>Register Arbitrary Models", "<span class=\"section-number\">3.2. </span>Register H2O Models", "<span class=\"section-number\">3.4. </span>Hyperparameter Optimization (Model Tune)", "<span class=\"section-number\">3.1. </span>Train and Register Sklearn Style Model", "Installation", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml</span></code>.Experiment", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.CBLOF", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.ECOD", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.HBOS", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.IsolationForest", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.KMeansTree", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.KNN", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.OneClassSVM", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.PCA", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ExplainableBoostingClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ExplainableBoostingRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.FIGSClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.FIGSRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMINetClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMINetRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GLMClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GLMRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ReluDNNClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ReluDNNRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.TreeClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.TreeRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB1Classifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB1Regressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB2Classifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB2Regressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_accuracy_plot", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_accuracy_residual", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_accuracy_table", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_overfit", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_reliability_calibration", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_reliability_distance", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_reliability_marginal", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_reliability_perf", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_reliability_table", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_resilience_distance", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_resilience_perf", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_resilience_shift_density", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_resilience_shift_histogram", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.scored_test</span></code>.test_weakspot", "Welcome to PiML", "&lt;no title&gt;", "User guide: contents"], "terms": {"load": [0, 9, 11, 15, 16, 19, 22, 23, 61, 73, 80, 83, 90, 93, 98, 100, 110, 112, 116, 120, 122, 124, 125, 127, 128, 130, 131, 138, 152, 153, 181], "built": [0, 8, 9, 80, 93, 101, 109, 117, 134, 138, 143], "dataset": [0, 2, 4, 5, 6, 7, 8, 9, 14, 15, 16, 22, 23, 24, 73, 80, 84, 85, 86, 87, 88, 90, 91, 92, 93, 96, 97, 98, 99, 100, 101, 103, 105, 106, 107, 108, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 135, 138, 152, 153, 157, 158], "panda": [0, 3, 7, 9, 15, 23, 70, 71, 80, 133, 136, 138], "datafram": [0, 3, 9, 15, 23, 80, 104, 133, 138], "spark": [0, 9, 80, 93, 138], "summari": [0, 9, 33, 53, 54, 70, 71, 80, 93, 98, 113, 122, 127, 130, 138, 181], "eda": [0, 9, 80, 84, 85, 86, 87, 88, 94, 110, 138], "prepar": [0, 1, 2, 4, 5, 7, 8, 9, 12, 13, 20, 21, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 83, 93, 99, 108, 114, 117, 118, 132, 135, 138, 181], "qualiti": [0, 9, 80, 93, 94, 110, 123, 125, 138, 139, 140, 141, 142, 143, 144, 145, 146, 159, 160, 181], "check": [0, 9, 14, 15, 16, 22, 23, 24, 80, 84, 85, 87, 92, 93, 94, 97, 99, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 181], "featur": [0, 4, 7, 9, 26, 29, 33, 35, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 80, 84, 85, 86, 87, 88, 90, 92, 93, 94, 95, 96, 97, 99, 102, 103, 104, 105, 106, 107, 110, 118, 122, 123, 124, 125, 126, 128, 129, 130, 133, 138, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181], "select": [0, 7, 9, 12, 13, 20, 21, 70, 71, 80, 86, 87, 90, 92, 93, 96, 99, 103, 115, 116, 117, 118, 119, 122, 126, 127, 129, 130, 134, 138, 141, 142, 146, 147, 148, 152, 153, 159, 160, 168, 174, 175, 176, 177, 178, 181], "go": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78], "end": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 97, 98, 99, 101, 103, 104, 105, 107, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 125, 159, 160], "download": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80], "full": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 91, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 109, 110, 112, 114, 115, 116, 117, 119, 120, 123, 125, 127, 137, 138, 146], "exampl": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 83, 84, 85, 86, 87, 88, 89, 93, 102, 110, 111, 121, 131], "code": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 83, 84, 85, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 134, 138], "run": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 84, 85, 86, 87, 88, 101, 110, 124, 127, 131, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 159, 160], "thi": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 83, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 136, 137, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 174, 176, 177], "your": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 87, 95, 96, 100, 119, 126, 129, 136], "browser": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78], "via": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 95, 101, 104, 112, 117, 120, 134, 138, 143, 146, 147, 148], "binder": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78], "experi": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 76, 77, 78, 82, 84, 85, 86, 87, 88, 95, 101, 110, 123, 127, 128, 132, 133, 134, 135, 136], "initi": [1, 2, 3, 4, 5, 6, 7, 8, 12, 13, 20, 21, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 101, 110, 119, 123, 130, 134, 135, 138, 147, 148, 152, 153, 157, 158], "from": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 82, 84, 85, 86, 87, 88, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 158, 160, 161, 162, 164], "piml": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 90, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 137], "import": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 84, 85, 86, 87, 88, 90, 91, 92, 93, 96, 99, 102, 104, 110, 118, 122, 125, 126, 127, 128, 129, 130, 132, 133, 135, 138, 152, 153, 159, 160, 181], "exp": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 76, 77, 78, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138], "data_load": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 19, 20, 21, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 76, 77, 78, 84, 85, 86, 87, 88, 95, 110, 135, 138], "cocircl": [1, 36, 55, 80, 95, 138, 151, 161], "x0": [1, 3, 14, 24, 29, 39, 45, 54, 95, 104, 119, 132, 138], "x1": [1, 3, 14, 24, 29, 39, 45, 86, 95, 104, 119, 132, 138], "target": [1, 6, 7, 8, 11, 12, 13, 15, 16, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 76, 77, 78, 87, 90, 92, 95, 96, 97, 103, 107, 108, 116, 119, 122, 127, 128, 133, 134, 135, 138, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "0": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 85, 87, 88, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103, 104, 106, 107, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 129, 130, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "783526": [1, 95], "502161": [1, 95], "1": [1, 2, 3, 6, 7, 8, 9, 11, 12, 13, 14, 15, 19, 20, 21, 23, 24, 29, 31, 34, 36, 38, 39, 40, 43, 44, 47, 48, 49, 50, 51, 53, 54, 55, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 83, 84, 85, 87, 88, 91, 96, 97, 98, 99, 100, 101, 110, 111, 123, 132, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178, 181], "297809": [1, 95], "658405": [1, 95], "2": [1, 2, 3, 6, 7, 8, 11, 12, 13, 14, 16, 19, 20, 21, 22, 24, 29, 36, 39, 41, 42, 52, 53, 54, 55, 59, 60, 61, 62, 65, 66, 67, 69, 70, 71, 73, 77, 78, 80, 83, 84, 88, 96, 97, 98, 99, 100, 101, 110, 111, 123, 136, 138, 143, 144, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 168, 174, 176, 177, 178, 181], "468272": [1, 95], "500653": [1, 95], "3": [1, 2, 3, 6, 7, 9, 11, 12, 13, 19, 20, 21, 29, 41, 42, 43, 44, 53, 54, 59, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 79, 84, 85, 86, 87, 88, 90, 92, 96, 98, 100, 103, 104, 105, 109, 113, 114, 115, 117, 118, 119, 122, 126, 127, 129, 130, 134, 136, 138, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164], "134700": 1, "887973": 1, "4": [1, 2, 3, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 143, 147, 148, 152, 153, 159], "337202": 1, "780797": 1, "1995": 1, "498109": 1, "889060": 1, "1996": 1, "312980": 1, "724953": 1, "1997": [1, 95], "542930": [1, 95], "583517": [1, 95], "1998": [1, 95], "871481": [1, 95], "491301": [1, 95], "1999": [1, 95], "323963": [1, 95], "719150": [1, 95], "2000": [1, 29, 99, 101, 103, 104, 105, 107, 138], "row": [1, 2, 3, 11, 12, 13, 19, 20, 21, 53, 98, 117, 138], "x": [1, 2, 3, 11, 14, 19, 24, 37, 38, 53, 72, 73, 90, 92, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 119, 120, 122, 125, 126, 127, 128, 130, 132, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "column": [1, 2, 3, 6, 7, 11, 12, 13, 15, 19, 20, 21, 23, 53, 87, 93, 95, 96, 113, 122, 129, 130, 133, 138, 159], "total": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 98, 116, 117, 119, 122, 138, 143, 147, 148, 150, 153, 158, 159, 160, 161, 162, 163, 164], "time": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 87, 97, 101, 108, 109, 110, 113, 117, 124, 125, 127, 134, 147, 148, 152, 153], "script": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 133], "minut": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78], "7": [1, 9, 11, 16, 17, 19, 22, 29, 35, 54, 59, 60, 62, 69, 70, 71, 77, 78, 79, 84, 85, 86, 87, 88, 90, 99, 100, 101, 104, 112, 120, 126, 127, 129, 135, 136], "267": [1, 9], "second": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 90, 92, 94, 96, 100, 103, 104, 105, 106, 107, 108, 109, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 147, 148, 152, 153], "estim": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 92, 97, 99, 103, 107, 109, 112, 113, 114, 115, 116, 119, 120, 122, 125, 132, 133, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "memori": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 144, 152, 153, 157, 158], "usag": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 97, 98, 99, 101, 102, 113, 119, 120, 121, 122, 131], "12": [1, 2, 25, 29, 39, 43, 44, 54, 69, 71, 85, 87, 95, 100, 104, 110, 113, 126, 127, 129, 136], "mb": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 145], "python": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 98, 103, 109, 110, 113, 114, 117, 119, 120, 136], "sourc": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80], "plot_0_data_loader_builtin": [1, 9], "py": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 136], "jupyt": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 110], "notebook": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 84, 85, 88, 110], "ipynb": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 84, 85, 86, 87, 88], "galleri": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80], "gener": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80, 90, 92, 95, 96, 97, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 138, 147, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 160, 162, 164, 168, 178, 181], "sphinx": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 80], "pd": [2, 3, 15, 23, 95, 107, 133, 138], "read_csv": [2, 95], "http": [2, 95, 101, 110, 138, 146, 149, 150], "github": [2, 16, 22, 73, 95, 110, 138, 149, 150], "com": [2, 95, 110, 138, 149, 150], "selfexplainml": [2, 95, 110], "toolbox": [2, 95, 181], "blob": [2, 95], "main": [2, 84, 85, 88, 95, 101, 103, 117, 147, 148, 151, 152, 153, 154, 161, 162, 163, 164], "bikeshar": [2, 4, 5, 6, 7, 8, 12, 20, 27, 28, 30, 31, 32, 33, 38, 48, 50, 52, 58, 60, 62, 64, 66, 68, 71, 77, 83, 95, 101, 103, 104, 105, 106, 107, 108, 109, 116, 128, 138, 181], "csv": [2, 93], "raw": [2, 66, 90, 92, 95, 98, 119, 120, 125, 127, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 157, 158, 161, 162, 163, 164], "true": [2, 3, 4, 5, 6, 7, 8, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 76, 77, 78, 90, 91, 95, 98, 99, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 129, 130, 132, 133, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "season": [2, 5, 7, 28, 38, 48, 50, 58, 71, 94, 95, 98, 100, 101, 107, 109, 112, 115, 116, 120, 122, 128, 129], "yr": [2, 4, 5, 7, 12, 20, 27, 28, 30, 31, 32, 33, 38, 48, 50, 52, 58, 60, 62, 64, 66, 68, 71, 77, 84, 94, 95, 100, 101], "mnth": [2, 4, 7, 12, 20, 27, 28, 30, 31, 32, 33, 38, 48, 50, 52, 58, 60, 62, 64, 66, 68, 71, 77, 84, 95, 100, 101], "hr": [2, 5, 7, 8, 28, 30, 31, 33, 48, 50, 52, 58, 60, 62, 64, 66, 68, 71, 77, 92, 94, 95, 98, 100, 101, 103, 105, 106, 107, 108, 109, 112, 115, 116, 120, 122, 124, 125, 127, 129], "holidai": [2, 7, 95, 98, 100, 108], "weekdai": [2, 4, 7, 30, 52, 95, 98, 100, 101, 115], "workingdai": [2, 7, 28, 60, 71, 95, 98, 100, 101, 107, 108, 112, 115, 120, 129], "weathersit": [2, 7, 31, 95, 98, 100, 101, 103], "temp": [2, 4, 5, 7, 8, 12, 20, 27, 28, 30, 31, 32, 33, 38, 48, 50, 52, 58, 60, 62, 64, 66, 68, 71, 77, 84, 94, 95, 100, 101, 116], "6": [2, 5, 6, 7, 8, 9, 11, 12, 17, 19, 20, 25, 29, 31, 35, 39, 40, 41, 42, 54, 59, 60, 62, 65, 66, 69, 70, 71, 78, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 98, 100, 101, 103, 104, 105, 106, 110, 114, 118, 122, 123, 127, 129, 130, 134, 136, 138, 143, 151, 154, 165, 166, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178], "24": [2, 4, 5, 9, 11, 17, 19, 21, 25, 29, 31, 35, 54, 61, 69, 95, 99, 104, 105, 136], "22": [2, 11, 19, 29, 54, 60, 69, 95, 104, 110], "17374": 2, "19": [2, 19, 29, 50, 54, 69, 99, 104], "26": [2, 7, 29, 45, 54, 74, 95, 98, 104], "17375": 2, "20": [2, 9, 29, 35, 39, 40, 45, 46, 54, 58, 61, 69, 79, 85, 87, 96, 101, 104, 109, 113, 114, 117, 118, 119, 124, 125, 126, 130, 134, 136, 138, 149, 150, 151, 152, 153, 154, 157, 158, 161, 162, 163, 164, 168, 178], "17376": 2, "21": [2, 6, 11, 19, 27, 29, 44, 54, 69, 72, 76, 77, 78, 79, 95, 104, 136], "17377": [2, 95], "17378": [2, 95], "23": [2, 9, 11, 19, 29, 54, 68, 69, 78, 95, 99, 100, 104, 110, 148, 150, 153, 158, 160, 162, 164], "atemp": [2, 7, 30, 31, 48, 62, 66, 71, 95, 97, 98, 100, 103, 106, 108, 109, 112, 115, 120, 124, 127, 129], "hum": [2, 7, 71, 95, 98, 100, 101, 106, 109, 112, 116, 120, 129], "windspe": [2, 7, 71, 95, 98, 100, 115, 129], "cnt": [2, 5, 6, 7, 8, 12, 20, 27, 28, 30, 31, 32, 33, 38, 48, 50, 52, 58, 60, 62, 64, 66, 68, 71, 77, 84, 92, 94, 95, 96, 98, 100, 103, 104, 105, 106, 107, 108, 109, 112, 115, 116, 119, 120, 122, 124, 125, 127, 128, 129, 130], "2879": [2, 61, 95], "81": [2, 12, 20, 77, 79, 95, 134], "0000": [2, 7, 38, 53, 54, 59, 60, 61, 95, 98, 100], "16": [2, 7, 11, 17, 19, 29, 41, 42, 43, 44, 54, 69, 95, 98, 104, 112, 113, 115, 118, 120], "2727": [2, 7, 95, 98], "80": [2, 12, 20, 95, 134, 146], "40": [2, 22, 24, 25, 29, 53, 54, 61, 66, 69, 78, 79, 92, 95, 100, 104, 117, 125, 127, 157, 158], "32": [2, 11, 19, 29, 35, 54, 62, 64, 69, 95, 104, 108, 110, 123, 147, 148], "75": [2, 61, 130], "13": [2, 7, 29, 43, 54, 69, 87, 98, 99, 100, 104], "2576": [2, 7, 95, 98], "60": [2, 87, 95], "1642": [2, 95], "119": 2, "89": 2, "90": [2, 69, 78, 87, 92, 95, 125, 139, 140, 141, 142, 143, 144, 145, 146], "56": [2, 12, 17, 35, 60, 67, 70, 95], "1343": [2, 95], "61": [2, 69, 78, 95], "65": [2, 7, 54, 95, 98, 105], "49": [2, 11, 19, 95], "17379": [2, 6, 95, 96, 100], "8": [2, 7, 11, 15, 19, 23, 29, 35, 54, 59, 60, 62, 69, 70, 71, 78, 84, 85, 86, 87, 88, 90, 91, 98, 104, 105, 109, 112, 115, 123, 127, 129, 130, 133, 136, 138, 147, 148, 165, 166, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178], "890": [2, 9], "plot_0_data_loader_datafram": [2, 9], "parquet": [3, 95], "demonstr": [3, 14, 15, 16, 22, 23, 24, 84, 85, 86, 87, 88, 90, 91, 92, 96, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 132, 133], "numpi": [3, 6, 14, 15, 23, 24, 72, 73, 128, 132, 133, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 161, 162, 163, 164], "np": [3, 6, 14, 15, 23, 24, 72, 73, 96, 132, 133, 134, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164], "random": [3, 6, 8, 10, 11, 14, 17, 18, 19, 24, 25, 80, 93, 95, 99, 106, 108, 122, 126, 128, 132, 138, 139, 142, 143, 146, 147, 148, 149, 150, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "seed": [3, 15, 23, 96, 128, 133, 138, 139, 143, 146, 149, 150, 152, 153, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "original_df": 3, "hstack": [3, 15, 23, 133], "randint": [3, 138], "size": [3, 7, 14, 24, 29, 65, 66, 70, 71, 87, 90, 92, 95, 97, 98, 99, 101, 107, 110, 117, 118, 119, 124, 127, 128, 129, 130, 132, 134, 138, 139, 143, 144, 145, 147, 148, 152, 153, 157, 158, 165, 166, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178], "100000": [3, 95, 138], "uniform": [3, 13, 14, 21, 24, 69, 71, 97, 123, 125, 127, 129, 132, 134, 138, 174], "10": [3, 7, 27, 28, 29, 31, 35, 40, 41, 42, 43, 44, 49, 50, 54, 57, 59, 63, 64, 67, 68, 69, 70, 71, 72, 76, 77, 84, 85, 87, 88, 90, 92, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 124, 125, 126, 127, 129, 130, 138, 139, 141, 143, 147, 148, 152, 153, 168, 171, 172, 174, 176, 177, 178], "y": [3, 14, 24, 72, 73, 90, 91, 92, 95, 97, 98, 101, 106, 109, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 125, 127, 128, 130, 132, 135, 138, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "str": [3, 138, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "i": [3, 7, 8, 14, 16, 22, 24, 73, 82, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164], "rang": [3, 94, 98, 99, 101, 103, 106, 109, 117, 119, 120, 122, 123, 124, 126, 129, 130, 134, 138, 144], "to_parquet": 3, "myfil": [3, 95], "10000": [3, 28, 95, 96, 97, 107, 152, 153, 157, 158], "sampl": [3, 6, 7, 11, 19, 65, 66, 67, 68, 70, 71, 72, 73, 76, 77, 84, 85, 87, 93, 95, 97, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 128, 129, 130, 132, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 168, 170, 174, 175, 176, 177, 178], "purli": [3, 95], "randomli": [3, 92, 96, 97, 99, 106, 108, 109, 134, 138, 142, 159, 160], "spark_sample_s": [3, 95, 138], "spark_random_st": [3, 95, 138], "x2": [3, 29, 54, 86, 95, 104, 138], "x3": [3, 29, 95, 104], "x4": [3, 29, 95, 104], "x5": [3, 29, 86, 95, 104, 138], "722108": 3, "630742": 3, "179797": 3, "046212": 3, "622879": 3, "087904": 3, "100578": 3, "064457": 3, "261228": 3, "298484": 3, "806278": 3, "297039": 3, "306140": 3, "979178": 3, "924876": 3, "148939": 3, "794436": 3, "026896": 3, "597057": 3, "736664": 3, "261621": 3, "585320": 3, "459879": 3, "581889": 3, "262903": 3, "676545": 3, "521757": 3, "051982": 3, "439505": 3, "422332": 3, "9936": 3, "377520": 3, "149886": 3, "267827": 3, "666580": 3, "233089": 3, "401495": 3, "9937": 3, "952963": 3, "415568": 3, "688008": 3, "225129": 3, "169116": 3, "190439": 3, "9938": 3, "601043": 3, "634523": 3, "282413": 3, "934208": 3, "492232": 3, "598559": 3, "9939": 3, "524421": 3, "683701": 3, "365216": 3, "107878": 3, "095759": 3, "190358": 3, "9940": [3, 24], "347192": 3, "458382": 3, "415295": 3, "618297": 3, "117932": 3, "873784": 3, "x6": [3, 29, 95, 104], "x7": [3, 29, 95, 104], "x8": [3, 29, 95, 104], "x9": [3, 29, 95, 104], "524907": 3, "493184": 3, "508395": 3, "993584": 3, "970116": 3, "378889": 3, "077614": 3, "703995": 3, "054786": 3, "890156": 3, "752913": 3, "938883": 3, "791780": 3, "018643": 3, "365007": 3, "048767": 3, "995145": 3, "868960": 3, "452228": 3, "110775": 3, "543934": 3, "444068": 3, "231257": 3, "025619": 3, "352821": 3, "611961": 3, "665948": 3, "449606": 3, "500579": 3, "161602": 3, "190709": 3, "113384": 3, "462231": 3, "612478": 3, "587393": 3, "313063": 3, "377266": 3, "734037": 3, "113734": 3, "830916": 3, "9941": 3, "11": [3, 7, 9, 17, 29, 46, 54, 69, 84, 85, 87, 98, 100, 104, 106, 136], "stratifi": [3, 95, 138], "spark_sample_by_featur": [3, 95, 138], "9946": 3, "9947": 3, "9948": 3, "9949": 3, "9950": [3, 14], "9951": 3, "given": [3, 7, 63, 64, 70, 71, 98, 99, 101, 106, 109, 112, 113, 115, 117, 119, 120, 124, 128, 134, 138, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 166, 168, 171, 178], "uneven": 3, "ratio": [3, 6, 7, 11, 15, 19, 23, 87, 91, 92, 95, 96, 98, 123, 124, 125, 126, 130, 133, 138, 152, 153, 157, 158, 174, 176, 177], "spark_sample_fract": [3, 95, 138], "5": [3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 117, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 141, 142, 144, 145, 148, 152, 153, 157, 158, 159, 160], "321004": 3, "340024": 3, "614322": 3, "863309": 3, "402909": 3, "380781": 3, "9954": 3, "802121": 3, "425349": 3, "139584": 3, "365250": 3, "677365": 3, "962125": 3, "9955": 3, "9956": 3, "9957": 3, "9958": 3, "046856": 3, "428831": 3, "600180": 3, "017023": 3, "689377": 3, "804052": 3, "854092": 3, "558963": 3, "723463": 3, "290868": 3, "235756": 3, "846328": 3, "983629": 3, "139173": 3, "822894": 3, "489409": 3, "372789": 3, "979409": 3, "9959": 3, "39": [3, 9, 11, 16, 17, 19, 29, 104, 110, 136], "289": [3, 9], "54": [3, 9, 15, 17, 57], "plot_0_data_loader_spark": [3, 9], "show": [4, 5, 7, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 86, 87, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 135, 138, 174], "result": [4, 6, 7, 12, 13, 20, 21, 59, 60, 61, 62, 64, 70, 71, 72, 73, 89, 90, 91, 92, 98, 99, 101, 103, 104, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 138, 142, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 167, 168, 171, 175, 178], "us": [4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 28, 34, 59, 60, 62, 72, 73, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 166, 168, 174, 175, 176, 177, 178], "highcode_onli": [4, 14, 15, 16, 22, 23, 24, 132, 133, 138], "silent": [4, 5, 6, 7, 8, 12, 13, 20, 21, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 76, 77, 78, 138], "remov": [4, 7, 87, 98, 99, 101, 108, 109, 116, 117, 120, 138, 146], "data_summari": [4, 7, 12, 13, 20, 21, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 41, 43, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 84, 85, 86, 87, 88, 98, 100, 110, 138], "feature_exclud": [4, 7, 12, 13, 20, 21, 27, 28, 30, 31, 32, 33, 34, 37, 38, 41, 43, 47, 48, 49, 50, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 76, 77, 78, 100, 138], "chang": [4, 72, 73, 92, 97, 99, 101, 105, 106, 110, 116, 117, 122, 126, 127, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "type": [4, 6, 7, 11, 19, 69, 94, 96, 98, 99, 110, 119, 123, 127, 128, 133, 138, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "feature_typ": [4, 16, 22, 72, 73, 100, 128, 138, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "categor": [4, 7, 38, 87, 90, 92, 94, 95, 96, 98, 101, 103, 107, 116, 122, 123, 128, 129, 138, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "096": [4, 9], "14": [4, 7, 9, 25, 29, 35, 50, 54, 59, 63, 69, 87, 98, 104], "plot_1_data_summari": [4, 9], "plot": [5, 7, 12, 20, 26, 27, 30, 31, 32, 33, 35, 37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 63, 64, 67, 68, 72, 73, 80, 90, 91, 92, 93, 97, 99, 102, 103, 104, 105, 106, 108, 110, 113, 116, 118, 123, 125, 126, 127, 128, 134, 138, 152, 153, 165, 166, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178, 181], "data": [5, 8, 9, 11, 12, 13, 15, 16, 19, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 81, 82, 83, 90, 92, 94, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 131, 133, 134, 138, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181], "histogram": [5, 59, 60, 61, 62, 63, 64, 67, 68, 72, 73, 76, 77, 90, 92, 94, 112, 114, 115, 119, 120, 124, 128, 130, 138, 141, 147, 148, 161, 162, 163, 164, 168, 177, 178], "densiti": [5, 67, 68, 70, 71, 72, 73, 94, 97, 99, 103, 128, 129, 130, 138, 152, 153, 176], "univari": [5, 93, 99, 119, 138], "uni_featur": [5, 11, 14, 19, 24, 28, 30, 31, 33, 34, 38, 39, 40, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 94, 103, 105, 107, 109, 112, 114, 115, 116, 117, 119, 120, 132, 135, 138], "figsiz": [5, 7, 8, 11, 12, 14, 15, 16, 19, 20, 22, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 90, 91, 92, 94, 97, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 134, 135, 138, 143, 165, 166, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178], "bar": [5, 90, 91, 92, 94, 101, 103, 106, 107, 109, 114, 116, 117, 119, 122], "scatter": [5, 33, 94, 109, 122, 138], "bivari": [5, 93, 138], "bi_featur": [5, 28, 31, 48, 50, 52, 53, 54, 94, 103, 107, 112, 115, 117, 120, 138], "box": [5, 92, 94, 110, 112, 117, 118, 120, 127, 135], "stack": [5, 94], "correl": [5, 7, 8, 84, 85, 93, 94, 99, 103, 107, 109, 119, 122, 125, 138], "heatmap": [5, 43, 44, 94, 103, 107, 120, 138], "multivari": [5, 93, 99, 107, 138], "multi_typ": [5, 94, 138], "correlation_heatmap": [5, 94, 138], "graph": [5, 94, 144, 147, 148], "correlation_graph": [5, 94, 138], "55": [5, 9, 23, 25, 66, 126], "352": [5, 9], "plot_2_data_eda": [5, 9], "displai": [6, 90, 91, 92, 94, 97, 98, 99, 109, 112, 113, 114, 115, 116, 119, 120, 122, 123, 124, 126, 127, 129, 130, 134, 138, 157, 158], "split": [6, 11, 19, 43, 44, 82, 93, 99, 103, 110, 113, 118, 119, 120, 129, 130, 138, 142, 143, 149, 150, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "data_prepar": [6, 7, 8, 11, 12, 13, 19, 20, 21, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 76, 77, 78, 84, 85, 86, 87, 88, 96, 98, 101, 110, 135, 138], "task_typ": [6, 7, 8, 11, 12, 13, 14, 15, 19, 20, 21, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 96, 128, 132, 133, 135, 138, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "regress": [6, 7, 8, 11, 12, 15, 19, 20, 23, 27, 28, 29, 30, 31, 32, 33, 36, 55, 56, 74, 75, 79, 80, 84, 85, 89, 95, 96, 99, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 117, 118, 119, 120, 121, 123, 124, 126, 127, 128, 129, 130, 133, 134, 135, 138, 148, 149, 150, 153, 154, 156, 158, 159, 160, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181], "sample_weight": [6, 96, 138, 142, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164], "none": [6, 11, 16, 19, 22, 66, 68, 73, 76, 77, 90, 92, 96, 113, 126, 127, 129, 130, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "split_method": [6, 96, 138], "test_ratio": [6, 12, 13, 20, 21, 96, 134, 138], "random_st": [6, 11, 16, 19, 22, 73, 96, 128, 135, 138, 139, 142, 143, 146, 147, 148, 149, 150, 152, 153, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "config": [6, 11, 19, 96, 138], "valu": [6, 7, 11, 15, 19, 23, 45, 46, 69, 87, 91, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 129, 130, 133, 134, 138, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "exclud": [6, 11, 19, 84, 86, 87, 88, 96, 103, 123, 138, 147, 148, 152, 153], "variabl": [6, 11, 19, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 105, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 128, 129, 130, 138], "weight": [6, 11, 19, 45, 46, 86, 96, 98, 106, 109, 116, 117, 122, 138, 139, 142, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164], "task": [6, 11, 19, 64, 90, 96, 99, 103, 104, 105, 107, 108, 109, 110, 118, 121, 123, 124, 126, 127, 128, 129, 130, 132, 134, 138, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "method": [6, 7, 8, 11, 12, 13, 19, 20, 21, 65, 66, 84, 87, 89, 90, 92, 94, 96, 97, 98, 101, 103, 107, 108, 109, 110, 114, 118, 119, 120, 123, 124, 125, 126, 127, 129, 130, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 168, 174, 175, 176, 177, 178], "test": [6, 7, 8, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 28, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 65, 66, 70, 74, 81, 82, 83, 90, 92, 93, 95, 98, 99, 103, 104, 105, 106, 107, 108, 109, 110, 116, 121, 122, 123, 124, 125, 126, 129, 130, 131, 138, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181], "state": [6, 11, 19, 95, 96, 109, 110, 117, 123, 130, 138, 147, 148, 156], "outer": [6, 67, 68, 126, 138, 147, 148, 174, 175, 176, 177], "base": [6, 38, 59, 60, 61, 62, 86, 90, 91, 97, 98, 100, 101, 103, 104, 106, 107, 108, 109, 110, 114, 115, 116, 118, 119, 122, 123, 124, 125, 126, 128, 129, 130, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 159, 160, 161, 162, 163, 164, 166, 168, 171, 178], "kmean": [6, 138, 139, 143], "420277": [6, 96], "custom": [6, 65, 66, 69, 82, 84, 85, 88, 96, 100, 114, 123, 126, 129, 130, 138, 143], "custom_train_idx": [6, 96], "arang": [6, 72, 73, 96], "16000": [6, 96], "custom_test_idx": [6, 96], "train_idx": [6, 72, 73, 96, 128, 138, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "test_idx": [6, 72, 73, 96, 128, 138, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "manual": [6, 87, 100, 110, 114, 119, 134, 152, 153], "079349": [6, 96], "35": [6, 9, 29, 44, 54, 61, 104], "172": [6, 9], "plot_3_data_prepar": [6, 9], "analysi": [7, 70, 71, 84, 85, 86, 87, 93, 96, 98, 103, 104, 105, 107, 108, 110, 124, 125, 129, 130, 134, 138, 181], "outlier_detect": [7, 99, 138], "pca": [7, 99, 138, 143], "cblof": [7, 138], "isolationforest": [7, 99, 138], "kmeanstre": [7, 138], "oneclasssvm": [7, 99, 138], "knn": [7, 99, 138], "hbo": [7, 99, 138], "ecod": [7, 99, 138], "integr": [7, 86, 93, 99, 106, 107, 110, 112, 116, 117, 134, 138, 181], "each": [7, 63, 64, 88, 90, 92, 94, 96, 97, 98, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 174, 175, 176, 177], "re": [7, 29, 70, 71, 113, 119, 149, 150, 159, 160], "data_qu": [7, 97, 98, 99, 110, 138], "integrity_single_column_check": [7, 98, 138], "return_data": [7, 29, 59, 60, 61, 62, 64, 69, 70, 71, 78, 91, 104, 106, 112, 114, 115, 116, 119, 120, 123, 124, 125, 129, 130, 138], "io": [7, 70, 71], "format": [7, 70, 71, 95, 98, 100, 119, 132, 133], "style": [7, 10, 14, 17, 18, 24, 25, 70, 71, 80, 96, 100, 131, 132, 133, 138, 181], "styler": [7, 70, 71], "object": [7, 70, 71, 114, 116, 128, 130, 134, 135, 138, 139, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "0x0000022054be01c0": 7, "nbsp": [7, 98, 100], "singl": [7, 59, 60, 61, 62, 90, 92, 93, 94, 101, 103, 107, 109, 113, 116, 117, 122, 126, 128, 130, 134, 138, 151, 154, 159, 160], "null": [7, 98, 101, 122], "mix": [7, 98], "long": [7, 98, 117, 127, 132], "string": [7, 90, 92, 98, 100, 134, 141, 142, 143, 144, 145, 146, 152, 153, 159, 160], "special": [7, 98, 113, 117, 119], "charact": [7, 98, 101], "new": [7, 95, 97, 98, 99, 110, 113, 114, 138, 142, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "categori": [7, 69, 78, 86, 87, 94, 95, 96, 98, 99, 100, 103, 116, 123, 127, 138, 152, 153], "numer": [7, 37, 38, 87, 90, 92, 94, 96, 98, 101, 103, 107, 116, 122, 123, 128, 129, 138, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "num": [7, 87, 98], "index": [7, 38, 69, 78, 96, 97, 98, 103, 106, 109, 113, 116, 117, 125, 126, 128, 129, 138, 147, 148, 151, 152, 153, 154, 159, 160, 161, 162, 163, 164, 170, 174], "fals": [7, 15, 16, 22, 23, 28, 31, 32, 37, 38, 48, 53, 54, 57, 58, 73, 98, 103, 104, 105, 106, 107, 108, 109, 116, 117, 120, 122, 130, 133, 138, 139, 142, 145, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 166, 178], "000000": [7, 98], "duplic": [7, 93, 138], "integrity_duplicated_sampl": [7, 98, 138], "leakag": [7, 98], "1507": [7, 98], "9867": [7, 98], "9822": [7, 98], "17336": [7, 98], "13559": [7, 98], "13727": [7, 98], "5598": [7, 98], "14639": [7, 98], "7958": [7, 98], "8126": [7, 98], "64": [7, 98, 143], "2273": [7, 98], "48": [7, 11, 19, 54, 74, 98], "2985": [7, 98], "6061": [7, 98], "83": [7, 98], "0896": [7, 98], "5606": [7, 62, 98], "88": [7, 11, 19, 46, 70, 98, 130], "1045": [7, 98, 100], "integrity_highly_correlated_featur": [7, 98, 138], "0x000002205340ddc0": 7, "00": [7, 9, 17, 25, 35, 55, 74, 79, 98], "01": [7, 9, 25, 35, 45, 46, 55, 74, 79, 98, 112, 119, 147, 148, 152, 153, 161, 162], "77": [7, 12, 20, 59, 98, 134], "05": [7, 17, 25, 35, 60, 61, 62, 98, 124, 157, 158], "28": [7, 12, 29, 54, 98, 104], "51": [7, 22, 25, 70, 74, 98], "09": [7, 11, 19, 29, 98, 104], "03": [7, 9, 25, 29, 60, 79, 98, 104], "04": [7, 29, 60, 98, 104, 109], "02": [7, 9, 17, 29, 98, 104], "42": [7, 29, 98, 104, 147, 148], "08": [7, 9, 29, 98, 104], "15": [7, 21, 28, 29, 32, 54, 69, 71, 73, 87, 98, 104, 109, 129, 147, 148], "29": [7, 29, 54, 64, 69, 78, 98, 99, 104, 110], "36": [7, 29, 54, 98, 101, 104], "score": [7, 56, 63, 74, 80, 103, 108, 109, 110, 115, 121, 122, 126, 127, 130, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 181], "distribut": [7, 63, 64, 67, 68, 70, 71, 72, 73, 84, 85, 87, 90, 92, 93, 94, 96, 101, 109, 110, 116, 117, 122, 125, 126, 127, 128, 134, 136, 138, 140, 145, 176, 177], "od_score_distribut": [7, 99, 138], "threshold": [7, 8, 59, 60, 61, 62, 63, 64, 69, 87, 95, 99, 101, 110, 121, 122, 124, 125, 129, 130, 138, 139, 140, 141, 142, 143, 144, 145, 146, 152, 153, 157, 158, 168, 170, 171, 178], "999": [7, 70, 99], "od_marginal_outlier_distribut": [7, 99, 138], "compar": [7, 12, 13, 16, 20, 21, 22, 89, 90, 91, 92, 97, 98, 99, 101, 103, 106, 110, 113, 114, 115, 116, 119, 122, 125, 126, 127, 128, 129, 130, 138, 170, 174, 176, 177], "differ": [7, 14, 16, 22, 24, 72, 73, 87, 89, 90, 91, 92, 94, 95, 96, 97, 98, 101, 103, 106, 107, 108, 109, 110, 112, 115, 116, 117, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 134, 138, 142, 159, 160, 174, 175, 176, 177], "outlier": [7, 92, 93, 94, 98, 112, 138, 139, 140, 141, 142, 143, 144, 145, 146, 181], "detect": [7, 72, 73, 90, 92, 93, 94, 98, 110, 112, 124, 130, 138, 139, 140, 141, 142, 144, 145, 146, 181], "algorithm": [7, 90, 92, 96, 99, 101, 102, 110, 112, 113, 117, 118, 120, 121, 123, 138, 139, 140, 141, 142, 143, 144, 145, 149, 150, 159, 160, 161, 162, 163, 164], "od_tsne_comparison": [7, 99, 138], "appli": [7, 87, 90, 92, 96, 97, 104, 109, 117, 119, 125, 126, 127, 130, 159, 160], "you": [7, 95, 96, 99, 100, 101, 103, 104, 105, 106, 107, 109, 110, 112, 114, 115, 116, 118, 119, 120, 123, 124, 125, 126, 127, 129, 130, 133, 134, 135, 136, 138, 143, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "can": [7, 14, 15, 23, 24, 72, 73, 82, 85, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 138, 142, 144, 146, 147, 148, 150, 153, 158, 159, 160, 162, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "also": [7, 72, 73, 90, 91, 96, 97, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 125, 126, 127, 129, 130, 132, 133, 134, 135, 143, 152, 153, 159, 160], "specifi": [7, 11, 19, 90, 92, 95, 96, 98, 100, 101, 103, 107, 108, 109, 110, 112, 113, 115, 116, 117, 119, 120, 122, 123, 124, 125, 126, 127, 129, 130, 134, 138, 145, 146, 159, 161, 162, 163, 164], "train": [7, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 81, 82, 83, 90, 92, 93, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 122, 123, 124, 125, 126, 128, 129, 130, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181], "all": [7, 37, 38, 66, 70, 71, 80, 87, 88, 90, 92, 96, 98, 99, 101, 103, 104, 105, 108, 109, 112, 113, 114, 115, 116, 117, 120, 122, 126, 127, 128, 129, 132, 133, 134, 135, 138, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "remove_outli": [7, 99, 138], "energi": [7, 93, 96, 138], "distanc": [7, 8, 63, 64, 67, 68, 70, 71, 72, 73, 76, 77, 87, 93, 96, 99, 103, 128, 129, 138, 143, 144, 159, 160, 170, 174, 175, 176, 177], "drift_test_info": [7, 97, 138], "13889": [7, 97], "3476": [7, 97], "000488": [7, 97], "margin": [7, 67, 68, 93, 94, 106, 109, 110, 115, 116, 117, 128, 129, 138, 152, 153, 166, 168, 171, 176, 177, 178], "drift": [7, 93, 98, 127, 129, 138, 181], "drift_test_dist": [7, 97, 138], "distance_metr": [7, 63, 64, 67, 68, 97, 125, 126, 129, 138, 170, 174], "psi": [7, 63, 64, 67, 68, 87, 97, 125, 126, 129, 138, 143, 170, 174], "psi_bucket": [7, 97, 125, 126, 129, 138, 174], "quantil": [7, 65, 66, 69, 87, 95, 97, 99, 103, 123, 125, 126, 127, 129, 138, 139, 140, 141, 142, 143, 144, 145, 146, 174], "show_featur": [7, 57, 58, 63, 64, 67, 68, 70, 71, 72, 73, 97, 122, 125, 126, 128, 129, 138, 166, 171, 176, 177], "914": [7, 9], "1326": 7, "plot_4_data_qu": [7, 9], "four": [8, 96, 101, 103, 110, 116, 126, 134, 143, 159], "strategi": [8, 101, 123, 124, 134, 138, 149, 150, 159, 160, 174], "pearson": [8, 101, 138], "feature_select": [8, 84, 85, 98, 101, 110, 138], "cor": [8, 101, 138], "corr_algorithm": [8, 101, 138], "spearman": [8, 98, 101, 138], "dcor": [8, 101, 136, 138], "permut": [8, 26, 35, 80, 85, 88, 101, 102, 110, 138, 159, 160, 181], "pfi": [8, 14, 15, 23, 24, 27, 34, 84, 101, 102, 110, 133, 138, 181], "95": [8, 101], "condit": [8, 26, 35, 80, 93, 94, 98, 99, 102, 109, 120, 123, 126, 130, 138, 181], "independ": [8, 93, 99, 107, 109, 117, 119, 126, 138, 141, 145], "rcit": [8, 138], "001": [8, 53, 54, 101, 117, 145, 152, 153, 157, 158], "n_forward_phas": [8, 101, 138], "kernel_s": [8, 101, 138], "100": [8, 12, 13, 16, 20, 21, 22, 28, 29, 33, 34, 43, 44, 45, 59, 60, 62, 66, 67, 68, 69, 73, 101, 103, 105, 107, 109, 113, 119, 123, 124, 130, 134, 135, 138, 142, 151, 152, 153, 154, 161, 162, 163, 164], "where": [8, 91, 94, 95, 96, 97, 98, 99, 101, 103, 104, 107, 109, 110, 112, 113, 116, 117, 118, 119, 120, 122, 123, 124, 127, 128, 130, 134, 147, 148, 150, 153, 158, 159, 160, 162, 164], "markov": [8, 101], "boundari": [8, 95, 101, 122, 138], "non": [8, 67, 87, 99, 101, 107, 114, 120, 122, 145, 147, 148, 151, 154, 155, 156, 159, 160], "empti": [8, 98, 101, 138, 152, 153, 174, 175, 176, 177], "preset": [8, 101, 138], "865": [8, 9], "973": [8, 9], "plot_5_feature_select": [8, 9], "06": [9, 29, 35, 104, 112, 115, 120], "845": [9, 11, 19], "execut": [9, 17, 25, 35, 55, 74, 79, 98, 101, 110, 128, 129, 134, 138], "auto_examples_0_data": 9, "file": [9, 11, 15, 17, 19, 23, 25, 35, 55, 74, 79, 93, 135, 138, 152, 153], "1325": 9, "9": [9, 11, 19, 25, 29, 35, 54, 60, 62, 65, 69, 70, 71, 74, 78, 84, 85, 87, 88, 99, 104, 105, 113, 114, 118, 119, 126, 127, 129, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 174, 176, 177], "18": [9, 11, 19, 29, 35, 54, 69, 100, 104, 105, 110, 159, 160], "07": [9, 29, 104, 109, 115], "extern": [10, 16, 17, 22, 93, 138], "hpo": [10, 17, 18, 25, 80, 134, 138, 155], "xgb": [10, 16, 17, 22, 36, 55, 80, 87, 101, 115, 119, 120, 126, 138, 161, 162, 163, 164, 174, 175, 176, 177], "grid": [10, 13, 17, 18, 21, 25, 29, 80, 103, 104, 105, 107, 123, 138], "search": [10, 17, 18, 25, 80, 113, 123, 138, 144, 155, 159, 160], "bike": [10, 17, 36, 55, 80, 84, 92, 95, 112, 115, 119, 120, 122, 124, 125, 127, 128, 129, 130, 138, 148, 153, 156], "share": [10, 17, 36, 55, 80, 95, 112, 115, 120, 122, 124, 128, 138, 148, 153, 156], "glm": [10, 14, 17, 21, 24, 36, 55, 77, 78, 80, 85, 87, 91, 92, 106, 110, 114, 116, 117, 119, 132, 138, 156, 161, 162], "simucredit": [10, 17, 21, 34, 69, 70, 78, 87, 91, 95, 138], "regist": [10, 11, 12, 13, 17, 18, 19, 20, 21, 25, 80, 82, 84, 86, 87, 88, 110, 113, 115, 129, 131, 134, 138, 181], "arbitrari": [10, 17, 18, 25, 80, 101, 110, 116, 131, 133, 138, 144, 181], "h2o": [10, 14, 17, 18, 24, 25, 80, 131, 132, 181], "sklearn": [10, 14, 15, 17, 18, 23, 24, 25, 73, 80, 85, 99, 101, 110, 113, 114, 116, 118, 122, 125, 126, 131, 132, 133, 138, 139, 142, 144, 145, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 181], "californiahousing_raw": [11, 19, 95, 135, 138], "medhousev": [11, 19, 40, 42, 44, 46, 85, 113, 114, 118, 126, 135], "medinc": [11, 15, 19, 23, 40, 46, 73, 113, 114, 119, 128, 135], "houseag": [11, 19], "averoom": [11, 19, 85, 95, 119, 138], "avebedrm": [11, 19, 85, 95, 138], "popul": [11, 19, 85, 95, 97, 98, 106, 116, 119, 125, 126, 129, 130, 138, 170, 174], "aveoccup": [11, 19, 85, 95, 113, 114, 119, 138], "latitud": [11, 19, 114, 119], "3252": [11, 19], "41": [11, 19, 29, 42, 61, 67, 70, 74, 104], "984127": [11, 19], "023810": [11, 19], "322": [11, 19, 59], "555556": [11, 19], "37": [11, 19, 29, 41, 54, 87, 104], "3014": [11, 19], "238137": [11, 19], "971880": [11, 19], "2401": [11, 19], "109842": [11, 19], "86": [11, 19], "2574": [11, 19], "52": [11, 19, 20, 25, 101], "288136": [11, 19], "073446": [11, 19], "496": [11, 19], "802260": [11, 19], "85": [11, 19, 60], "6431": [11, 19], "817352": [11, 19], "073059": [11, 19], "558": [11, 19], "547945": [11, 19], "8462": [11, 19], "281853": [11, 19], "081081": [11, 19], "565": [11, 19], "181467": [11, 19], "20635": [11, 19], "5603": [11, 19], "25": [11, 19, 29, 49, 54, 59, 68, 69, 104], "045455": [11, 19], "133333": [11, 19], "560606": [11, 19], "20636": [11, 19], "5568": [11, 19], "114035": [11, 19], "315789": [11, 19], "356": [11, 19], "122807": [11, 19], "20637": [11, 19], "7000": [11, 19, 61], "17": [11, 13, 14, 19, 24, 25, 27, 29, 35, 45, 52, 54, 69, 84, 92, 99, 103, 104, 105, 106, 107, 108, 109, 112, 115, 116, 119, 120, 122, 124, 125, 127, 128, 129, 130, 136, 159, 160], "205543": [11, 19], "120092": [11, 19], "1007": [11, 19], "325635": [11, 19], "43": [11, 19, 29, 33, 35, 38, 43, 47, 51, 54, 55, 59, 104], "20638": [11, 19], "8672": [11, 19], "329513": [11, 19], "171920": [11, 19], "741": [11, 19], "123209": [11, 19], "20639": [11, 19], "3886": [11, 19], "254717": [11, 19], "162264": [11, 19], "1387": [11, 19], "616981": [11, 19], "longitud": [11, 19, 114, 119], "122": [11, 19], "526": [11, 19, 54, 63], "585": [11, 19, 71], "521": [11, 19], "413": [11, 19, 99], "422": [11, 19, 99], "121": [11, 19], "781": [11, 19], "771": [11, 19], "923": [11, 19], "847": [11, 19], "894": [11, 19], "20640": [11, 19], "lightgbm": [11, 19, 135], "lgbmregressor": [11, 19, 135], "lgbm2": [11, 19, 135], "max_depth": [11, 16, 19, 22, 41, 42, 43, 44, 66, 67, 69, 73, 77, 87, 113, 118, 130, 135, 138, 143, 149, 150, 159, 160, 163, 164], "model_train": [11, 12, 13, 19, 20, 21, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 76, 77, 78, 84, 85, 86, 87, 88, 112, 113, 114, 115, 116, 117, 118, 119, 120, 134, 135, 138], "name": [11, 12, 13, 19, 20, 21, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 76, 77, 78, 86, 87, 90, 92, 96, 97, 99, 100, 101, 103, 105, 107, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 127, 128, 133, 134, 135, 138, 142, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "lgbm_2": [11, 19, 135], "save": [11, 15, 19, 23, 131, 138, 152, 153], "fit": [11, 14, 15, 16, 19, 22, 23, 24, 73, 96, 99, 101, 103, 104, 105, 106, 107, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 128, 129, 130, 131, 132, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 168, 174, 175, 176, 177, 178], "model_sav": [11, 19, 135, 138], "ch_lgbm_2": [11, 19, 135], "pkl": [11, 19, 135, 138], "system": [11, 15, 19, 23, 84, 92, 103, 104, 105, 106, 107, 108, 109, 110, 112, 115, 116, 119, 120, 122, 124, 125, 127, 128, 129, 130], "default": [11, 12, 13, 19, 20, 21, 28, 34, 65, 76, 77, 84, 85, 86, 87, 88, 90, 92, 95, 96, 97, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 117, 118, 122, 124, 125, 126, 127, 129, 130, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "pipelin": [11, 14, 15, 16, 19, 22, 23, 24, 81, 110, 132, 133, 135, 138, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 181], "make_pipelin": [11, 14, 15, 16, 19, 22, 23, 24, 132, 133, 135, 138], "lgbm_2_load": [11, 19, 135], "post": [11, 14, 15, 19, 23, 24, 81, 84, 85, 88, 101, 108, 110, 138, 181], "hoc": [11, 14, 15, 19, 23, 24, 81, 84, 85, 88, 101, 108, 110, 138, 181], "explan": [11, 14, 15, 19, 23, 24, 26, 35, 80, 84, 85, 88, 89, 99, 102, 103, 104, 105, 107, 108, 110, 132, 133, 135, 138, 181], "pdp": [11, 14, 19, 24, 28, 34, 84, 85, 88, 102, 103, 104, 105, 109, 110, 120, 135, 138, 181], "model_explain": [11, 14, 15, 19, 23, 24, 27, 28, 29, 30, 31, 32, 33, 34, 84, 85, 88, 103, 104, 105, 106, 107, 108, 109, 110, 132, 133, 135, 138], "38": [11, 17, 19, 29, 72, 104], "412": [11, 17], "plot_0_model_train": [11, 17, 19, 25], "model": [12, 13, 17, 20, 21, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 78, 79, 81, 82, 83, 90, 91, 92, 95, 96, 97, 99, 101, 102, 103, 104, 105, 107, 108, 122, 123, 124, 125, 126, 127, 128, 129, 130, 138, 139, 142, 143, 144, 145, 146, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181], "xgb2regressor": [12, 20, 27, 28, 29, 30, 32, 33, 48, 58, 60, 62, 64, 68, 71, 120, 134, 138], "xgb2": [12, 16, 20, 22, 27, 28, 29, 30, 32, 33, 34, 47, 48, 56, 57, 58, 59, 60, 61, 62, 64, 67, 68, 70, 71, 72, 73, 74, 76, 77, 80, 87, 90, 92, 104, 105, 106, 107, 108, 109, 110, 112, 115, 120, 122, 123, 124, 125, 126, 129, 130, 134, 138], "defin": [12, 13, 20, 21, 96, 97, 98, 99, 101, 104, 105, 107, 109, 117, 122, 123, 125, 126, 129, 131, 134, 138, 142, 143, 145, 147, 148, 150, 153, 158, 159, 160, 162, 164], "hyperparamet": [12, 13, 20, 21, 112, 113, 114, 115, 116, 117, 118, 119, 120, 131, 138, 181], "space": [12, 13, 20, 21, 94, 99, 101, 113, 114, 123, 127, 130, 134, 138, 144, 147, 148, 152, 153, 168, 178], "paramet": [12, 13, 20, 21, 92, 95, 96, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 112, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "n_estim": [12, 16, 20, 22, 28, 29, 34, 45, 46, 67, 68, 69, 73, 119, 120, 134, 135, 138, 142, 161, 162, 163, 164], "300": [12, 20, 53, 134, 138], "500": [12, 20, 46, 100, 109, 134, 138, 157, 158], "eta": [12, 20, 98, 117, 119, 120, 134, 161, 162, 163, 164], "reg_lambda": [12, 20, 119, 120, 134, 161, 162, 163, 164], "reg_alpha": [12, 20, 119, 120, 134, 161, 162, 163, 164], "tune": [12, 13, 20, 21, 81, 99, 115, 119, 138, 152, 153, 181], "model_tun": [12, 13, 20, 21, 134, 138], "metric": [12, 13, 20, 21, 59, 60, 62, 65, 66, 69, 70, 71, 76, 77, 78, 86, 87, 89, 90, 92, 96, 97, 99, 108, 110, 121, 122, 124, 125, 126, 127, 129, 130, 134, 138, 144, 147, 149, 151, 152, 154, 157, 159, 161, 163, 168, 170, 174, 175, 176, 177, 178], "mse": [12, 15, 16, 20, 22, 23, 38, 40, 42, 44, 46, 48, 50, 52, 54, 58, 66, 71, 73, 77, 92, 108, 110, 122, 124, 125, 126, 127, 129, 130, 134, 138, 168, 174, 175, 176, 177, 178], "mae": [12, 15, 16, 20, 22, 23, 38, 40, 42, 44, 46, 48, 50, 52, 54, 58, 60, 62, 73, 77, 92, 110, 122, 124, 126, 127, 129, 130, 134, 138, 168, 174, 175, 176, 177, 178], "rank": [12, 13, 20, 21, 90, 92, 101, 108, 110, 116, 119, 126, 134, 138], "param": [12, 13, 14, 20, 21, 24, 132, 134, 138, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "006082": [12, 20, 134], "055082": [12, 20, 134], "717187": 12, "006267": [12, 20, 134], "055823": [12, 20, 134], "687025": 12, "006328": [12, 20, 134], "056353": [12, 20, 134], "762645": 12, "006331": [12, 20, 134], "056674": [12, 20, 134], "680690": 12, "006416": [12, 20, 134], "056506": [12, 20, 134], "746338": 12, "011644": [12, 20, 134], "074410": [12, 20, 134], "522234": 12, "78": [12, 20, 134], "011669": [12, 20, 134], "074375": [12, 20, 134], "500074": 12, "79": [12, 20, 134], "011741": [12, 20, 134], "074464": [12, 20, 134], "494155": 12, "011752": [12, 20, 134], "074676": [12, 20, 134], "499123": 12, "011808": [12, 20, 134], "074723": [12, 20, 134], "502602": 12, "fig": [12, 20, 36, 55, 66, 76, 80, 90, 110, 113, 127, 138, 149, 150], "refit": [12, 13, 20, 21, 119, 134, 138, 161, 162], "get_params_rank": [12, 13, 20, 21, 134], "gridsearch": [12, 20, 134], "model_diagnos": [12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 84, 85, 88, 110, 116, 122, 124, 125, 126, 127, 128, 130, 138], "accuracy_t": [12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 70, 116, 122, 129, 138], "r2": [12, 15, 16, 20, 22, 23, 38, 40, 42, 44, 46, 48, 50, 52, 54, 58, 66, 73, 77, 92, 122, 126, 127, 129, 130, 134, 138, 154, 168, 174, 175, 176, 177, 178], "0090": [12, 20, 48, 58, 122], "0669": [12, 20, 48, 58, 122], "7382": [12, 20, 48, 58, 122], "0095": [12, 20, 48, 53, 58, 62, 122], "0688": [12, 20, 48, 58, 122], "7287": [12, 20, 48, 58, 122], "gap": [12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 70, 72, 73, 90, 92, 110, 122, 124, 129, 130, 138, 159, 160, 168, 178], "0005": [12, 20, 46, 48, 54, 58, 85, 122], "0019": [12, 20, 37, 48, 58, 122], "0057": [12, 20, 47, 57, 122], "0535": [12, 20], "8346": [12, 20], "0063": [12, 20, 51, 59, 69], "0559": [12, 20], "8193": [12, 20], "0006": [12, 20, 46, 50, 62], "0024": [12, 20, 54], "0153": [12, 20], "372": [12, 17], "plot_1_hpo_grid": [12, 17, 20, 25], "scipi": [13, 21, 97, 134, 136, 138, 144, 146], "glmclassifi": [13, 21, 37, 78, 91, 116, 138], "race": [13, 21, 34, 69, 70, 78, 86, 87, 91, 123], "gender": [13, 21, 34, 69, 70, 78, 87, 91, 123], "approv": [13, 21, 34, 69, 70, 78, 87, 129], "classif": [13, 14, 21, 24, 34, 36, 37, 55, 56, 69, 74, 75, 78, 79, 80, 86, 87, 88, 89, 95, 96, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 126, 127, 128, 129, 130, 132, 134, 138, 147, 149, 151, 152, 157, 159, 160, 161, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 181], "l1_regular": [13, 21, 88, 116, 155, 156], "stat": [13, 21, 97, 134, 138], "l2_regular": [13, 21, 116, 155, 156], "n_run": [13, 21, 134, 138], "auc": [13, 14, 21, 24, 37, 39, 41, 43, 45, 47, 49, 51, 53, 57, 59, 65, 70, 72, 76, 108, 110, 117, 122, 126, 127, 129, 130, 134, 138, 168, 174, 175, 176, 177, 178], "020239411195815772": [13, 21], "002493911719174813": [13, 21], "729472": [13, 21], "037271": 13, "0801649627572255": [13, 21], "0009505206902733599": [13, 21], "729471": [13, 21], "038029": 13, "07054458515086691": [13, 21], "002443422808146689": [13, 21], "729470": [13, 21], "041150": 13, "0200826243066503": [13, 21], "0038925653368613645": [13, 21], "729469": [13, 21], "038459": 13, "08763141285690618": [13, 21], "0011317924903120004": [13, 21], "034966": 13, "014018374389893852": [13, 21], "08885523820070576": [13, 21], "96": [13, 21], "729274": [13, 21], "038200": 13, "06720040139301987": [13, 21], "08585578494124796": [13, 21], "97": [13, 21, 60, 69, 78], "729273": [13, 21], "035774": 13, "05105133900697683": [13, 21], "0845254996471495": [13, 21], "035115": 13, "05346229516211951": [13, 21], "09880860499665617": [13, 21], "99": [13, 21, 138], "729267": [13, 21], "036528": 13, "09599608264816151": [13, 21], "09690348478707304": [13, 21], "729255": [13, 21], "039574": 13, "randsearch": [13, 21], "acc": [13, 14, 21, 24, 37, 39, 41, 43, 45, 47, 49, 51, 53, 57, 59, 69, 70, 72, 76, 87, 90, 110, 122, 123, 124, 126, 127, 129, 130, 134, 138, 168, 174, 175, 176, 177, 178], "f1": [13, 14, 21, 24, 37, 39, 41, 43, 45, 47, 49, 51, 53, 57, 69, 70, 72, 76, 87, 110, 122, 123, 126, 127, 129, 130, 134, 138, 168, 174, 175, 176, 177, 178], "logloss": [13, 14, 21, 24, 37, 39, 41, 43, 45, 47, 49, 51, 53, 57, 70, 72, 90, 122, 129, 130, 134, 138, 168, 174, 175, 176, 177, 178], "brier": [13, 14, 21, 24, 37, 39, 41, 43, 45, 47, 49, 51, 53, 57, 63, 70, 72, 90, 122, 128, 129, 130, 134, 138, 168, 173, 174, 175, 176, 177, 178], "6722": [13, 21], "7309": [13, 21], "6965": [13, 21], "6047": [13, 21], "2088": [13, 21, 70], "6690": [13, 21], "7318": [13, 21], "6976": [13, 21], "6073": [13, 21], "2095": [13, 21], "0032": [13, 21, 51, 69], "0009": [13, 21, 24, 54, 62, 69, 72], "0011": [13, 21, 62], "0026": [13, 21, 24], "0008": [13, 21, 41, 54, 62, 69, 88, 116, 129], "6721": [13, 21], "6964": [13, 21, 59], "0031": [13, 21], "0012": [13, 21, 44, 51], "50": [13, 17, 28, 31, 34, 35, 53, 103, 107, 120, 127, 143, 147, 148, 157, 158], "828": [13, 17], "plot_1_hpo_random": [13, 17, 21, 25], "If": [14, 24, 87, 95, 96, 98, 99, 103, 104, 105, 106, 107, 108, 109, 113, 116, 119, 123, 125, 127, 129, 130, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "neither": [14, 24, 132], "nor": [14, 24, 132], "we": [14, 15, 16, 22, 23, 24, 72, 73, 87, 90, 91, 92, 94, 95, 96, 97, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 130, 132, 133, 134, 138, 142, 143, 145, 152, 153], "still": [14, 24, 99, 103, 105, 112, 115, 117, 119, 120, 126], "For": [14, 15, 16, 22, 23, 24, 87, 90, 94, 95, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 125, 126, 128, 129, 130, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 152, 153, 158, 159, 160, 162, 164, 168, 174, 175, 176, 177, 178], "simul": [14, 24, 83, 95, 106, 109, 114, 119, 123, 132, 138, 181], "simpl": [14, 24, 99, 103, 117, 130, 132, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "binari": [14, 24, 86, 87, 88, 90, 95, 96, 99, 103, 104, 105, 106, 107, 108, 109, 110, 114, 116, 117, 118, 119, 121, 123, 126, 127, 132, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "statsmodel": [14, 24, 101, 132, 136], "api": [14, 16, 22, 24, 81, 86, 90, 92, 99, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 134, 136, 138], "sm": [14, 24, 132], "1000": [14, 24, 61, 113, 132, 138, 152, 153, 157, 158], "sum": [14, 24, 87, 97, 98, 99, 101, 110, 111, 112, 114, 115, 116, 117, 119, 120, 127, 132, 138, 148, 149, 150, 153, 158, 159, 160, 162, 164, 181], "axi": [14, 24, 72, 90, 91, 92, 106, 109, 112, 113, 115, 116, 117, 119, 120, 125, 126, 127, 130, 132, 138, 166, 176, 177], "normal": [14, 24, 90, 92, 98, 99, 101, 109, 113, 114, 116, 117, 119, 120, 127, 132, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 152, 153, 159, 160], "glm_binom": [14, 24, 132], "famili": [14, 24, 132], "binomi": [14, 24, 132], "glm_result": [14, 24, 132], "next": [14, 24, 108, 113, 114, 118, 119, 125, 126, 127, 130, 132, 134], "def": [14, 24, 132], "predict_proba_func": [14, 24, 132, 138], "proba": [14, 24, 132, 149, 152, 159, 161, 163], "predict": [14, 24, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 63, 72, 73, 82, 90, 92, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 125, 126, 127, 128, 129, 130, 131, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "exog": [14, 24, 132], "return": [14, 24, 104, 109, 114, 123, 130, 132, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "vstack": [14, 24, 132], "t": [14, 24, 99, 132, 135, 138, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "predict_func": [14, 24, 132, 138], "pleas": [14, 16, 22, 24, 73, 94, 98, 99, 103, 105, 108, 109, 115, 117, 137, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "make": [14, 16, 22, 24, 99, 101, 105, 106, 108, 110, 112, 114, 115, 116, 117, 118, 120, 122, 123, 130, 132, 146, 152, 153, 161, 162, 163, 164], "sure": [14, 16, 22, 24], "ar": [14, 16, 22, 24, 86, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "same": [14, 16, 22, 24, 92, 94, 95, 98, 99, 110, 112, 113, 115, 117, 120, 123, 126, 127, 128, 138, 147, 148, 159, 174, 175, 176, 177], "train_x": [14, 15, 16, 22, 23, 24, 72, 73, 132, 133, 135, 138], "800": [14, 24, 50, 59, 130, 132], "train_i": [14, 15, 16, 22, 23, 24, 72, 73, 132, 133, 135, 138], "test_x": [14, 15, 16, 22, 23, 24, 72, 73, 132, 133, 135, 138], "test_i": [14, 15, 16, 22, 23, 24, 72, 73, 132, 133, 135, 138], "feature_nam": [14, 15, 16, 22, 23, 24, 72, 73, 119, 128, 130, 132, 133, 138, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "target_nam": [14, 15, 16, 22, 23, 24, 72, 73, 128, 132, 133, 138, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "perform": [14, 15, 16, 22, 23, 24, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 67, 68, 70, 71, 72, 73, 87, 91, 96, 97, 99, 108, 110, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 129, 130, 134, 138, 139, 142, 146, 147, 148, 152, 153, 157, 158, 159, 160, 168, 174, 175, 176, 177, 178], "9600": [14, 24], "9573": 14, "0895": 14, "0283": [14, 45], "9550": 14, "9909": 14, "9569": 14, "1246": 14, "0397": 14, "0050": 14, "0041": [14, 59], "0004": [14, 47, 52, 54, 57, 69, 122, 124], "0352": 14, "0114": [14, 44], "explain": [14, 15, 23, 24, 81, 83, 98, 99, 103, 105, 106, 107, 108, 109, 110, 111, 119, 122, 138, 146, 147, 148, 181], "tool": [14, 15, 23, 24, 106, 107, 109, 110, 122, 129, 132, 133, 135, 138], "al": [14, 24, 31, 34, 84, 85, 88, 102, 109, 120, 132, 138, 146, 181], "validataion": [14, 15, 23, 24], "46": [14, 17, 28, 35, 57], "539": [14, 17], "plot_2_register_arbitrari": [14, 17], "assum": [15, 16, 22, 23, 96, 98, 101, 107, 108, 109, 114, 117, 118, 125, 127, 130, 134, 135, 141, 144, 152, 153], "have": [15, 16, 22, 23, 90, 92, 96, 98, 99, 100, 103, 104, 105, 107, 108, 109, 110, 112, 113, 114, 115, 117, 118, 122, 124, 125, 126, 127, 129, 130, 132, 133, 134, 135, 138, 142, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "outsid": [15, 16, 22, 23, 92, 103, 107, 125, 128, 138, 141, 170], "workflow": [15, 16, 22, 23, 72, 73, 110, 117, 119, 128, 133, 138], "no_progress": [15, 23, 133], "init": [15, 23, 133, 152, 153], "verbos": [15, 23, 133, 142, 145, 152, 153, 157, 158], "fetch_california_h": [15, 16, 22, 23, 73, 133], "h2ogradientboostingestim": [15, 23, 133], "h2o_data": [15, 23, 133], "h2ofram": [15, 23, 133], "reshap": [15, 23, 133], "h2o_data_train": [15, 23, 133], "h2o_data_test": [15, 23, 133], "split_fram": [15, 23, 133], "2023": [15, 23, 110, 133], "glm_model": 15, "training_fram": [15, 23, 133], "mojo_file_path": [15, 23, 133], "save_mojo": [15, 23, 133], "path": [15, 23, 95, 99, 109, 110, 113, 118, 133, 138, 142, 143, 152, 153, 159, 160], "Then": [15, 23, 85, 90, 92, 96, 97, 101, 116, 117, 126, 127, 128, 135], "mojo": [15, 23], "imported_model": [15, 23, 133], "import_mojo": [15, 23, 133], "as_data_fram": [15, 23, 133], "ravel": [15, 16, 22, 23, 72, 133, 135], "gbm": [15, 23, 133], "2423": [15, 23], "3396": [15, 23], "8180": [15, 23], "2377": [15, 23], "3429": [15, 23], "8216": [15, 23], "0046": [15, 23, 37], "0033": [15, 23], "0037": [15, 23, 54, 100], "weakspot": [15, 23, 56, 70, 71, 72, 73, 74, 80, 110, 121, 124, 125, 128, 138, 168, 178, 181], "slice_featur": [15, 23, 59, 60, 61, 62, 70, 71, 72, 73, 76, 77, 90, 92, 124, 129, 130, 138, 168, 178], "747": [15, 17], "31": [15, 20, 29, 30, 35, 38, 48, 54, 55, 62, 104], "plot_2_register_h2o": [15, 17], "xgboost": [16, 22, 73, 77, 87, 99, 110, 111, 123, 126, 134, 136, 138, 181], "": [16, 22, 83, 84, 90, 97, 98, 99, 101, 102, 103, 105, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 134, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 181], "xgbregressor": [16, 22, 73, 77], "model_select": [16, 22, 73, 135], "train_test_split": [16, 22, 73, 135], "test_siz": [16, 22, 73, 135], "xgb7": [16, 22, 77, 87, 92], "base_scor": [16, 22, 73], "booster": [16, 22, 73], "callback": [16, 22, 73], "colsample_bylevel": [16, 22, 73], "colsample_bynod": [16, 22, 73], "colsample_bytre": [16, 22, 73], "early_stopping_round": [16, 22, 73, 147, 148], "enable_categor": [16, 22, 73], "eval_metr": [16, 22, 73], "gamma": [16, 22, 73, 101, 119, 120, 145, 161, 162, 163, 164], "gpu_id": [16, 22, 73], "grow_polici": [16, 22, 73], "importance_typ": [16, 22, 73], "interaction_constraint": [16, 22, 73], "learning_r": [16, 22, 53, 54, 73, 112, 117, 147, 148, 149, 150, 152, 153, 157, 158], "max_bin": [16, 22, 45, 46, 73, 112, 119, 120, 147, 148, 161, 162, 163, 164], "max_cat_threshold": [16, 22, 73], "max_cat_to_onehot": [16, 22, 73], "max_delta_step": [16, 22, 73], "max_leav": [16, 22, 73, 143, 147, 148], "min_child_weight": [16, 22, 73], "miss": [16, 22, 73, 100, 109, 112], "nan": [16, 22, 53, 59, 73, 98, 147, 148], "monotone_constraint": [16, 22, 73], "n_job": [16, 22, 73, 138, 140, 142, 144, 147, 148, 152, 153], "num_parallel_tre": [16, 22, 73], "predictor": [16, 22, 73, 91, 96, 105, 106, 107, 108, 110, 112, 114, 115, 116, 120, 130], "In": [16, 22, 73, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 103, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 138, 147, 149, 152, 153, 157, 159, 161, 163], "environ": [16, 22, 73, 136], "rerun": [16, 22, 73], "cell": [16, 22, 73, 110], "html": [16, 22, 73, 96, 100, 101, 146], "represent": [16, 22, 73, 94, 99, 114, 115, 117, 120, 130], "trust": [16, 22, 73, 110], "On": [16, 22, 73, 90, 92, 96, 103, 113, 122, 127, 130], "unabl": [16, 22, 73], "render": [16, 22, 73, 118], "try": [16, 22, 73, 136], "page": [16, 22, 73, 99], "nbviewer": [16, 22, 73], "org": [16, 22, 73, 101, 146], "xgbregressorxgbregressor": [16, 22, 73], "pipeline_xgb2": [16, 22], "pipeline_xgb7": [16, 22], "2533": 16, "3524": 16, "8102": 16, "2780": 16, "3617": 16, "7894": 16, "0247": 16, "0092": 16, "0208": 16, "0491": 16, "1565": 16, "9632": 16, "2224": 16, "3040": 16, "8315": 16, "1733": 16, "1475": 16, "1317": [16, 53], "robust": [16, 22, 56, 74, 76, 77, 80, 89, 110, 112, 121, 128, 138, 150, 157, 181], "model_compar": [16, 22, 76, 77, 84, 85, 88, 90, 92, 110, 138], "robustness_perf": [16, 22, 65, 66, 76, 77, 90, 92, 127, 138], "resili": [16, 22, 56, 72, 73, 74, 76, 77, 80, 89, 110, 121, 128, 138, 175, 181], "resilience_perf": [16, 22, 67, 68, 76, 77, 90, 92, 126, 138], "653": [16, 17], "34": [16, 17, 23, 29, 37, 41, 49, 54, 104], "plot_2_register_sklearn": [16, 17], "551": 17, "auto_examples_1_model_train": 17, "30": [17, 25, 29, 32, 35, 54, 61, 87, 88, 90, 96, 100, 104, 110, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130, 144], "27": [17, 29, 42, 54, 71, 104], "partial": [26, 35, 80, 101, 102, 104, 110, 138, 147, 148, 151, 152, 153, 154, 161, 162, 163, 164, 181], "depend": [26, 35, 80, 98, 99, 101, 102, 103, 104, 105, 106, 108, 110, 111, 119, 126, 127, 138, 144, 147, 148, 151, 152, 153, 154, 161, 162, 163, 164, 181], "h": [26, 34, 35, 80, 98, 99, 102, 103, 110, 112, 115, 120, 138, 181], "statist": [26, 34, 35, 80, 93, 97, 101, 102, 105, 110, 116, 117, 122, 138, 157, 158, 181], "individu": [26, 35, 80, 96, 98, 99, 102, 103, 106, 108, 109, 116, 125, 128, 129, 130, 138, 142, 152, 153, 181], "expect": [26, 35, 80, 92, 94, 95, 98, 99, 102, 109, 113, 116, 125, 127, 132, 134, 138, 142, 146, 148, 150, 153, 158, 160, 162, 164, 181], "accumul": [26, 35, 80, 101, 102, 110, 119, 120, 138, 158, 181], "local": [26, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 80, 84, 102, 107, 109, 110, 111, 122, 138, 139, 152, 153, 158, 181], "effect": [26, 35, 39, 40, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 80, 84, 85, 88, 96, 99, 102, 105, 106, 107, 109, 110, 116, 117, 122, 123, 124, 126, 130, 138, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 181], "interpret": [26, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 81, 83, 99, 101, 102, 103, 133, 138, 140, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 181], "agnost": [26, 35, 80, 84, 85, 88, 102, 103, 107, 110, 125, 126, 181], "shaplei": [26, 35, 80, 102, 181], "addit": [26, 35, 80, 90, 91, 92, 96, 97, 98, 99, 100, 102, 103, 106, 107, 110, 111, 112, 113, 115, 118, 119, 120, 122, 123, 124, 126, 127, 128, 129, 130, 138, 144, 147, 148, 149, 150, 151, 152, 153, 154, 181], "n_repeat": [27, 108, 138], "928": [27, 35], "plot_0_pfi": [27, 35], "1d": [28, 31, 85, 88, 97, 103, 105, 107, 110, 120, 138, 144, 170, 174], "grid_siz": [28, 29, 31, 34, 103, 104, 105, 107, 138], "original_scal": [28, 30, 31, 32, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 57, 58, 61, 63, 64, 67, 68, 76, 77, 90, 103, 105, 106, 107, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 125, 126, 130, 138], "use_test": [28, 34, 38, 57, 58, 59, 60, 61, 103, 104, 105, 106, 107, 108, 109, 116, 122, 124, 129, 130, 138, 166, 178], "2d": [28, 31, 85, 88, 99, 103, 107, 110, 120, 138], "sample_s": [28, 29, 33, 103, 104, 105, 107, 109, 138, 152, 153], "sliced_lin": [28, 31, 48, 103, 107, 120, 138], "333": [28, 35], "plot_1_pdp": [28, 35], "friedman": [29, 36, 55, 80, 86, 95, 102, 110, 138, 158, 160, 181], "subsampl": [29, 95, 96, 99, 103, 104, 105, 107, 109, 138, 142], "hstat": [29, 34, 102, 138, 181], "354665e": [29, 104], "772886e": [29, 104], "769194e": [29, 104], "488876e": [29, 104], "939141e": [29, 104], "891201e": [29, 104], "615382e": [29, 104], "110027e": [29, 104], "062784e": [29, 104], "224594e": [29, 104], "187721e": [29, 104], "826716e": [29, 104], "798646e": [29, 104], "139691e": [29, 104], "499676e": [29, 104], "367038e": [29, 104], "256837e": [29, 104], "022405e": [29, 104], "017541e": [29, 104], "553405e": [29, 104], "510080e": [29, 104], "003126e": [29, 104], "001398e": [29, 104], "355216e": [29, 104], "842721e": [29, 104], "703580e": [29, 104], "405027e": [29, 104], "302398e": [29, 104], "020537e": [29, 104], "266068e": [29, 104], "271688e": [29, 104], "382035e": [29, 104], "910548e": [29, 104], "33": [25, 29, 33, 54, 104], "166214e": [29, 104], "757503e": [29, 104], "158681e": [29, 104], "689033e": [29, 104], "289872e": [29, 104], "034555e": [29, 104], "418748e": [29, 104], "989873e": [29, 104], "310739e": [29, 104], "203739e": [29, 104], "804507e": [29, 104], "44": [25, 29, 59, 104, 105], "885018e": [29, 104], "682": [29, 35], "plot_1_pdp_hstat": [29, 35], "ic": [30, 34, 95, 102, 138, 181], "900": [30, 35], "57": [30, 37, 71, 74, 78, 79], "plot_2_ic": [30, 35], "reludnnregressor": [31, 54, 117, 138], "reludnn": [31, 53, 65, 103, 117, 157, 158], "027": [31, 35], "plot_3_al": [31, 35], "lime": [32, 34, 84, 85, 88, 102, 110, 136, 138, 181], "without": [32, 37, 38, 53, 54, 109, 113, 116, 142], "center": [32, 37, 38, 53, 54, 96, 101, 103, 106, 117, 129, 138, 139, 152, 153], "sample_id": [32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 106, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 138], "185": [32, 35, 54], "plot_4_lim": [32, 35], "shap": [33, 34, 84, 85, 88, 102, 110, 136, 138, 181], "waterfal": 33, "shap_waterfal": [33, 34, 109, 138], "shap_fi": [33, 109, 138], "shap_summari": [33, 109, 138], "shap_scatt": [33, 109, 138], "691": [33, 35], "plot_5_shap": [33, 35], "xgb2classifi": [34, 47, 57, 59, 61, 67, 69, 70, 72, 76, 120, 138], "balanc": [34, 69, 70, 78, 87, 91, 119, 122, 123, 138, 159], "451": [34, 35], "70": 34, "plot_6_data_dependent_explain": [34, 35], "195": 35, "auto_examples_2_explain": 35, "69": [35, 59, 61, 65], "logist": [36, 55, 80, 110, 116], "taiwan": [36, 55, 80, 88, 147, 149, 152, 157], "credit": [36, 55, 69, 80, 87, 88, 95, 123, 138, 147, 149, 152, 157], "linear": [36, 53, 54, 55, 80, 101, 106, 107, 109, 110, 111, 113, 114, 115, 134, 138, 143, 145, 147, 148, 155, 156, 181], "gam": [36, 55, 63, 80, 86, 110, 112, 114, 119, 120, 125, 138, 151, 152, 153, 154], "california": [36, 55, 80, 95, 112, 113, 118, 119, 126, 133, 138, 150, 154, 160, 162], "hous": [36, 55, 80, 85, 95, 112, 113, 118, 119, 126, 133, 138, 150, 154, 160, 162], "tree": [36, 43, 44, 55, 59, 60, 76, 80, 90, 99, 106, 107, 109, 110, 111, 112, 114, 119, 120, 130, 134, 138, 142, 143, 144, 147, 148, 149, 150, 159, 160, 161, 162, 163, 164, 168, 178, 181], "taiwancredit": [36, 37, 43, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 72, 76, 80, 83, 90, 95, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130, 138, 159, 181], "ebm": [36, 55, 78, 80, 88, 91, 110, 112, 115, 120, 138, 147, 148], "gami": [36, 55, 80, 110, 111, 112, 120, 138, 152, 153, 181], "net": [36, 55, 80, 110, 111, 112, 116, 120, 138, 152, 153, 159, 160, 181], "relu": [36, 55, 80, 85, 88, 110, 111, 115, 138, 152, 153, 157, 158, 181], "dnn": [36, 55, 80, 85, 88, 110, 117, 138, 157, 158], "limit_b": [37, 41, 43, 47, 49, 51, 53, 57, 59, 61, 63, 65, 67, 76], "sex": [37, 41, 43, 47, 49, 51, 53, 57, 59, 61, 63, 65, 67, 76], "educ": [37, 41, 43, 47, 49, 51, 53, 57, 59, 61, 63, 65, 67, 76], "marriag": [37, 41, 43, 47, 49, 51, 53, 57, 59, 61, 63, 65, 67, 76], "ag": [37, 41, 43, 47, 49, 51, 53, 57, 59, 61, 63, 65, 67, 76, 86, 126], "flagdefault": [37, 41, 43, 47, 49, 51, 53, 57, 59, 61, 63, 65, 67, 76, 88, 90, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130], "evalu": [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 87, 90, 91, 97, 98, 101, 106, 108, 109, 110, 115, 122, 123, 124, 125, 126, 127, 129, 130, 134, 138], "8083": 37, "7375": 37, "3745": 37, "4585": 37, "1431": 37, "8150": 37, "7356": 37, "3764": 37, "4458": 37, "1385": 37, "0067": 37, "0127": [37, 38], "coeffici": [37, 38, 94, 98, 101, 106, 109, 110, 114, 117, 119, 138, 145, 148, 150, 153, 158, 160, 162, 164], "model_interpret": [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 84, 85, 88, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 138], "glm_coef_plot": [37, 38, 116, 138], "tabl": [37, 38, 57, 58, 72, 73, 86, 87, 96, 97, 98, 101, 116, 123, 127, 130, 134, 138], "glm_coef_tabl": [37, 38, 116, 138], "global_fi": [37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 112, 114, 115, 116, 117, 119, 120, 138], "local_fi": [37, 38, 39, 40, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 112, 114, 115, 116, 117, 119, 120, 138], "origin": [37, 38, 63, 69, 72, 95, 99, 101, 103, 106, 107, 108, 109, 113, 119, 123, 125, 127, 128, 130, 134, 138, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 169], "scale": [37, 38, 85, 92, 107, 113, 119, 127, 130, 138, 139, 140, 141, 142, 143, 144, 145, 146], "648": 37, "plot_0_glm_cl": [37, 55], "glmregressor": [38, 77, 116, 138], "0225": 38, "1105": 38, "3467": 38, "1090": 38, "3593": 38, "0015": [38, 53, 60, 124], "943": [], "plot_0_glm_reg": [38, 55], "gamclassifi": [39, 63, 114, 138], "spline_ord": [39, 40, 114, 151, 154], "n_spline": [39, 40, 114, 151, 154], "lam": [39, 40, 114, 151, 154], "8363": 39, "9226": 39, "8387": 39, "3512": 39, "1130": 39, "8475": 39, "9306": 39, "8432": 39, "3406": 39, "1062": 39, "0112": 39, "0080": [39, 42], "0045": [39, 43], "0105": 39, "0068": 39, "global": [38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 84, 107, 110, 111, 138, 152, 153], "global_effect_plot": [39, 40, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 112, 114, 115, 117, 119, 120, 138], "861": 39, "plot_1_gam_cl": [39, 55], "gamregressor": [40, 114, 138], "californiahousing_trim2": [40, 42, 44, 46, 85, 95, 138], "0145": 40, "0867": 40, "7453": 40, "0152": 40, "0883": 40, "7257": 40, "0007": [40, 41, 54], "0017": [40, 49, 62], "0196": 40, "59": [40, 99], "951": 40, "150": 40, "plot_1_gam_reg": [40, 55], "treeclassifi": [41, 76, 109, 118, 138], "8248": 41, "7716": 41, "4872": 41, "4281": 41, "1334": [41, 51], "8255": 41, "7605": 41, "4715": 41, "4537": 41, "1342": 41, "0111": 41, "0157": 41, "0256": [41, 44], "start": [41, 42, 95, 101, 113, 117, 118, 119, 129, 136, 138, 143], "root": [41, 42, 43, 44, 90, 113, 118, 129, 138, 142, 143, 146, 159, 160], "node": [41, 42, 94, 99, 109, 113, 117, 118, 119, 120, 138, 142, 143, 149, 150, 159, 160, 161, 162, 163, 164], "tree_glob": [41, 42, 43, 44, 113, 118, 138], "depth": [41, 42, 43, 44, 99, 110, 111, 112, 113, 118, 123, 125, 138, 143, 149, 150, 159, 160, 161, 162, 163, 164, 181], "th": [41, 99, 101, 103, 104, 107, 109, 113, 114, 117, 119], "tree_loc": [41, 42, 43, 44, 113, 118, 138], "505": 41, "plot_2_tree_cl": [41, 55], "treeregressor": [42, 109, 118, 138], "0184": [42, 70], "0979": 42, "6762": 42, "0212": 42, "1059": [42, 110], "6178": 42, "0028": [42, 43, 129], "0584": 42, "834": 42, "plot_2_tree_reg": [42, 55], "figsclassifi": [43, 76, 113, 138], "max_it": [43, 44, 66, 112, 113, 145, 149, 150, 151, 154], "8246": 43, "7891": 43, "4926": 43, "4205": 43, "1312": [43, 49], "8218": [43, 49], "7637": 43, "4636": [43, 62], "4378": 43, "1357": [43, 53], "0255": 43, "0290": 43, "0173": 43, "figs_heatmap": [43, 44, 113, 138], "tree_idx": [43, 44, 113, 138], "first": [43, 44, 85, 86, 87, 90, 92, 95, 96, 98, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 133, 134, 136, 138, 146, 147, 148, 152, 153, 159, 160], "044": 43, "plot_3_figs_cl": [43, 55], "figsregressor": [44, 66, 113, 138], "0103": [44, 60, 62], "0705": 44, "8196": 44, "0739": 44, "7941": 44, "0034": 44, "194": 44, "plot_3_figs_reg": [44, 55], "xgb1classifi": [45, 119, 138], "min_bin_s": [45, 46, 119, 161, 162], "xgb1": [45, 46, 110, 119, 120, 129, 138], "8512": [45, 70], "9311": 45, "8499": 45, "3327": 45, "1052": 45, "8450": 45, "9028": 45, "8368": 45, "4084": 45, "1214": 45, "0062": [24, 45, 52], "0131": [45, 46], "0758": 45, "0162": 45, "evid": [45, 46, 122, 125, 126, 138], "xgb1_woe": [45, 46, 119, 138], "inform": [45, 46, 72, 73, 90, 94, 95, 96, 98, 99, 100, 110, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 129, 130, 138, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "xgb1_iv": [45, 46, 119, 138], "187": 45, "plot_4_xgb1_cl": [45, 55], "xgb1regressor": [46, 119, 138], "0816": 46, "7704": 46, "0136": 46, "0822": 46, "7546": 46, "0159": [46, 60], "012": 46, "plot_4_xgb1_reg": [46, 55], "8219": [47, 57, 122], "7978": [47, 57, 69, 122], "4759": [47, 57, 122], "4196": [47, 57, 122], "1316": [47, 57, 122], "8290": [47, 57, 122], "7728": [47, 57, 122], "4797": [47, 57, 122], "4252": [47, 57, 122], "1319": [47, 57, 122], "0071": [47, 57, 62, 122], "0251": [47, 57, 122], "0038": [47, 57, 122], "pay_1": [47, 49, 51, 53, 57, 59, 61, 63, 67, 72, 76, 88, 90, 117, 122, 125, 126, 130], "global_ei": [47, 48, 49, 50, 51, 52, 112, 115, 120, 138], "local_ei": [47, 48, 49, 50, 51, 52, 112, 115, 120, 138], "592": 47, "plot_5_xgb2_cl": [47, 55], "947": 48, "plot_5_xgb2_reg": [48, 55], "explainableboostingclassifi": [49, 78, 91, 112, 138], "interact": [49, 50, 84, 85, 88, 99, 103, 104, 105, 107, 109, 110, 116, 117, 147, 148, 151, 152, 153, 154, 163, 164], "7896": 49, "4778": 49, "4239": 49, "1327": 49, "8272": 49, "7753": 49, "4792": 49, "4222": 49, "0054": 49, "0143": [49, 60], "0013": [49, 54], "0016": [49, 54], "154": 49, "plot_6_ebm_cl": [49, 55], "explainableboostingregressor": [50, 112, 138], "0072": 50, "0589": [50, 62], "7918": 50, "0078": [50, 62, 73], "0615": 50, "7779": 50, "0025": 50, "0140": 50, "plot_6_ebm_reg": [50, 55], "gaminetclassifi": [51, 115, 138], "8169": 51, "7734": 51, "4465": 51, "4352": 51, "1366": 51, "8228": 51, "7672": 51, "4478": 51, "4292": [51, 69], "0060": 51, "896": 51, "374": 51, "plot_7_gaminet_cl": [51, 55], "gaminetregressor": [52, 115, 138], "0058": [52, 60, 100], "0536": 52, "8332": 52, "0551": [52, 54], "8241": 52, "0014": [52, 54], "0091": 52, "495": 52, "308": 52, "plot_7_gaminet_reg": [52, 55], "reludnnclassifi": [53, 65, 117, 138], "hidden_layer_s": [53, 54, 117, 157, 158], "l1_reg": [53, 54, 117, 157, 158], "0002": [53, 54, 60, 117], "8200": [53, 110], "7723": 53, "4722": 53, "4334": 53, "8300": 53, "7708": 53, "4817": 53, "4250": 53, "0100": 53, "0083": 53, "0039": 53, "llm": [53, 54, 138], "llm_summari": [53, 54, 117, 138], "count": [53, 54, 84, 92, 100, 103, 104, 105, 106, 107, 108, 109, 112, 115, 116, 117, 119, 120, 122, 124, 125, 127, 128, 129, 130, 138, 147, 148, 157, 158], "respons": [53, 54, 57, 84, 85, 86, 87, 88, 90, 92, 95, 97, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 138, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "mean": [53, 54, 96, 98, 99, 100, 101, 103, 106, 108, 109, 113, 114, 116, 117, 119, 120, 122, 123, 124, 125, 126, 127, 130, 134, 138, 139, 142, 144, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 174, 175, 176, 177], "std": [53, 54, 100, 138], "6535": 53, "1053": 53, "3069": 53, "6037": 53, "7349": 53, "4166": 53, "1066": 53, "3086": 53, "6477": 53, "6261": 53, "1307": 53, "2295": 53, "4207": 53, "5999": 53, "5003": 53, "1158": 53, "3100": 53, "4627": 53, "7819": [53, 78], "7348": 53, "903": 53, "1595": 53, "3663": 53, "6118": 53, "5528": 53, "7334": 53, "301": 53, "4979": 53, "302": 53, "7322": 53, "303": 53, "7364": 53, "304": 53, "6900": [53, 78], "305": 53, "parallel": [53, 54, 138, 140, 142, 144, 147, 148, 152, 153], "coordin": [53, 54, 138], "llm_pc": [53, 54, 117, 138], "violin": [53, 54, 138], "llm_violin": [53, 54, 117, 138], "one": [53, 54, 70, 71, 72, 73, 84, 86, 87, 92, 94, 95, 97, 99, 100, 101, 103, 105, 107, 108, 110, 112, 115, 116, 117, 118, 119, 120, 122, 123, 128, 130, 136, 143, 144, 152, 153, 159, 160], "two": [53, 54, 59, 60, 61, 62, 87, 91, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 106, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 125, 127, 134, 138, 143, 144], "pay_3": [53, 117], "871": 53, "120": [53, 76, 79, 110], "plot_8_reludnn_cl": [53, 55], "0192": 54, "9784": 54, "0199": 54, "9709": 54, "0075": [54, 62], "215": [54, 101, 110], "4711": 54, "1584": 54, "0309": 54, "207": 54, "4700": 54, "1648": 54, "0327": 54, "4592": 54, "1754": 54, "0324": [54, 115], "148": 54, "4698": 54, "1601": 54, "0003": [54, 60], "0340": 54, "126": 54, "3969": 54, "1574": 54, "0186": 54, "106": 54, "3815": 54, "1582": 54, "0218": 54, "6136": 54, "1315": 54, "0783": 54, "62": [54, 59, 69, 78, 86], "6301": 54, "1698": 54, "0750": 54, "3266": 54, "1242": 54, "0542": 54, "45": [54, 69, 70, 108], "2920": 54, "1354": [54, 59], "6213": [54, 61], "1345": 54, "6046": 54, "1563": [22, 54], "2811": 54, "1128": 54, "0560": 54, "5604": 54, "1171": [54, 60, 62], "0784": 54, "2250": 54, "1211": 54, "0288": [54, 59], "2636": 54, "1341": 54, "0604": 54, "5663": 54, "1579": 54, "5213": 54, "1795": 54, "0010": 54, "0441": 54, "5491": 54, "1967": 54, "0451": 54, "6115": 54, "1256": 54, "0023": 54, "5365": 54, "1195": 54, "4459": 54, "1685": 54, "2393": 54, "1061": 54, "0342": 54, "3573": 54, "1770": 54, "0404": [54, 70], "4821": 54, "1186": 54, "0135": 54, "0625": 54, "0238": 54, "5134": 54, "0839": 54, "0138": 54, "4321": 54, "1450": 54, "0164": [54, 59], "1801": 54, "0305": 54, "0385": 54, "4558": 54, "0107": 54, "0240": [22, 54], "1400": 54, "0890": 54, "0040": 54, "0302": 54, "2187": 54, "1037": [54, 61], "0203": 54, "0751": 54, "6258": 54, "0943": 54, "5209": 54, "0035": [54, 59], "0884": 54, "4773": 54, "0875": 54, "plot_8_reludnn_reg": [54, 55], "459": [77, 79], "auto_examples_3_model": 55, "307": [], "373": [], "149": [], "accuraci": [56, 70, 72, 73, 74, 76, 77, 80, 89, 98, 101, 109, 110, 121, 125, 127, 128, 130, 134, 138, 146, 147, 149, 151, 152, 157, 159, 161, 163, 167, 181], "overfit": [56, 72, 73, 74, 76, 77, 80, 89, 101, 110, 112, 114, 117, 118, 119, 121, 122, 128, 130, 138, 168, 178, 181], "reliabl": [56, 72, 73, 74, 76, 77, 80, 89, 99, 103, 110, 121, 128, 130, 138, 151, 170, 171, 172, 181], "fair": [56, 74, 75, 79, 80, 83, 89, 95, 110, 121, 138, 147, 181], "segment": [56, 69, 74, 78, 80, 86, 87, 89, 94, 95, 110, 121, 126, 130, 138, 163, 164, 181], "diagnos": [56, 74, 80, 128, 129, 138, 163, 164], "confus": [57, 122, 128, 138, 165], "matrix": [57, 94, 99, 101, 103, 117, 120, 122, 128, 138, 144, 145, 148, 150, 153, 157, 158, 159, 160, 162, 164, 165], "roc": [57, 122, 128, 138, 165], "recal": [57, 110, 122, 123, 128, 138, 165], "precis": [57, 99, 110, 122, 123, 125, 128, 138, 165], "accuracy_plot": [57, 76, 77, 90, 92, 122, 138], "residu": [57, 58, 70, 71, 72, 73, 110, 112, 113, 115, 125, 126, 127, 128, 138, 148, 150, 153, 158, 160, 162, 164, 166], "respect": [57, 58, 96, 97, 98, 101, 104, 106, 109, 113, 117, 123, 125, 127, 130, 138, 146, 152, 153], "accuracy_residu": [57, 58, 70, 71, 122, 129, 138], "flagdefault_predict": 57, "487": [57, 70], "plot_0_accuracy_cl": [57, 74], "cnt_predict": [58, 122], "47": [58, 69, 78], "407": 58, "plot_0_accuracy_reg": [58, 74], "slice_method": [59, 60, 61, 62, 72, 73, 76, 77, 90, 92, 124, 129, 130, 138, 168, 178], "min_sampl": [59, 60, 61, 62, 124, 129, 130, 138, 168, 178], "test_acc": [59, 61], "train_acc": [59, 61], "1350": 59, "5440": 59, "7052": 59, "6888": 59, "pay_2": [59, 130], "3750": 59, "5625": 59, "244": 59, "8551": 59, "7336": 59, "1215": 59, "2500": 59, "191": [59, 130], "6963": [59, 78], "6675": 59, "1111": [59, 61], "2222": [59, 61], "268": 59, "956": 59, "7276": 59, "7207": 59, "0069": [24, 59], "6250": 59, "7205": 59, "7164": 59, "3333": [59, 61, 100], "5556": 59, "351": 59, "1430": 59, "6154": 59, "6119": 59, "357": 59, "6234": 59, "6303": 59, "set": [38, 59, 60, 61, 65, 76, 77, 84, 85, 86, 87, 88, 90, 92, 93, 95, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 134, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "4444": [59, 61], "1265": 59, "5090": 59, "6876": 59, "0088": 59, "test_auc": 59, "train_auc": 59, "752": 59, "2936": 59, "6478": 59, "7071": 59, "0593": 59, "3521": 59, "13975": 59, "6350": 59, "6970": 59, "0620": 59, "513": 59, "2154": 59, "5481": 59, "6325": 59, "0844": 59, "5250": 59, "7179": 59, "1929": [59, 100], "6314": 59, "4400": 59, "2778": 59, "602": 59, "2528": 59, "6994": 59, "0282": 59, "1667": 59, "6862": 59, "6798": 59, "136": 59, "plot_1_weakspot_cl": [59, 74], "test_ms": [60, 62], "train_ms": [60, 62], "445": [60, 62], "1736": [60, 62], "0219": [24, 60, 62], "0197": [60, 62], "0022": [60, 62, 72], "290": 60, "1168": 60, "0307": 60, "0304": 60, "2042e": 60, "377": 60, "0207": 60, "1186e": 60, "0630e": 60, "155": 60, "538": [60, 70], "0158": 60, "2337e": 60, "365": 60, "0110": 60, "7680e": 60, "test_ma": [60, 62], "train_ma": [60, 62], "1163": 60, "1106": 60, "735": [60, 71, 129], "2911": 60, "1046": 60, "1031": 60, "2826": 60, "3696": 60, "283": 60, "1495": 60, "1352": 60, "2214": 60, "8710": 60, "0749": 60, "0747": 60, "209": 60, "plot_1_weakspot_reg": [60, 74], "bill_amt1": [61, 65, 88], "3781": 61, "131": 61, "7561": 61, "8473": 61, "0912": 61, "7167": 61, "8037": 61, "117": 61, "6333": 61, "7094": 61, "0761": [61, 70], "7311": 61, "7953": 61, "160": 61, "6000": 61, "9237": 61, "9558": 61, "338": 61, "5797": 61, "6834": 61, "2814": 61, "3685": 61, "7083": 61, "8133": 61, "1050": 61, "6715": 61, "73": 61, "6500": 61, "7808": 61, "1308": 61, "038": 61, "plot_2_overfit_cl": [61, 74], "1743": 62, "0096": 62, "285": 62, "0081": [62, 129], "5000": [62, 100, 101, 147, 148, 152, 153], "6636": 62, "103": 62, "366": 62, "0421": 62, "0350": 62, "2318": 62, "173": 62, "645": 62, "0250": 62, "0198": 62, "0052": 62, "1364": 62, "240": 62, "882": 62, "2546": 62, "3940": 62, "105": 62, "432": 62, "0020": 62, "197": [62, 110], "4924": 62, "1649": 62, "6580": 62, "0639": 62, "005": 62, "176": [62, 70], "plot_2_overfit_reg": [62, 74], "calcul": [63, 64, 72, 73, 90, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 119, 120, 122, 124, 125, 126, 127, 129, 130, 138, 139, 140, 141, 142, 143, 144, 145, 146, 152, 153], "shift": [63, 64, 72, 73, 87, 90, 92, 97, 125, 127, 138], "between": [63, 64, 67, 68, 70, 71, 72, 73, 87, 90, 92, 94, 95, 96, 97, 98, 99, 101, 103, 104, 105, 107, 108, 109, 112, 114, 115, 116, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 134, 138, 142, 144, 146, 159, 160, 170, 174, 176, 177], "un": [63, 64], "reliability_dist": [63, 64, 125, 138, 174], "bandwidth": [63, 64, 76, 77, 105, 128, 138, 173], "against": [63, 64, 67, 68, 72, 73, 90, 91, 92, 99, 106, 112, 115, 120, 122, 125, 127, 128, 136, 138], "reliability_margin": [63, 64, 125, 138], "bin": [63, 64, 69, 76, 77, 87, 90, 92, 97, 99, 103, 110, 112, 119, 120, 121, 124, 125, 126, 129, 130, 138, 141, 147, 148, 161, 162, 163, 164, 168, 171, 172, 178], "calibr": [63, 72, 90, 128, 138, 169], "probabl": [63, 72, 90, 97, 103, 104, 105, 107, 109, 117, 122, 125, 126, 127, 128, 132, 138, 147, 149, 151, 152, 157, 158, 159, 161, 163, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "v": [63, 72, 85, 88, 101, 128, 138, 148, 150, 153, 158, 160, 162, 164, 169], "reliability_calibr": [63, 125, 138], "diagram": [63, 72, 76, 118, 128, 138, 143, 172], "reliability_perf": [63, 76, 90, 125, 138], "reliability_t": [63, 64, 125, 138], "1258": 63, "1276": 63, "922": 63, "plot_3_reliability_cl": [63, 74], "empir": [64, 96, 97, 120, 128, 138, 140, 173], "coverag": [64, 77, 128, 138, 170, 173], "averag": [64, 87, 92, 98, 99, 101, 103, 105, 106, 107, 108, 109, 113, 116, 117, 118, 119, 122, 124, 125, 128, 130, 138, 142, 144, 152, 153, 173], "alpha": [64, 65, 66, 67, 68, 76, 77, 90, 92, 99, 125, 126, 127, 134, 138, 141, 143, 146, 159, 160, 169, 170, 171, 172, 173, 174, 176, 177], "9014": 64, "2231": 64, "571": 64, "plot_3_reliability_reg": [64, 74], "perturb": [65, 66, 90, 92, 106, 110, 128, 138], "perturb_featur": [65, 66, 90, 92, 127, 138], "bill_amt2": 65, "bill_amt3": 65, "perturb_s": [65, 66, 90, 92, 127, 138], "perturb_method": [65, 66, 90, 92, 127, 138], "worst": [65, 66, 67, 68, 70, 71, 76, 77, 125, 126, 128, 138, 174, 175, 176, 177], "percent": [65, 66, 76, 77, 96, 138], "robustness_perf_worst": [65, 66, 76, 77, 90, 92, 127, 138], "751": 65, "plot_4_robustness_cl": [65, 74], "being": [66, 103, 108, 109, 110, 119, 123, 126], "815": 66, "plot_4_robustness_reg": [66, 74], "scenario": [67, 68, 76, 77, 90, 92, 96, 99, 110, 125, 126, 128], "resilience_method": [67, 68, 76, 77, 90, 92, 126, 138, 174, 175, 176, 177], "hard": [67, 68, 117, 126, 127, 138, 145, 146, 157, 158, 174, 175, 176, 177], "cluster": [67, 68, 96, 113, 126, 138, 139, 143, 174, 175, 176, 177], "resilience_dist": [67, 68, 76, 77, 90, 92, 126, 138, 174], "immut": [67, 68, 126, 138, 174, 175, 176, 177], "immu_featur": [67, 68, 76, 77, 90, 92, 126, 138, 174, 175, 176, 177], "wd1": [67, 68, 97, 125, 126, 129, 138, 143, 170, 174], "n_cluster": [67, 68, 126, 138, 139, 174, 176, 177], "resilience_shift_histogram": [67, 68, 126, 138], "resilience_shift_dens": [67, 68, 126, 138], "200": [67, 145], "plot_5_resilience_cl": [67, 74], "540": 68, "plot_5_resilience_reg": [68, 74], "mono_increasing_list": [69, 119, 120, 152, 153, 161, 162, 163, 164], "mortgag": [69, 70, 87, 95, 123, 138], "mono_decreasing_list": [69, 119, 152, 153, 161, 162, 163, 164], "amount": [69, 87, 123, 127, 146], "past": [69, 87, 123], "due": [69, 87, 95, 101, 110, 114, 117, 120, 123, 127, 130], "util": [69, 70, 87, 91, 92, 96, 99, 113, 122, 124, 125, 126, 127, 130, 134, 138, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "delinqu": [69, 87], "inquiri": [69, 87], "open": [69, 87, 110], "trade": [69, 87, 123, 134, 138], "xgb2_monoton": [69, 123], "metrics_result": [69, 78, 91, 123], "model_fair": [69, 87, 123, 138], "air": [69, 78, 87, 91, 123, 138], "group_categori": [69, 78, 91, 123, 138], "reference_group": [69, 78, 91, 123, 138], "protected_group": [69, 78, 91, 123, 138], "favorable_threshold": [69, 78, 91, 123, 138], "performance_metr": [69, 123, 138], "group": [69, 78, 86, 87, 91, 98, 106, 117, 123, 125, 126, 138], "refer": [69, 78, 81, 86, 87, 91, 94, 95, 97, 98, 103, 107, 113, 114, 119, 123, 125, 126, 129, 138, 159, 160], "protect": [69, 78, 86, 87, 91, 123, 138], "612": 69, "745": 69, "segmented_result": [69, 78, 91, 123], "segment_featur": [69, 70, 71, 78, 91, 123, 129, 138], "segment_bin": [69, 71, 78, 91, 123, 129, 138], "lower": [69, 78, 87, 91, 92, 99, 105, 114, 122, 125, 130, 145, 146], "bound": [69, 78, 112, 130, 145, 147, 148], "upper": [69, 78, 95, 101, 112, 130, 138, 145], "306": [69, 78], "4485": 69, "6607": 69, "601": [69, 78], "4767": 69, "6426": 69, "1027": [69, 78], "6319": 69, "6556": 69, "1864": [69, 78], "6486": 69, "94": [69, 78], "20384": [69, 78], "87": [69, 70, 78], "8781": 69, "8266": 69, "binning_result": [69, 123], "binning_dict": [69, 123, 138], "id": [69, 70, 71, 113, 116, 118, 129, 134, 138, 143], "configur": [69, 96, 105, 122, 123, 129, 130, 134, 138], "7450": 69, "6120": 69, "7163": 69, "5049": 69, "5064": 69, "9776": 69, "5127": 69, "0048": 69, "9273": 69, "5276": 69, "0160": [22, 69], "8439": 69, "5374": 69, "5674": 69, "9873": 69, "3577": 69, "5718": 69, "9743": 69, "3611": 69, "5805": 69, "9321": 69, "3713": 69, "5921": 69, "8310": 69, "3991": 69, "5918": [69, 78], "6627": 69, "4014": 69, "4346": 69, "0061": 69, "3877": 69, "4388": [69, 100], "9928": 69, "3915": 69, "4569": 69, "9530": 69, "4011": 69, "4852": 69, "8571": 69, "4290": 69, "5129": 69, "7078": 69, "4340": 69, "4720": 69, "9962": 69, "4153": 69, "4746": 69, "9865": 69, "4179": 69, "4921": 69, "9476": 69, "4276": 69, "5191": 69, "8632": 69, "4516": 69, "5259": 69, "6781": 69, "4835": 69, "0036": 69, "4054": 69, "4873": 69, "9920": 69, "4087": 69, "5048": 69, "9508": 69, "4186": 69, "5227": 69, "8739": 69, "4412": 69, "5172": 69, "7055": 69, "4302": 69, "thresholding_result": [69, 123], "3324": 69, "8862": 69, "6757": 69, "8917": 69, "841": 69, "plot_6_fair": [69, 74], "top": [70, 71, 90, 92, 98, 99, 100, 101, 104, 106, 112, 114, 115, 116, 117, 119, 120, 122, 126, 127, 129, 134, 146, 152, 153], "segmented_diagnos": [70, 71, 129, 138], "segment_t": [70, 71, 129, 138], "segment_method": [70, 71, 129, 138], "auto": [70, 129, 138, 141, 142, 144, 145, 146, 147, 148, 152, 153, 159, 160, 161, 162, 163, 164], "head": [70, 71, 129], "0x00000220575d5fa0": [], "1831": 70, "63": [70, 99], "5397": 70, "0447": 70, "064": 70, "5975": [], "072": 70, "5977": [], "inf": [70, 143], "011": 70, "575": 70, "6035": [], "0234": 70, "6193": [], "101": 70, "6238": [], "2221": 70, "309": 70, "6245": [], "2859": 70, "316": [70, 79], "384": 70, "6354": [], "6446": [], "0x00000220578a0160": [], "446": 70, "6502": [], "0211": 70, "158": 70, "6582": [], "0469": 70, "1119": 70, "6756": [], "2804": 70, "6889": [], "1506": 70, "7244": [], "7955": [], "talb": 70, "segment_id": [70, 71, 129, 138], "7563": 70, "7622": 70, "4899": 70, "1604": 70, "5777": 70, "5538": 70, "7566": 70, "2760": 70, "2166": 70, "2735": 70, "2084": 70, "2667": 70, "1156": 70, "comparison": [70, 71, 79, 81, 83, 93, 110, 129, 130, 138, 147, 149, 159, 181], "specif": [70, 71, 84, 85, 88, 90, 91, 92, 96, 97, 98, 99, 100, 103, 105, 107, 108, 110, 115, 116, 117, 118, 119, 120, 122, 123, 125, 126, 127, 128, 129, 130, 134, 137, 138], "remain": [70, 71, 90, 92, 96, 101, 105, 106, 109, 116, 117, 125, 126, 127, 128, 174, 176, 177], "distribution_shift": [70, 71, 129, 138], "363": [], "plot_7_segmented_cl": [70, 74], "0x0000022059334040": [], "712": [71, 129], "0141": [], "0133": [], "441": [71, 129], "0132": [], "5909": [71, 129], "7878": [71, 129], "1026": [71, 129], "0126": 129, "912": [71, 129], "7298": [71, 129], "9123": [71, 129], "1131": [71, 129], "0108": [], "1825": [71, 129], "3649": [71, 129], "1598": [71, 129], "0106": [], "874": [71, 129], "0104": [], "0x00000220031ec520": [], "732": 71, "717": [76, 79], "plot_7_segmented_reg": [71, 74], "extract": [72, 73, 117, 120, 129, 133, 135, 146], "requir": [72, 73, 87, 90, 96, 99, 100, 101, 103, 107, 109, 110, 112, 116, 120, 122, 124, 125, 126, 127, 128, 129, 130, 138, 142, 144, 146, 147, 148, 149, 150, 152, 157, 158, 159, 160, 161, 162, 163, 164], "input": [72, 73, 90, 92, 95, 103, 105, 106, 107, 108, 109, 115, 116, 117, 122, 126, 127, 128, 132, 138, 139, 140, 141, 142, 143, 144, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "_": [72, 97, 98, 101, 103, 105, 107, 112, 115, 120, 122, 125], "get_data": [72, 138], "concaten": 72, "get_model": [72, 138], "prediction_proba": [72, 128, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "predict_proba": [72, 103, 104, 105, 106, 107, 132, 138, 147, 149, 151, 152, 157, 159, 161, 163], "get_feature_nam": [72, 138], "get_feature_typ": [72, 138], "get_target_nam": [72, 138], "shape": [72, 73, 100, 112, 114, 115, 119, 120, 132, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "necessari": [72, 73, 113, 123, 125], "data_dict": [72, 73, 128], "scored_test": [72, 73, 128], "test_accuracy_t": [72, 73, 128], "8227": 72, "8059": [72, 73], "4809": 72, "4147": 72, "1300": 72, "8292": 72, "7817": 72, "4831": 72, "4211": 72, "1310": 72, "0065": 72, "0242": 72, "0064": 72, "test_accuracy_plot": [72, 128], "interest": [72, 73, 90, 92, 99, 103, 105, 106, 107, 110, 122, 123, 124, 125, 128, 129, 130, 138, 166, 176, 177], "test_accuracy_residu": [72, 73, 128, 129], "weak": [72, 73, 110, 124, 129, 130, 138], "region": [72, 73, 90, 92, 110, 117, 124, 128, 129, 130, 138, 168, 174, 176, 177, 178], "test_weakspot": [72, 73, 128, 129], "test_overfit": [72, 73, 128], "No": [72, 130, 136, 157, 158], "get": [72, 82, 87, 101, 103, 104, 106, 109, 112, 113, 114, 115, 116, 117, 119, 120, 123, 125, 128, 136, 138, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 167, 168, 169, 171, 172, 173, 175, 178], "test_reliability_perf": [72, 128], "relationship": [72, 73, 94, 97, 98, 99, 101, 103, 105, 107, 108, 109, 114, 116, 117, 119, 122, 125, 127], "uncertainti": [72, 73, 92, 98, 110, 125], "test_reliability_margin": [72, 73, 128], "unreli": [72, 73, 103, 125, 128, 138, 170], "test_reliability_dist": [72, 73, 128], "test_reliability_calibr": [72, 128], "how": [72, 73, 82, 84, 85, 88, 90, 92, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 132, 133, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "under": [72, 73, 90, 92, 99, 101, 110, 116, 122, 125, 126, 127, 129, 130, 138], "test_resilience_perf": [72, 73, 128], "good": [72, 73, 87, 117, 126, 130], "bad": [72, 73, 138], "e": [72, 73, 87, 97, 99, 101, 103, 104, 105, 107, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 126, 127, 128, 129, 130, 134, 138, 142, 143, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "g": [72, 73, 87, 97, 99, 101, 109, 110, 112, 113, 114, 115, 116, 119, 120, 125, 126, 127, 128, 134, 138, 143, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "rest": [72, 73, 86, 95, 99, 103, 105, 108, 112, 113, 115, 119, 138], "similarli": [72, 73, 92, 99, 112, 113, 117, 120, 125], "other": [72, 73, 86, 88, 91, 96, 97, 98, 99, 100, 101, 103, 105, 107, 109, 110, 113, 114, 115, 116, 119, 122, 125, 128, 130, 138, 145, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "like": [72, 73, 91, 99, 103, 110, 112, 115, 116, 117, 122, 130, 138, 142, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "test_resilience_dist": [72, 73, 128], "The": [72, 73, 84, 85, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 134, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "test_resilience_shift_histogram": [72, 73, 128], "test_resilience_shift_dens": [72, 73, 128], "636": 72, "plot_8_scored_test_cl": [72, 74], "2585": 73, "3558": 73, "2709": 73, "3636": 73, "7965": 73, "0124": 73, "0094": 73, "113": 73, "plot_8_scored_test_reg": [73, 74], "920": [], "auto_examples_4_test": 74, "68": 110, "reliability_bandwidth": [76, 77, 90, 92, 138], "plot_0_compare_classif": [76, 79], "reliability_coverag": [77, 92, 138], "plot_0_compare_regress": [77, 79], "model_fairness_compar": [78, 87, 91, 138], "glm_air": 78, "ebm_air": 78, "7124": 78, "6453": 78, "8326": 78, "8251": 78, "4405": 78, "9017": 78, "6953": 78, "5457": 78, "7452": 78, "6506": 78, "6338": 78, "7080": 78, "6135": 78, "7131": 78, "6028": 78, "8209": 78, "7490": 78, "8734": [78, 100], "7147": 78, "8212": 78, "140": [78, 79], "plot_1_compare_fair": [78, 79], "auto_examples_5_compar": 79, "auto_examples_python": 80, "zip": 80, "auto_examples_jupyt": 80, "welcom": 81, "outcom": [81, 83, 99, 110, 122, 123, 125, 129, 138], "user": [81, 96, 99, 100, 101, 110, 113, 120, 123, 129, 130, 136, 137, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "guid": [81, 110, 137, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "introduct": [81, 96, 101, 117, 181], "diagnost": [81, 83, 89, 128, 129, 131, 138, 174, 176, 177, 181], "suit": [81, 100, 129, 181], "case": [81, 86, 87, 96, 100, 106, 108, 113, 116, 119, 122, 124, 126, 127, 130, 138, 144, 145, 159, 160, 181], "studi": [81, 181], "frequent": 81, "ask": 81, "question": 81, "read": [82, 110], "my": 82, "own": [82, 96, 159], "frame": [82, 114, 116], "chapter": 83, "includ": [83, 85, 88, 90, 92, 95, 96, 97, 98, 99, 100, 101, 107, 110, 112, 114, 115, 118, 119, 120, 122, 123, 125, 126, 128, 129, 130, 134, 136, 138, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "multipl": [83, 89, 99, 109, 110, 113, 115, 119, 123, 130, 138, 142], "low": [83, 84, 85, 87, 88, 95, 109, 110, 114, 118, 122, 138], "experiment": [83, 110, 138], "intepret": 83, "benchmark": 83, "californiah": [83, 114, 181], "ml": [83, 95, 101, 110, 116, 138], "descript": [83, 95, 110, 138], "its": [84, 85, 88, 92, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 134, 138, 152, 153, 159], "mode": [84, 85, 88, 90, 95, 110, 138, 152, 153, 159], "develop": [84, 85, 88, 92, 95, 97, 98, 103, 104, 105, 106, 107, 108, 109, 110, 112, 115, 116, 117, 119, 120, 122, 124, 125, 127, 128, 129, 130, 134, 138], "machin": [84, 85, 88, 89, 91, 92, 95, 97, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 113, 115, 116, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 134, 138, 181], "learn": [84, 85, 88, 89, 91, 92, 95, 97, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 132, 133, 134, 136, 138, 146, 147, 148, 149, 150, 152, 153, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "uci": [84, 88, 90, 92, 95, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 138], "repositori": [84, 88, 90, 92, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130], "which": [84, 85, 88, 90, 92, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 138, 143, 144, 147, 149, 150, 152, 153, 157, 159, 160, 161, 162, 163, 164, 174, 176, 177], "consist": [84, 85, 88, 92, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 139, 140, 141, 142, 143, 144, 145, 146, 148, 150, 153, 158, 160, 162, 164], "389": [84, 92, 103, 104, 105, 106, 107, 108, 109, 112, 115, 116, 119, 120, 122, 124, 125, 127, 128, 129, 130], "hourli": [84, 92, 103, 104, 105, 106, 107, 108, 109, 112, 115, 116, 119, 120, 122, 124, 125, 127, 128, 129, 130], "rental": [84, 92, 103, 104, 105, 106, 107, 108, 109, 112, 115, 116, 119, 120, 122, 124, 125, 127, 128, 129, 130], "capit": [84, 92, 103, 104, 105, 106, 107, 108, 109, 112, 115, 116, 119, 120, 122, 124, 125, 127, 128, 129, 130], "see": [84, 85, 88, 91, 92, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 138, 145, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "detail": [84, 85, 88, 90, 92, 94, 99, 101, 102, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 125, 128, 129, 134, 137, 138, 159, 160], "here": [84, 85, 88, 90, 92, 95, 96, 97, 99, 101, 103, 105, 107, 108, 112, 113, 115, 116, 120, 122, 126, 127, 128, 132, 133, 138, 143], "continu": [84, 85, 92, 96, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 147, 148, 152, 153], "problem": [84, 85, 86, 87, 88, 90, 92, 95, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 138, 144, 145, 159], "click": [84, 85, 86, 87, 88, 95, 136], "link": [84, 85, 86, 87, 88, 91, 94, 95, 96, 97, 98, 99, 100, 101, 116, 123, 134, 147, 148], "googl": [84, 85, 86, 87, 88, 95, 138], "colab": [84, 85, 86, 87, 88], "choos": [84, 85, 86, 87, 88, 95, 99, 119, 124, 126, 127, 129, 130, 149, 150, 159, 160], "exploratori": [84, 85, 86, 87, 93, 138, 181], "need": [84, 92, 99, 100, 101, 103, 105, 107, 109, 110, 113, 119, 120, 122, 123, 129, 130, 132, 133, 136, 146, 147, 148, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "inher": [84, 85, 88, 110, 115, 117, 133, 138], "pairwis": [84, 85, 88, 94, 101, 103, 110, 112, 115, 120, 144, 147, 148, 151, 152, 153, 154, 163, 164], "640": [85, 113, 114, 118, 126], "fetch": [85, 113, 114, 118, 126], "three": [85, 90, 92, 94, 96, 97, 98, 100, 101, 110, 115, 116, 122, 123, 125, 126, 127, 129, 130, 134], "version": [85, 97, 110, 125, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "_raw": 85, "_trim1": 85, "trim": [85, 95, 138], "onli": [85, 88, 92, 98, 99, 106, 108, 109, 110, 112, 114, 115, 116, 117, 118, 119, 120, 123, 124, 126, 127, 128, 129, 130, 133, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 165, 169, 170, 171, 172, 173, 174, 176, 177], "_trim2": 85, "median": [85, 99, 100, 113, 114, 118, 126, 144, 160], "price": [85, 114], "per": [85, 103, 109, 112, 117, 143, 145, 147, 148, 152, 153, 161, 162, 163, 164], "block": [85, 152, 153], "log": [85, 99, 103, 104, 105, 107, 116, 119, 122, 130, 148, 152, 153, 159], "l1": [85, 116, 117, 144, 155, 156, 157, 158, 160, 161, 162, 163, 164], "reigster": 85, "sola": [86, 95, 136, 138], "ai": [86, 95, 110, 136, 138], "solassimu1": [86, 95, 138], "modifi": [86, 95, 100, 112, 129, 138], "demo": [86, 99, 130, 138, 152, 153], "covari": [86, 95, 99, 101, 110, 127, 129, 132, 138, 139, 140, 141, 142, 143, 144, 145, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "label": [86, 90, 95, 96, 100, 122, 126, 130, 132, 138, 147, 148, 149, 151, 152, 157, 159, 160, 161, 163], "demograph": [86, 87, 91, 95, 123, 138], "contribut": [86, 95, 99, 105, 106, 108, 109, 114, 116, 119, 138], "minor": [86, 112], "major": [86, 99], "grei": [86, 87], "color": [86, 87, 113], "when": [86, 87, 90, 91, 97, 98, 99, 101, 103, 105, 106, 108, 109, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 129, 130, 134, 138, 142, 143, 144, 145, 146, 148, 150, 152, 153, 157, 158, 159, 160, 162, 164, 174, 176, 177], "finish": 86, "suggest": [86, 92, 97, 99, 103, 107, 109, 110, 114, 116, 125, 126], "procudur": 86, "add": [86, 87, 110, 120, 127, 138, 142], "By": [86, 90, 92, 95, 96, 99, 100, 101, 105, 106, 108, 110, 112, 113, 114, 116, 117, 118, 119, 122, 123, 124, 125, 126, 127, 129, 130, 134, 138, 145, 159, 160], "enter": [86, 100], "button": [86, 87, 95], "switch": [86, 116, 119, 130], "tab": [86, 87], "view": [86, 103, 107, 108, 109, 112, 113, 115, 118, 120, 125], "breakdown": 86, "model_fairness_sola": [86, 138], "decis": [87, 95, 106, 109, 110, 111, 113, 123, 130, 138, 142, 143, 145, 159, 160, 168, 178, 181], "hypothes": 87, "statu": [87, 130, 143, 157, 158], "well": [87, 97, 98, 99, 101, 113, 114, 116, 118, 119, 120, 122, 125, 130, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "indic": [87, 90, 91, 95, 96, 97, 98, 99, 103, 105, 107, 108, 109, 112, 113, 114, 115, 116, 117, 119, 120, 122, 124, 125, 126, 127, 130, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 152, 153, 159, 160, 161, 162, 163, 164], "20k": 87, "applic": [87, 95, 101, 110, 138], "last": [87, 90, 96, 97, 101, 103, 126, 133, 136, 138, 147, 148, 152, 153, 157, 158], "month": 87, "card": [87, 88, 90, 95, 96, 100, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130, 138], "minimum": [87, 99, 100, 110, 119, 122, 124, 129, 130, 136, 142, 143, 147, 148, 149, 150, 159, 160, 161, 162, 163, 164], "payment": [87, 88], "wa": [87, 147, 148], "account": [87, 99, 109, 119, 125, 127], "date": 87, "ordin": [87, 96, 119, 138, 147, 148], "current": [87, 125, 136, 159, 160], "dai": [87, 103, 105, 107, 112, 115, 120, 122], "so": [87, 92, 100, 101, 106, 108, 109, 113, 114, 116, 120, 126, 138, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "number": [87, 90, 92, 96, 97, 98, 99, 100, 101, 103, 104, 105, 107, 108, 109, 112, 113, 114, 117, 119, 122, 123, 124, 125, 126, 127, 129, 130, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 168, 171, 172, 174, 176, 177, 178], "divid": [87, 94, 96, 99, 103, 112, 115, 118, 120, 122, 125, 129, 130, 146], "limit": [87, 92, 101, 103, 107, 113, 114, 117, 118, 145, 146], "cannot": [87, 91, 101, 116, 146], "kind": [87, 138], "should": [87, 95, 101, 103, 104, 107, 108, 110, 116, 117, 122, 124, 125, 132, 134, 138, 145, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "nearli": [87, 95, 138], "depth2": 87, "depth7": 87, "xgbclassifi": 87, "To": [87, 92, 96, 97, 101, 103, 104, 105, 106, 107, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 130, 136, 138, 159, 160], "favor": [87, 115, 138], "defaut": 87, "class": [87, 116, 122, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "find": [87, 112, 115, 117, 119, 125, 129, 134, 159, 160], "higher": [87, 91, 92, 97, 99, 107, 113, 114, 122, 126, 146], "debias": 87, "unfair": [87, 91, 123], "mitig": [87, 99, 101, 123, 124], "an": [87, 90, 92, 94, 96, 98, 99, 100, 101, 103, 105, 106, 107, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 129, 130, 134, 136, 138, 141, 142, 145, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 168, 174, 175, 176, 177, 178], "attribut": [87, 88, 91, 100, 106, 109, 126, 138, 139, 142, 143, 145, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "repeat": [87, 99, 101, 106, 108, 120, 147, 148, 151, 154], "mani": [87, 99, 103, 110, 116, 117, 122, 147, 148, 159, 160], "clear": [87, 103, 126], "could": [87, 95, 109, 115, 126, 152, 153], "record": [87, 90, 92, 99, 105, 108, 127, 147, 148, 161, 162], "adjust": [87, 100, 103, 118, 124, 125, 126, 129, 159], "vari": [87, 101, 105, 106, 122, 126, 159, 160], "both": [87, 91, 92, 94, 98, 99, 101, 103, 105, 109, 110, 112, 113, 114, 115, 116, 119, 120, 122, 125, 127, 132, 140, 142, 152, 153, 159], "000": [25, 55, 74, 88, 90, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130], "client": [88, 90, 95, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130, 138], "200504": 88, "200509": 88, "subject": [88, 101, 110, 116, 127, 152, 153, 161, 162, 163, 164], "slight": [88, 92, 126], "preprocess": [88, 90, 95, 96, 112, 113, 116, 120, 122, 124, 125, 127, 128, 130, 138, 146], "histori": [88, 152, 153], "pay_amt1": [88, 117], "keep": [88, 103, 108, 117, 138, 146, 148, 150, 153, 158, 160, 162, 164], "while": [88, 98, 99, 101, 103, 105, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 122, 123, 124, 125, 126, 127, 130, 134, 141, 159, 160], "section": [90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 105, 109, 117, 122, 123, 127], "describ": [90, 99, 101, 103, 107, 143], "done": [90, 103, 106, 120], "function": [90, 91, 92, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 131, 134, 138, 140, 142, 143, 144, 145, 147, 148, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164], "illustr": [90, 92, 103, 105, 107, 109, 119, 120, 122, 123, 125, 127, 130, 133], "chosen": [90, 96, 113, 114, 115, 119, 129, 130, 138, 159, 160], "chart": [90, 92, 94, 107, 116, 122], "below": [90, 91, 92, 95, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 134, 138], "As": [90, 98, 99, 100, 101, 103, 108, 109, 112, 114, 115, 117, 118, 119, 120, 125, 126, 127, 128, 132, 133, 134, 135, 138, 152, 153], "legend": 90, "similar": [90, 97, 99, 101, 103, 105, 106, 109, 112, 113, 114, 115, 117, 119, 120, 122, 124, 125, 126, 129, 134, 152, 153], "ha": [90, 92, 95, 97, 98, 99, 101, 103, 106, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 126, 127, 129, 138, 142, 145, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 174, 176, 177], "slightli": [90, 95, 101, 112, 115, 120, 124], "better": [90, 92, 99, 105, 108, 112, 117, 118, 119, 122, 123, 125, 130, 134], "present": [90, 91, 92, 98, 100, 109, 122, 123, 129, 130, 134], "variou": [90, 92, 96, 97, 99, 109, 110, 112, 115, 116, 122, 123, 126, 136, 138], "relat": [90, 92, 97, 98, 101, 105, 113, 115, 119, 120, 126, 128, 129, 136, 142, 145, 174, 175, 176, 177], "found": [90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 112, 113, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128, 130, 136, 148, 159, 160], "It": [90, 91, 92, 97, 98, 99, 100, 101, 103, 106, 109, 110, 112, 113, 114, 115, 116, 118, 119, 120, 122, 125, 126, 127, 129, 130, 134, 138, 141, 145, 146, 152, 153, 157, 158, 159, 160, 174, 176, 177], "note": [90, 91, 92, 96, 97, 98, 99, 101, 103, 106, 107, 108, 109, 112, 113, 114, 115, 116, 118, 119, 120, 122, 125, 126, 127, 129, 130, 138, 142, 144, 145, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "unlik": [90, 92, 99, 109, 113, 124], "argument": [90, 92, 95, 97, 101, 103, 104, 105, 106, 107, 109, 113, 115, 119, 122, 124, 125, 127, 129, 130, 144], "slice": [90, 92, 103, 107, 110, 120, 124, 128, 129, 130, 138, 168, 171, 178], "instead": [90, 92, 100, 101, 103, 104, 105, 107, 109, 110, 112, 113, 116, 119, 120, 125, 126, 138, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "repres": [90, 91, 92, 94, 97, 98, 99, 101, 103, 104, 105, 106, 107, 109, 113, 114, 116, 117, 118, 119, 120, 122, 125, 126, 127, 129, 130, 134, 142, 144, 157, 158], "keyword": [90, 92, 99, 101, 103, 104, 106, 107, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 129, 144], "reveal": [90, 92, 99, 108, 112, 120, 122, 124, 130], "within": [90, 91, 94, 96, 97, 99, 113, 118, 120, 124, 125, 126, 128, 129, 130, 134, 138, 145, 147, 148, 152, 153, 159, 160], "greater": [90, 96, 99, 100, 101, 105, 124, 125, 130, 138, 139, 140, 141, 142, 143, 144, 145, 146, 149, 150, 152, 153, 159, 160], "than": [90, 91, 92, 98, 99, 100, 101, 103, 104, 105, 106, 107, 109, 110, 113, 114, 116, 117, 119, 120, 122, 124, 125, 126, 127, 130, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 159, 160], "interv": [90, 92, 103, 117, 125, 129, 145], "quantifi": [90, 96, 97, 99, 109, 125], "squar": [90, 99, 101, 116, 117, 122, 124, 125, 127, 130, 134, 143, 144, 146, 148, 150, 153, 156, 158, 160, 162, 164], "hat": [90, 101, 103, 104, 105, 107, 112, 113, 114, 115, 119, 120, 122, 125, 127], "p": [90, 97, 99, 104, 107, 109, 119, 123, 125, 127, 132, 138, 144], "henc": [90, 101, 112, 117, 119, 138, 142], "shown": [90, 95, 97, 101, 103, 104, 109, 112, 113, 115, 116, 117, 118, 120, 123, 125, 128, 129, 132, 134], "actual": [90, 95, 96, 99, 112, 114, 115, 118, 119, 120, 122, 125, 126, 127, 129, 138, 142, 152, 153, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "involv": [90, 92, 99, 100, 108, 116, 119, 124, 126, 127, 129, 130, 134, 138], "ad": [90, 92, 101, 120, 127, 152, 153], "nois": [90, 92, 106, 110, 127, 138], "undergo": [90, 92], "unless": [90, 92, 138, 142, 159, 160], "otherwis": [90, 92, 98, 99, 100, 103, 104, 105, 106, 107, 108, 109, 113, 119, 124, 130, 138, 142, 145, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "abov": [90, 92, 95, 98, 99, 101, 103, 104, 107, 108, 109, 112, 114, 115, 117, 119, 120, 123, 124, 125, 126, 127, 129, 130, 134], "best": [90, 119, 120, 134, 148, 149, 150, 152, 153, 158, 159, 160, 162, 164], "follow": [90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 133, 134, 136, 138, 142, 147, 148, 159, 160], "option": [90, 96, 97, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 117, 119, 122, 124, 125, 126, 127, 129, 130, 134, 136, 138, 140, 141, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "proport": [90, 92, 97, 98, 116, 122, 125, 126, 127, 134, 159], "consid": [90, 91, 99, 104, 107, 108, 109, 110, 115, 117, 118, 119, 120, 122, 124, 126, 127, 129, 130, 134, 138, 144, 147, 148, 149, 150, 159, 160], "largest": [90, 92, 99, 106, 112, 114, 115, 116, 117, 119, 120, 125, 126, 127, 159, 160], "high": [90, 92, 95, 97, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 138, 145, 159, 160], "compris": [90, 98, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130], "april": [90, 110, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130], "2005": [90, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130], "septemb": [90, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130], "more": [90, 91, 92, 94, 96, 97, 98, 99, 101, 105, 107, 108, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 134, 138, 142, 146, 147, 148, 159, 160], "taiwancreditdata": [90, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130], "websit": [90, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130], "directli": [90, 91, 94, 108, 109, 112, 116, 117, 119, 120, 122, 124, 125, 127, 128, 130, 136, 138], "although": [90, 99, 103, 112, 115, 116, 120, 122, 124, 125, 127, 128, 130], "some": [90, 99, 101, 107, 108, 112, 114, 115, 116, 117, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 138, 146, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "serv": [90, 99, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 129, 130], "dedic": [91, 125], "bia": [91, 110, 117, 157, 158], "superior": [91, 120], "sinc": [91, 92, 110, 113, 119, 122, 142, 147, 149, 152, 157, 159, 161, 163], "former": [91, 109, 127], "intric": [91, 114], "howev": [91, 92, 95, 96, 99, 101, 105, 106, 107, 108, 109, 110, 112, 113, 114, 116, 117, 119, 120, 122, 125, 126, 127, 130, 138], "observ": [91, 97, 98, 99, 101, 105, 107, 112, 113, 114, 115, 116, 120, 122, 123, 124, 125, 126, 127, 128, 129, 142], "distinct": [91, 96, 99, 126, 128, 129], "perspect": [91, 112], "assess": [91, 92, 94, 96, 97, 98, 108, 114, 122, 124, 125, 126, 127, 130, 134], "focus": [91, 98, 129], "consequ": [91, 110, 130, 134], "ani": [91, 98, 105, 108, 109, 110, 112, 113, 114, 120, 122, 125, 129, 149, 150, 159, 160], "influenc": [91, 108, 114, 126, 148, 150, 153, 158, 160, 162, 164], "associ": [91, 116, 125, 159], "depict": [91, 122, 126], "advers": [91, 123, 127, 138], "impact": [91, 97, 99, 103, 109, 119, 120, 123, 124, 134, 138], "left": [91, 96, 98, 99, 100, 101, 104, 109, 112, 113, 115, 120, 122, 143, 149, 150, 159, 160], "convers": [91, 99, 114], "right": [91, 98, 99, 101, 104, 106, 109, 112, 113, 115, 116, 119, 120, 122, 143, 149, 150, 159, 160], "signifi": [91, 126], "discrimin": 91, "practic": [91, 109, 113, 117, 134], "term": [91, 106, 109, 110, 113, 114, 116, 117, 120, 122, 145, 147, 148, 149, 150, 161, 162, 163, 164], "provid": [91, 96, 97, 98, 99, 100, 105, 107, 108, 109, 110, 113, 115, 116, 117, 118, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 142, 143, 145, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "figur": [91, 101, 110, 112, 114, 115, 117, 119, 120, 123, 125, 127, 128, 138, 143, 165, 166, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178], "impli": [91, 117, 126], "notabl": [91, 122, 129], "those": [91, 92, 94, 123, 144], "level": [91, 98, 99, 101, 109, 110, 112, 115, 120, 123, 125, 127, 147, 148], "overal": [91, 99, 101, 103, 110, 113, 116, 118, 122, 127, 138, 161, 162], "entir": [91, 92, 107, 109, 118, 126, 130], "possibl": [91, 109, 116, 122, 123, 134, 136, 138, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "appropri": [91, 96, 99, 110, 118, 124, 144], "subset": [91, 99, 101, 103, 104, 105, 107, 109, 118, 125, 129, 142, 147, 149, 152, 157, 159, 161, 163], "offer": [91, 92, 100, 103, 109, 117, 118, 122, 126, 129, 130, 134], "veri": [91, 101, 103, 106, 108, 115, 116, 152, 153, 157, 158], "explor": [92, 94, 134], "conveni": [92, 110], "wai": [92, 95, 97, 99, 101, 105, 109, 110, 114, 115, 117, 120, 138, 142], "through": [92, 110, 113, 115, 117, 134, 159, 160], "process": [92, 96, 99, 106, 107, 110, 113, 117, 119, 120, 122, 123, 125, 127, 129, 130, 134, 142, 145, 159, 160], "obtain": [92, 99, 100, 107, 109, 112, 117, 119, 122, 125, 127, 129, 134, 142, 152, 153, 159, 160, 161, 162], "support": [92, 94, 95, 96, 99, 103, 109, 110, 119, 120, 122, 123, 125, 126, 127, 128, 132, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 149, 150, 159, 160, 165], "list": [92, 96, 98, 100, 101, 104, 110, 115, 117, 124, 127, 128, 130, 133, 134, 138, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "too": [92, 103, 109, 117, 119], "crowd": 92, "These": [92, 94, 95, 96, 101, 122, 127, 128, 129, 130, 138], "boxplot": 92, "summar": [92, 100, 113, 127, 138], "mark": [92, 99, 101, 117, 126], "circl": [92, 99], "lowest": [92, 126], "rel": [92, 99, 101, 112, 114, 116, 117, 119, 122, 126, 127, 130, 146, 159, 160], "sensit": [92, 99, 100, 109, 116, 117, 122, 123], "lead": [92, 97, 103, 106, 110, 112, 114, 116, 119, 123, 142, 146], "conclus": [92, 125], "significantli": [92, 97, 98, 99, 103, 106, 116, 122, 126], "larger": [92, 99, 103, 104, 105, 107, 108, 109, 113, 114, 116, 117, 134, 138, 139, 140, 141, 142, 143, 144, 145, 146, 151, 152, 153, 154], "less": [92, 100, 103, 105, 107, 109, 114, 119, 125, 126, 130, 138, 142, 144, 159, 160], "furthermor": [92, 110, 113, 122], "deriv": [92, 99, 119, 145, 152, 153], "metricmetr": 92, "suffer": [92, 118], "issu": [92, 98, 116, 123, 124, 127, 152, 153, 157, 158], "especi": [92, 101, 113, 114, 116, 149, 150, 159, 160], "aim": [92, 99, 101, 103, 125, 126], "dot": [92, 99, 125, 126, 130, 138], "line": [92, 94, 99, 101, 103, 105, 107, 110, 117, 120, 122, 123, 125, 126, 130, 138], "close": [92, 106, 112, 116, 117, 122, 125, 142], "fall": [92, 99, 125, 130, 141], "smallest": [92, 146, 147, 148], "certain": [92, 96, 97, 99, 100, 107, 109, 115, 130], "signific": [92, 96, 101, 108, 109, 110, 112, 115, 124, 126, 145], "degrad": [92, 108, 110, 127], "increas": [92, 97, 99, 101, 105, 108, 109, 110, 112, 114, 115, 116, 117, 119, 120, 122, 124, 125, 126, 127, 130, 152, 153, 161, 162, 163, 164], "emploi": [92, 97, 122, 123, 124, 125, 126, 129, 130, 134], "extra": 92, "call": [92, 98, 100, 101, 103, 105, 107, 110, 112, 116, 117, 119, 123, 132, 136, 138, 142, 146, 148, 150, 153, 158, 160, 162, 164], "taken": [92, 119, 145], "consider": [92, 101, 122], "previou": [92, 103, 105, 125, 126, 142], "much": [92, 103, 105, 109, 113, 116, 122, 126, 127], "manipul": 93, "basic": [93, 100, 138, 147, 148], "highli": [93, 101, 103, 107, 109, 118, 119, 138, 140, 142, 147, 148], "methodologi": [93, 110, 121, 131], "allow": [94, 96, 99, 100, 107, 109, 114, 119, 122, 123, 124, 125, 126, 130, 134, 138, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164], "visual": [94, 99, 103, 105, 107, 110, 112, 113, 115, 116, 117, 120, 125, 126, 130], "identif": [94, 110, 124, 126], "potenti": [94, 99, 114, 122, 123, 126, 160], "aid": [94, 119], "understand": [94, 99, 105, 110, 114, 116, 117, 119, 123, 124, 125, 126, 129], "deviat": [94, 99, 100, 126, 127, 138, 147, 148, 152, 153], "pattern": [94, 97, 99, 105, 110, 112, 114, 117, 122, 124, 127], "presenc": [94, 98, 99, 130], "frequenc": [94, 97, 99, 100, 125, 127, 159], "graphic": [94, 105, 110], "combin": [94, 99, 101, 109, 113, 116, 122, 123, 134], "collect": [94, 113, 119, 120, 142], "point": [94, 97, 99, 101, 103, 104, 105, 106, 107, 109, 114, 117, 119, 122, 125, 127, 129, 130, 138, 147, 148, 149, 150, 152, 153, 159, 160, 161, 162, 163, 164], "dimension": [94, 97, 99, 116, 145], "There": [94, 95, 101, 110, 116, 123, 134], "integrity_check": 94, "altern": [94, 101, 103, 107, 109, 127, 159, 160], "connect": [94, 130], "introduc": [95, 98, 99, 109, 114, 117, 122, 123, 126, 129], "loader": [95, 152, 153], "modul": [95, 96, 98, 99, 100, 101, 110, 116, 118, 128, 129, 135, 136, 138, 152, 153], "usual": [95, 103, 108, 109, 110, 113, 123, 126, 134, 138, 166, 176, 177], "step": [95, 99, 101, 108, 109, 112, 113, 115, 117, 118, 119, 120, 125, 126, 127, 128, 130, 132, 134, 138, 142, 147, 148, 149, 150, 175], "whole": [95, 96, 97, 98, 138, 139, 140, 141, 142, 143, 144, 145, 146], "sever": [95, 101, 109, 115, 119, 125, 129, 134, 138, 159, 160], "alreadi": [95, 108, 117, 133, 134, 135], "upload": 95, "gaussian": [95, 99, 101, 127, 138, 139], "spheric": [95, 138], "scikit": [95, 99, 101, 105, 107, 108, 110, 116, 117, 134, 136, 138, 146, 147, 148, 155, 156, 159, 160], "archiv": [95, 138], "edu": [95, 138], "crash": [95, 138], "cours": [95, 138], "californiahousing_trim1": [95, 138], "98": [95, 138], "A": [95, 97, 99, 101, 103, 107, 110, 116, 117, 122, 125, 126, 127, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "solasai": [95, 138], "dispar": [95, 110, 122, 123, 129, 138], "solashmda": [95, 138], "2018": [95, 109, 110, 138], "home": [95, 113, 114, 118, 126, 138], "disclosur": [95, 138], "act": [95, 138], "hmda": [95, 138], "about": [95, 98, 99, 103, 110, 129, 138], "everi": [95, 113, 138, 151, 154, 159], "unit": [95, 116, 117, 138, 146], "just": [95, 103, 109, 116, 138, 142, 147, 148], "wrap": [95, 101, 132], "backend": [95, 110, 138], "162726": 95, "989380": 95, "977290": 95, "022444": 95, "833418": 95, "897849": 95, "931033": 95, "718005": 95, "695946": 95, "998672": 95, "883336": 95, "443349": 95, "628205": 95, "383016": 95, "782193": 95, "470701": 95, "950189": 95, "278926": 95, "041356": 95, "204163": 95, "549002": 95, "718085": 95, "934676": 95, "722246": 95, "235314": 95, "914188": 95, "401711": 95, "826569": 95, "049154": 95, "291550": 95, "759445": 95, "509802": 95, "770044": 95, "799497": 95, "517969": 95, "965879": 95, "934110": 95, "230116": 95, "104878": 95, "408100": 95, "858583": 95, "468189": 95, "656293": 95, "970217": 95, "566793": 95, "037980": 95, "867851": 95, "055172": 95, "123488": 95, "594408": 95, "2117": 95, "325774": 95, "298574": 95, "984911": 95, "660747": 95, "894813": 95, "971714": 95, "263716": 95, "386797": 95, "177803": 95, "546942": 95, "2118": 95, "631497": 95, "209968": 95, "060872": 95, "981552": 95, "319807": 95, "552832": 95, "256842": 95, "059649": 95, "120317": 95, "194922": 95, "2119": 95, "918874": 95, "502420": 95, "759211": 95, "143963": 95, "851615": 95, "530987": 95, "295923": 95, "576709": 95, "472256": 95, "470885": 95, "2120": 95, "505041": 95, "592865": 95, "458442": 95, "022174": 95, "396257": 95, "430562": 95, "394588": 95, "286274": 95, "493732": 95, "581601": 95, "2121": 95, "304829": 95, "028269": 95, "903502": 95, "400436": 95, "932546": 95, "409703": 95, "272170": 95, "739227": 95, "744509": 95, "398449": 95, "tell": [95, 103, 113, 119, 127], "program": [95, 110, 138], "would": [95, 96, 101, 103, 104, 105, 107, 116, 117, 118, 122, 123, 125, 130, 132, 138, 148, 150, 152, 153, 158, 159, 160, 162, 164], "denot": [95, 101, 105, 108, 109, 117, 123, 125, 126], "do": [95, 100, 101, 103, 108, 109, 116, 123, 125, 126, 138, 159, 160], "transform": [95, 96, 99, 101, 109, 114, 116, 117, 119, 127, 133, 146], "frac": [95, 97, 98, 101, 103, 104, 107, 109, 119, 120, 122, 123, 125, 138, 148, 150, 153, 158, 160, 162, 164], "work": [95, 98, 99, 101, 107, 109, 110, 119, 120, 122, 123, 129, 138, 143, 144, 145, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "mechan": [95, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "mai": [95, 97, 99, 101, 103, 105, 106, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 122, 123, 125, 126, 127, 129, 136, 137, 138, 143, 144, 145, 148, 149, 150, 153, 158, 159, 160, 162, 164], "want": [95, 100, 105, 107, 109, 113, 116, 120, 127, 130, 135], "must": [95, 100, 103, 106, 144, 145, 151, 154, 155, 156], "dictionari": [95, 123, 128, 134, 147, 148, 149, 150, 159, 160], "kei": [95, 99, 107, 112, 114, 115, 119, 123, 134], "abil": [96, 97, 99, 122, 124], "aspect": [96, 99, 110, 115], "addition": [96, 100, 103, 104, 107, 119, 120, 122, 124, 125, 129], "control": [96, 99, 100, 107, 113, 114, 117, 118, 119, 123, 126, 128, 142, 146, 159, 160], "flexibl": [96, 100, 108, 110, 114, 115, 119, 129, 130, 141], "accord": [96, 110, 117, 119, 123, 126, 138, 152, 153, 174, 175, 176, 177], "prefer": [96, 129, 134], "typic": [96, 99, 108, 116, 134], "locat": 96, "explicitli": [96, 100, 109], "identifi": [96, 98, 99, 101, 105, 109, 110, 114, 116, 119, 120, 122, 124, 126, 127, 129, 130, 134, 138], "desir": [96, 97, 99, 119, 122, 123, 125, 130, 134, 138], "ensur": [96, 98, 100, 114, 118, 119, 120, 123, 124, 146], "correct": [96, 112, 122, 130, 136], "automat": [96, 100, 101, 110, 119, 129, 138, 141, 147, 148, 159], "determin": [96, 97, 99, 100, 101, 107, 109, 113, 114, 122, 124, 125, 126, 127, 129, 130, 134, 138, 147, 148, 150, 153, 157, 158, 160, 162, 164, 170, 174, 176, 177], "hand": [96, 103, 110, 113, 122, 125], "most": [96, 98, 101, 105, 106, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 124, 134, 136, 138, 144, 152, 153, 168, 178], "suitabl": [96, 99, 116, 119, 127, 130, 134], "handl": [96, 99, 101, 122, 126], "assign": [96, 99, 106, 116, 118, 123, 126, 134, 139, 140, 141, 142, 143, 144, 145, 146], "carri": [96, 159, 160], "n": [96, 97, 100, 101, 103, 104, 107, 109, 122, 125, 127, 132, 138, 159, 160], "width": [96, 97, 100, 122, 123, 125, 138], "pa": [96, 100], "encod": [96, 110, 116, 119, 138], "standard": [96, 100, 101, 103, 110, 112, 116, 123, 127, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 152, 153], "min": [96, 100, 138, 142, 146, 147, 148, 152, 153, 161, 162], "max": [96, 99, 100, 112, 113, 117, 125, 138, 142, 143, 144, 147, 148, 149, 150, 152, 153, 159, 160, 161, 162, 163, 164], "scaler": 96, "onc": [96, 103, 113, 118, 120, 123, 129], "conduct": [96, 101, 124, 130], "dissimilar": [96, 97, 99], "edf": 96, "reduc": [96, 99, 101, 103, 109, 113, 117, 120], "comput": [96, 97, 99, 101, 103, 104, 105, 107, 108, 109, 117, 119, 122, 125, 126, 130, 138, 144, 145, 146, 152, 153, 157, 158, 159, 160], "burden": [96, 99, 101], "befor": [96, 101, 116, 126, 136, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 151, 152, 153, 157, 158, 159, 160, 163], "output": [96, 98, 99, 101, 103, 105, 106, 107, 109, 114, 117, 120, 123, 127, 129, 132, 138, 145, 146, 152, 153, 159, 160], "euclidean": [96, 99, 101, 126, 138, 143, 144, 174, 175, 176, 177], "far": [96, 99, 107], "awai": 96, "farthest": 96, "length": [96, 98, 99, 117, 138, 142, 147, 148, 151, 154], "contain": [96, 98, 99, 101, 108, 114, 116, 129, 130, 138, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "element": [96, 103, 106, 122, 128, 138, 144, 157, 158, 159, 160], "k": [96, 97, 101, 103, 104, 108, 110, 112, 113, 115, 120, 125, 126, 129, 138, 139, 143, 144, 170, 174, 175, 176, 177], "third": [96, 100, 117, 126, 152, 153], "characterist": [96, 99, 126], "over": [96, 97, 100, 101, 103, 109, 112, 115, 120, 138, 142, 157, 158], "aforement": [96, 130], "composit": 96, "part": [97, 112, 113, 120], "phenomenon": [97, 99], "properti": [97, 109, 117, 145, 159, 160], "mismatch": 97, "word": [97, 98, 103], "assumpt": [97, 107, 114, 116, 119, 127, 146], "made": [97, 127], "dure": [97, 103, 105, 106, 107, 113, 115, 119, 122, 125, 129, 130, 134, 142, 144, 145, 147, 148, 159, 160], "longer": [97, 98, 99, 116, 142], "hold": [97, 116, 126, 134], "unseen": [97, 124], "manifest": 97, "alter": [97, 127, 129], "discrep": [97, 99, 122, 127, 130], "stabil": [97, 125, 126, 129, 138, 170, 174], "measur": [97, 98, 99, 101, 104, 108, 116, 119, 122, 124, 125, 126, 129, 142, 143, 159, 160], "extent": [97, 127, 129], "discret": [97, 123, 125, 127], "kullback": 97, "leibler": 97, "l": [97, 108, 117], "scheme": [97, 99, 113], "q": [97, 125], "b": [97, 101, 110, 117, 125, 126, 127, 152, 153], "d_": [97, 104], "kl": 97, "sum_": [97, 99, 101, 103, 104, 107, 109, 113, 117, 122], "p_i": 97, "ln": 97, "q_i": 97, "asymmetr": [97, 98], "resect": 97, "begin": [97, 98, 99, 101, 103, 104, 105, 107, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 125, 129, 130, 134, 143], "align": [97, 98, 99, 100, 101, 103, 104, 105, 107, 109, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 125], "d": [97, 101, 114, 116, 117, 127], "equal": [97, 109, 112, 114, 116, 117, 122, 123, 125, 126, 129, 130, 138, 142, 146, 147, 148, 149, 150, 151, 152, 153, 154, 159, 160, 168, 178], "fix": [97, 103, 109, 136, 152, 153, 159, 160], "wasserstein": [97, 138, 170, 174], "absolut": [97, 101, 109, 116, 117, 122, 126, 127, 130, 134, 138, 160], "cumul": [97, 140, 146], "f": [97, 103, 104, 105, 107, 108, 109, 114, 115, 119, 120, 125, 127], "w": [110, 117, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "int": [97, 107, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "dx": 97, "kolmogorov": [97, 138, 170, 174], "smirnov": [97, 138, 170, 174], "maximum": [97, 99, 100, 101, 112, 113, 118, 119, 120, 142, 144, 147, 148, 151, 154, 159, 160, 161, 162, 163, 164], "wasserstein_dist": 97, "ks_2samp": 97, "sup_x": 97, "particular": [97, 101, 106, 109, 110, 114, 116, 117, 118, 119, 120, 124, 125, 126, 129, 130, 142], "commonli": [97, 99, 107, 118, 119, 120, 122], "anoth": [97, 98, 100, 103, 112, 119, 122, 126, 143], "particularli": [97, 99, 109, 110, 122], "formula": [97, 98, 99, 101, 103, 109, 117, 122, 125, 147, 148], "mathrm": [97, 101, 105, 107, 119], "nm": 97, "j": [97, 99, 101, 103, 104, 109, 112, 114, 115, 116, 119, 120], "m": [97, 109], "x_": [97, 99, 103, 105, 107, 112, 114, 115, 117, 119, 120, 125], "y_": [97, 98, 122, 125], "speed": [97, 101, 103, 104, 105, 107, 109, 144], "up": [97, 101, 103, 104, 105, 107, 109, 110, 120, 138, 159, 160], "zero": [97, 98, 101, 103, 108, 112, 113, 114, 116, 117, 120, 122, 146, 159, 160], "perfect": [97, 98, 101, 122], "ident": [97, 116, 117, 122, 125, 138, 148, 159, 160], "design": [98, 99, 109, 115, 126, 129, 181], "submodul": [98, 99], "articl": [98, 133], "critic": [98, 117], "valid": [98, 101, 106, 109, 110, 115, 125, 133, 134, 138, 147, 148, 152, 153, 157, 158, 159, 160], "anticip": [98, 129], "except": [98, 101, 109, 120, 128, 147, 148, 150, 153, 158, 160, 162, 164], "ones": [98, 101, 107, 115], "deepcheck": 98, "packag": [98, 101, 103, 105, 106, 107, 109, 110, 112, 113, 114, 116, 117, 119, 120, 132, 136], "tailor": [98, 126, 128], "command": [98, 101, 110, 116, 136], "whether": [98, 99, 101, 107, 113, 119, 122, 129, 138, 139, 140, 141, 142, 143, 144, 145, 146, 149, 150, 152, 153, 156, 157, 158, 161, 162, 163, 164, 166, 170, 178], "uniqu": [98, 99, 100, 110, 117, 119, 120, 123, 130, 147, 148, 159, 160], "across": [98, 99, 103, 105, 109, 116, 122, 123, 126, 138, 142, 159, 160], "mixtur": [98, 99, 101, 139], "strength": [98, 101, 104, 114, 116, 117, 119, 129, 138, 151, 152, 153, 154, 155, 156], "direct": [98, 101, 114, 116, 119, 122], "monoton": [98, 101, 107, 115, 117, 119, 120, 123, 126, 152, 153, 161, 162, 163, 164], "xi": 98, "let": [98, 103, 105, 117, 125, 127, 130], "n_x": 98, "overlin": 98, "sqrt": [98, 101, 125, 148, 159, 160], "n_": [98, 103, 117, 123], "denomin": 98, "varianc": [98, 99, 109, 112, 113, 114, 115, 116, 119, 120, 122, 129, 146, 152, 153, 160], "symmetr": [98, 104], "theil": 98, "u": [98, 99, 103, 107, 108, 119, 122, 125, 126, 127, 130, 136, 148, 150, 153, 158, 160, 162, 164], "entropi": [98, 122, 159], "And": [98, 99, 152, 153], "role": [98, 109, 112, 120], "revers": 98, "thu": [98, 113], "mid": [98, 101], "lie": 98, "complet": [98, 112, 115, 122, 123], "subsequ": [99, 126, 130, 134], "valuabl": [99, 108, 119, 122, 126, 129], "insight": [99, 108, 115, 122, 124, 126, 129, 130], "pinpoint": [99, 124, 129], "elimin": [99, 101, 147, 148], "therebi": 99, "improv": [99, 110, 119, 122, 124, 126, 146, 147, 148, 157, 158, 159, 160], "eight": 99, "adopt": [99, 110], "approach": [99, 101, 109, 110, 113, 116, 122, 124, 125, 126, 130, 134], "liu2008": 99, "recurs": [99, 107, 117, 118, 142, 143], "construct": [99, 125, 144], "until": [99, 112, 120, 147, 148, 159, 160], "instanc": [99, 100, 105, 106, 109, 112, 113, 116, 122, 125, 126, 130, 138, 142, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "anomali": [99, 139, 140, 141, 142, 143, 144, 145, 146], "shorter": [99, 142], "thei": [99, 101, 107, 109, 110, 112, 119, 120, 122, 125, 126, 127, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 159, 160], "easier": [99, 118, 119], "separ": [99, 100, 116, 119, 122, 129, 147, 148], "contrast": [99, 106, 112, 113, 116, 119, 120, 122, 134], "effici": [99, 110, 134, 141, 144, 146], "doe": [99, 103, 104, 105, 106, 107, 108, 124, 125, 128, 130, 138, 159, 160], "reli": [99, 100, 122], "wrapper": [99, 118, 120, 131, 140, 141, 142, 144, 145, 146, 151, 154, 155, 156, 159, 160], "implement": [99, 101, 105, 106, 113, 116, 117, 124, 126, 134, 145, 149, 150], "ensembl": [99, 104, 109, 113, 114, 142], "propos": [99, 112, 113, 120], "he2003": 99, "partit": [99, 105, 107, 130, 142, 159, 160, 161, 162, 163, 164], "classifi": [99, 110, 116, 122, 126, 128, 130, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 149, 151, 152, 155, 157, 159, 165, 169, 172], "larg": [99, 101, 106, 109, 113, 114, 116, 117, 122, 139, 152, 153, 157, 158], "small": [99, 103, 109, 112, 113, 115, 117, 122, 127, 139], "belong": [99, 117, 125], "correspond": [99, 101, 109, 112, 113, 114, 115, 116, 117, 119, 120, 122, 127, 128, 129, 130, 134, 138, 157, 158, 159, 160], "centroid": 99, "multipli": [99, 125, 145, 146, 147, 148, 159], "emphas": 99, "comprehens": [99, 110, 122, 123, 126, 129, 134], "reduct": [99, 109, 143, 159, 160, 161, 162, 163, 164], "techniqu": [99, 110, 119, 124, 130, 134], "mahalanobi": [99, 146], "error": [99, 110, 122, 124, 125, 127, 130, 134, 136, 138, 145, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 168, 169, 170, 171, 172, 173, 178], "reconstruct": 99, "elabor": 99, "take": [99, 101, 109, 110, 112, 115, 119, 120, 124, 127, 130, 132, 144, 145], "structur": [99, 109, 110, 112, 115, 117, 122, 142], "easili": [99, 110, 113, 133], "shyu2003": 99, "md": 99, "z_": [99, 103], "lambda_": 99, "eigenvalu": 99, "But": [99, 159, 160], "give": [99, 108, 117, 119, 137, 152, 153], "final": [99, 101, 103, 105, 108, 109, 112, 114, 115, 117, 119, 120, 127, 128, 132, 161, 162], "among": [99, 101, 109, 116, 159, 160], "mutual": [99, 115], "author": [99, 113], "advantag": [99, 101, 110, 112, 113, 145], "outlin": [99, 123, 126], "iter": [99, 101, 108, 112, 113, 117, 120, 127, 134, 138, 145, 146, 149, 150, 151, 152, 153, 154, 157, 158], "met": 99, "reach": [99, 103, 126, 147, 148], "child": [99, 142, 143, 159, 160], "leav": [99, 143, 147, 148, 149, 150, 159, 160], "behavior": [99, 116, 124], "capabl": [99, 101, 110, 116, 126], "enhanc": [99, 101, 110, 117, 124, 126, 130], "homogen": 99, "after": [99, 103, 110, 116, 117, 125, 126, 127, 129, 133, 134, 135, 136, 138, 152, 153], "further": [99, 101, 115, 119, 125, 128, 129, 132, 133, 137, 161, 162, 163, 164], "known": [99, 110, 116, 117, 118, 122, 126, 134, 159, 160], "adapt": [99, 116, 119], "ramaswamy2000": 99, "angiulli2002": 99, "idea": 99, "fewer": [99, 101, 152, 153], "sort": [99, 101, 126], "ascend": 99, "order": [99, 101, 103, 110, 114, 116, 117, 119, 125, 126, 130, 151, 152, 153, 154, 159], "aggreg": [99, 115, 116, 120, 130, 144], "rational": 99, "behind": 99, "vicin": 99, "analyz": [99, 116, 122, 123, 125, 129, 130], "brief": [99, 110, 117], "overview": [99, 100, 117, 127], "creat": [99, 103, 106, 117, 123, 126, 130, 142, 147, 148, 159, 160], "f_j": 99, "jth": 99, "regular": [99, 110, 114, 115, 116, 117, 124, 141, 147, 148, 152, 153, 155, 156, 157, 158, 161, 162, 163, 164], "prevent": [99, 114, 124, 141], "overflow": [99, 141], "might": [99, 103, 118], "captur": [99, 101, 106, 112, 114, 115, 116, 122, 127], "complex": [99, 101, 107, 112, 113, 114, 117, 118, 119, 124, 126, 130, 159, 160], "advanc": [99, 110], "goldstein2012": 99, "vector": [99, 101, 103, 109, 117, 120, 144, 145, 146, 157, 158], "sch\u00f6lkopf2001": 99, "tradit": 99, "goal": [99, 101, 109, 110, 124, 134], "even": [99, 110, 113, 117, 126, 134, 159, 160], "clearli": 99, "preval": [99, 124], "rare": 99, "exhibit": [99, 117, 122, 124, 126, 127], "care": 99, "kernel": [99, 101, 109, 134, 145, 148, 150, 153, 158, 160, 162, 164], "achiev": [99, 108, 115, 117, 119, 122, 125, 126, 127, 134, 152, 153], "optim": [99, 110, 119, 122, 131, 138, 141, 144, 145, 147, 148, 152, 153, 161, 162, 181], "choic": [99, 110, 116, 117, 138], "radial": 99, "basi": 99, "polynomi": [99, 114, 145], "underli": [99, 127, 129, 159, 160], "ocsvm": 99, "parametr": [99, 101, 114], "context": [99, 107, 109, 118, 120, 122, 123, 125, 134, 138, 142, 145], "leverag": [99, 123], "skew": [99, 127], "dimens": [99, 130, 143, 145, 146, 147, 148], "cdf": [99, 101, 140], "complement": [99, 105, 107, 129], "s_l": 99, "s_r": 99, "public": 99, "li2021": 99, "subsect": [99, 133], "briefli": [99, 114, 117], "decid": [99, 138, 141, 144, 166], "red": [99, 109, 113, 125, 126, 130], "highlight": [99, 101, 118, 124, 126], "sne": [99, 138], "worth": [99, 109, 113], "purpos": [99, 101, 103, 107, 109, 110, 116, 120, 125, 126, 130, 133], "meaning": [99, 122, 125], "mention": [99, 110], "notic": [99, 122, 126, 142], "fei": 99, "toni": 99, "liu": [99, 101], "kai": 99, "ming": 99, "ting": 99, "zhi": 99, "hua": 99, "zhou": 99, "2008": [99, 104], "eighth": 99, "ieee": [99, 110], "intern": [99, 110, 157, 158, 159, 160], "confer": [99, 110], "mine": [99, 110], "pisa": 99, "itali": 99, "pp": [99, 101, 110], "doi": [99, 110], "1109": 99, "icdm": 99, "zengyou": 99, "he": [99, 110], "xiaofei": 99, "xu": 99, "shengchun": 99, "deng": 99, "2003": 99, "discov": 99, "recognit": [99, 110], "letter": 99, "1641": 99, "1650": 99, "mei": 99, "ling": [99, 101], "shyu": 99, "shu": 99, "ching": 99, "chen": [99, 110], "kanoksri": 99, "sarinnapakorn": 99, "liwu": 99, "novel": 99, "miami": 99, "univ": 99, "coral": 99, "gabl": 99, "fl": 99, "dept": 99, "electr": 99, "engin": [99, 110], "sridhar": 99, "ramaswami": 99, "rajeev": 99, "rastogi": 99, "kyuseok": 99, "shim": 99, "acm": [99, 101, 110], "sigmod": 99, "427": 99, "438": 99, "fabrizio": 99, "angiulli": 99, "clara": 99, "pizzuti": 99, "2002": 99, "fast": [99, 101, 110, 111, 112, 115, 117, 138, 149, 150, 181], "principl": 99, "knowledg": [99, 110], "discoveri": [99, 101, 110], "6th": 99, "european": 99, "pkdd": 99, "helsinki": 99, "finland": 99, "august": 99, "proceed": [99, 110], "marku": 99, "goldstein": [99, 105], "andrea": 99, "dengel": 99, "2012": [99, 101], "unsupervis": [99, 126, 130, 140, 141, 143], "ki": [99, 110], "poster": 99, "track": [99, 110], "bernhard": [99, 101], "sch\u00f6lkopf": 99, "john": [99, 116], "c": [99, 105, 107, 117, 127, 136, 145], "platt": 99, "shaw": 99, "taylor": 99, "alexand": [99, 110], "smola": 99, "2001": [99, 108, 110], "neural": [99, 110, 111, 114, 115, 134, 181], "1443": 99, "1471": 99, "zheng": 99, "li": [99, 101, 110, 120], "yue": 99, "zhao": 99, "xiyang": 99, "hu": 99, "nicola": 99, "botta": 99, "cezar": 99, "ionescu": 99, "georg": 99, "2021": [99, 110], "arxiv": [99, 101, 109, 110], "2201": [99, 110], "00382": 99, "meta": [100, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "enabl": [100, 110, 118, 119, 124, 134, 142, 145, 146], "panel": [100, 110], "regard": [100, 110, 125, 129, 130], "n_miss": 100, "q1": 100, "quartil": 100, "q3": 100, "n_uniqu": 100, "top1": 100, "highest": [100, 103, 109, 126, 127], "top2": 100, "top3": 100, "n_other": 100, "5378": 100, "5468": 100, "9144": 100, "4970": 100, "1926": 100, "0200": 100, "3400": 100, "6600": 100, "4758": 100, "1719": 100, "4848": 100, "6212": 100, "6272": 100, "4800": 100, "6300": 100, "7800": 100, "1901": 100, "1223": 100, "1940": 100, "2537": 100, "8507": 100, "189": 100, "4631": 100, "181": 100, "3876": 100, "142": 100, "281": 100, "977": 100, "4496": 100, "4409": 100, "4242": 100, "4232": 100, "8645": 100, "16879": 100, "11865": 100, "5514": 100, "11413": 100, "4544": 100, "1419": 100, "sole": [100, 109, 122, 128, 130, 134], "avail": [100, 105, 107, 109, 110, 119, 123, 124, 125, 126, 127, 129, 130, 134, 138, 145, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "2512": 100, "2502": 100, "2487": 100, "9878": 100, "relev": [101, 103, 104, 105, 107, 116, 118, 125, 134, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "help": [101, 107, 109, 114, 116, 117, 119, 122, 129, 130, 147, 148], "avoid": [101, 116, 117, 152, 153, 157, 158], "moreov": [101, 103, 109, 126, 129, 130], "benefici": 101, "distinguish": [101, 113, 115, 122, 125, 130, 138, 174, 175, 176, 177], "treatment": 101, "rigor": 101, "mathemat": [101, 110], "rho_": 101, "x_i": 101, "y_i": 101, "sign": [101, 124], "magnitud": [101, 110, 116, 122, 127], "straightforward": [101, 106, 107], "blue": [101, 109, 113], "orang": 101, "posit": [101, 112, 114, 115, 116, 117, 120, 122, 123, 138, 151, 152, 153, 154, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "neg": [101, 103, 108, 112, 114, 115, 116, 119, 120, 122, 145, 147, 148, 150, 151, 153, 154, 155, 156, 158, 159, 160, 162, 164], "bottom": [101, 106, 112, 114, 115, 119], "text": 101, "easi": [101, 110, 118, 138, 174, 175, 176, 177], "One": [101, 110, 136], "deal": [101, 130, 141, 152, 153, 157, 158], "r_": 101, "r": [101, 110, 117, 122, 123, 127, 130, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "d_i": 101, "them": [101, 113, 114, 119, 124, 130, 132, 159, 160], "occur": [101, 120, 124, 127, 147, 148], "replac": [101, 109, 123, 142], "pair": [101, 120, 123, 147, 148, 152, 153, 159], "a_": 101, "x_j": [101, 104, 112, 116], "x_k": [101, 104], "quad": 101, "ldot": [101, 109, 114, 116, 117, 125, 126], "b_": 101, "y_j": 101, "y_k": 101, "matric": [101, 139, 140, 141, 142, 143, 144, 145, 146], "cdot": [101, 116, 122], "arithmet": 101, "product": [101, 152, 153], "dcov": 101, "dvar": 101, "operatornam": 101, "alwai": [101, 114, 122, 124, 138, 148, 150, 153, 158, 159, 160, 162, 164], "computation": [101, 134], "expens": [101, 134, 138], "scalabl": [101, 152, 153], "big": 101, "downsampl": [101, 109], "instal": [101, 110], "compos": 101, "descend": [101, 117, 126], "pre": [101, 109, 110], "stabl": [101, 114, 116, 119, 146], "inspect": [101, 110, 159, 160], "permutation_import": [101, 108, 159, 160], "percentag": [101, 146, 147, 148], "concern": [101, 129], "ii": 101, "iii": 101, "underfit": [101, 110, 112], "minim": [101, 122, 127, 138, 159, 160, 168, 178], "power": [101, 110, 117, 118, 119, 129, 146, 148], "probabilist": [101, 122], "incorpor": [101, 115, 125, 126, 134], "z": [101, 109, 117, 120], "perp": 101, "kcit": 101, "zhang2012": 101, "strobl2019": 101, "approxim": [101, 107, 109, 110, 112, 113, 115, 119, 122, 124, 126, 130], "fourier": [101, 138], "reproduc": [101, 138, 142], "hibert": 101, "therefor": [101, 103, 106, 109, 116, 117, 126, 138], "hypothesi": 101, "equival": [101, 117, 120, 142, 144], "cross": [101, 122, 134, 138], "sigma_": 101, "sigma": [101, 117], "_f": 101, "asymptot": 101, "lambda_i": 101, "z_i": 101, "lindsai": 101, "pilla": 101, "basak": 101, "lpb": 101, "lindsayl2000": 101, "finit": 101, "borboudakis2019": 101, "delet": 101, "insignific": 101, "predefin": [101, 125, 134], "candid": [101, 115, 130, 134], "p_valu": 101, "stop": [101, 110, 113, 138, 145, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160], "phase": [101, 157, 158], "recommend": [101, 117], "yu2020": 101, "twice": 101, "temporarili": 101, "temporari": [101, 125], "perman": 101, "formul": [101, 110, 111], "smaller": [101, 113, 117, 118, 119, 122, 125, 126, 127, 130, 134, 138, 152, 153, 159, 160], "procedur": [101, 119], "seven": 101, "deep": [101, 110, 113, 117, 118, 138, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 174, 175, 176, 177], "causal": [101, 125], "disadvantag": 101, "sequenti": [101, 152, 153], "kun": 101, "zhang": [101, 110], "jona": 101, "peter": [101, 110, 116], "dominik": 101, "janz": 101, "schoelkopf": 101, "preprint": [101, 109, 110], "1202": 101, "3775": 101, "eric": 101, "strobl": 101, "shyam": 101, "visweswaran": 101, "2019": [101, 110], "journal": [101, 105, 110], "infer": [101, 119, 152, 153, 157, 158, 159, 160], "bruce": 101, "ramani": 101, "prasanta": 101, "moment": [101, 109], "theori": 101, "annal": [101, 104, 110], "institut": 101, "230": 101, "giorgo": 101, "borboudaki": 101, "ioanni": 101, "tsamardino": 101, "research": [101, 110, 112], "276": 101, "314": 101, "kui": 101, "yu": [101, 110], "xianji": 101, "guo": 101, "lin": 101, "jiuyong": 101, "hao": [101, 110], "wang": [101, 110], "zhaolong": 101, "xindong": 101, "wu": [101, 110], "2020": [101, 110], "survei": 101, "csur": 101, "53": 101, "apley2016": [103, 110], "Its": [103, 122, 125], "bias": [103, 117, 123, 130], "overcom": 103, "quicker": 103, "unbias": 103, "definit": [103, 112, 115, 117, 125], "uncent": [103, 106, 116], "k_": 103, "textbf": [103, 112, 113, 114, 115, 116, 117, 119, 120], "tag": [103, 104, 107, 109, 112, 113, 114, 115, 116, 117, 119, 120, 122], "faster": [103, 107, 112, 113], "accur": [103, 110, 118, 119, 122, 130], "curv": [103, 122, 125, 126, 127, 130], "down": [103, 109], "paper": [103, 110], "pyal": 103, "strongli": 103, "That": [103, 126, 159, 160], "becaus": [103, 106, 116, 119, 122, 127, 148, 150, 153, 158, 160, 162, 164], "extrapol": [103, 107], "beyond": [103, 110], "envelop": [103, 107], "move": 103, "response_method": [103, 104, 105, 107, 138], "odd": [103, 104, 105, 107, 116, 138], "decision_funct": [103, 104, 105, 107, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 157, 161, 163], "peak": [103, 112, 115, 120, 122, 126], "rush": [103, 112, 115, 122, 125], "hour": [103, 112, 115, 116, 120, 122, 125], "around": [103, 105, 112, 115, 120, 122, 126, 130], "draw": [103, 109, 112, 113, 115, 119, 120, 125, 126, 138, 142, 143], "light": 103, "rain": 103, "etc": [103, 119], "heavi": 103, "technic": 103, "subtract": [103, 106, 116, 120, 138], "lighter": 103, "shade": [103, 113], "darker": [103, 113], "quit": [103, 112, 119, 120], "mind": 103, "friedman2008": 104, "h_": [104, 112, 115, 119, 120], "d_j": 104, "d_k": 104, "pd_": 104, "jk": [104, 112, 115, 120], "stronger": [104, 151, 154], "kj": 104, "jerom": [104, 110], "bogdan": 104, "popescu": 104, "rule": [104, 118, 143, 149, 150], "916": 104, "954": 104, "alex2015": 105, "focu": [105, 116, 124, 126, 130], "document": [105, 108, 126, 129], "exist": [105, 110, 112, 113, 115, 116, 120, 122, 130, 138, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "global_ic": 105, "snippet": 105, "produc": [105, 129, 142], "constant": [105, 112, 114, 116, 119, 120, 122, 145, 148, 150, 153, 158, 160, 162, 164], "examin": [105, 122, 125, 129, 134], "our": [105, 106, 108, 110, 113, 124, 126, 130, 142], "apart": 105, "period": [105, 125], "alex": 105, "adam": [105, 152, 153], "kapeln": 105, "justin": 105, "bleich": 105, "emil": 105, "pitkin": 105, "2015": [105, 110], "ribeiro2016": [106, 110], "surrog": [106, 109, 126, 129, 138, 174, 175, 176, 177], "lasso": [106, 110, 116, 156], "proxim": 106, "greatli": [106, 109], "judgment": 106, "sens": 106, "test_sample_s": [106, 109], "train_sample_s": [106, 109], "stem": [106, 117], "crucial": [106, 118, 122, 124, 125, 126, 129, 134], "itself": [106, 116], "unchang": [106, 108, 116, 127, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "essenti": [106, 116, 122, 123, 129, 130], "rather": [106, 116], "becom": [106, 109, 110, 113, 114, 116, 122, 126, 127, 129, 130], "neglig": [106, 116], "am": [106, 112, 115], "now": [106, 116, 124, 133], "mainli": [106, 116], "intercept": [106, 113, 116, 117, 119, 120, 147, 148, 149, 150, 156, 161, 162], "friedman2001": [107, 110], "suppos": [107, 109, 159], "x_c": 107, "mathbb": [107, 112, 113, 114, 115, 116, 117, 119, 120], "dx_": 107, "brute": [107, 134, 144], "partial_depend": [107, 147, 148, 151, 152, 153, 154, 161, 162, 163, 164], "few": [107, 119], "inaccur": 107, "inconsist": 107, "accomplish": [107, 125], "trigger": [107, 116, 117, 119, 129, 147, 148, 149, 150, 152, 153], "tend": [107, 110, 114, 117, 120, 126], "substanti": 107, "4th": 107, "joint": 107, "daytim": 107, "nighttim": 107, "loss": [108, 113, 119, 122, 128, 130, 138, 152, 153, 157, 158, 160, 161, 162, 163, 164, 173, 174, 175, 176, 177], "l2001": 108, "shuffl": [108, 138], "broken": 108, "drop": [108, 116, 127, 130, 147], "relianc": 108, "fulli": [108, 110, 125], "either": [108, 110, 112, 113, 118, 120, 122, 125, 138, 147, 148, 159, 160], "futur": [108, 133, 135, 181], "releas": 108, "truncat": [108, 146], "site": 108, "repetit": [108, 127, 138], "appear": [108, 119, 122], "seem": [108, 109], "surpris": 108, "breiman": 108, "forest": [108, 134, 142], "lundberg2017": [109, 110], "lundberg2018": 109, "concept": 109, "sport": 109, "analogi": 109, "won": 109, "soccer": 109, "game": 109, "winner": 109, "bonu": 109, "fairli": 109, "team": 109, "member": 109, "know": [109, 116, 159, 160], "five": 109, "player": 109, "who": 109, "plai": 109, "victori": 109, "recogn": [109, 124], "come": [109, 110, 147, 148], "success": [109, 117, 147, 148], "imlbook": 109, "shapblog": 109, "possess": 109, "attract": 109, "missing": 109, "decompos": [109, 120], "prime": 109, "phi_0": 109, "phi_j": 109, "z_j": 109, "coalit": 109, "off": [109, 117, 122, 123, 134, 138, 143, 147, 148], "phi_": 109, "shap_": 109, "subseteq": 109, "backslash": 109, "val": 109, "cup": 109, "factor": [109, 119, 126, 130, 139], "accept": [109, 139, 140, 141, 142, 143, 144, 145, 146], "problemat": 109, "affect": [109, 116, 127, 130, 144], "common": [109, 114, 116, 128, 134], "background": 109, "mere": [109, 125], "challeng": [109, 122], "latter": [109, 127, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "break": 109, "interven": 109, "intervent": 109, "inspir": 109, "ignor": [109, 124, 130, 136, 138, 145, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "put": [109, 135, 147, 148], "guarante": 109, "lot": 109, "linearshap": 109, "treeshap": 109, "paragraph": 109, "benefit": 109, "math": 109, "coef": 109, "leaf": [109, 113, 119, 120, 143, 144, 149, 150, 159, 160, 161, 162, 163, 164], "went": 109, "exactli": [109, 114, 119, 147, 148], "bit": 109, "slower": [109, 113], "ll": 109, "i_j": 109, "consum": 109, "place": 109, "had": 109, "greatest": 109, "pdf": 109, "spap": 109, "lundberg": [109, 110], "scott": [109, 110], "gabriel": 109, "erion": 109, "su": [109, 110], "lee": [109, 110], "1802": 109, "03888": 109, "pi": [110, 117], "pai": 110, "em": 110, "el": 110, "access": 110, "grow": [110, 113, 159, 160], "mlop": 110, "platform": [110, 136], "assur": 110, "bank": 110, "project": 110, "supervis": [110, 130], "increasingli": 110, "domain": 110, "lack": 110, "difficult": 110, "emerg": 110, "pedregosa2011": 110, "kokhlikyan2020": 110, "klaise2021": 110, "baniecki2021": 110, "li2022": 110, "black": [110, 112, 117, 120, 135], "pitfal": 110, "rudin2019": 110, "molnar2020": 110, "yang2021a": 110, "yang2021b": [110, 115], "sudjianto2020": [110, 117], "interpretml": 110, "nori2013": [110, 112], "microsoft": [110, 112], "promot": [110, 123], "boost": [110, 111, 113, 119, 133, 138, 147, 148, 161, 162, 163, 164, 181], "ga2m": 110, "lou2013": [110, 112], "sudjianto2021": 110, "discuss": [110, 122, 127], "meantim": 110, "chung2019": 110, "pycaret": 110, "tensorflow": 110, "finra": 110, "toolkit": 110, "Such": [110, 117, 127], "sometim": [110, 146], "demand": [110, 122], "risk": [110, 119], "manag": [110, 138], "routin": [110, 145], "exercis": 110, "conceptu": 110, "sound": 110, "angl": 110, "been": [110, 113, 114, 117, 118, 132], "launch": 110, "2022": 110, "interfac": [110, 138], "widget": 110, "dashboard": 110, "lab": 110, "parameter": 110, "action": 110, "termin": [110, 142, 160], "autom": [110, 146], "registr": [110, 138], "mandatori": 110, "unifi": 110, "glass": 110, "section_3": 110, "section_4": 110, "cover": [110, 128], "treat": [110, 126], "though": 110, "simplif": 110, "worthwhil": 110, "enough": [110, 117, 137], "simplic": 110, "v0": 110, "latest": 110, "updat": [110, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "ell_1": 110, "ell_2": 110, "hastie2015": 110, "spline": [110, 114, 119, 151, 152, 153, 154], "serven2018": 110, "greedi": [110, 111, 138, 147, 148, 149, 150, 181], "tan2022": [110, 113], "extrem": [110, 113, 117], "gradient": [110, 112, 117, 133, 161, 162, 163, 164], "chen2015": 110, "guillermo2020": 110, "purifi": [110, 120], "lengerich2020": [110, 119, 120], "network": [110, 111, 114, 115, 134, 152, 153, 157, 158, 181], "aletheia": [110, 117, 157, 158], "unwrapp": [110, 157, 158], "sparsif": 110, "popular": [110, 116, 122], "quantif": 110, "conform": [110, 125, 138, 169, 170, 171, 172, 173], "cui2023": 110, "out": [110, 117, 119, 126, 130, 134, 152, 153, 157, 158], "de": [110, 117], "art": 110, "expand": [110, 159, 160], "report": 110, "fabian": 110, "pedregosa": 110, "ga\u00ebl": 110, "varoquaux": 110, "alexandr": 110, "gramfort": 110, "vincent": 110, "michel": 110, "bertrand": 110, "thirion": 110, "olivi": 110, "grisel": 110, "mathieu": 110, "blondel": 110, "prettenhof": 110, "ron": 110, "weiss": 110, "dubourg": 110, "jake": 110, "vanderpla": 110, "passo": 110, "david": 110, "cournapeau": 110, "matthieu": 110, "brucher": 110, "perrot": 110, "\u00e9douard": 110, "duchesnai": 110, "2011": 110, "2825": 110, "2830": 110, "narin": 110, "kokhlikyan": 110, "vivek": 110, "miglani": 110, "miguel": 110, "martin": 110, "edward": 110, "bilal": 110, "alsallakh": 110, "jonathan": 110, "reynold": 110, "melnikov": 110, "natalia": 110, "kliushkina": 110, "carlo": 110, "araya": 110, "siqi": 110, "yan": 110, "orion": 110, "reblitz": 110, "richardson": 110, "captum": 110, "librari": [110, 125], "pytorch": [110, 157, 158], "2009": 110, "07896": 110, "jani": 110, "klais": 110, "arnaud": 110, "van": 110, "looveren": 110, "giovanni": 110, "vacanti": 110, "alexandru": 110, "coca": 110, "alibi": 110, "8194": 110, "hubert": 110, "baniecki": 110, "wojciech": 110, "kretowicz": 110, "piotr": 110, "piatyszek": 110, "jakub": 110, "wisniewski": 110, "przemyslaw": 110, "biecek": 110, "dalex": 110, "9759": 110, "9765": 110, "xuhong": 110, "haoyi": 110, "xiong": 110, "xingjian": 110, "xuanyu": 110, "zeyu": 110, "deje": 110, "dou": 110, "interpretdl": 110, "paddlepaddl": 110, "cynthia": 110, "rudin": 110, "stake": 110, "natur": [110, 126, 130, 144], "ntellig": 110, "206": 110, "christoph": 110, "molnar": 110, "gunnar": 110, "k\u00f6nig": 110, "julia": 110, "herbing": 110, "timo": 110, "freiesleben": 110, "susann": 110, "dandl": 110, "christian": 110, "scholbeck": 110, "giusepp": 110, "casalicchio": 110, "moritz": 110, "gross": 110, "wentrup": 110, "bernd": 110, "bischl": 110, "xxai": 110, "workshop": 110, "held": 110, "conjunct": [110, 126], "icml": 110, "juli": 110, "vienna": 110, "austria": 110, "revis": 110, "extend": [110, 113], "cham": 110, "springer": 110, "publish": 110, "harsha": 110, "nori": 110, "samuel": 110, "jenkin": 110, "paul": 110, "koch": 110, "rich": 110, "caruana": 110, "framework": [110, 125], "1909": 110, "09223": 110, "yin": 110, "lou": 110, "johann": 110, "gehrk": 110, "gile": 110, "hooker": 110, "2013": 110, "intellig": 110, "19th": 110, "sigkdd": 110, "623": 110, "631": 110, "agu": 110, "sudjianto": 110, "aijun": 110, "2111": 110, "01743": 110, "yeounoh": 110, "chung": 110, "tim": 110, "kraska": 110, "neokli": 110, "polyzoti": 110, "hyun": 110, "tae": 110, "steven": 110, "euijong": 110, "whang": 110, "finder": 110, "35th": 110, "icd": 110, "1550": 110, "1553": 110, "daniel": 110, "aplei": 110, "jingyu": 110, "zhu": 110, "2016": 110, "royal": 110, "societi": 110, "seri": 110, "82": [110, 127, 130], "1086": 110, "marco": 110, "tulio": 110, "ribeiro": 110, "sameer": 110, "singh": 110, "guestrin": 110, "why": [110, 119], "22nd": 110, "2017": 110, "trevor": 110, "hasti": 110, "robert": 110, "tibshirani": 110, "wainwright": 110, "sparsiti": [110, 115, 143, 146], "crc": 110, "press": 110, "1189": 110, "1232": 110, "serv\u00e9n": 110, "charli": 110, "brummitt": 110, "pygam": [110, 114, 136, 151, 154], "zenodo": 110, "5281": 110, "1208723": 110, "shuo": 110, "tan": 110, "chandan": 110, "keyan": 110, "nasseri": 110, "abhineet": 110, "agarw": 110, "11931": 110, "benjamin": 110, "lengerich": 110, "sarah": 110, "chun": 110, "june": 110, "anova": [110, 120, 147, 148, 151, 152, 153, 154, 161, 162, 163, 164], "recov": 110, "artifici": 110, "2402": 110, "2412": 110, "pmlr": 110, "tianqi": 110, "tong": 110, "william": 110, "knauth": 110, "rahul": 110, "zebin": 110, "yang": 110, "unwrap": [110, 117], "04041": 110, "shiji": 110, "cui": 110, "runz": 110, "hot": [110, 116, 119], "2304": 110, "13761": 110, "architectur": [110, 152, 153], "constraint": [110, 115, 116, 119, 120, 130, 149, 150, 152, 153, 161, 162, 163, 164], "transact": 110, "2610": 110, "2621": 110, "108192": 110, "nava": 110, "palencia": 110, "guillermo": 110, "08025": 110, "additon": 132, "write": 132, "arrai": [128, 132, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "build": [133, 141, 142], "gbm_model": [23, 133], "abl": [113, 114, 133, 135], "rate": [112, 117, 122, 123, 134, 138, 147, 148, 149, 150, 152, 153, 157, 158, 161, 162, 163, 164, 169, 170, 171, 172, 173], "batch": [134, 152, 153, 157, 158], "hidden": [115, 117, 134, 152, 153, 157, 158], "layer": [115, 117, 134, 152, 153, 157, 158], "maxim": [122, 134], "forc": [134, 144], "gridsearchcv": 134, "often": [118, 134], "yield": [127, 134, 138, 146], "randomizedsearchcv": 134, "dictat": [134, 147, 148], "rbf": [134, 145], "linspac": 134, "cv": [134, 138], "fold": [134, 138], "integ": [113, 134, 138, 142, 147, 148, 159, 160], "alloc": 134, "absenc": 134, "invok": 134, "constitut": 134, "upon": [117, 122, 134], "proce": [120, 127, 134], "965160": 134, "432415": 134, "303924": 134, "095008": 134, "485461": 134, "885018": 134, "912729": 134, "948782": 134, "801720": 134, "921155": 134, "negat": 134, "simpler": [114, 117, 119, 134], "retriev": [134, 138], "refin": [126, 134], "pickl": [135, 138], "don": [135, 159, 160], "lgbm7": 135, "lgbm_7": 135, "mu": [112, 113, 114, 115, 116, 119, 120], "limits_": [112, 115, 119, 120], "f_": [112, 113, 114, 115, 120], "shallow": [112, 118], "round": [112, 127, 147, 148], "fashion": [112, 159, 160], "cut": [112, 138, 147, 148], "pick": [112, 138], "converg": [112, 117, 120, 151, 154], "piecewis": [112, 114, 115, 119, 120], "sacrific": [112, 123], "256": [112, 142, 147, 148, 161, 162, 163, 164], "togeth": [112, 114, 115, 116, 117, 152, 153], "pm": [112, 115], "somehow": 112, "night": 112, "spring": 112, "domin": [112, 120], "titl": [112, 113, 115, 119, 120], "0818": 112, "almost": 112, "recent": [113, 136], "cart": 113, "f_k": 113, "mathbf": 113, "manner": [113, 126, 138], "pseudo": [113, 138, 142], "express": [113, 114, 117, 120, 152, 153], "form": [113, 116, 117, 118, 120, 122, 143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "whichev": 113, "imodel": [113, 149, 150], "unlimit": [113, 159, 160], "criteria": [113, 126, 159, 160], "hardli": 113, "complic": [113, 117], "gain": [113, 122, 124, 126, 159], "along": [113, 122, 127, 130], "hierarch": 113, "dendrogram": 113, "subplot": [113, 117, 122], "middl": [113, 122], "deeper": [113, 125], "rightmost": 113, "convei": 113, "decision_tre": 113, "099": 113, "094": 113, "primari": [114, 148], "equat": [114, 117, 159, 160], "unknown": 114, "smooth": [114, 115, 122, 147, 148, 149, 150, 151, 154, 159, 160], "varieti": 114, "degre": [114, 124, 141, 145], "quadrat": 114, "cubic": 114, "knot": 114, "anchor": 114, "With": [114, 116, 119, 126], "poorer": [114, 126], "penalti": [114, 116, 117, 151, 154], "encourag": 114, "generaliz": 114, "smoother": 114, "rougher": 114, "slope": 114, "flat": 114, "steep": 114, "sharp": 114, "incom": 114, "area": [114, 122, 123, 124, 126, 127, 130], "_j": [114, 119], "strongest": 114, "drive": 114, "3804": 114, "reformul": 115, "disentangl": [115, 117], "feedforward": [115, 117], "subnetwork": [115, 152, 153], "parsimoni": [115, 120], "hered": [115, 152, 153], "least": [115, 117, 119, 149, 150, 156, 159, 160], "parent": 115, "clariti": [115, 129, 152, 153], "purif": [115, 120], "constrain": [115, 119, 122], "decreas": [115, 119, 126, 149, 150, 152, 153, 159, 160, 161, 162, 163, 164], "impos": [115, 152, 153, 157, 158], "gaminet": 115, "prune": [115, 120, 152, 153, 159, 160], "trivial": [115, 117, 120], "retrain": 115, "simultan": 115, "fine": [115, 152, 153], "activ": [115, 117, 120, 152, 153, 157, 158], "saturdai": 115, "sundai": 115, "mondai": 115, "fridai": 115, "compon": [115, 117, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "literatur": 116, "reader": 116, "consult": 116, "mccullagh1989": 116, "w_1": 116, "x_1": 116, "w_2": 116, "x_2": 116, "w_d": 116, "x_d": 116, "logit": [116, 147, 163], "l2": [116, 144, 155, 156, 160, 161, 162, 163, 164], "penal": [116, 117, 152, 153], "shrink": [116, 117, 145], "toward": [116, 117], "spars": [116, 139, 140, 141, 142, 143, 144, 145, 146, 159, 160], "shrunk": 116, "variant": [116, 119], "linear_model": 116, "linearregress": 116, "ridg": [116, 156], "elasticnet": [116, 156], "elast": 116, "logisticregress": 116, "address": [116, 123, 124, 130], "opposit": [116, 145], "temperatur": [116, 120, 128], "humid": 116, "convert": [116, 127, 138, 146, 147, 148, 159, 160], "dummi": 116, "season_1": 116, "season_2": 116, "season_3": 116, "season_4": 116, "overparameter": 116, "fourth": 116, "nonlinear": [116, 117], "print": 116, "screen": [116, 152, 153], "export": 116, "w_j": 116, "absorb": 116, "unstabl": [116, 117, 127], "turn": [116, 119, 138, 147, 148, 152, 153], "mccullagh": 116, "nelder": 116, "1989": 116, "chapman": 116, "hall": 116, "edit": 116, "rectifi": 117, "remark": 117, "appeal": 117, "excel": 117, "intrins": 117, "neuron": 117, "chi": 117, "mbox": 117, "sigmoid": [117, 145, 152, 153], "despit": 117, "said": 117, "equiv": 117, "n_l": 117, "simplifi": [117, 119, 128], "tild": 117, "oper": [117, 118, 125], "tupl": [117, 138, 143, 145, 147, 148, 151, 152, 153, 154, 157, 158, 161, 162, 163, 164, 165, 166, 168, 169, 170, 171, 172, 174, 175, 176, 177, 178], "poor": [117, 124, 126], "1e": [117, 138, 145, 147, 148, 152, 153, 157, 158], "descent": 117, "unpen": 117, "float": [117, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 168, 169, 170, 171, 172, 173, 174, 176, 177, 178], "unnecessarili": 117, "wherea": 117, "5153": 117, "105570": 117, "584421": 117, "735054": 117, "static": 117, "wide": 117, "roughli": 117, "vice": [117, 147, 148], "versa": [117, 147, 148], "eleg": 117, "diagon": [117, 122], "decomposit": [117, 119], "uniformli": [117, 152, 153], "sin": 117, "epsilon": 117, "n_featur": [117, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "influenti": 118, "decisiontreeregressor": 118, "criterion": [118, 145, 159, 160], "branch": [118, 142, 149, 150, 159, 160], "restrict": 119, "stump": 119, "stage": [119, 147, 148, 152, 153, 157, 158], "optbin": [119, 136], "woe": 119, "firstli": 119, "arrang": 119, "inherit": [119, 120], "tree_method": [119, 120, 161, 162, 163, 164], "correctli": [119, 122, 145, 147, 149, 152, 157, 159, 161, 163], "max_n_bin": 119, "strike": 119, "difficulti": [119, 126], "fit_method": 119, "iv": 119, "accompani": [119, 126, 130], "trend": [119, 122, 126], "plateau": 119, "geograph": 119, "amplifi": 119, "lontitud": 119, "restructur": 120, "enforc": [120, 151, 154], "feel": 120, "celsiu": 120, "comfort": 120, "outdoor": 120, "cooler": 120, "hotter": 120, "peopl": 120, "willing": 120, "ride": 120, "bicycl": 120, "0606": 120, "summat": 120, "plu": [120, 122], "regardless": 122, "showcas": [122, 129], "ideal": [122, 125], "band": 122, "residual_plot": 122, "wider": 122, "logic": 122, "evenli": 122, "lastli": 122, "_predict": 122, "earlier": 122, "imbalanc": 122, "incorrect": [122, 127, 130], "guess": [122, 146], "harmon": 122, "2tp": 122, "fp": 122, "fn": 122, "diverg": 122, "p_": 122, "scatterplot": 122, "lowess": 122, "match": [122, 136, 138], "tp": 122, "tn": 122, "mislabel": 122, "tpr": 122, "fpr": 122, "closer": 122, "corner": 122, "maintain": 122, "irrelev": 122, "tradeoff": 122, "imparti": 123, "ethnic": 123, "sexual": 123, "orient": 123, "disabl": [123, 138], "subscript": 123, "tp_": 123, "fp_": 123, "fn_": 123, "smd": [123, 138], "binar": [123, 138], "bucket": [123, 129, 138, 174], "granular": 123, "span": 123, "enumer": 123, "dash": 123, "ax": 123, "character": 124, "strong": 124, "allevi": 124, "empow": 124, "promin": 124, "tendenc": 124, "warn": [124, 130, 145, 159, 160], "messag": [124, 130, 136], "emphasi": 124, "7am": 124, "9am": 124, "0171": 124, "0156": 124, "exce": [124, 125], "insuffici": [124, 130], "confid": 125, "crqr": 125, "interchang": 125, "epsilon_": 125, "s_": 125, "histgradientboostingregressor": 125, "gbdt": 125, "delv": 125, "clarifi": 125, "whose": 125, "wise": [125, 146], "233": 125, "2563": 125, "establish": 125, "notion": 125, "yet": 125, "matur": 125, "isoton": 125, "analog": 125, "sustain": 126, "face": 126, "verifi": 126, "unexpect": [126, 127], "facilit": [126, 129], "At": 126, "divers": 126, "likelihood": 126, "sophist": 126, "harder": 126, "inde": 126, "poorest": 126, "increment": 126, "hover": 126, "interestingli": 126, "gradual": 126, "declin": 126, "plausibl": 126, "outperform": 126, "fluctuat": 126, "variat": [126, 127], "thought": 126, "recalcul": 126, "moder": 126, "encount": 127, "noisi": 127, "delta": [127, 147, 148], "ten": 127, "throughout": 127, "forthcom": 127, "lambda": [127, 157, 158], "var": [127, 145], "invalid": 127, "tail": 127, "solv": 127, "nearest": [127, 144], "back": 127, "kept": [127, 146], "were": 127, "previous": 127, "wors": [127, 148, 150, 153, 158, 160, 162, 164], "poorli": 127, "absent": 128, "necessit": 128, "convent": 128, "prefix": 128, "test_reliability_t": 128, "consolid": 128, "pass": [128, 138, 142, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164], "caus": 129, "underperform": [129, 130], "analys": 129, "filter": [129, 130], "quickli": 129, "018380": [71, 129], "014116": [71, 129], "013335": [71, 129], "013161": [71, 129], "012643": [71, 129], "011245": [71, 129], "011149": [71, 129], "010764": [71, 129], "010634": [71, 129], "010363": [71, 129], "weakest": 129, "test_accuraci": 129, "0692": 129, "8144": 129, "0089": 129, "0721": 129, "8018": 129, "nevertheless": 129, "instrument": 129, "comprehend": 129, "undefin": 129, "twosample_test": 129, "reason": 129, "prone": 130, "aris": 130, "inadequ": 130, "unsuit": 130, "suffici": 130, "merg": 130, "min_samples_leaf": [130, 143, 147, 148, 149, 150, 159, 160], "accordingli": 130, "simpli": 130, "723": 130, "boolean": [130, 149, 150], "annot": 130, "test_metr": 130, "train_metr": 130, "sai": 130, "retain": [130, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "o": 136, "py37": 136, "py38": 136, "py39": 136, "py310": 136, "win": 136, "linux": 136, "maco": 136, "mac": 136, "m1": 136, "pip": 136, "cmake": 136, "conda": 136, "ipykernel": 136, "ipywidget": 136, "joblib": [136, 138, 142, 147, 148], "ipython": 136, "matplotlib": 136, "seaborn": 136, "xlrd": 136, "torch": [136, 152, 153], "natsort": 136, "psutil": 136, "dill": 136, "ortool": 136, "momentchi2": 136, "got": 136, "upgrad": 136, "reinstal": 136, "forg": 136, "runtimeerror": 136, "traceback": 136, "compil": 136, "0x10": 136, "0xf": 136, "restart": 136, "runtim": [136, 138, 142, 145], "guidelin": 137, "bool": [138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 166, 178], "css": 138, "ingest": 138, "look": [138, 159, 160], "union": [138, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "unicod": [138, 147, 148], "dict": [138, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "reset": 138, "preview": 138, "mi": 138, "n_samples_train": [138, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "n_samples_test": [138, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "score_distribut": 138, "marginal_outlier_distribut": 138, "multi_featur": 138, "forward": 138, "backward": 138, "earli": [138, 147, 148, 149, 150, 152, 153, 157, 158], "fbedk": 138, "ndarrai": [138, 139, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "n_sampl": [138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "Not": [138, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "get_interpretable_model_list": 138, "get_leaderboard": 138, "model_nam": 138, "get_leaderboard_regist": 138, "modelpipelin": 138, "get_model_config": 138, "get_model_list": 138, "get_raw_data": 138, "datatupl": 138, "train_sample_weight": 138, "test_sample_weight": 138, "fit_func": 138, "excluded_featur": 138, "normalize_strategi": 138, "encode_strategi": 138, "rais": [138, 145, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "callabl": [138, 143, 144, 145], "receiv": 138, "one_hot": 138, "_estimator_typ": 138, "minmax": 138, "unit_norm": 138, "regressor": [138, 148, 150, 153, 154, 156, 158, 160, 162, 164], "insid": [138, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 170], "testresult": 138, "tri": 138, "revert": 138, "metric_threshold": 138, "favorable_class": 138, "thresholding_bin": 138, "by_weight": 138, "rsmd": 138, "categorical_feature_nam": 138, "useless": 138, "savedmodel": 138, "get_all_supported_model": 138, "exhaust": 138, "solut": [138, 142], "kfold": 138, "splitter": [138, 149, 150, 159, 160], "multiclass": [138, 147], "stratifiedkfold": 138, "instanti": 138, "job": [138, 140, 142, 144, 147, 148], "parallel_backend": [138, 142], "processor": [138, 142, 144], "glossari": 138, "slice_bin": 138, "weaskspot": 138, "clustering_method": 139, "clustering_threshold": 139, "use_weight": 139, "gmm": 139, "base_estimator_": [139, 142], "is_fitted_": [139, 143, 152, 153, 157, 158, 161, 162, 163, 164], "cluster_centers_": 139, "cluster_sizes_": 139, "small_cluster_labels_": 139, "large_cluster_labels_": 139, "detector": [139, 140, 141, 142, 143, 144, 145, 146], "outlier_scor": [139, 140, 141, 142, 143, 144, 145, 146], "outlier_ind": [139, 140, 141, 142, 143, 144, 145, 146], "pyod": [140, 141], "free": 140, "core": [140, 152, 153], "n_bin": 141, "tol": [141, 145, 146], "outlying": 141, "birg": 141, "rozenblac": 141, "max_sampl": 142, "max_featur": [142, 159, 160], "bootstrap": 142, "warm_start": [142, 152, 153], "isol": 142, "n_features_in_": [142, 143, 145, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "randomst": [142, 159, 160], "reus": 142, "estimator_": 142, "extratreeregressor": 142, "templat": 142, "sub": [142, 147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "estimators_": 142, "estimators_features_": 142, "drawn": 142, "estimators_samples_": 142, "bag": [142, 147, 148], "max_samples_": 142, "offset_": [142, 145], "offset": [142, 145], "score_sampl": [142, 145], "contamin": 142, "inlier": 142, "seen": [142, 145], "feature_names_in_": [142, 145, 147, 148], "n_compon": [143, 146], "d_reduction_method": [143, 146], "min_dist": 143, "distance_measur": 143, "reconsterr": 143, "distance_measure_param": 143, "sparsepca": 143, "sparse_pca": 143, "n_samples1": 143, "n_samples2": 143, "tree_": [143, 159, 160], "node_count_": 143, "leaf_idx_list_": 143, "calculate_spca": 143, "dist": 143, "decision_path": [143, 159, 160], "path_al": 143, "node_count": [143, 159, 160], "get_metadata_rout": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "metadata": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "rout": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "metadatarequest": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "encapsul": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "get_param": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "subobject": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "map": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "get_rul": 143, "node_id": 143, "inequ": 143, "plot_tre": 143, "draw_depth": 143, "start_node_id": 143, "predict_leaf_id": 143, "set_param": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "nest": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "__": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "self": [143, 147, 148, 149, 150, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164], "n_neighbor": 144, "radiu": 144, "leaf_siz": 144, "minkowski": 144, "metric_param": 144, "score_method": 144, "neighbor": 144, "ball_tre": 144, "kd_tree": 144, "balltre": 144, "kdtree": 144, "attempt": 144, "overrid": 144, "queri": 144, "store": 144, "precomput": [144, 145, 148, 150, 153, 158, 160, 162, 164], "nonzero": 144, "pairwise_dist": 144, "manhattan_dist": 144, "euclidean_dist": 144, "minkowski_dist": 144, "l_p": 144, "coef0": 145, "nu": 145, "cache_s": 145, "libsvm": 145, "poli": 145, "toler": [145, 146, 147, 148, 152, 153], "fraction": [145, 159, 160, 161, 162], "heurist": 145, "cach": 145, "properli": 145, "multithread": 145, "solver": [145, 146, 151, 154], "class_weight_": 145, "n_class": [145, 147, 159], "class_weight": [145, 159], "coef_": 145, "primal": 145, "readonli": 145, "dual_coef_": 145, "support_vectors_": 145, "n_sv": 145, "fit_status_": 145, "intercept_": [145, 147, 148, 149, 150, 161, 162], "n_iter_": [145, 149, 150], "n_support_": 145, "dtype": [145, 159, 160], "int32": 145, "shape_fit_": 145, "n_dimensions_of_x": 145, "support_": 145, "n_selected_compon": 146, "cumulative_vari": 146, "score_typ": 146, "copi": 146, "whiten": 146, "svd_solver": 146, "iterated_pow": 146, "mle": 146, "minka": 146, "arpack": 146, "princip": 146, "overwritten": 146, "fit_transform": 146, "components_": 146, "singular": 146, "uncorrel": 146, "signal": 146, "downstream": 146, "wire": 146, "polici": 146, "500x500": 146, "exact": [146, 161, 162, 163, 164], "svd": 146, "afterward": 146, "lapack": 146, "linalg": 146, "postprocess": 146, "strictli": 146, "halko": 146, "et": 146, "sparser": 146, "auto_exampl": 146, "plot_scaling_import": 146, "sequenc": [147, 148], "max_interaction_bin": [147, 148], "validation_s": [147, 148], "outer_bag": [147, 148], "inner_bag": [147, 148], "smoothing_round": [147, 148], "max_round": [147, 148], "early_stopping_toler": [147, 148], "0001": [147, 148, 152, 153], "log_loss": [147, 159], "featuretyp": [147, 148], "inner": [147, 148], "robin": [147, 148], "intermix": [147, 148], "cyclic": [147, 148], "n_term": [147, 148], "n_cpu": [147, 148], "eg": [147, 148], "thread": [147, 148], "device_random": [147, 148], "classes_": [147, 159], "resolv": [147, 148], "feature_types_in_": [147, 148], "nomin": [147, 148], "bins_": [147, 148], "n_cut": [147, 148], "resolut": [147, 148], "item": [147, 148], "feature_bounds_": [147, 148], "feature_index": [147, 148], "histogram_edges_": [147, 148], "n_hist_edg": [147, 148], "edg": [147, 148], "histogram_weights_": [147, 148], "n_hist_bin": [147, 148], "unique_val_counts_": [147, 148], "term_features_": [147, 148], "term_names_": [147, 148], "bin_weights_": [147, 148], "n_feature0_bin": [147, 148], "n_featuren_bin": [147, 148], "tensor": [147, 148, 152, 153], "bagged_scores_": [147, 148], "n_outer_bag": [147, 148], "term_scores_": [147, 148], "standard_deviations_": [147, 148], "link_": [147, 148], "invers": [147, 148, 159], "custom_classif": 147, "probit": 147, "cloglog": 147, "loglog": 147, "cauchit": 147, "link_param_": [147, 148], "bag_weights_": [147, 148], "breakpoint_iteration_": [147, 148], "n_stage": [147, 148], "init_scor": [147, 148], "softmax": [147, 148, 151, 152, 157, 158, 163], "pred": [147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 161, 162, 163, 164], "content": [147, 148], "parse_model": [147, 148, 149, 150, 151, 152, 153, 154, 157, 158, 159, 160, 161, 162, 163, 164], "fanovainterpret": [147, 148, 151, 152, 153, 154, 161, 162, 163, 164], "fidx": [147, 148, 151, 152, 153, 154, 161, 162, 163, 164], "multi": [147, 149, 152, 157, 158, 159, 161, 163], "harsh": [147, 149, 152, 157, 159, 161, 163], "n_output": [147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "set_score_request": [147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "request": [147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "enable_metadata_rout": [147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "set_config": [147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "alia": [147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "metadata_rout": [147, 148, 149, 150, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164], "rmse": 148, "poisson_devi": 148, "tweedie_devi": 148, "variance_pow": 148, "gamma_devi": 148, "pseudo_hub": 148, "rmse_log": 148, "custom_regress": 148, "inverse_squar": 148, "min_target_": 148, "max_target_": 148, "y_true": [148, 150, 153, 158, 160, 162, 164], "y_pred": [148, 150, 153, 158, 160, 162, 164], "arbitrarili": [148, 150, 153, 158, 160, 162, 164], "disregard": [148, 150, 153, 158, 160, 162, 164], "n_samples_fit": [148, 150, 153, 158, 160, 162, 164], "multioutput": [148, 150, 153, 158, 159, 160, 162, 164], "uniform_averag": [148, 150, 153, 158, 160, 162, 164], "r2_score": [148, 150, 153, 158, 160, 162, 164], "multioutputregressor": [148, 150, 153, 158, 160, 162, 164], "min_impurity_decreas": [149, 150, 159, 160], "concis": [149, 150], "csinva": [149, 150], "induc": [149, 150, 159, 160], "impur": [149, 150, 159, 160], "feature_names_": [149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "feature_types_": [149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "trees_": [149, 150], "n_tree_": [149, 150], "early_stop_": [149, 150], "figsinterpret": [149, 150], "pred_proba": [149, 152, 157, 161, 163], "interact_num": [152, 153], "subnet_size_main_effect": [152, 153], "subnet_size_interact": [152, 153], "activation_func": [152, 153], "max_epoch": [152, 153, 157, 158], "early_stop_thr": [152, 153], "batch_siz": [152, 153, 157, 158], "batch_size_infer": [152, 153, 157, 158], "max_iter_per_epoch": [152, 153], "val_ratio": [152, 153, 157, 158], "gam_sample_s": [152, 153], "mlp_sample_s": [152, 153], "reg_clar": [152, 153], "loss_threshold": [152, 153], "reg_mono": [152, 153], "mono_sample_s": [152, 153], "include_interaction_list": [152, 153], "boundary_clip": [152, 153], "devic": [152, 153, 157, 158], "cpu": [152, 153, 157, 158], "tanh": [152, 153], "epoch": [152, 153, 157, 158], "clip": [152, 153], "reshuffl": [152, 153], "rough": [152, 153], "teacher": [152, 153], "feature_name1": [152, 153], "feature_name2": [152, 153], "hardwar": [152, 153], "net_": [152, 153, 157, 158], "data_dict_density_": [152, 153], "err_train_main_effect_training_": [152, 153], "err_val_main_effect_training_": [152, 153], "err_train_interaction_training_": [152, 153], "err_val_interaction_training_": [152, 153], "err_train_tuning_": [152, 153], "err_val_tuning_": [152, 153], "interaction_list_": [152, 153], "active_main_effect_index_": [152, 153], "active_interaction_index_": [152, 153], "main_effect_val_loss_": [152, 153], "interaction_val_loss_": [152, 153], "time_cost_": [152, 153], "cost": [152, 153, 159, 160], "clarity_": [152, 153], "monotonicity_": [152, 153], "n_interactions_": [152, 153], "dummy_values_": [152, 153], "cfeature_num_": [152, 153], "nfeature_num_": [152, 153], "cfeature_names_": [152, 153], "nfeature_names_": [152, 153], "cfeature_index_list_": [152, 153], "nfeature_index_list_": [152, 153], "num_classes_list_": [152, 153], "mu_list_": [152, 153], "std_list_": [152, 153], "min_value_": [152, 153, 161, 162], "max_value_": [152, 153, 161, 162], "mono_increasing_list_index_": [152, 153], "mono_decreasing_list_index_": [152, 153], "include_interaction_list_index_": [152, 153], "training_generator_": [152, 153], "fasttensordataload": [152, 153], "validation_generator_": [152, 153], "warm_init_main_effect_data_": [152, 153], "warm": [152, 153], "warm_init_interaction_data_": [152, 153], "main_effect_norm_": [152, 153], "interaction_norm_": [152, 153], "feature_importance_": 152, "data_dict_global_": [152, 153], "global_explain": [152, 153], "certify_mono": [152, 153], "certifi": [152, 153], "satisfi": [152, 153], "mono_statu": [152, 153], "main_effect": [152, 153], "fine_tune_select": [152, 153], "main_effect_list": [152, 153], "interaction_list": [152, 153], "lr": [152, 153], "unselect": [152, 153], "norm": [152, 153], "get_clarity_loss": [152, 153], "clarity_loss": [152, 153], "get_interaction_raw_output": [152, 153], "n_interact": [152, 153], "get_main_effect_raw_output": [152, 153], "get_mono_loss": [152, 153], "mono_loss": [152, 153], "get_raw_output": [152, 153, 157, 158, 161, 162], "folder": [152, 153], "disk": [152, 153], "partial_deriv": [152, 153], "arg": 155, "kwarg": 155, "fit_intercept": 156, "ordinari": 156, "dropout_prob": [157, 158], "n_epoch_no_chang": [157, 158], "iht": [157, 158], "phase_epoch": [157, 158], "perceptron": [157, 158], "dropout": [157, 158], "doesn": [157, 158], "early_stop": [157, 158], "cuda": [157, 158], "coefs_": [157, 158], "len": [157, 158], "ith": [157, 158], "intercepts_": [157, 158], "no_improved_count_": [157, 158], "train_epoch_loss_": [157, 158], "valid_epoch_loss_": [157, 158], "reludnninterpreterregressor": [157, 158], "gini": [159, 160], "min_samples_split": [159, 160], "min_weight_fraction_leaf": [159, 160], "max_leaf_nod": [159, 160], "ccp_alpha": [159, 160], "docstr": [159, 160], "shannon": 159, "pure": [159, 160], "ceil": [159, 160], "log2": [159, 160], "determinist": [159, 160], "behaviour": [159, 160], "n_t": [159, 160], "n_t_r": [159, 160], "right_impur": [159, 160], "n_t_l": [159, 160], "left_impur": [159, 160], "class_label": 159, "multilabel": 159, "bincount": 159, "subtre": [159, 160], "feature_importances_": [159, 160], "max_features_": [159, 160], "n_classes_": 159, "n_outputs_": [159, 160], "check_input": [159, 160], "float32": [159, 160], "csr_matrix": [159, 160], "bypass": [159, 160], "what": [159, 160], "x_leav": [159, 160], "datapoint": [159, 160], "possibli": [159, 160], "cost_complexity_pruning_path": [159, 160], "minimal_cost_complexity_prun": [159, 160], "csc_matrix": [159, 160], "ccp_path": [159, 160], "bunch": [159, 160], "n_node": [159, 160], "csr": [159, 160], "goe": [159, 160], "brought": [159, 160], "mislead": [159, 160], "cardin": [159, 160], "get_depth": [159, 160], "get_n_leav": [159, 160], "n_leav": [159, 160], "treeinterpret": [159, 160], "predict_log_proba": 159, "set_fit_request": [159, 160], "set_predict_proba_request": 159, "set_predict_request": [159, 160], "squared_error": 160, "friedman_ms": 160, "absolute_error": 160, "poisson": 160, "devianc": 160, "refit_method": [161, 162], "max_bin_s": [161, 162], "xgboostclassifi": [161, 163], "hist": [161, 162, 163, 164], "approx": [161, 162, 163, 164], "gpu_hist": [161, 162, 163, 164], "split_info_": [161, 162, 163, 164], "n_splits_raw_": [161, 162, 163, 164], "n_splits_": [161, 162, 163, 164], "xgb_params_": [161, 162, 163, 164], "effects_": [161, 162], "xgboostregressor": [162, 164], "prediciton": [165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "prediciton_proba": [165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "classificaiton": [165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "clust": [174, 175, 176, 177], "plan": 181, "988": [], "678548": [], "716495": [], "576134": [], "632684": [], "020826": [], "477170": [], "475025": [], "512815": [], "527018": [], "521386": [], "040122": [], "045322": [], "039150": [], "046337": [], "040150": [], "042424": [], "037943": [], "038105": [], "040811": [], "042970": [], "886": [], "2509": 22, "3531": 22, "8112": 22, "2857": 22, "3691": 22, "7872": 22, "0348": 22, "0508": 22, "1594": 22, "9617": 22, "2363": 22, "3158": 22, "8240": 22, "1855": 22, "1377": 22, "819": [], "plot_2_register_0_sklearn": [22, 25], "196": [], "plot_2_register_1_h2o": [23, 25], "9537": 24, "0983": 24, "0313": 24, "9966": 24, "9545": 24, "0764": 24, "0244": 24, "797": [], "plot_2_register_2_arbitrari": [24, 25], "288": [], "auto_examples_1_train": 25, "674": 19, "674156": 20, "981528": 20, "933432": 20, "523289": 20, "211272": 20, "522839": 20, "524328": 20, "662398": 20, "523580": 20, "584545": 20, "724": [20, 25], "058955": 21, "049783": 21, "070307": 21, "054850": 21, "038847": 21, "046059": 21, "041242": 21, "047853": 21, "046578": 21, "044768": 21, "760": [21, 25], "249": [22, 25], "568": [23, 25], "009": [24, 25], "310": 25, "0x0000020332a6b820": 70, "539683": 70, "597536": 70, "597701": 70, "603478": 70, "619318": 70, "623762": 70, "624535": 70, "625000": 70, "635417": 70, "644645": 70, "0x00000203172f50d0": 70, "650224": 70, "658228": 70, "675603": 70, "688889": 70, "724436": 70, "795455": 70, "680": [70, 74], "0x00000203177a7ee0": 71, "0x00000203177b2ca0": 71, "007795": 71, "005194": 71, "001655": 71, "184": [71, 74], "863": 74, "048": [], "stand": 116, "829": [38, 55]}, "objects": {"piml": [[138, 0, 1, "", "Experiment"]], "piml.Experiment": [[138, 1, 1, "", "data_loader"], [138, 1, 1, "", "data_prepare"], [138, 1, 1, "", "data_quality"], [138, 1, 1, "", "data_summary"], [138, 1, 1, "", "eda"], [138, 1, 1, "", "feature_select"], [138, 1, 1, "", "get_data"], [138, 1, 1, "", "get_feature_names"], [138, 1, 1, "", "get_feature_types"], [138, 1, 1, "", "get_interpretable_model_list"], [138, 1, 1, "", "get_leaderboard"], [138, 1, 1, "", "get_leaderboard_registered"], [138, 1, 1, "", "get_model"], [138, 1, 1, "", "get_model_config"], [138, 1, 1, "", "get_model_list"], [138, 1, 1, "", "get_raw_data"], [138, 1, 1, "", "get_target_name"], [138, 1, 1, "", "make_pipeline"], [138, 1, 1, "", "model_compare"], [138, 1, 1, "", "model_diagnose"], [138, 1, 1, "", "model_explain"], [138, 1, 1, "", "model_fairness"], [138, 1, 1, "", "model_fairness_compare"], [138, 1, 1, "", "model_fairness_solas"], [138, 1, 1, "", "model_interpret"], [138, 1, 1, "", "model_save"], [138, 1, 1, "", "model_train"], [138, 1, 1, "", "model_tune"], [138, 1, 1, "", "register"], [138, 1, 1, "", "segmented_diagnose"]], "piml.data.outlier_detection": [[139, 0, 1, "", "CBLOF"], [140, 0, 1, "", "ECOD"], [141, 0, 1, "", "HBOS"], [142, 0, 1, "", "IsolationForest"], [143, 0, 1, "", "KMeansTree"], [144, 0, 1, "", "KNN"], [145, 0, 1, "", "OneClassSVM"], [146, 0, 1, "", "PCA"]], "piml.data.outlier_detection.CBLOF": [[139, 1, 1, "", "decision_function"], [139, 1, 1, "", "fit"], [139, 1, 1, "", "predict"]], "piml.data.outlier_detection.ECOD": [[140, 1, 1, "", "decision_function"], [140, 1, 1, "", "fit"], [140, 1, 1, "", "predict"]], "piml.data.outlier_detection.HBOS": [[141, 1, 1, "", "decision_function"], [141, 1, 1, "", "fit"], [141, 1, 1, "", "predict"]], "piml.data.outlier_detection.IsolationForest": [[142, 1, 1, "", "decision_function"], [142, 1, 1, "", "fit"], [142, 1, 1, "", "predict"]], "piml.data.outlier_detection.KMeansTree": [[143, 1, 1, "", "decision_function"], [143, 1, 1, "", "decision_path"], [143, 1, 1, "", "fit"], [143, 1, 1, "", "get_metadata_routing"], [143, 1, 1, "", "get_params"], [143, 1, 1, "", "get_rule"], [143, 1, 1, "", "plot_tree"], [143, 1, 1, "", "predict"], [143, 1, 1, "", "predict_leaf_id"], [143, 1, 1, "", "set_params"]], "piml.data.outlier_detection.KNN": [[144, 1, 1, "", "decision_function"], [144, 1, 1, "", "fit"], [144, 1, 1, "", "predict"]], "piml.data.outlier_detection.OneClassSVM": [[145, 1, 1, "", "decision_function"], [145, 1, 1, "", "fit"], [145, 1, 1, "", "predict"]], "piml.data.outlier_detection.PCA": [[146, 1, 1, "", "decision_function"], [146, 1, 1, "", "fit"], [146, 1, 1, "", "predict"]], "piml.models": [[147, 0, 1, "", "ExplainableBoostingClassifier"], [148, 0, 1, "", "ExplainableBoostingRegressor"], [149, 0, 1, "", "FIGSClassifier"], [150, 0, 1, "", "FIGSRegressor"], [151, 0, 1, "", "GAMClassifier"], [152, 0, 1, "", "GAMINetClassifier"], [153, 0, 1, "", "GAMINetRegressor"], [154, 0, 1, "", "GAMRegressor"], [155, 0, 1, "", "GLMClassifier"], [156, 0, 1, "", "GLMRegressor"], [157, 0, 1, "", "ReluDNNClassifier"], [158, 0, 1, "", "ReluDNNRegressor"], [159, 0, 1, "", "TreeClassifier"], [160, 0, 1, "", "TreeRegressor"], [161, 0, 1, "", "XGB1Classifier"], [162, 0, 1, "", "XGB1Regressor"], [163, 0, 1, "", "XGB2Classifier"], [164, 0, 1, "", "XGB2Regressor"]], "piml.models.ExplainableBoostingClassifier": [[147, 1, 1, "", "decision_function"], [147, 1, 1, "", "fit"], [147, 1, 1, "", "get_metadata_routing"], [147, 1, 1, "", "get_params"], [147, 1, 1, "", "parse_model"], [147, 1, 1, "", "partial_dependence"], [147, 1, 1, "", "predict"], [147, 1, 1, "", "predict_proba"], [147, 1, 1, "", "score"], [147, 1, 1, "", "set_params"], [147, 1, 1, "", "set_score_request"]], "piml.models.ExplainableBoostingRegressor": [[148, 1, 1, "", "decision_function"], [148, 1, 1, "", "fit"], [148, 1, 1, "", "get_metadata_routing"], [148, 1, 1, "", "get_params"], [148, 1, 1, "", "parse_model"], [148, 1, 1, "", "partial_dependence"], [148, 1, 1, "", "predict"], [148, 1, 1, "", "score"], [148, 1, 1, "", "set_params"], [148, 1, 1, "", "set_score_request"]], "piml.models.FIGSClassifier": [[149, 1, 1, "", "decision_function"], [149, 1, 1, "", "fit"], [149, 1, 1, "", "get_metadata_routing"], [149, 1, 1, "", "get_params"], [149, 1, 1, "", "parse_model"], [149, 1, 1, "", "predict"], [149, 1, 1, "", "predict_proba"], [149, 1, 1, "", "score"], [149, 1, 1, "", "set_params"], [149, 1, 1, "", "set_score_request"]], "piml.models.FIGSRegressor": [[150, 1, 1, "", "fit"], [150, 1, 1, "", "get_metadata_routing"], [150, 1, 1, "", "get_params"], [150, 1, 1, "", "parse_model"], [150, 1, 1, "", "predict"], [150, 1, 1, "", "score"], [150, 1, 1, "", "set_params"], [150, 1, 1, "", "set_score_request"]], "piml.models.GAMClassifier": [[151, 1, 1, "", "decision_function"], [151, 1, 1, "", "fit"], [151, 1, 1, "", "get_metadata_routing"], [151, 1, 1, "", "get_params"], [151, 1, 1, "", "parse_model"], [151, 1, 1, "", "partial_dependence"], [151, 1, 1, "", "predict"], [151, 1, 1, "", "predict_proba"], [151, 1, 1, "", "score"], [151, 1, 1, "", "set_params"]], "piml.models.GAMINetClassifier": [[152, 1, 1, "", "certify_mono"], [152, 1, 1, "", "decision_function"], [152, 1, 1, "", "fine_tune_selected"], [152, 1, 1, "", "fit"], [152, 1, 1, "", "get_clarity_loss"], [152, 1, 1, "", "get_interaction_raw_output"], [152, 1, 1, "", "get_main_effect_raw_output"], [152, 1, 1, "", "get_metadata_routing"], [152, 1, 1, "", "get_mono_loss"], [152, 1, 1, "", "get_params"], [152, 1, 1, "", "get_raw_output"], [152, 1, 1, "", "load"], [152, 1, 1, "", "parse_model"], [152, 1, 1, "", "partial_dependence"], [152, 1, 1, "", "partial_derivatives"], [152, 1, 1, "", "predict"], [152, 1, 1, "", "predict_proba"], [152, 1, 1, "", "save"], [152, 1, 1, "", "score"], [152, 1, 1, "", "set_params"], [152, 1, 1, "", "set_score_request"]], "piml.models.GAMINetRegressor": [[153, 1, 1, "", "certify_mono"], [153, 1, 1, "", "fine_tune_selected"], [153, 1, 1, "", "fit"], [153, 1, 1, "", "get_clarity_loss"], [153, 1, 1, "", "get_interaction_raw_output"], [153, 1, 1, "", "get_main_effect_raw_output"], [153, 1, 1, "", "get_metadata_routing"], [153, 1, 1, "", "get_mono_loss"], [153, 1, 1, "", "get_params"], [153, 1, 1, "", "get_raw_output"], [153, 1, 1, "", "load"], [153, 1, 1, "", "parse_model"], [153, 1, 1, "", "partial_dependence"], [153, 1, 1, "", "partial_derivatives"], [153, 1, 1, "", "predict"], [153, 1, 1, "", "save"], [153, 1, 1, "", "score"], [153, 1, 1, "", "set_params"], [153, 1, 1, "", "set_score_request"]], "piml.models.GAMRegressor": [[154, 1, 1, "", "fit"], [154, 1, 1, "", "get_metadata_routing"], [154, 1, 1, "", "get_params"], [154, 1, 1, "", "parse_model"], [154, 1, 1, "", "partial_dependence"], [154, 1, 1, "", "predict"], [154, 1, 1, "", "score"], [154, 1, 1, "", "set_params"]], "piml.models.GLMRegressor": [[156, 1, 1, "", "get_metadata_routing"], [156, 1, 1, "", "get_params"], [156, 1, 1, "", "set_params"]], "piml.models.ReluDNNClassifier": [[157, 1, 1, "", "decision_function"], [157, 1, 1, "", "fit"], [157, 1, 1, "", "get_metadata_routing"], [157, 1, 1, "", "get_params"], [157, 1, 1, "", "get_raw_output"], [157, 1, 1, "", "parse_model"], [157, 1, 1, "", "predict"], [157, 1, 1, "", "predict_proba"], [157, 1, 1, "", "score"], [157, 1, 1, "", "set_params"], [157, 1, 1, "", "set_score_request"]], "piml.models.ReluDNNRegressor": [[158, 1, 1, "", "fit"], [158, 1, 1, "", "get_metadata_routing"], [158, 1, 1, "", "get_params"], [158, 1, 1, "", "get_raw_output"], [158, 1, 1, "", "parse_model"], [158, 1, 1, "", "predict"], [158, 1, 1, "", "score"], [158, 1, 1, "", "set_params"], [158, 1, 1, "", "set_score_request"]], "piml.models.TreeClassifier": [[159, 1, 1, "", "apply"], [159, 1, 1, "", "cost_complexity_pruning_path"], [159, 1, 1, "", "decision_path"], [159, 2, 1, "", "feature_importances_"], [159, 1, 1, "", "fit"], [159, 1, 1, "", "get_depth"], [159, 1, 1, "", "get_metadata_routing"], [159, 1, 1, "", "get_n_leaves"], [159, 1, 1, "", "get_params"], [159, 1, 1, "", "parse_model"], [159, 1, 1, "", "predict"], [159, 1, 1, "", "predict_log_proba"], [159, 1, 1, "", "predict_proba"], [159, 1, 1, "", "score"], [159, 1, 1, "", "set_fit_request"], [159, 1, 1, "", "set_params"], [159, 1, 1, "", "set_predict_proba_request"], [159, 1, 1, "", "set_predict_request"], [159, 1, 1, "", "set_score_request"]], "piml.models.TreeRegressor": [[160, 1, 1, "", "apply"], [160, 1, 1, "", "cost_complexity_pruning_path"], [160, 1, 1, "", "decision_path"], [160, 2, 1, "", "feature_importances_"], [160, 1, 1, "", "fit"], [160, 1, 1, "", "get_depth"], [160, 1, 1, "", "get_metadata_routing"], [160, 1, 1, "", "get_n_leaves"], [160, 1, 1, "", "get_params"], [160, 1, 1, "", "parse_model"], [160, 1, 1, "", "predict"], [160, 1, 1, "", "score"], [160, 1, 1, "", "set_fit_request"], [160, 1, 1, "", "set_params"], [160, 1, 1, "", "set_predict_request"], [160, 1, 1, "", "set_score_request"]], "piml.models.XGB1Classifier": [[161, 1, 1, "", "decision_function"], [161, 1, 1, "", "fit"], [161, 1, 1, "", "get_metadata_routing"], [161, 1, 1, "", "get_params"], [161, 1, 1, "", "get_raw_output"], [161, 1, 1, "", "parse_model"], [161, 1, 1, "", "partial_dependence"], [161, 1, 1, "", "predict"], [161, 1, 1, "", "predict_proba"], [161, 1, 1, "", "score"], [161, 1, 1, "", "set_params"], [161, 1, 1, "", "set_score_request"]], "piml.models.XGB1Regressor": [[162, 1, 1, "", "fit"], [162, 1, 1, "", "get_metadata_routing"], [162, 1, 1, "", "get_params"], [162, 1, 1, "", "get_raw_output"], [162, 1, 1, "", "parse_model"], [162, 1, 1, "", "partial_dependence"], [162, 1, 1, "", "predict"], [162, 1, 1, "", "score"], [162, 1, 1, "", "set_params"], [162, 1, 1, "", "set_score_request"]], "piml.models.XGB2Classifier": [[163, 1, 1, "", "decision_function"], [163, 1, 1, "", "fit"], [163, 1, 1, "", "get_metadata_routing"], [163, 1, 1, "", "get_params"], [163, 1, 1, "", "parse_model"], [163, 1, 1, "", "partial_dependence"], [163, 1, 1, "", "predict"], [163, 1, 1, "", "predict_proba"], [163, 1, 1, "", "score"], [163, 1, 1, "", "set_params"], [163, 1, 1, "", "set_score_request"]], "piml.models.XGB2Regressor": [[164, 1, 1, "", "fit"], [164, 1, 1, "", "get_metadata_routing"], [164, 1, 1, "", "get_params"], [164, 1, 1, "", "parse_model"], [164, 1, 1, "", "partial_dependence"], [164, 1, 1, "", "predict"], [164, 1, 1, "", "score"], [164, 1, 1, "", "set_params"], [164, 1, 1, "", "set_score_request"]], "piml.scored_test": [[165, 3, 1, "", "test_accuracy_plot"], [166, 3, 1, "", "test_accuracy_residual"], [167, 3, 1, "", "test_accuracy_table"], [168, 3, 1, "", "test_overfit"], [169, 3, 1, "", "test_reliability_calibration"], [170, 3, 1, "", "test_reliability_distance"], [171, 3, 1, "", "test_reliability_marginal"], [172, 3, 1, "", "test_reliability_perf"], [173, 3, 1, "", "test_reliability_table"], [174, 3, 1, "", "test_resilience_distance"], [175, 3, 1, "", "test_resilience_perf"], [176, 3, 1, "", "test_resilience_shift_density"], [177, 3, 1, "", "test_resilience_shift_histogram"], [178, 3, 1, "", "test_weakspot"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property", "3": "py:function"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"], "3": ["py", "function", "Python function"]}, "titleterms": {"data": [0, 1, 2, 3, 4, 6, 7, 34, 80, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 99, 100, 116, 125, 135, 137, 139, 140, 141, 142, 143, 144, 145, 146], "pipelin": [0, 80, 93, 137], "load": [1, 2, 3, 84, 85, 86, 87, 88, 95, 133, 135, 136], "built": [1, 95], "dataset": [1, 95], "panda": [2, 95], "datafram": [2, 95], "spark": [3, 95], "summari": [4, 100, 109, 117, 129], "eda": 5, "prepar": [6, 84, 85, 86, 87, 88, 96], "qualiti": [7, 97, 98, 99], "check": [7, 98], "featur": [8, 27, 98, 100, 101, 108, 109, 112, 113, 114, 115, 116, 117, 119, 120, 127], "select": [8, 101], "comput": [9, 17, 25, 35, 55, 74, 79], "time": [9, 17, 25, 35, 55, 74, 79], "model": [10, 11, 14, 15, 16, 18, 19, 22, 23, 24, 32, 36, 75, 76, 77, 80, 84, 85, 86, 87, 88, 89, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 131, 132, 133, 134, 135, 137, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "train": [10, 11, 18, 19, 80, 84, 85, 86, 87, 88, 96, 112, 113, 114, 115, 116, 117, 118, 119, 120, 131, 132, 133, 135, 137], "tune": [10, 18, 80, 131, 134], "extern": [11, 95], "hpo": [12, 13, 20, 21], "xgb": [12, 45, 46, 47, 48], "grid": [12, 20, 134], "search": [12, 13, 20, 21, 134], "bike": [12, 38, 48, 50, 52, 103, 104, 105, 106, 107, 108, 109, 116], "share": [12, 38, 48, 50, 52, 103, 104, 105, 106, 107, 108, 109, 116], "glm": [13, 37, 38], "random": [13, 21, 96, 101, 134], "simucredit": [13, 103, 104, 105, 106, 107, 108, 109, 129], "regist": [14, 15, 16, 22, 23, 24, 132, 133, 135], "arbitrari": [14, 24, 132, 135], "h2o": [15, 23, 133], "sklearn": [16, 22, 135], "style": [16, 22, 135], "post": [26, 80, 102, 137], "hoc": [26, 80, 102, 137], "explain": [26, 80, 84, 85, 88, 102, 112, 137], "permut": [27, 108], "import": [27, 101, 108, 109, 112, 113, 114, 115, 116, 117, 119, 120, 136], "partial": [28, 107], "depend": [28, 34, 107, 109, 116, 136], "plot": [28, 94, 107, 109, 112, 114, 115, 117, 119, 120, 122, 124, 129, 130], "h": [29, 104], "statist": [29, 100, 104], "individu": [30, 105], "condit": [30, 101, 105], "expect": [30, 105], "accumul": [31, 103], "local": [31, 32, 99, 103, 106, 112, 113, 114, 115, 116, 117, 118, 119, 120], "effect": [31, 103, 112, 114, 115, 119, 120], "interpret": [32, 36, 80, 84, 85, 88, 106, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 137], "agnost": [32, 106], "explan": [32, 33, 34, 106, 109], "shaplei": [33, 109], "addit": [33, 109, 114], "logist": 37, "regress": [37, 38, 40, 42, 44, 46, 48, 50, 52, 54, 58, 60, 62, 64, 66, 68, 71, 73, 77, 92, 116, 122, 125], "taiwan": [37, 43, 47, 49, 51, 53, 90, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130], "credit": [37, 43, 47, 49, 51, 53, 90, 112, 113, 115, 116, 117, 118, 120, 122, 124, 125, 126, 127, 128, 130], "linear": [38, 116, 117], "gam": [39, 40], "classif": [39, 41, 43, 45, 47, 49, 51, 53, 57, 59, 61, 63, 65, 67, 70, 72, 76, 90, 122, 125], "cocircl": [39, 45, 114, 119], "california": [40, 42, 44, 46, 114, 128], "hous": [40, 42, 44, 46, 114, 128], "tree": [41, 42, 113, 118], "taiwancredit": [41, 88], "fig": [43, 44], "1": [45, 46, 86, 90, 92, 95, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 133, 134, 135], "2": [47, 48, 87, 95, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 130, 132, 134, 135], "ebm": [49, 50], "gami": [51, 52, 115], "net": [51, 52, 115], "relu": [53, 54, 117], "dnn": [53, 54], "friedman": [54, 104, 117], "outcom": [56, 80, 84, 85, 88, 137], "test": [56, 69, 72, 73, 80, 84, 85, 86, 87, 88, 96, 97, 101, 127, 128, 132, 133, 135, 137], "accuraci": [57, 58, 90, 92, 122, 129], "weakspot": [59, 60, 129, 130], "overfit": [61, 62, 90, 92, 124], "reliabl": [63, 64, 90, 92, 125], "robust": [65, 66, 90, 92, 127], "resili": [67, 68, 90, 92, 126], "fair": [69, 78, 86, 87, 91, 123], "xgb2": 69, "segment": [70, 71, 91, 123, 129], "diagnos": [70, 71], "score": [72, 73, 90, 92, 99, 125, 128, 137], "comparison": [75, 76, 77, 78, 80, 84, 85, 87, 88, 89, 90, 91, 92, 99, 126], "exampl": [80, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "tabl": [81, 117, 122, 125, 129], "Of": 81, "content": 81, "frequent": 82, "ask": 82, "question": 82, "case": 83, "studi": [83, 86, 87], "bikeshar": [84, 92, 112, 115, 119, 120, 122, 124, 125, 127, 129, 130], "intepret": [84, 85, 88], "diagnost": [84, 85, 88, 110, 121, 132, 133, 135], "benchmark": [84, 85, 88], "californiah": [85, 113, 118, 126], "simul": [86, 87], "ml": [86, 87], "": [86, 87, 104], "descript": 87, "auc": 90, "f1": 90, "bandwidth": [90, 92, 125], "diagram": [90, 113, 125], "perform": [90, 92, 126], "worst": [90, 92, 127], "sampl": [90, 92, 96, 98, 127], "distanc": [90, 92, 97, 101, 125, 126], "metric": [91, 123], "mean": 92, "squar": 92, "error": 92, "absolut": 92, "r": 92, "coverag": [92, 125], "exploratori": 94, "analysi": [94, 99], "univari": 94, "bivari": 94, "multivari": 94, "csv": 95, "file": 95, "from": 95, "3": 95, "basic": 96, "set": 96, "split": 96, "outer": 96, "base": [96, 99], "kmean": 96, "manual": 96, "drift": 97, "margin": [97, 99, 125, 126], "distribut": [97, 99, 129], "energi": 97, "integr": [98, 137], "singl": 98, "column": 98, "duplic": 98, "highli": 98, "correl": [98, 101], "outlier": [99, 137], "detect": [99, 137], "methodologi": [99, 129, 134], "isol": 99, "forest": 99, "cluster": 99, "factor": 99, "cblof": [99, 139], "princip": 99, "compon": 99, "kmeanstre": [99, 143], "k": 99, "nearest": 99, "neighbor": 99, "histogram": [99, 126], "One": [99, 103, 107, 124, 130], "class": 99, "svm": 99, "empir": 99, "cumul": 99, "differ": 99, "method": 99, "refer": [99, 101, 104, 105, 108, 109, 110, 116, 137], "numer": [100, 127], "categor": [100, 127], "manipul": 100, "remov": 100, "chang": 100, "type": 100, "us": [101, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164], "independ": 101, "rcit": 101, "forward": 101, "backward": 101, "earli": 101, "drop": 101, "fbedk": 101, "al": 103, "algorithm": [103, 104, 105, 106, 107, 108, 109, 124, 126, 127, 130, 137], "detail": [103, 104, 105, 106, 107, 108, 109, 124, 126, 127, 130], "usag": [103, 104, 105, 106, 107, 108, 109, 124, 126, 127, 128, 129, 130, 134], "wai": [103, 107, 124, 130], "two": [103, 107, 124, 130], "hstat": 104, "ic": 105, "lime": 106, "pdp": 107, "pfi": 108, "shap": 109, "exact": 109, "solut": 109, "kernelshap": 109, "specif": 109, "The": 109, "waterfal": 109, "introduct": 110, "toolbox": 110, "design": 110, "suit": [110, 121], "futur": 110, "plan": 110, "defin": 132, "wrapper": 132, "predict": 132, "function": [132, 137], "run": [132, 133, 135], "save": [133, 135], "fit": [133, 135], "hyperparamet": 134, "optim": 134, "get": 134, "tun": 134, "result": 134, "boost": 112, "machin": 112, "global": [112, 113, 114, 115, 116, 117, 118, 119, 120], "main": [112, 114, 115, 119, 120], "interact": [112, 115, 120], "contribut": [112, 115, 117, 120], "fast": 113, "greedi": 113, "sum": 113, "heatmap": 113, "gener": [114, 116], "coeffici": 116, "origin": 116, "scale": 116, "option": 116, "center": 116, "neural": 117, "network": 117, "formul": 117, "llm": 117, "parallel": 117, "coordin": 117, "violin": 117, "profil": 117, "pairwis": 117, "decis": 118, "xgboost": [119, 120], "depth": [119, 120], "weight": 119, "evid": 119, "inform": 119, "valu": 119, "task": [122, 125], "residu": [122, 129], "binari": [122, 125], "bin": 123, "threshold": 123, "un": 125, "classifi": 125, "calibr": 125, "brier": 125, "densiti": 126, "perturb": 127, "For": 127, "variabl": 127, "whole": 127, "shift": 129, "instal": 136, "quick": 136, "troubleshoot": 136, "could": 136, "find": 136, "version": 136, "satisfi": 136, "requir": 136, "piml": [136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179], "cannot": 136, "uninstal": 136, "llvmlite": 136, "librari": 136, "libxgboost": 136, "so": 136, "colab": 136, "api": 137, "high": [], "code": [], "experi": 138, "outlier_detect": [139, 140, 141, 142, 143, 144, 145, 146], "ecod": 140, "hbo": 141, "isolationforest": 142, "knn": 144, "oneclasssvm": 145, "pca": 146, "explainableboostingclassifi": 147, "explainableboostingregressor": 148, "figsclassifi": 149, "figsregressor": 150, "gamclassifi": 151, "gaminetclassifi": 152, "gaminetregressor": 153, "gamregressor": 154, "glmclassifi": 155, "glmregressor": 156, "reludnnclassifi": 157, "reludnnregressor": 158, "treeclassifi": 159, "treeregressor": 160, "xgb1classifi": 161, "xgb1regressor": 162, "xgb2classifi": 163, "xgb2regressor": 164, "scored_test": [165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178], "test_accuracy_plot": 165, "test_accuracy_residu": 166, "test_accuracy_t": 167, "test_overfit": 168, "test_reliability_calibr": 169, "test_reliability_dist": 170, "test_reliability_margin": 171, "test_reliability_perf": 172, "test_reliability_t": 173, "test_resilience_dist": 174, "test_resilience_perf": 175, "test_resilience_shift_dens": 176, "test_resilience_shift_histogram": 177, "test_weakspot": 178, "welcom": 179, "user": 181, "guid": 181}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"Data Pipeline": [[0, "data-pipeline"], [93, "data-pipeline"], [137, "data-pipeline"], [80, "data-pipeline"]], "Data Load (Built-in Dataset)": [[1, "data-load-built-in-dataset"]], "Data Load (Pandas DataFrame)": [[2, "data-load-pandas-dataframe"]], "Data Load (Spark)": [[3, "data-load-spark"]], "Data Summary": [[4, "data-summary"], [100, "data-summary"]], "EDA": [[5, "eda"]], "Data Preparation": [[6, "data-preparation"], [96, "data-preparation"]], "Data Quality Check": [[7, "data-quality-check"]], "Feature Selection": [[8, "feature-selection"], [101, "feature-selection"]], "Computation times": [[9, "computation-times"], [17, "computation-times"], [35, "computation-times"], [79, "computation-times"], [25, "computation-times"], [74, "computation-times"], [55, "computation-times"]], "Model Train and Tune": [[10, "model-train-and-tune"], [131, "model-train-and-tune"], [18, "model-train-and-tune"], [80, "model-train-and-tune"]], "Train External Models": [[11, "train-external-models"]], "HPO - XGB - Grid Search (Bike Sharing)": [[12, "hpo-xgb-grid-search-bike-sharing"]], "HPO - GLM - Random Search (SimuCredit)": [[13, "hpo-glm-random-search-simucredit"]], "Registering Arbitrary Models": [[14, "registering-arbitrary-models"]], "Registering H2O Models": [[15, "registering-h2o-models"]], "Registering sklearn Style Models": [[16, "registering-sklearn-style-models"]], "Post hoc Explainability": [[26, "post-hoc-explainability"], [80, "post-hoc-explainability"]], "Permutation Feature Importance": [[27, "permutation-feature-importance"]], "Partial Dependence Plot": [[28, "partial-dependence-plot"]], "H-statistics": [[29, "h-statistics"]], "Individual Conditional Expectation": [[30, "individual-conditional-expectation"]], "Accumulated Local Effects": [[31, "accumulated-local-effects"]], "Local Interpretable Model-Agnostic Explanation": [[32, "local-interpretable-model-agnostic-explanation"]], "SHapley Additive exPlanations": [[33, "shapley-additive-explanations"]], "Data Dependent Explanation": [[34, "data-dependent-explanation"]], "GLM Logistic Regression (Taiwan Credit)": [[37, "glm-logistic-regression-taiwan-credit"]], "GAM Classification (CoCircles)": [[39, "gam-classification-cocircles"]], "GAM Regression (California Housing)": [[40, "gam-regression-california-housing"]], "Tree Classification (TaiwanCredit)": [[41, "tree-classification-taiwancredit"]], "Tree Regression (California Housing)": [[42, "tree-regression-california-housing"]], "FIGS Classification (Taiwan Credit)": [[43, "figs-classification-taiwan-credit"]], "FIGS Regression (California Housing)": [[44, "figs-regression-california-housing"]], "XGB-1 Classification (CoCircles)": [[45, "xgb-1-classification-cocircles"]], "XGB-1 Regression (California Housing)": [[46, "xgb-1-regression-california-housing"]], "XGB-2 Classification (Taiwan Credit)": [[47, "xgb-2-classification-taiwan-credit"]], "XGB-2 Regression (Bike Sharing)": [[48, "xgb-2-regression-bike-sharing"]], "EBM Classification (Taiwan Credit)": [[49, "ebm-classification-taiwan-credit"]], "EBM Regression (Bike Sharing)": [[50, "ebm-regression-bike-sharing"]], "GAMI-Net Classification (Taiwan Credit)": [[51, "gami-net-classification-taiwan-credit"]], "GAMI-Net Regression (Bike Sharing)": [[52, "gami-net-regression-bike-sharing"]], "ReLU DNN Classification (Taiwan Credit)": [[53, "relu-dnn-classification-taiwan-credit"]], "ReLU DNN Regression (Friedman)": [[54, "relu-dnn-regression-friedman"]], "Accuracy: Classification": [[57, "accuracy-classification"]], "Accuracy: Regression": [[58, "accuracy-regression"]], "WeakSpot: Classification": [[59, "weakspot-classification"]], "WeakSpot: Regression": [[60, "weakspot-regression"]], "Overfit: Classification": [[61, "overfit-classification"]], "Overfit: Regression": [[62, "overfit-regression"]], "Reliability: Classification": [[63, "reliability-classification"]], "Reliability: Regression": [[64, "reliability-regression"]], "Robustness: Classification": [[65, "robustness-classification"]], "Robustness:  Regression": [[66, "robustness-regression"]], "Resilience:  Classification": [[67, "resilience-classification"]], "Resilience - Regression": [[68, "resilience-regression"]], "Fairness Test: XGB2": [[69, "fairness-test-xgb2"]], "Scored Test: Classification": [[72, "scored-test-classification"]], "Scored Test: Regression": [[73, "scored-test-regression"]], "Model Comparison": [[75, "model-comparison"], [89, "model-comparison"], [80, "model-comparison"]], "Model Comparison: Classification": [[76, "model-comparison-classification"]], "Model Comparison: Regression": [[77, "model-comparison-regression"]], "Fairness Comparison": [[78, "fairness-comparison"], [91, "fairness-comparison"]], "Table Of Contents": [[81, "table-of-contents"]], "Frequently Asked Questions": [[82, "frequently-asked-questions"]], "Case Studies": [[83, "case-studies"]], "BikeSharing Data": [[84, "BikeSharing-Data"]], "Load and Prepare Data": [[84, "Load-and-Prepare-Data"], [85, "Load-and-Prepare-Data"], [86, "Load-and-Prepare-Data"], [88, "Load-and-Prepare-Data"]], "Train Intepretable Models": [[84, "Train-Intepretable-Models"], [85, "Train-Intepretable-Models"], [88, "Train-Intepretable-Models"]], "Interpretability and Explainability": [[84, "Interpretability-and-Explainability"], [85, "Interpretability-and-Explainability"], [88, "Interpretability-and-Explainability"]], "Model Diagnostics and Outcome Testing": [[84, "Model-Diagnostics-and-Outcome-Testing"], [85, "Model-Diagnostics-and-Outcome-Testing"], [88, "Model-Diagnostics-and-Outcome-Testing"]], "Model Comparison and Benchmarking": [[84, "Model-Comparison-and-Benchmarking"], [85, "Model-Comparison-and-Benchmarking"], [88, "Model-Comparison-and-Benchmarking"]], "CaliforniaHousing Data": [[85, "CaliforniaHousing-Data"]], "Fairness Simulation Study 1": [[86, "Fairness-Simulation-Study-1"]], "Train ML Model(s)": [[86, "Train-ML-Model(s)"], [87, "Train-ML-Model(s)"]], "Fairness Testing": [[86, "Fairness-Testing"], [87, "Fairness-Testing"]], "Fairness Simulation Study 2": [[87, "Fairness-Simulation-Study-2"]], "Data Description": [[87, "Data-Description"]], "Load and Prepare data": [[87, "Load-and-Prepare-data"]], "Fairness Testing Comparison": [[87, "Fairness-Testing-Comparison"]], "TaiwanCredit Data": [[88, "TaiwanCredit-Data"]], "Examples": [[90, "examples"], [91, "examples"], [92, "examples"], [94, "examples"], [95, "examples"], [96, "examples"], [100, "examples"], [101, "examples"], [103, "examples"], [104, "examples"], [105, "examples"], [106, "examples"], [107, "examples"], [109, "examples"], [112, "examples"], [113, "examples"], [115, "examples"], [118, "examples"], [119, "examples"], [120, "examples"], [122, "examples"], [123, "examples"], [124, "examples"], [125, "examples"], [126, "examples"], [127, "examples"], [130, "examples"], [135, "examples"], [117, "examples"], [128, "examples"], [132, "examples"], [133, "examples"], [134, "examples"], [129, "examples"], [98, "examples"], [97, "examples"], [99, "examples"], [80, "examples"], [116, "examples"]], "Comparison for Classification": [[90, "comparison-for-classification"]], "Accuracy Comparison": [[90, "accuracy-comparison"], [92, "accuracy-comparison"]], "Accuracy Score": [[90, "accuracy-score"]], "AUC Score": [[90, "auc-score"]], "F1 Score": [[90, "f1-score"]], "Overfit Comparison": [[90, "overfit-comparison"], [92, "overfit-comparison"]], "Reliability Comparison": [[90, "reliability-comparison"], [92, "reliability-comparison"]], "Bandwidth Comparison": [[90, "bandwidth-comparison"], [92, "bandwidth-comparison"]], "Reliability Diagram Comparison": [[90, "reliability-diagram-comparison"]], "Robustness Comparison": [[90, "robustness-comparison"], [92, "robustness-comparison"]], "Robustness Performance": [[90, "robustness-performance"], [92, "robustness-performance"]], "Robustness Performance on Worst Samples": [[90, "robustness-performance-on-worst-samples"], [92, "robustness-performance-on-worst-samples"]], "Resilience Comparison": [[90, "resilience-comparison"], [92, "resilience-comparison"]], "Resilience Performance": [[90, "resilience-performance"], [92, "resilience-performance"], [126, "resilience-performance"]], "Resilience Distance": [[90, "resilience-distance"], [92, "resilience-distance"], [126, "resilience-distance"]], "Examples 1: Taiwan Credit": [[90, null]], "Fairness Metrics": [[91, "fairness-metrics"], [123, "fairness-metrics"]], "Segmented": [[91, "segmented"], [129, "segmented"]], "Example": [[91, null], [94, null], [96, null], [100, null], [101, null], [108, "example"], [114, "example"], [123, null], [98, null], [97, null], [99, null]], "Comparison for Regression": [[92, "comparison-for-regression"]], "Mean Squared Error": [[92, "mean-squared-error"]], "Mean Absolute Error": [[92, "mean-absolute-error"]], "R-squared Score": [[92, "r-squared-score"]], "Coverage Comparison": [[92, "coverage-comparison"]], "Example 1: BikeSharing": [[92, null], [112, null], [115, null], [119, null], [120, null], [122, null], [124, null], [125, null], [127, null], [130, null], [129, null]], "Exploratory Analysis": [[94, "exploratory-analysis"]], "Univariate Plots": [[94, "univariate-plots"]], "Bivariate Plots": [[94, "bivariate-plots"]], "Multivariate Plots": [[94, "multivariate-plots"]], "Data Load": [[95, "data-load"]], "Built-in Dataset": [[95, "built-in-dataset"]], "External Dataset (csv files)": [[95, "external-dataset-csv-files"]], "External Dataset (Spark file)": [[95, "external-dataset-spark-file"]], "Example 1: Load built-in datasets": [[95, null]], "Example 2: Load data from pandas DataFrame": [[95, null]], "Example 3: Load data from spark DataFrame": [[95, null]], "Basic Settings": [[96, "basic-settings"]], "Train-test Splits": [[96, "train-test-splits"]], "Random Split": [[96, "random-split"]], "Outer-sample-based Split": [[96, "outer-sample-based-split"]], "KMeans-based Split": [[96, "kmeans-based-split"]], "Manual Split": [[96, "manual-split"]], "Summary Statistics": [[100, "summary-statistics"]], "Numerical Features": [[100, "numerical-features"]], "Categorical Features": [[100, "categorical-features"]], "Feature Manipulation": [[100, "feature-manipulation"]], "Remove Features": [[100, "remove-features"]], "Change Feature Types": [[100, "change-feature-types"]], "References": [[101, null], [104, null], [105, null], [108, null], [109, null], [110, null], [99, null], [116, null]], "Correlations": [[101, "correlations"]], "Distance Correlation": [[101, "distance-correlation"]], "Use of Feature Importance": [[101, "use-of-feature-importance"]], "Randomized Conditional Independence Test": [[101, "randomized-conditional-independence-test"]], "RCIT Test": [[101, "rcit-test"]], "Forward-Backward selection with Early Dropping (FBEDk):": [[101, "forward-backward-selection-with-early-dropping-fbedk"]], "Post-hoc Explainability": [[102, "post-hoc-explainability"], [137, "post-hoc-explainability"]], "ALE (Accumulated Local Effects)": [[103, "ale-accumulated-local-effects"]], "Algorithm Details": [[103, "algorithm-details"], [104, "algorithm-details"], [105, "algorithm-details"], [106, "algorithm-details"], [107, "algorithm-details"], [108, "algorithm-details"], [109, "algorithm-details"], [124, "algorithm-details"], [126, "algorithm-details"], [127, "algorithm-details"], [130, "algorithm-details"]], "Usage": [[103, "usage"], [104, "usage"], [105, "usage"], [106, "usage"], [107, "usage"], [108, "usage"], [109, "usage"], [124, "usage"], [126, "usage"], [127, "usage"], [130, "usage"], [128, "usage"], [134, "usage"], [129, "usage"]], "One-way ALE": [[103, "one-way-ale"]], "Two-way ALE": [[103, "two-way-ale"]], "Example 1: Bike Sharing": [[103, null], [104, null], [105, null], [106, null], [107, null], [108, null], [109, null], [116, null]], "Example 2: SimuCredit": [[103, null], [104, null], [105, null], [106, null], [107, null], [108, null], [109, null]], "Hstats (Friedman\u2019s H-statistic)": [[104, "hstats-friedman-s-h-statistic"]], "ICE (Individual Conditional Expectation)": [[105, "ice-individual-conditional-expectation"]], "LIME (Local Interpretable Model-Agnostic Explanation)": [[106, "lime-local-interpretable-model-agnostic-explanation"]], "PDP (Partial Dependence Plot)": [[107, "pdp-partial-dependence-plot"]], "One-way PDPs": [[107, "one-way-pdps"]], "Two-way PDPs": [[107, "two-way-pdps"]], "PFI (Permutation Feature Importance)": [[108, "pfi-permutation-feature-importance"]], "SHAP (SHapley Additive exPlanations)": [[109, "shap-shapley-additive-explanations"]], "Exact Solution": [[109, "exact-solution"]], "KernelSHAP": [[109, "kernelshap"]], "Algorithms for specific models": [[109, "algorithms-for-specific-models"]], "The Waterfall plot": [[109, "the-waterfall-plot"]], "SHAP Feature importance": [[109, "shap-feature-importance"]], "SHAP Summary plot": [[109, "shap-summary-plot"]], "SHAP Dependence Plot": [[109, "shap-dependence-plot"]], "Interpretable Models": [[110, "interpretable-models"], [137, "interpretable-models"], [36, "interpretable-models"], [80, "interpretable-models"], [111, "interpretable-models"]], "Introduction": [[110, "introduction"], [110, "id1"]], "Toolbox Design": [[110, "toolbox-design"]], "Diagnostic Suite": [[110, "diagnostic-suite"], [121, "diagnostic-suite"]], "Future Plan": [[110, "future-plan"]], "Explainable Boosting Machines": [[112, "explainable-boosting-machines"]], "Model Training": [[112, "model-training"], [113, "model-training"], [114, "model-training"], [115, "model-training"], [118, "model-training"], [119, "model-training"], [120, "model-training"], [117, "model-training"], [137, "model-training"], [116, "model-training"]], "Global Interpretation": [[112, "global-interpretation"], [113, "global-interpretation"], [114, "global-interpretation"], [115, "global-interpretation"], [118, "global-interpretation"], [119, "global-interpretation"], [120, "global-interpretation"], [117, "global-interpretation"], [116, "global-interpretation"]], "Main Effect Plot": [[112, "main-effect-plot"], [114, "main-effect-plot"], [115, "main-effect-plot"], [119, "main-effect-plot"], [120, "main-effect-plot"]], "Interaction Plot": [[112, "interaction-plot"], [115, "interaction-plot"], [120, "interaction-plot"]], "Effect Importance": [[112, "effect-importance"], [115, "effect-importance"], [120, "effect-importance"]], "Feature Importance": [[112, "feature-importance"], [114, "feature-importance"], [115, "feature-importance"], [119, "feature-importance"], [120, "feature-importance"], [116, "feature-importance"]], "Local Interpretation": [[112, "local-interpretation"], [113, "local-interpretation"], [114, "local-interpretation"], [115, "local-interpretation"], [118, "local-interpretation"], [119, "local-interpretation"], [120, "local-interpretation"], [117, "local-interpretation"], [116, "local-interpretation"]], "Local Effect Contribution": [[112, "local-effect-contribution"], [115, "local-effect-contribution"], [120, "local-effect-contribution"]], "Local Feature Contribution": [[112, "local-feature-contribution"], [115, "local-feature-contribution"], [120, "local-feature-contribution"]], "Examples 2: Taiwan Credit": [[112, null], [113, null], [115, null], [118, null], [120, null], [122, null], [124, null], [125, null], [126, null], [127, null], [130, null], [117, null], [128, null]], "Fast Interpretable Greedy-tree Sums": [[113, "fast-interpretable-greedy-tree-sums"]], "Feature Importance Heatmap": [[113, "feature-importance-heatmap"]], "Tree Diagram": [[113, "tree-diagram"]], "Example 1: CaliforniaHousing": [[113, null], [118, null], [126, null]], "Generalized Additive Model": [[114, "generalized-additive-model"]], "Example 1: California Housing": [[114, null], [128, null]], "Example 2: CoCircles": [[114, null], [119, null]], "GAMI-Net": [[115, "gami-net"]], "Decision Tree": [[118, "decision-tree"]], "XGBoost Depth 1": [[119, "xgboost-depth-1"]], "Weight of Evidence Plot": [[119, "weight-of-evidence-plot"]], "Information Value Plot": [[119, "information-value-plot"]], "XGBoost Depth 2": [[120, "xgboost-depth-2"]], "Accuracy": [[122, "accuracy"]], "Regression Tasks": [[122, "regression-tasks"]], "Accuracy Table": [[122, "accuracy-table"], [122, "id1"], [129, "accuracy-table"]], "Residual Plot": [[122, "residual-plot"], [122, "id2"], [129, "residual-plot"]], "Binary Classification": [[122, "binary-classification"]], "Accuracy Plot": [[122, "accuracy-plot"]], "Fairness": [[123, "fairness"]], "Fairness Segmented": [[123, "fairness-segmented"]], "Fairness Binning": [[123, "fairness-binning"]], "Fairness Thresholding": [[123, "fairness-thresholding"]], "Overfit": [[124, "overfit"]], "One-way Overfit Plot": [[124, "one-way-overfit-plot"]], "Two-way Overfit Plot": [[124, "two-way-overfit-plot"]], "Reliability": [[125, "reliability"]], "Reliability for Regression Tasks": [[125, "reliability-for-regression-tasks"]], "Coverage and Bandwidth Table": [[125, "coverage-and-bandwidth-table"]], "Distance of Reliable and Un-reliable Data": [[125, "distance-of-reliable-and-un-reliable-data"], [125, "id1"]], "Marginal Bandwidth": [[125, "marginal-bandwidth"], [125, "id2"]], "Reliability for Binary Classification": [[125, "reliability-for-binary-classification"]], "Classifier Calibration": [[125, "classifier-calibration"]], "Reliability Diagram": [[125, "reliability-diagram"]], "Brier Score Table": [[125, "brier-score-table"]], "Resilience": [[126, "resilience"]], "Marginal Density Comparison": [[126, "marginal-density-comparison"]], "Marginal Histogram Comparison": [[126, "marginal-histogram-comparison"]], "Robustness": [[127, "robustness"]], "Perturbation For Numerical Features": [[127, "perturbation-for-numerical-features"]], "Perturbation for Categorical Variable": [[127, "perturbation-for-categorical-variable"]], "Robustness on the whole test sample": [[127, "robustness-on-the-whole-test-sample"]], "Robustness on worst test samples": [[127, "robustness-on-worst-test-samples"]], "WeakSpot": [[130, "weakspot"]], "One-way WeakSpot Plot": [[130, "one-way-weakspot-plot"]], "Two-way WeakSpot Plot": [[130, "two-way-weakspot-plot"]], "Installation": [[136, "installation"]], "Quick Install": [[136, "quick-install"]], "Dependencies": [[136, "dependencies"]], "Troubleshooting": [[136, "troubleshooting"]], "Could not find a version that satisfies the requirement PiML": [[136, "could-not-find-a-version-that-satisfies-the-requirement-piml"]], "Cannot uninstall \u201cllvmlite\u201d.": [[136, "cannot-uninstall-llvmlite"]], "Library \u201clibxgboost.so\u201d not loaded": [[136, "library-libxgboost-so-not-loaded"]], "Cannot import PiML on Colab": [[136, "cannot-import-piml-on-colab"]], "Welcome to PiML": [[179, "welcome-to-piml"]], "User Guide": [[181, "user-guide"]], "Train Models": [[19, "train-models"]], "Train and Register Models": [[135, "train-and-register-models"], [132, "train-and-register-models"], [133, "train-and-register-models"]], "Run Diagnostic Tests": [[135, "run-diagnostic-tests"], [132, "run-diagnostic-tests"], [133, "run-diagnostic-tests"]], "Example 2:": [[135, null], [132, null]], "Save Fitted Models": [[135, "save-fitted-models"], [133, "save-fitted-models"]], "Load and Register Fitted Models": [[135, "load-and-register-fitted-models"], [133, "load-and-register-fitted-models"]], "Example 1:": [[135, null], [133, null]], "Train and Register Sklearn Style Model": [[135, "train-and-register-sklearn-style-model"]], "Register Arbitrary Models and Data": [[135, "register-arbitrary-models-and-data"]], "HPO - Grid Search": [[20, "hpo-grid-search"]], "HPO - Random Search": [[21, "hpo-random-search"]], "Register sklearn Style Models": [[22, "register-sklearn-style-models"]], "Register H2O Models": [[23, "register-h2o-models"], [133, "register-h2o-models"]], "Register Arbitrary Models": [[24, "register-arbitrary-models"], [132, "register-arbitrary-models"]], "ReLU Neural Network": [[117, "relu-neural-network"]], "Model Formulation": [[117, "model-formulation"]], "Local Linear Models": [[117, "local-linear-models"]], "LLM Summary Table": [[117, "llm-summary-table"]], "Parallel Coordinate Plot": [[117, "parallel-coordinate-plot"]], "LLM Violin Plot": [[117, "llm-violin-plot"]], "Feature Importance Plot": [[117, "feature-importance-plot"]], "LLM profile plot": [[117, "llm-profile-plot"]], "LLM pairwise plot": [[117, "llm-pairwise-plot"]], "Local Feature Contribution plot": [[117, "local-feature-contribution-plot"]], "Example 1: Friedman": [[117, null]], "Scored Test": [[128, "scored-test"]], "Define Wrapper Predict Functions": [[132, "define-wrapper-predict-functions"]], "Register the predict Functions": [[132, "register-the-predict-functions"]], "Methodology": [[134, "methodology"], [129, "methodology"], [99, "methodology"]], "Hyperparameter Optimization (Model Tune)": [[134, "hyperparameter-optimization-model-tune"]], "Get model tunning result": [[134, "get-model-tunning-result"]], "Example 1: Grid Search": [[134, null]], "Example 2: Randomized Search": [[134, null]], "Outcome Testing": [[56, "outcome-testing"], [137, "outcome-testing"], [80, "outcome-testing"]], "Segmented Diagnose (Classification)": [[70, "segmented-diagnose-classification"]], "Segmented Diagnose (Regression)": [[71, "segmented-diagnose-regression"]], "Segments summary": [[129, "segments-summary"]], "Weakspot": [[129, "weakspot"]], "Distribution shift": [[129, "distribution-shift"]], "Examples 2: SimuCredit": [[129, null]], "API Reference": [[137, "api-reference"]], "Functions": [[137, "functions"]], "Outlier Detection Algorithms": [[137, "outlier-detection-algorithms"]], "Integrated Functions": [[137, "integrated-functions"]], "Scored Test Function": [[137, "scored-test-function"]], "piml.data.outlier_detection.CBLOF": [[139, "piml-data-outlier-detection-cblof"]], "Examples using piml.data.outlier_detection.CBLOF": [[139, "examples-using-piml-data-outlier-detection-cblof"]], "piml.data.outlier_detection.ECOD": [[140, "piml-data-outlier-detection-ecod"]], "Examples using piml.data.outlier_detection.ECOD": [[140, "examples-using-piml-data-outlier-detection-ecod"]], "piml.data.outlier_detection.HBOS": [[141, "piml-data-outlier-detection-hbos"]], "Examples using piml.data.outlier_detection.HBOS": [[141, "examples-using-piml-data-outlier-detection-hbos"]], "piml.data.outlier_detection.IsolationForest": [[142, "piml-data-outlier-detection-isolationforest"]], "Examples using piml.data.outlier_detection.IsolationForest": [[142, "examples-using-piml-data-outlier-detection-isolationforest"]], "piml.data.outlier_detection.KMeansTree": [[143, "piml-data-outlier-detection-kmeanstree"]], "Examples using piml.data.outlier_detection.KMeansTree": [[143, "examples-using-piml-data-outlier-detection-kmeanstree"]], "piml.data.outlier_detection.KNN": [[144, "piml-data-outlier-detection-knn"]], "Examples using piml.data.outlier_detection.KNN": [[144, "examples-using-piml-data-outlier-detection-knn"]], "piml.data.outlier_detection.OneClassSVM": [[145, "piml-data-outlier-detection-oneclasssvm"]], "Examples using piml.data.outlier_detection.OneClassSVM": [[145, "examples-using-piml-data-outlier-detection-oneclasssvm"]], "piml.data.outlier_detection.PCA": [[146, "piml-data-outlier-detection-pca"]], "Examples using piml.data.outlier_detection.PCA": [[146, "examples-using-piml-data-outlier-detection-pca"]], "piml.models.ExplainableBoostingClassifier": [[147, "piml-models-explainableboostingclassifier"]], "Examples using piml.models.ExplainableBoostingClassifier": [[147, "examples-using-piml-models-explainableboostingclassifier"]], "piml.models.ExplainableBoostingRegressor": [[148, "piml-models-explainableboostingregressor"]], "Examples using piml.models.ExplainableBoostingRegressor": [[148, "examples-using-piml-models-explainableboostingregressor"]], "piml.models.FIGSClassifier": [[149, "piml-models-figsclassifier"]], "Examples using piml.models.FIGSClassifier": [[149, "examples-using-piml-models-figsclassifier"]], "piml.models.FIGSRegressor": [[150, "piml-models-figsregressor"]], "Examples using piml.models.FIGSRegressor": [[150, "examples-using-piml-models-figsregressor"]], "piml.models.GAMClassifier": [[151, "piml-models-gamclassifier"]], "Examples using piml.models.GAMClassifier": [[151, "examples-using-piml-models-gamclassifier"]], "piml.models.GAMINetClassifier": [[152, "piml-models-gaminetclassifier"]], "Examples using piml.models.GAMINetClassifier": [[152, "examples-using-piml-models-gaminetclassifier"]], "piml.models.GAMINetRegressor": [[153, "piml-models-gaminetregressor"]], "Examples using piml.models.GAMINetRegressor": [[153, "examples-using-piml-models-gaminetregressor"]], "piml.models.GAMRegressor": [[154, "piml-models-gamregressor"]], "Examples using piml.models.GAMRegressor": [[154, "examples-using-piml-models-gamregressor"]], "piml.models.GLMClassifier": [[155, "piml-models-glmclassifier"]], "Examples using piml.models.GLMClassifier": [[155, "examples-using-piml-models-glmclassifier"]], "piml.models.ReluDNNClassifier": [[157, "piml-models-reludnnclassifier"]], "Examples using piml.models.ReluDNNClassifier": [[157, "examples-using-piml-models-reludnnclassifier"]], "piml.models.ReluDNNRegressor": [[158, "piml-models-reludnnregressor"]], "Examples using piml.models.ReluDNNRegressor": [[158, "examples-using-piml-models-reludnnregressor"]], "piml.models.TreeClassifier": [[159, "piml-models-treeclassifier"]], "Examples using piml.models.TreeClassifier": [[159, "examples-using-piml-models-treeclassifier"]], "piml.models.TreeRegressor": [[160, "piml-models-treeregressor"]], "Examples using piml.models.TreeRegressor": [[160, "examples-using-piml-models-treeregressor"]], "piml.models.XGB1Classifier": [[161, "piml-models-xgb1classifier"]], "Examples using piml.models.XGB1Classifier": [[161, "examples-using-piml-models-xgb1classifier"]], "piml.models.XGB1Regressor": [[162, "piml-models-xgb1regressor"]], "Examples using piml.models.XGB1Regressor": [[162, "examples-using-piml-models-xgb1regressor"]], "piml.models.XGB2Classifier": [[163, "piml-models-xgb2classifier"]], "Examples using piml.models.XGB2Classifier": [[163, "examples-using-piml-models-xgb2classifier"]], "piml.models.XGB2Regressor": [[164, "piml-models-xgb2regressor"]], "Examples using piml.models.XGB2Regressor": [[164, "examples-using-piml-models-xgb2regressor"]], "piml.scored_test.test_accuracy_plot": [[165, "piml-scored-test-test-accuracy-plot"]], "piml.scored_test.test_accuracy_residual": [[166, "piml-scored-test-test-accuracy-residual"]], "piml.scored_test.test_accuracy_table": [[167, "piml-scored-test-test-accuracy-table"]], "piml.scored_test.test_overfit": [[168, "piml-scored-test-test-overfit"]], "piml.scored_test.test_reliability_calibration": [[169, "piml-scored-test-test-reliability-calibration"]], "piml.scored_test.test_reliability_distance": [[170, "piml-scored-test-test-reliability-distance"]], "piml.scored_test.test_reliability_marginal": [[171, "piml-scored-test-test-reliability-marginal"]], "piml.scored_test.test_reliability_perf": [[172, "piml-scored-test-test-reliability-perf"]], "piml.scored_test.test_reliability_table": [[173, "piml-scored-test-test-reliability-table"]], "piml.scored_test.test_resilience_distance": [[174, "piml-scored-test-test-resilience-distance"]], "piml.scored_test.test_resilience_perf": [[175, "piml-scored-test-test-resilience-perf"]], "piml.scored_test.test_resilience_shift_density": [[176, "piml-scored-test-test-resilience-shift-density"]], "piml.scored_test.test_resilience_shift_histogram": [[177, "piml-scored-test-test-resilience-shift-histogram"]], "piml.scored_test.test_weakspot": [[178, "piml-scored-test-test-weakspot"]], "Data Quality (Integrity Check)": [[98, "data-quality-integrity-check"]], "Single-column Checks": [[98, "single-column-checks"]], "Duplicated Samples": [[98, "duplicated-samples"]], "Highly correlated features": [[98, "highly-correlated-features"]], "Data Quality (Drift Test)": [[97, "data-quality-drift-test"]], "Marginal Distribution Drift": [[97, "marginal-distribution-drift"]], "Energy Distance": [[97, "energy-distance"]], "Data Quality (Outlier Detection)": [[99, "data-quality-outlier-detection"]], "Isolation Forest": [[99, "isolation-forest"]], "Cluster-Based Local Outlier Factor (CBLOF)": [[99, "cluster-based-local-outlier-factor-cblof"]], "Principal Component Analysis": [[99, "principal-component-analysis"]], "KmeansTree": [[99, "kmeanstree"]], "K-Nearest Neighbor": [[99, "k-nearest-neighbor"]], "Histogram-based outlier detection": [[99, "histogram-based-outlier-detection"]], "One Class SVM": [[99, "one-class-svm"]], "Empirical Cumulative Distribution-based Outlier Detection": [[99, "empirical-cumulative-distribution-based-outlier-detection"]], "Analysis and Comparison": [[99, "analysis-and-comparison"]], "Outlier Score distribution": [[99, "outlier-score-distribution"]], "Marginal Distribution of Outliers": [[99, "marginal-distribution-of-outliers"]], "Comparison of Different Methods": [[99, "comparison-of-different-methods"]], "GLM Linear Regression (Bike Sharing)": [[38, "glm-linear-regression-bike-sharing"]], "Generalized Linear Models": [[116, "generalized-linear-models"]], "Regression Coefficients": [[116, "regression-coefficients"]], "Original Scale Option": [[116, "original-scale-option"]], "Centered Option": [[116, "centered-option"]], "Data Dependent Interpretation": [[116, "data-dependent-interpretation"]], "Example 2: Taiwan Credit": [[116, null]], "piml.Experiment": [[138, "piml-experiment"]], "Examples using piml.Experiment": [[138, "examples-using-piml-experiment"]], "piml.models.GLMRegressor": [[156, "piml-models-glmregressor"]], "Examples using piml.models.GLMRegressor": [[156, "examples-using-piml-models-glmregressor"]]}, "indexentries": {"experiment (class in piml)": [[138, "piml.Experiment"]], "data_loader() (piml.experiment method)": [[138, "piml.Experiment.data_loader"]], "data_prepare() (piml.experiment method)": [[138, "piml.Experiment.data_prepare"]], "data_quality() (piml.experiment method)": [[138, "piml.Experiment.data_quality"]], "data_summary() (piml.experiment method)": [[138, "piml.Experiment.data_summary"]], "eda() (piml.experiment method)": [[138, "piml.Experiment.eda"]], "feature_select() (piml.experiment method)": [[138, "piml.Experiment.feature_select"]], "get_data() (piml.experiment method)": [[138, "piml.Experiment.get_data"]], "get_feature_names() (piml.experiment method)": [[138, "piml.Experiment.get_feature_names"]], "get_feature_types() (piml.experiment method)": [[138, "piml.Experiment.get_feature_types"]], "get_interpretable_model_list() (piml.experiment method)": [[138, "piml.Experiment.get_interpretable_model_list"]], "get_leaderboard() (piml.experiment method)": [[138, "piml.Experiment.get_leaderboard"]], "get_leaderboard_registered() (piml.experiment method)": [[138, "piml.Experiment.get_leaderboard_registered"]], "get_model() (piml.experiment method)": [[138, "piml.Experiment.get_model"]], "get_model_config() (piml.experiment method)": [[138, "piml.Experiment.get_model_config"]], "get_model_list() (piml.experiment method)": [[138, "piml.Experiment.get_model_list"]], "get_raw_data() (piml.experiment method)": [[138, "piml.Experiment.get_raw_data"]], "get_target_name() (piml.experiment method)": [[138, "piml.Experiment.get_target_name"]], "make_pipeline() (piml.experiment method)": [[138, "piml.Experiment.make_pipeline"]], "model_compare() (piml.experiment method)": [[138, "piml.Experiment.model_compare"]], "model_diagnose() (piml.experiment method)": [[138, "piml.Experiment.model_diagnose"]], "model_explain() (piml.experiment method)": [[138, "piml.Experiment.model_explain"]], "model_fairness() (piml.experiment method)": [[138, "piml.Experiment.model_fairness"]], "model_fairness_compare() (piml.experiment method)": [[138, "piml.Experiment.model_fairness_compare"]], "model_fairness_solas() (piml.experiment method)": [[138, "piml.Experiment.model_fairness_solas"]], "model_interpret() (piml.experiment method)": [[138, "piml.Experiment.model_interpret"]], "model_save() (piml.experiment method)": [[138, "piml.Experiment.model_save"]], "model_train() (piml.experiment method)": [[138, "piml.Experiment.model_train"]], "model_tune() (piml.experiment method)": [[138, "piml.Experiment.model_tune"]], "register() (piml.experiment method)": [[138, "piml.Experiment.register"]], "segmented_diagnose() (piml.experiment method)": [[138, "piml.Experiment.segmented_diagnose"]], "glmregressor (class in piml.models)": [[156, "piml.models.GLMRegressor"]], "get_metadata_routing() (piml.models.glmregressor method)": [[156, "piml.models.GLMRegressor.get_metadata_routing"]], "get_params() (piml.models.glmregressor method)": [[156, "piml.models.GLMRegressor.get_params"]], "set_params() (piml.models.glmregressor method)": [[156, "piml.models.GLMRegressor.set_params"]]}})