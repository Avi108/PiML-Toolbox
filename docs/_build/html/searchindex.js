Search.setIndex({"docnames": ["auto_examples/data/index", "auto_examples/data/plot_0_data_loader_builtin", "auto_examples/data/plot_0_data_loader_dataframe", "auto_examples/data/plot_1_data_summary", "auto_examples/data/plot_2_data_eda", "auto_examples/data/plot_3_data_prepare", "auto_examples/data/plot_4_data_quality", "auto_examples/data/plot_5_feature_select", "auto_examples/data/plot_6_twosample_test", "auto_examples/data/sg_execution_times", "auto_examples/explain/index", "auto_examples/explain/plot_0_pfi", "auto_examples/explain/plot_1_pdp", "auto_examples/explain/plot_2_ice", "auto_examples/explain/plot_3_ale", "auto_examples/explain/plot_4_lime", "auto_examples/explain/plot_5_shap", "auto_examples/explain/sg_execution_times", "auto_examples/index", "auto_examples/models/index", "auto_examples/models/plot_0_glm_cls", "auto_examples/models/plot_0_glm_reg", "auto_examples/models/plot_1_gam_cls", "auto_examples/models/plot_1_gam_reg", "auto_examples/models/plot_2_tree_cls", "auto_examples/models/plot_2_tree_reg", "auto_examples/models/plot_3_figs_cls", "auto_examples/models/plot_3_figs_reg", "auto_examples/models/plot_4_xgb1_cls", "auto_examples/models/plot_4_xgb1_reg", "auto_examples/models/plot_5_xgb2_cls", "auto_examples/models/plot_5_xgb2_reg", "auto_examples/models/plot_6_ebm_cls", "auto_examples/models/plot_6_ebm_reg", "auto_examples/models/plot_7_gaminet_cls", "auto_examples/models/plot_7_gaminet_reg", "auto_examples/models/plot_8_reludnn_cls", "auto_examples/models/plot_8_reludnn_reg", "auto_examples/models/sg_execution_times", "auto_examples/testing/index", "auto_examples/testing/plot_0_accuracy_cls", "auto_examples/testing/plot_0_accuracy_reg", "auto_examples/testing/plot_1_weakspot_cls", "auto_examples/testing/plot_1_weakspot_reg", "auto_examples/testing/plot_2_overfit_cls", "auto_examples/testing/plot_2_overfit_reg", "auto_examples/testing/plot_3_reliability_cls", "auto_examples/testing/plot_3_reliability_reg", "auto_examples/testing/plot_4_robustness_cls", "auto_examples/testing/plot_4_robustness_reg", "auto_examples/testing/plot_5_resilience_cls", "auto_examples/testing/plot_5_resilience_reg", "auto_examples/testing/plot_6_fairness", "auto_examples/testing/sg_execution_times", "auto_examples/testing_compare/index", "auto_examples/testing_compare/plot_0_compare_classification", "auto_examples/testing_compare/plot_0_compare_regression", "auto_examples/testing_compare/plot_1_compare_fairness", "auto_examples/testing_compare/sg_execution_times", "contents", "faq", "guides/cases", "guides/cases/Example_BikeSharing", "guides/cases/Example_CaliforniaHousing", "guides/cases/Example_Fairness_SimuStudy1", "guides/cases/Example_Fairness_SimuStudy2", "guides/cases/Example_TaiwanCredit", "guides/comparison", "guides/comparison/compare_classification", "guides/comparison/compare_fairness", "guides/comparison/compare_regression", "guides/data", "guides/data/data_eda", "guides/data/data_load", "guides/data/data_prepare", "guides/data/data_quality", "guides/data/data_summary", "guides/data/feature_select", "guides/data/twosample_test", "guides/explain/ale", "guides/explain/ice", "guides/explain/lime", "guides/explain/pdp", "guides/explain/pfi", "guides/explain/shap", "guides/explainability", "guides/extmodels", "guides/introduction", "guides/models", "guides/models/ebm", "guides/models/figs", "guides/models/gam", "guides/models/gaminet", "guides/models/glm", "guides/models/reludnn", "guides/models/tree", "guides/models/xgb1", "guides/models/xgb2", "guides/testing", "guides/testing/accuracy", "guides/testing/fairness", "guides/testing/overfit", "guides/testing/reliability", "guides/testing/resilience", "guides/testing/robustness", "guides/testing/weakspot", "install", "modules/classes", "modules/generated/piml.Experiment", "modules/generated/piml.data.outlier_detection.CBLOF", "modules/generated/piml.data.outlier_detection.IsolationForest", "modules/generated/piml.data.outlier_detection.KMeansTree", "modules/generated/piml.data.outlier_detection.PCA", "modules/generated/piml.models.ExplainableBoostingClassifier", "modules/generated/piml.models.ExplainableBoostingRegressor", "modules/generated/piml.models.FIGSClassifier", "modules/generated/piml.models.FIGSRegressor", "modules/generated/piml.models.GAMClassifier", "modules/generated/piml.models.GAMINetClassifier", "modules/generated/piml.models.GAMINetRegressor", "modules/generated/piml.models.GAMRegressor", "modules/generated/piml.models.GLMClassifier", "modules/generated/piml.models.GLMRegressor", "modules/generated/piml.models.ReluDNNClassifier", "modules/generated/piml.models.ReluDNNRegressor", "modules/generated/piml.models.TreeClassifier", "modules/generated/piml.models.TreeRegressor", "modules/generated/piml.models.XGB1Classifier", "modules/generated/piml.models.XGB1Regressor", "modules/generated/piml.models.XGB2Classifier", "modules/generated/piml.models.XGB2Regressor", "preface", "tune_toc", "user_guide"], "filenames": ["auto_examples\\data\\index.rst", "auto_examples\\data\\plot_0_data_loader_builtin.rst", "auto_examples\\data\\plot_0_data_loader_dataframe.rst", "auto_examples\\data\\plot_1_data_summary.rst", "auto_examples\\data\\plot_2_data_eda.rst", "auto_examples\\data\\plot_3_data_prepare.rst", "auto_examples\\data\\plot_4_data_quality.rst", "auto_examples\\data\\plot_5_feature_select.rst", "auto_examples\\data\\plot_6_twosample_test.rst", "auto_examples\\data\\sg_execution_times.rst", "auto_examples\\explain\\index.rst", "auto_examples\\explain\\plot_0_pfi.rst", "auto_examples\\explain\\plot_1_pdp.rst", "auto_examples\\explain\\plot_2_ice.rst", "auto_examples\\explain\\plot_3_ale.rst", "auto_examples\\explain\\plot_4_lime.rst", "auto_examples\\explain\\plot_5_shap.rst", "auto_examples\\explain\\sg_execution_times.rst", "auto_examples\\index.rst", "auto_examples\\models\\index.rst", "auto_examples\\models\\plot_0_glm_cls.rst", "auto_examples\\models\\plot_0_glm_reg.rst", "auto_examples\\models\\plot_1_gam_cls.rst", "auto_examples\\models\\plot_1_gam_reg.rst", "auto_examples\\models\\plot_2_tree_cls.rst", "auto_examples\\models\\plot_2_tree_reg.rst", "auto_examples\\models\\plot_3_figs_cls.rst", "auto_examples\\models\\plot_3_figs_reg.rst", "auto_examples\\models\\plot_4_xgb1_cls.rst", "auto_examples\\models\\plot_4_xgb1_reg.rst", "auto_examples\\models\\plot_5_xgb2_cls.rst", "auto_examples\\models\\plot_5_xgb2_reg.rst", "auto_examples\\models\\plot_6_ebm_cls.rst", "auto_examples\\models\\plot_6_ebm_reg.rst", "auto_examples\\models\\plot_7_gaminet_cls.rst", "auto_examples\\models\\plot_7_gaminet_reg.rst", "auto_examples\\models\\plot_8_reludnn_cls.rst", "auto_examples\\models\\plot_8_reludnn_reg.rst", "auto_examples\\models\\sg_execution_times.rst", "auto_examples\\testing\\index.rst", "auto_examples\\testing\\plot_0_accuracy_cls.rst", "auto_examples\\testing\\plot_0_accuracy_reg.rst", "auto_examples\\testing\\plot_1_weakspot_cls.rst", "auto_examples\\testing\\plot_1_weakspot_reg.rst", "auto_examples\\testing\\plot_2_overfit_cls.rst", "auto_examples\\testing\\plot_2_overfit_reg.rst", "auto_examples\\testing\\plot_3_reliability_cls.rst", "auto_examples\\testing\\plot_3_reliability_reg.rst", "auto_examples\\testing\\plot_4_robustness_cls.rst", "auto_examples\\testing\\plot_4_robustness_reg.rst", "auto_examples\\testing\\plot_5_resilience_cls.rst", "auto_examples\\testing\\plot_5_resilience_reg.rst", "auto_examples\\testing\\plot_6_fairness.rst", "auto_examples\\testing\\sg_execution_times.rst", "auto_examples\\testing_compare\\index.rst", "auto_examples\\testing_compare\\plot_0_compare_classification.rst", "auto_examples\\testing_compare\\plot_0_compare_regression.rst", "auto_examples\\testing_compare\\plot_1_compare_fairness.rst", "auto_examples\\testing_compare\\sg_execution_times.rst", "contents.rst", "faq.rst", "guides\\cases.rst", "guides\\cases\\Example_BikeSharing.ipynb", "guides\\cases\\Example_CaliforniaHousing.ipynb", "guides\\cases\\Example_Fairness_SimuStudy1.ipynb", "guides\\cases\\Example_Fairness_SimuStudy2.ipynb", "guides\\cases\\Example_TaiwanCredit.ipynb", "guides\\comparison.rst", "guides\\comparison\\compare_classification.rst", "guides\\comparison\\compare_fairness.rst", "guides\\comparison\\compare_regression.rst", "guides\\data.rst", "guides\\data\\data_eda.rst", "guides\\data\\data_load.rst", "guides\\data\\data_prepare.rst", "guides\\data\\data_quality.rst", "guides\\data\\data_summary.rst", "guides\\data\\feature_select.rst", "guides\\data\\twosample_test.rst", "guides\\explain\\ale.rst", "guides\\explain\\ice.rst", "guides\\explain\\lime.rst", "guides\\explain\\pdp.rst", "guides\\explain\\pfi.rst", "guides\\explain\\shap.rst", "guides\\explainability.rst", "guides\\extmodels.rst", "guides\\introduction.rst", "guides\\models.rst", "guides\\models\\ebm.rst", "guides\\models\\figs.rst", "guides\\models\\gam.rst", "guides\\models\\gaminet.rst", "guides\\models\\glm.rst", "guides\\models\\reludnn.rst", "guides\\models\\tree.rst", "guides\\models\\xgb1.rst", "guides\\models\\xgb2.rst", "guides\\testing.rst", "guides\\testing\\accuracy.rst", "guides\\testing\\fairness.rst", "guides\\testing\\overfit.rst", "guides\\testing\\reliability.rst", "guides\\testing\\resilience.rst", "guides\\testing\\robustness.rst", "guides\\testing\\weakspot.rst", "install.rst", "modules\\classes.rst", "modules\\generated\\piml.Experiment.rst", "modules\\generated\\piml.data.outlier_detection.CBLOF.rst", "modules\\generated\\piml.data.outlier_detection.IsolationForest.rst", "modules\\generated\\piml.data.outlier_detection.KMeansTree.rst", "modules\\generated\\piml.data.outlier_detection.PCA.rst", "modules\\generated\\piml.models.ExplainableBoostingClassifier.rst", "modules\\generated\\piml.models.ExplainableBoostingRegressor.rst", "modules\\generated\\piml.models.FIGSClassifier.rst", "modules\\generated\\piml.models.FIGSRegressor.rst", "modules\\generated\\piml.models.GAMClassifier.rst", "modules\\generated\\piml.models.GAMINetClassifier.rst", "modules\\generated\\piml.models.GAMINetRegressor.rst", "modules\\generated\\piml.models.GAMRegressor.rst", "modules\\generated\\piml.models.GLMClassifier.rst", "modules\\generated\\piml.models.GLMRegressor.rst", "modules\\generated\\piml.models.ReluDNNClassifier.rst", "modules\\generated\\piml.models.ReluDNNRegressor.rst", "modules\\generated\\piml.models.TreeClassifier.rst", "modules\\generated\\piml.models.TreeRegressor.rst", "modules\\generated\\piml.models.XGB1Classifier.rst", "modules\\generated\\piml.models.XGB1Regressor.rst", "modules\\generated\\piml.models.XGB2Classifier.rst", "modules\\generated\\piml.models.XGB2Regressor.rst", "preface.rst", "tune_toc.rst", "user_guide.rst"], "titles": ["Data Pipeline", "Data Load (Built-in Dataset)", "Data Load (Pandas DataFrame)", "Data Summary", "EDA", "Data Preparation", "Data Quality Check", "Feature Selection", "Two Sample Test", "Computation times", "Post hoc Explainability", "Permutation Feature Importance", "Partial Dependence Plot", "Individual Conditional Expectation", "Accumulated Local Effects", "Local Interpretable Model-Agnostic Explanation", "SHapley Additive exPlanations", "Computation times", "Examples", "Interpretable Models", "GLM Logistic Regression (Taiwan Credit)", "GLM Linear Regression (Bike Sharing)", "GAM Classification (CoCircles)", "GAM Regression (California Housing)", "Tree Classification (TaiwanCredit)", "Tree Regression (California Housing)", "FIGS Classification (Taiwan Credit)", "FIGS Regression (California Housing)", "XGB-1 Classification (CoCircles)", "XGB-1 Regression (California Housing)", "XGB-2 Classification (Taiwan Credit)", "XGB-2 Regression (Bike Sharing)", "EBM Classification (Taiwan Credit)", "EBM Regression (Bike Sharing)", "GAMI-Net Classification (Taiwan Credit)", "GAMI-Net Regression (Bike Sharing)", "ReLU DNN Classification (Taiwan Credit)", "ReLU DNN Regression (Friedman)", "Computation times", "Outcome Testing", "Accuracy: Classification", "Accuracy: Regression", "WeakSpot: Classification", "WeakSpot: Regression", "Overfit: Classification", "Overfit: Regression", "Reliability: Classification", "Reliability: Regression", "Robustness: Classification", "Robustness:  Regression", "Resilience:  Classification", "Resilience - Regression", "Fairness Test: XGB2", "Computation times", "Model Comparison", "Model Comparison: Classification", "Model Comparison: Regression", "Fairness Comparison", "Computation times", "Table Of Contents", "Frequently Asked Questions", "<span class=\"section-number\">8. </span>Case Studies", "<span class=\"section-number\">8.1. </span>BikeSharing Data", "<span class=\"section-number\">8.2. </span>CaliforniaHousing Data", "<span class=\"section-number\">8.4. </span>Fairness Simulation Study 1", "<span class=\"section-number\">8.5. </span>Fairness Simulation Study 2", "<span class=\"section-number\">8.3. </span>TaiwanCredit Data", "<span class=\"section-number\">7. </span>Model Comparison", "<span class=\"section-number\">7.2. </span>Comparison for Classification", "<span class=\"section-number\">7.3. </span>Fairness Comparison", "<span class=\"section-number\">7.1. </span>Comparison for Regression", "<span class=\"section-number\">2. </span>Data Pipeline", "<span class=\"section-number\">2.4. </span>Exploratory Analysis", "<span class=\"section-number\">2.1. </span>Data Load", "<span class=\"section-number\">2.3. </span>Data Preparation", "<span class=\"section-number\">2.5. </span>Data Quality", "<span class=\"section-number\">2.2. </span>Data Summary", "<span class=\"section-number\">2.6. </span>Feature Selection", "<span class=\"section-number\">2.7. </span>Two Sample Test", "<span class=\"section-number\">4.1.4. </span>ALE (Accumulated Local Effects)", "<span class=\"section-number\">4.1.3. </span>ICE (Individual Conditional Expectation)", "<span class=\"section-number\">4.2.1. </span>LIME (Local Interpretable Model-Agnostic Explanation)", "<span class=\"section-number\">4.1.2. </span>PDP (Partial Dependence Plot)", "<span class=\"section-number\">4.1.1. </span>PFI (Permutation Feature Importance)", "<span class=\"section-number\">4.2.2. </span>SHAP (SHapley Additive exPlanations)", "<span class=\"section-number\">4. </span>Post-hoc Explainability", "<span class=\"section-number\">3. </span>Black-box Models", "<span class=\"section-number\">1. </span>Introduction", "<span class=\"section-number\">5. </span>Interpretable Models", "<span class=\"section-number\">5.7. </span>Explainable Boosting Machines", "<span class=\"section-number\">5.4. </span>Fast Interpretable Greedy-tree Sums", "<span class=\"section-number\">5.2. </span>Generalized Additive Model", "<span class=\"section-number\">5.8. </span>GAMI-Net", "<span class=\"section-number\">5.1. </span>Generalized Linear Models", "<span class=\"section-number\">5.9. </span>ReLU Neural Network", "<span class=\"section-number\">5.3. </span>Decision Tree", "<span class=\"section-number\">5.5. </span>XGBoost Depth 1", "<span class=\"section-number\">5.6. </span>XGBoost Depth 2", "<span class=\"section-number\">6. </span>Diagnostic Suite", "<span class=\"section-number\">6.1. </span>Accuracy", "<span class=\"section-number\">6.7. </span>Fairness", "<span class=\"section-number\">6.3. </span>Overfit", "<span class=\"section-number\">6.4. </span>Reliability", "<span class=\"section-number\">6.6. </span>Resilience", "<span class=\"section-number\">6.5. </span>Robustness", "<span class=\"section-number\">6.2. </span>WeakSpot", "Installation", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml</span></code>.Experiment", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.CBLOF", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.IsolationForest", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.KMeansTree", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.data.outlier_detection</span></code>.PCA", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ExplainableBoostingClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ExplainableBoostingRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.FIGSClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.FIGSRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMINetClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMINetRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GLMClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GLMRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ReluDNNClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ReluDNNRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.TreeClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.TreeRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB1Classifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB1Regressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB2Classifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB2Regressor", "Welcome to scikit-learn", "&lt;no title&gt;", "User guide: contents"], "terms": {"load": [0, 9, 18, 44, 61, 68, 71, 76, 87, 89, 93, 97, 99, 101, 102, 104, 105, 108, 118, 119, 133], "built": [0, 7, 9, 18, 71, 77, 84, 94, 101, 108, 111], "dataset": [0, 2, 3, 4, 5, 6, 7, 9, 18, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 118, 119, 123, 124], "panda": [0, 9, 18, 106, 108], "datafram": [0, 9, 18, 108], "summari": [0, 9, 16, 18, 36, 37, 71, 90, 99, 104, 105, 108, 133], "eda": [0, 9, 18, 62, 63, 64, 65, 66, 72, 87, 108], "prepar": [0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 61, 71, 75, 83, 86, 91, 94, 95, 108, 133], "qualiti": [0, 9, 18, 71, 87, 100, 102, 108, 125, 126, 133], "check": [0, 9, 18, 62, 63, 65, 70, 75, 108, 125, 126], "featur": [0, 3, 6, 8, 9, 10, 16, 17, 18, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 62, 63, 64, 65, 66, 68, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 85, 87, 95, 99, 100, 101, 102, 103, 105, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 133], "select": [0, 6, 9, 18, 64, 65, 68, 70, 71, 74, 75, 79, 92, 94, 95, 96, 99, 101, 103, 104, 105, 108, 112, 118, 119, 125, 126, 133], "two": [0, 9, 18, 36, 37, 42, 43, 44, 45, 65, 69, 71, 72, 73, 74, 75, 76, 77, 80, 81, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 102, 104, 108, 111, 133], "sampl": [0, 5, 9, 18, 48, 49, 50, 51, 55, 56, 62, 63, 65, 71, 73, 75, 76, 77, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130, 133], "test": [0, 5, 7, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 48, 49, 53, 59, 60, 61, 68, 70, 71, 73, 83, 87, 93, 99, 100, 101, 102, 103, 105, 108, 113, 114, 115, 116, 118, 119, 123, 124, 125, 126, 127, 128, 129, 130, 133], "go": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57], "end": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 77, 78, 79, 80, 82, 84, 87, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 102, 125, 126], "download": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57], "full": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 81, 87, 89, 91, 92, 93, 94, 96, 97, 100, 102, 103, 104, 107, 108, 112], "exampl": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 61, 62, 63, 64, 65, 66, 67, 71, 85, 87, 88, 98], "code": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 61, 62, 63, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108], "run": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 62, 63, 64, 65, 66, 77, 87, 104, 106, 108, 112, 113, 114, 125, 126], "thi": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 61, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "your": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 65, 73, 74, 76, 96, 103, 106], "browser": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57], "via": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 73, 77, 79, 89, 94, 108, 111, 112], "binder": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57], "experi": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 59, 60, 62, 63, 64, 65, 66, 73, 77, 86, 87, 100, 104, 106], "initi": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 77, 86, 87, 96, 100, 105, 108, 118, 119, 123, 124], "from": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 111, 112, 113, 114, 116, 118, 119, 124, 126, 127, 128, 130], "piml": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 68, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107], "import": [1, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 62, 63, 64, 65, 66, 68, 69, 70, 71, 74, 75, 85, 86, 87, 95, 99, 101, 102, 103, 104, 105, 108, 115, 116, 117, 118, 119, 120, 125, 126, 127, 128, 129, 130], "exp": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106], "data_load": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 62, 63, 64, 65, 66, 73, 86, 87, 108], "cocircl": [1, 18, 19, 38, 73, 108], "x0": [1, 22, 28, 37, 73, 96, 108], "x1": [1, 22, 28, 64, 73, 96, 108], "target": [1, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 65, 73, 74, 78, 79, 82, 83, 86, 93, 96, 99, 104, 108, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "0": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 63, 65, 66, 68, 69, 70, 73, 74, 75, 76, 77, 79, 81, 82, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "783526": [1, 73], "502161": [1, 73], "1": [1, 2, 3, 5, 7, 11, 15, 17, 18, 19, 20, 21, 23, 26, 27, 36, 37, 38, 42, 43, 44, 45, 46, 47, 49, 52, 55, 56, 57, 61, 62, 63, 65, 66, 69, 74, 75, 77, 78, 87, 88, 100, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130, 133], "297809": [1, 73], "658405": [1, 73], "2": [1, 2, 3, 5, 7, 13, 18, 19, 20, 21, 22, 24, 25, 36, 37, 38, 40, 41, 42, 43, 44, 45, 48, 49, 50, 52, 56, 57, 61, 62, 66, 74, 75, 77, 79, 82, 84, 86, 87, 88, 100, 106, 108, 110, 111, 113, 114, 115, 116, 118, 119, 123, 124, 125, 126, 127, 128, 129, 130, 133], "468272": [1, 73], "500653": [1, 73], "3": [1, 2, 3, 5, 20, 21, 24, 25, 26, 27, 30, 36, 37, 42, 43, 44, 45, 48, 49, 50, 51, 52, 55, 56, 57, 62, 63, 64, 65, 66, 68, 70, 74, 76, 79, 80, 84, 90, 91, 92, 94, 95, 96, 99, 101, 103, 104, 105, 106, 108, 111, 113, 114, 117, 118, 119, 120, 125, 127, 128, 129, 130], "134700": 1, "887973": 1, "4": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 62, 63, 64, 65, 66, 68, 69, 70, 72, 74, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 111, 113, 114, 118, 119, 125], "337202": 1, "780797": 1, "1995": 1, "498109": 1, "889060": 1, "1996": 1, "312980": 1, "724953": 1, "1997": [1, 73], "542930": [1, 73], "583517": [1, 73], "1998": [1, 73], "871481": [1, 73], "491301": [1, 73], "1999": [1, 73], "323963": [1, 73], "719150": [1, 73], "2000": [1, 77, 82, 108], "row": [1, 2, 36, 94, 108], "x": [1, 2, 20, 21, 36, 68, 70, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 89, 90, 91, 92, 93, 94, 96, 97, 99, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "column": [1, 2, 5, 36, 65, 74, 90, 99, 105, 108, 125], "total": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 93, 94, 96, 99, 112, 114, 116, 119, 124, 125, 126, 127, 128, 129, 130], "time": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 65, 77, 83, 84, 87, 90, 94, 101, 102, 104, 118, 119], "script": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57], "minut": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57], "8": [1, 20, 21, 27, 37, 42, 43, 44, 45, 52, 57, 62, 63, 64, 65, 66, 68, 69, 70, 80, 84, 89, 92, 100, 101, 104, 105, 106, 108, 113, 114, 117, 118, 119, 120, 127, 128], "553": 1, "second": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 68, 70, 72, 74, 76, 84, 89, 90, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 118, 119], "estim": [1, 2, 3, 4, 5, 6, 12, 52, 55, 56, 57, 70, 79, 82, 84, 89, 90, 91, 92, 93, 96, 97, 99, 102, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "memori": [1, 2, 3, 4, 5, 6, 12, 52, 55, 56, 57, 110, 118, 119, 123, 124], "usag": [1, 2, 3, 4, 5, 6, 12, 52, 55, 56, 57, 71, 75, 77, 85, 90, 96, 97, 98, 99], "12": [1, 2, 3, 20, 21, 26, 27, 37, 52, 63, 65, 73, 87, 90, 103, 104, 106], "mb": [1, 2, 3, 4, 5, 6, 9, 12, 17, 38, 52, 53, 55, 56, 57, 58], "python": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 79, 84, 87, 90, 91, 94, 96, 97, 106], "sourc": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57], "plot_0_data_loader_builtin": [1, 9], "py": [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 106], "jupyt": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 87], "notebook": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 62, 63, 66, 87], "ipynb": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 62, 63, 64, 65, 66], "galleri": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57], "gener": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 68, 70, 73, 74, 77, 79, 80, 83, 84, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 103, 104, 105, 108, 110, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 126, 128, 130, 133], "sphinx": [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57], "pd": [2, 73, 82, 108], "read_csv": [2, 73], "http": [2, 73, 77, 87, 108, 112, 115, 116], "github": [2, 73, 87, 108, 115, 116], "com": [2, 73, 87, 108, 115, 116], "selfexplainml": [2, 73, 87], "toolbox": [2, 73, 133], "blob": [2, 73], "main": [2, 62, 63, 66, 73, 77, 79, 94, 113, 114, 117, 118, 119, 120, 127, 128], "bikeshar": [2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 21, 31, 33, 35, 41, 43, 45, 47, 49, 51, 56, 61, 73, 77, 79, 80, 81, 82, 83, 84, 93, 108, 133], "csv": [2, 73], "raw": [2, 49, 68, 70, 73, 96, 97, 102, 104, 107, 108, 109, 112, 115, 117, 118, 119, 120, 123, 124, 127, 128, 129, 130], "true": [2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 69, 73, 79, 80, 81, 82, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "season": [2, 3, 4, 12, 21, 31, 33, 41, 72, 73, 77, 82, 84, 89, 92, 93, 97, 99], "yr": [2, 3, 4, 11, 12, 13, 14, 15, 16, 21, 31, 33, 35, 41, 43, 45, 47, 49, 51, 56, 62, 72, 73, 76, 77], "mnth": [2, 3, 11, 12, 13, 14, 15, 16, 21, 31, 33, 35, 41, 43, 45, 47, 49, 51, 56, 62, 73, 76, 77], "hr": [2, 3, 4, 7, 12, 13, 14, 16, 21, 31, 33, 35, 41, 43, 45, 47, 49, 51, 56, 70, 72, 73, 77, 79, 80, 81, 82, 83, 84, 89, 92, 93, 97, 99, 101, 102, 104], "holidai": [2, 3, 73, 83], "weekdai": [2, 3, 13, 21, 35, 73, 76, 77, 92], "workingdai": [2, 3, 12, 43, 73, 77, 82, 83, 89, 92, 97], "weathersit": [2, 3, 14, 73, 77, 79], "6": [2, 3, 4, 5, 9, 20, 21, 22, 23, 24, 25, 37, 42, 43, 45, 48, 49, 52, 57, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 77, 79, 80, 81, 87, 91, 95, 100, 101, 104, 106, 108, 111, 117, 118, 119, 120, 127, 128], "17374": 2, "19": [2, 37, 52], "17375": 2, "20": [2, 22, 23, 28, 29, 37, 42, 44, 52, 63, 65, 74, 77, 84, 90, 91, 94, 95, 96, 101, 102, 103, 105, 106, 108, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "17376": 2, "21": [2, 37, 52, 73, 106], "17377": [2, 73], "22": [2, 37, 52, 73, 87], "17378": [2, 73], "23": [2, 3, 37, 52, 57, 58, 73, 87, 114, 116, 119, 124, 126, 128, 130], "temp": [2, 3, 4, 7, 11, 12, 13, 14, 15, 16, 21, 31, 33, 35, 41, 43, 45, 47, 49, 51, 56, 62, 72, 73, 76, 77, 93], "atemp": [2, 3, 8, 13, 14, 21, 31, 43, 45, 49, 73, 78, 79, 81, 83, 84, 89, 92, 97, 101, 104], "hum": [2, 3, 21, 73, 77, 81, 84, 89, 93, 97], "windspe": [2, 3, 21, 73, 92], "cnt": [2, 3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 21, 31, 33, 35, 41, 43, 45, 47, 49, 51, 56, 62, 70, 72, 73, 74, 79, 80, 81, 82, 83, 84, 89, 92, 93, 96, 97, 99, 101, 102, 104, 105], "24": [2, 3, 5, 7, 37, 44, 52, 53, 57, 73, 75, 80, 106], "2879": [2, 44, 73], "81": [2, 73], "0000": [2, 3, 21, 36, 42, 44, 73], "16": [2, 3, 20, 21, 24, 25, 26, 27, 37, 52, 73, 89, 90, 92, 95, 97], "2727": [2, 73], "80": [2, 44, 73, 112], "40": [2, 3, 9, 36, 37, 52, 57, 70, 73, 94, 102, 104, 123, 124], "32": [2, 37, 52, 73, 83, 87, 100, 113, 114], "75": [2, 44, 105], "13": [2, 3, 20, 21, 32, 37, 38, 52, 65, 76], "26": [2, 37, 73], "2576": [2, 73], "60": [2, 42, 43, 56, 58, 65, 73], "1642": [2, 73], "119": 2, "89": 2, "90": [2, 52, 57, 65, 70, 73, 102], "56": [2, 56, 58, 73], "1343": [2, 73], "61": [2, 52, 57, 73], "65": [2, 37, 73, 80], "49": [2, 73], "17379": [2, 3, 5, 73, 74, 76], "7": [2, 3, 5, 20, 21, 37, 42, 43, 44, 45, 52, 56, 57, 62, 63, 64, 65, 66, 68, 74, 77, 86, 89, 90, 97, 101, 102, 103, 104, 106, 113, 114], "656": 2, "plot_0_data_loader_datafram": [2, 9], "show": [3, 4, 6, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 64, 65, 68, 69, 70, 72, 74, 75, 77, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 117, 118, 119, 120, 127, 128], "result": [3, 5, 6, 42, 43, 44, 45, 46, 47, 67, 68, 69, 70, 75, 77, 79, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 104, 105, 108, 112, 113, 114, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "us": [3, 4, 5, 6, 7, 42, 43, 45, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 116, 117, 118, 119, 120, 123, 124, 126, 127, 128, 130], "highcode_onli": [3, 108], "silent": [3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 108], "data_summari": [3, 11, 12, 13, 14, 15, 16, 20, 21, 24, 26, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 62, 63, 64, 65, 66, 76, 87, 108], "feature_typ": [3, 76, 108, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "feature_exclud": [3, 11, 12, 13, 14, 15, 16, 20, 21, 24, 26, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 76, 108], "name": [3, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 64, 65, 68, 70, 74, 75, 76, 77, 79, 80, 82, 84, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 104, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "n_miss": [3, 76], "mean": [3, 36, 37, 74, 75, 76, 77, 79, 81, 83, 84, 90, 91, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 112, 113, 114, 115, 116, 118, 119, 123, 124, 125, 126, 127, 128, 129, 130], "std": [3, 36, 37, 76, 108], "min": [3, 74, 76, 108, 112, 118, 119, 127, 128], "q1": [3, 76], "median": [3, 63, 76, 90, 91, 95, 103, 126], "537775": 3, "438776": 3, "00": [3, 9, 17, 38, 53, 58, 105], "11": [3, 20, 21, 37, 46, 50, 52, 62, 63, 65, 81, 90, 106], "546752": 3, "914405": 3, "003683": 3, "005771": 3, "496987": 3, "192556": 3, "02": [3, 38], "3400": 3, "5000": [3, 42, 45, 77, 113, 114, 118, 119], "475775": 3, "171850": 3, "3333": [3, 42, 44], "4848": [3, 43], "5": [3, 4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 51, 52, 55, 56, 57, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 112, 118, 119, 123, 124, 125, 126], "627229": 3, "192930": 3, "4800": 3, "6300": 3, "190098": 3, "122340": 3, "1045": 3, "1940": 3, "189": 3, "463088": 3, "181": 3, "387599": 3, "142": 3, "q3": [3, 76], "max": [3, 74, 76, 89, 90, 94, 102, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 127, 128, 129, 130], "10": [3, 11, 20, 21, 24, 25, 26, 27, 32, 33, 37, 38, 40, 42, 46, 47, 50, 51, 52, 55, 56, 62, 63, 65, 66, 68, 70, 75, 77, 78, 80, 81, 83, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 101, 102, 103, 104, 105, 108, 109, 111, 113, 114, 117, 118, 119, 120, 125, 126, 127, 128], "18": [3, 37, 52, 80, 87, 125, 126], "6600": 3, "6212": [3, 43], "7800": 3, "2537": 3, "8507": 3, "281": 3, "977": 3, "n_uniqu": [3, 76], "top1": [3, 76], "top2": [3, 76], "top3": [3, 76], "4496": 3, "4409": 3, "4242": 3, "8734": 3, "8645": 3, "16879": 3, "500": [3, 29, 84, 108, 123, 124], "11865": 3, "5514": 3, "11413": 3, "4544": 3, "1419": 3, "n_other": [3, 76], "4232": 3, "html": [3, 74, 76, 77, 112], "valu": [3, 5, 28, 29, 52, 65, 69, 72, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "shape": [3, 76, 89, 91, 92, 96, 97, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "tab": [3, 64, 65, 76], "children": [3, 76], "output": [3, 74, 76, 77, 79, 81, 82, 84, 91, 94, 97, 100, 104, 112, 118, 119, 125, 126], "layout": [3, 76], "height": [3, 76], "350px": [3, 76], "selected_index": [3, 76], "titl": [3, 76, 89, 90, 92, 96, 97], "numer": [3, 20, 21, 65, 68, 70, 72, 74, 77, 79, 82, 93, 99, 100, 108, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "attribut": [3, 65, 66, 69, 81, 84, 103, 109, 110, 111, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "categor": [3, 21, 65, 68, 70, 72, 74, 77, 79, 82, 93, 99, 100, 108, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "remov": [3, 65, 75, 77, 83, 84, 93, 94, 97, 108, 110, 112, 125, 126], "chang": [3, 70, 75, 77, 78, 80, 81, 87, 93, 94, 99, 103, 104], "type": [3, 5, 52, 72, 74, 75, 78, 87, 96, 100, 104, 108, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "2512": 3, "2502": 3, "2487": 3, "9878": 3, "595": 3, "plot_1_data_summari": [3, 9], "plot": [4, 6, 8, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 46, 47, 50, 51, 68, 69, 70, 71, 75, 79, 80, 81, 83, 85, 87, 90, 93, 95, 100, 102, 103, 104, 108, 117, 118, 119, 120, 125, 126, 127, 128], "data": [4, 7, 8, 9, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 59, 60, 61, 68, 70, 72, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 103, 104, 105, 108, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130, 133], "data_prepar": [4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 62, 63, 64, 65, 66, 74, 77, 86, 87, 108], "histogram": [4, 42, 43, 44, 45, 46, 47, 50, 51, 55, 56, 68, 70, 72, 89, 91, 92, 96, 97, 101, 105, 108, 127, 128, 129, 130], "densiti": [4, 50, 51, 72, 79, 105, 108, 118, 119], "univari": [4, 71, 96, 108], "uni_featur": [4, 12, 13, 14, 16, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 72, 79, 80, 82, 84, 89, 91, 92, 93, 94, 96, 97, 108], "figsiz": [4, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 68, 69, 70, 72, 77, 78, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 111, 117, 118, 119, 120, 125, 126, 127, 128], "bar": [4, 68, 69, 70, 72, 77, 79, 82, 84, 91, 93, 96, 99], "scatter": [4, 16, 72, 84, 99, 108], "bivari": [4, 71, 108], "bi_featur": [4, 12, 14, 31, 33, 35, 36, 37, 72, 79, 82, 89, 92, 94, 97, 108], "box": [4, 59, 70, 72, 87, 89, 94, 95, 97, 104, 133], "stack": [4, 72, 115, 116], "correl": [4, 6, 7, 62, 63, 71, 72, 75, 79, 82, 84, 96, 99, 102, 108], "heatmap": [4, 26, 27, 72, 108], "multivari": [4, 71, 75, 82, 108], "multi_typ": [4, 72, 108], "correlation_heatmap": [4, 72, 108], "graph": [4, 72], "correlation_graph": [4, 72, 108], "48": [4, 9, 35, 37, 38], "021": [4, 9], "41": [4, 44], "plot_2_data_eda": [4, 9], "displai": [5, 68, 69, 70, 72, 75, 78, 84, 89, 90, 91, 92, 93, 96, 97, 99, 100, 101, 103, 104, 105, 108, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128], "numpi": [5, 106, 109, 112, 113, 114, 115, 116, 118, 119, 123, 124, 127, 128, 129, 130], "np": [5, 74, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "random": [5, 7, 71, 75, 81, 83, 99, 101, 103, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130], "split": [5, 26, 27, 60, 71, 75, 79, 87, 90, 95, 96, 97, 105, 108, 110, 113, 114, 115, 116, 125, 126, 127, 128, 129, 130], "task_typ": [5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 74, 86, 108], "regress": [5, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 19, 38, 39, 53, 54, 58, 62, 63, 67, 73, 74, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 108, 115, 116, 122, 125, 126, 133], "sample_weight": [5, 74, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "none": [5, 49, 51, 55, 56, 68, 70, 74, 90, 103, 104, 105, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "split_method": [5, 74, 108], "test_ratio": [5, 74, 108], "random_st": [5, 74, 86, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 122, 123, 124, 125, 126, 127, 128, 129, 130], "config": [5, 74, 108], "exclud": [5, 62, 64, 65, 66, 74, 79, 100, 108, 118, 119], "variabl": [5, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 77, 78, 80, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 108], "weight": [5, 28, 29, 64, 74, 81, 84, 93, 94, 99, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "task": [5, 47, 68, 74, 75, 83, 84, 87, 95, 98, 100, 101, 103, 104, 105, 108], "method": [5, 6, 7, 48, 49, 62, 65, 67, 68, 70, 74, 77, 78, 79, 82, 83, 84, 87, 91, 95, 96, 97, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "ratio": [5, 65, 69, 70, 74, 100, 101, 102, 103, 105, 108, 118, 119, 123, 124], "state": [5, 73, 74, 84, 87, 94, 100, 105, 108, 113, 114, 122], "train": [5, 11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 60, 61, 68, 70, 71, 77, 78, 81, 82, 83, 84, 87, 88, 99, 100, 101, 102, 103, 105, 108, 109, 112, 113, 114, 115, 116, 118, 119, 123, 124, 125, 126, 127, 128, 133], "energi": [5, 74], "distanc": [5, 6, 7, 8, 46, 47, 50, 51, 55, 56, 65, 71, 74, 75, 79, 108, 111, 125, 126], "000586": [5, 74], "outer": [5, 50, 51, 103, 108, 113, 114], "base": [5, 42, 43, 44, 45, 64, 68, 69, 76, 77, 78, 79, 81, 82, 83, 84, 87, 91, 92, 93, 95, 96, 99, 100, 101, 102, 103, 105, 108, 109, 110, 112, 113, 114, 115, 116, 118, 119, 125, 126, 127, 128, 129, 130], "167242": [5, 74], "kmean": [5, 108, 109, 111], "421888": [5, 74], "178697": [5, 74], "custom": [5, 48, 49, 52, 60, 62, 63, 66, 74, 76, 91, 100, 103, 105, 108, 111, 115, 116, 118, 119, 127, 128], "custom_train_idx": [5, 74], "arang": [5, 74], "16000": [5, 74], "custom_test_idx": [5, 74], "train_idx": [5, 74, 108], "test_idx": [5, 74, 108], "manual": [5, 65, 76, 87, 91, 96, 118, 119], "079349": [5, 74], "542053": [5, 74], "418": 5, "2184": 5, "plot_3_data_prepar": [5, 9], "analysi": [6, 62, 63, 64, 65, 71, 74, 80, 83, 87, 101, 102, 105, 108, 133], "score": [6, 46, 79, 83, 84, 87, 92, 99, 103, 104, 105, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "distribut": [6, 8, 46, 47, 50, 51, 62, 63, 65, 68, 70, 72, 74, 77, 78, 84, 87, 94, 99, 102, 103, 104, 106, 108, 127, 128], "outlier_detect": [6, 75, 108], "pca": [6, 75, 108, 111], "cblof": [6, 108], "data_quality_check": [6, 75, 108], "score_distribut": [6, 75, 108], "threshold": [6, 7, 42, 43, 44, 45, 46, 47, 52, 65, 73, 75, 77, 87, 98, 99, 101, 102, 105, 108, 109, 110, 118, 119, 123, 124], "999": [6, 75], "marginal_outlier_distribut": [6, 75, 108], "strategi": [6, 7, 77, 100, 101, 108, 115, 116, 125, 126], "tsne_comparison": [6, 75, 108], "36": [6, 12, 17, 37, 77], "681": 6, "130": 6, "plot_4_data_qu": [6, 9], "four": [7, 74, 75, 77, 79, 87, 93, 103, 108, 111, 125], "pearson": [7, 72, 77, 108], "feature_select": [7, 62, 63, 77, 87, 108], "cor": [7, 77, 108], "corr_algorithm": [7, 77, 108], "spearman": [7, 77, 108], "dcor": [7, 77, 106, 108], "permut": [7, 10, 17, 18, 63, 66, 77, 85, 87, 108, 125, 126], "pfi": [7, 11, 62, 77, 85, 87, 108], "95": [7, 77], "condit": [7, 10, 17, 18, 71, 72, 75, 84, 85, 97, 100, 103, 105, 108], "independ": [7, 71, 75, 82, 84, 94, 96, 103, 108], "rcit": [7, 108], "001": [7, 36, 37, 77, 94, 118, 119, 123, 124], "n_forward_phas": [7, 77, 108], "kernel_s": [7, 77, 108], "100": [7, 12, 16, 26, 27, 28, 42, 43, 45, 49, 50, 51, 52, 77, 84, 86, 90, 96, 100, 101, 105, 108, 110, 117, 118, 119, 120, 127, 128, 129, 130], "where": [7, 68, 69, 72, 73, 74, 75, 77, 79, 82, 84, 87, 89, 90, 93, 94, 95, 96, 97, 99, 100, 101, 104, 105, 114, 116, 119, 124, 125, 126, 128, 130], "markov": [7, 77], "boundari": [7, 73, 77, 99, 108], "i": [7, 60, 62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "non": [7, 65, 77, 82, 91, 97, 99, 113, 114, 117, 120, 121, 122, 125, 126], "empti": [7, 77, 108, 118, 119], "preset": [7, 77, 108], "390": 7, "plot_5_feature_select": [7, 9], "shift": [8, 46, 47, 65, 68, 70, 78, 102, 104, 108], "psi": [8, 46, 47, 50, 51, 65, 78, 102, 103, 108, 111], "twosample_test": [8, 78, 108], "metric": [8, 42, 43, 44, 45, 48, 49, 52, 55, 56, 57, 64, 65, 67, 68, 70, 71, 74, 83, 87, 98, 99, 101, 102, 103, 104, 105, 108, 113, 115, 118, 123, 125, 127, 129], "psi_bucket": [8, 78, 102, 103, 108], "uniform": [8, 52, 78, 100, 102, 104, 108, 113, 114, 127, 128], "wd1": [8, 50, 51, 78, 102, 103, 108, 111], "k": [8, 74, 75, 77, 78, 79, 83, 87, 89, 90, 92, 97, 102, 103, 108, 109, 111], "singl": [8, 42, 43, 44, 45, 68, 70, 72, 77, 79, 82, 84, 90, 93, 94, 99, 103, 105, 108, 117, 120, 125, 126], "quantil": [8, 48, 49, 52, 65, 73, 75, 78, 79, 100, 102, 103, 104, 108, 113, 114], "740": 8, "plot_6_twosample_test": [8, 9], "execut": [9, 17, 38, 53, 58, 77, 87], "auto_examples_data": 9, "file": [9, 17, 38, 53, 58, 86, 108, 118, 119], "000": [9, 17, 53, 58, 66, 68, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "partial": [10, 17, 18, 77, 85, 87, 108, 118, 119], "depend": [10, 17, 18, 77, 80, 85, 87, 96, 103, 104, 108, 131], "individu": [10, 17, 18, 74, 75, 79, 81, 83, 84, 85, 93, 102, 105, 108, 118, 119], "expect": [10, 17, 18, 70, 72, 75, 84, 85, 90, 93, 102, 104, 110, 112, 114, 116, 119, 124, 126, 128, 130], "accumul": [10, 17, 18, 77, 85, 87, 96, 97, 108], "local": [10, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 62, 82, 84, 87, 88, 99, 108, 109, 117, 118, 119, 120, 125, 126, 127, 128, 133], "effect": [10, 17, 18, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 62, 63, 66, 74, 75, 80, 81, 82, 84, 85, 87, 93, 94, 99, 100, 101, 103, 105, 108, 113, 114, 115, 116, 117, 118, 119, 120, 125, 126, 127, 128], "interpret": [10, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 59, 61, 77, 79, 85, 108, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130, 133], "model": [10, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 57, 58, 59, 60, 61, 68, 69, 70, 73, 74, 75, 77, 79, 80, 82, 83, 85, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 133], "agnost": [10, 17, 18, 62, 63, 66, 79, 82, 85, 87, 102, 103], "explan": [10, 17, 18, 62, 63, 66, 67, 82, 85, 87, 108], "shaplei": [10, 17, 18, 85], "addit": [10, 17, 18, 68, 69, 70, 74, 75, 76, 79, 81, 85, 87, 88, 89, 90, 92, 95, 96, 97, 99, 100, 101, 103, 104, 105, 108, 113, 114, 115, 116, 117, 118, 119, 120, 133], "xgb2regressor": [11, 12, 13, 15, 16, 31, 41, 43, 45, 47, 51, 97, 108], "model_train": [11, 12, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 62, 63, 64, 65, 66, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 108], "xgb2": [11, 12, 13, 15, 16, 18, 30, 31, 39, 40, 41, 42, 43, 44, 45, 47, 50, 51, 53, 55, 56, 65, 68, 70, 80, 81, 82, 83, 84, 87, 89, 92, 97, 99, 100, 101, 102, 103, 105, 108], "model_explain": [11, 12, 13, 14, 15, 16, 62, 63, 66, 79, 80, 81, 82, 83, 84, 87, 108], "n_repeat": [11, 83, 108], "574": 11, "plot_0_pfi": [11, 17], "n_estim": [12, 28, 29, 50, 51, 52, 86, 96, 97, 110, 127, 128, 129, 130], "1d": [12, 14, 63, 66, 78, 87, 97, 108], "pdp": [12, 62, 63, 66, 79, 80, 84, 85, 87, 108], "original_scal": [12, 13, 14, 15, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 55, 56, 79, 80, 81, 82, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 105, 108, 125, 126], "2d": [12, 14, 63, 66, 75, 82, 87, 97, 108], "pdp_size": [12, 82, 108], "10000": [12, 74, 82, 118, 119, 123, 124], "179": [12, 17], "31": [12, 17, 37], "plot_1_pdp": [12, 17], "ic": [13, 73, 85, 108], "313": 13, "plot_2_ic": [13, 17], "reludnnregressor": [14, 37, 94, 108], "reludnn": [14, 36, 48, 79, 94, 123, 124], "al": [14, 62, 63, 66, 84, 85, 108, 112], "17": [14, 20, 37, 52, 62, 70, 75, 79, 80, 81, 82, 83, 84, 89, 92, 93, 96, 97, 99, 101, 102, 104, 105, 106, 125, 126], "598": 14, "plot_3_al": [14, 17], "lime": [15, 62, 63, 66, 85, 87, 106, 108], "without": [15, 20, 21, 36, 37, 84, 90, 93], "center": [15, 20, 21, 36, 37, 74, 77, 79, 81, 94, 108, 109, 117, 118, 119, 120, 127, 128], "sample_id": [15, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 81, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 108], "fals": [15, 20, 21, 36, 37, 40, 41, 81, 93, 94, 99, 105, 108, 109, 110, 112, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128], "783": 15, "plot_4_lim": [15, 17], "shap": [16, 62, 63, 66, 85, 87, 106, 108], "waterfal": 16, "shap_waterfal": [16, 84, 108], "shap_fi": [16, 84, 108], "sample_s": [16, 84, 108, 118, 119], "shap_summari": [16, 84, 108], "shap_scatt": [16, 84, 108], "9": [16, 20, 21, 26, 37, 42, 45, 52, 53, 57, 62, 63, 65, 66, 75, 80, 90, 91, 95, 96, 101, 103, 104, 106], "493": 16, "plot_5_shap": [16, 17], "auto_examples_explain": 17, "glm": [18, 19, 38, 56, 57, 63, 65, 69, 70, 81, 87, 91, 93, 94, 96, 108, 127, 128], "logist": [18, 19, 38, 87, 93], "taiwan": [18, 19, 38, 66], "credit": [18, 19, 38, 52, 65, 66, 73, 100, 108], "linear": [18, 19, 36, 37, 38, 77, 81, 82, 84, 87, 88, 90, 91, 92, 108, 111, 121, 122, 133], "bike": [18, 19, 38, 62, 70, 73, 89, 92, 96, 97, 99, 101, 102, 104, 105, 108], "share": [18, 19, 38, 73, 89, 92, 97, 99, 101, 105, 108], "gam": [18, 19, 38, 46, 64, 87, 89, 91, 96, 97, 102, 108, 117, 118, 119, 120], "classif": [18, 19, 20, 38, 39, 52, 53, 54, 57, 58, 64, 65, 66, 67, 73, 74, 75, 76, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 101, 103, 104, 105, 108, 113, 115, 118, 123, 125, 126, 127, 129, 133], "california": [18, 19, 38, 73, 89, 90, 95, 96, 103, 108], "hous": [18, 19, 38, 63, 73, 89, 90, 95, 96, 103, 108], "tree": [18, 19, 26, 27, 38, 42, 43, 44, 45, 55, 56, 68, 70, 75, 81, 82, 84, 87, 88, 89, 91, 96, 97, 101, 105, 108, 110, 111, 113, 114, 115, 116, 125, 126, 127, 128, 129, 130, 133], "taiwancredit": [18, 19, 20, 26, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 55, 61, 68, 73, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105, 108, 133], "fig": [18, 19, 38, 49, 55, 68, 87, 90, 104, 108, 115, 116, 117, 118, 119, 120, 127, 128], "xgb": [18, 19, 38, 42, 43, 65, 77, 92, 96, 97, 103, 105, 108, 127, 128, 129, 130], "ebm": [18, 19, 38, 57, 66, 69, 87, 89, 92, 108], "gami": [18, 19, 38, 87, 88, 89, 97, 108, 118, 119, 133], "net": [18, 19, 38, 87, 88, 89, 93, 108, 118, 119, 125, 126, 133], "relu": [18, 19, 38, 63, 66, 87, 88, 92, 108, 118, 119, 123, 124, 133], "dnn": [18, 19, 38, 63, 66, 87, 94, 108], "friedman": [18, 19, 38, 64, 73, 108, 126], "accuraci": [18, 39, 53, 55, 56, 67, 77, 84, 87, 98, 102, 104, 105, 108, 112, 113, 115, 118, 123, 125, 127, 129, 133], "weakspot": [18, 39, 53, 87, 98, 101, 102, 108, 133], "overfit": [18, 39, 53, 55, 56, 67, 77, 87, 89, 91, 94, 95, 96, 98, 99, 105, 108, 133], "reliabl": [18, 39, 53, 55, 56, 67, 75, 79, 87, 98, 105, 108, 133], "robust": [18, 39, 53, 55, 56, 67, 87, 89, 98, 108, 133], "resili": [18, 39, 53, 55, 56, 67, 87, 98, 108, 133], "fair": [18, 39, 53, 54, 58, 61, 67, 73, 87, 98, 108, 133], "all": [18, 20, 21, 49, 65, 66, 68, 70, 74, 75, 77, 79, 80, 83, 84, 89, 90, 91, 92, 93, 94, 97, 99, 103, 104, 108, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "auto_examples_python": 18, "zip": 18, "auto_examples_jupyt": 18, "glmclassifi": [20, 57, 69, 93, 108], "limit_b": [20, 24, 26, 30, 32, 34, 36, 40, 42, 44, 46, 48, 50, 55], "sex": [20, 24, 26, 30, 32, 34, 36, 40, 42, 44, 46, 48, 50, 55], "educ": [20, 24, 26, 30, 32, 34, 36, 40, 42, 44, 46, 48, 50, 55], "marriag": [20, 24, 26, 30, 32, 34, 36, 40, 42, 44, 46, 48, 50, 55], "ag": [20, 24, 26, 30, 32, 34, 36, 40, 42, 44, 46, 48, 50, 55, 64, 103], "flagdefault": [20, 24, 26, 30, 32, 34, 36, 40, 42, 44, 46, 48, 50, 55, 66, 68, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "evalu": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 65, 68, 69, 77, 81, 83, 84, 87, 92, 99, 100, 101, 102, 103, 104, 105, 108], "predict": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 46, 60, 68, 70, 77, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 123, 124, 125, 126, 127, 128, 129, 130], "perform": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 50, 51, 65, 69, 74, 75, 83, 87, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 108, 109, 110, 112, 118, 119, 123, 124, 125, 126], "model_diagnos": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 62, 63, 66, 87, 93, 99, 101, 102, 103, 104, 105, 108], "accuracy_t": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 93, 99, 108], "acc": [20, 22, 24, 26, 28, 30, 32, 34, 36, 40, 42, 44, 52, 55, 65, 68, 87, 99, 100, 101, 103, 104, 105, 108], "auc": [20, 22, 24, 26, 28, 30, 32, 34, 36, 40, 42, 48, 55, 83, 87, 94, 99, 103, 104, 105, 108], "recal": [20, 22, 24, 26, 28, 30, 32, 34, 36, 40, 87, 99, 100, 108], "precis": [20, 22, 24, 26, 28, 30, 32, 34, 36, 40, 75, 87, 99, 100, 102, 108], "f1": [20, 22, 24, 26, 28, 30, 32, 34, 36, 40, 52, 55, 65, 87, 99, 100, 103, 104, 105, 108], "8083": 20, "7375": 20, "2579": 20, "6834": 20, "3745": 20, "8150": 20, "7356": 20, "2583": 20, "6936": 20, "3764": 20, "gap": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 45, 68, 70, 87, 99, 101, 105, 108, 125, 126], "0067": [20, 34], "0019": [20, 45], "0004": [20, 35, 37, 101], "0102": [20, 43], "coeffici": [20, 21, 72, 77, 81, 84, 87, 91, 94, 96, 108, 114, 116, 119, 124, 126, 128, 130], "model_interpret": [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 62, 63, 66, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 108], "glm_coef_plot": [20, 21, 93, 108], "tabl": [20, 21, 40, 41, 64, 65, 74, 77, 93, 100, 101, 104, 105, 108], "glm_coef_tabl": [20, 21, 93, 108], "pay_amt3": 20, "6906": 20, "pay_amt1": [20, 66, 94], "6464": 20, "pay_amt2": [20, 105], "5927": 20, "pay_amt4": 20, "4080": 20, "pay_amt6": 20, "3255": 20, "pay_amt5": 20, "3122": 20, "bill_amt5": 20, "1892": 20, "pay_4": 20, "0329": 20, "bill_amt1": [20, 42, 44, 48, 66], "0168": 20, "bill_amt2": [20, 48], "1473": 20, "pay_2": [20, 42, 105], "bill_amt3": [20, 48], "6271": 20, "pay_5": 20, "6885": 20, "bill_amt4": 20, "7107": 20, "14": [20, 21, 37, 42, 52, 65], "bill_amt6": 20, "8201": 20, "15": [20, 21, 37, 52, 65, 84, 109, 110, 111, 113, 114], "pay_3": [20, 36, 94], "8883": 20, "pay_6": 20, "0435": 20, "pay_1": [20, 30, 32, 34, 36, 40, 42, 44, 46, 50, 55, 66, 68, 94, 99, 102, 103, 105], "2420": 20, "global_fi": [20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 89, 91, 92, 93, 94, 96, 97, 108], "local_fi": [20, 21, 22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 89, 91, 92, 93, 94, 96, 97, 108], "origin": [20, 21, 46, 52, 75, 77, 79, 81, 82, 83, 84, 90, 96, 100, 101, 102, 104, 105, 108, 110, 117, 118, 119, 120, 125, 126, 127, 128], "scale": [20, 21, 63, 70, 82, 90, 96, 101, 104, 105, 108, 109, 110, 111, 112, 117, 118, 119, 120, 125, 126, 127, 128], "089": [20, 38], "plot_0_glm_cl": [20, 38], "glmregressor": [21, 56, 93, 108], "mse": [21, 23, 25, 27, 29, 31, 33, 35, 37, 41, 49, 56, 70, 83, 87, 99, 101, 102, 103, 104, 105, 108], "mae": [21, 23, 25, 27, 29, 31, 33, 35, 37, 41, 43, 45, 56, 70, 87, 99, 101, 103, 104, 105, 108], "r2": [21, 23, 25, 27, 29, 31, 33, 35, 37, 41, 49, 56, 70, 99, 103, 104, 105, 108], "0225": 21, "1105": 21, "3467": 21, "1090": 21, "3593": 21, "0015": [21, 36, 101], "0127": 21, "2133": 21, "weathersit_2": 21, "0274": 21, "holiday_1": 21, "0250": 21, "season_2": [21, 93], "0038": 21, "workingday_0": 21, "holiday_0": 21, "season_0": 21, "weathersit_0": 21, "workingday_1": 21, "0035": [21, 37, 42], "weathersit_1": 21, "0104": 21, "0125": 21, "season_1": [21, 93], "0193": 21, "0365": 21, "season_3": [21, 93], "0659": 21, "weathersit_3": 21, "0727": 21, "1742": 21, "4082": [21, 45], "546": [21, 38], "plot_0_glm_reg": [21, 38], "gamclassifi": [22, 46, 91, 108], "spline_ord": [22, 23, 91, 117, 120], "n_spline": [22, 23, 91, 117, 120], "lam": [22, 23, 91, 117, 120], "8363": 22, "9226": 22, "8428": 22, "8346": 22, "8387": 22, "8475": 22, "9306": 22, "8542": 22, "8325": 22, "8432": 22, "0112": [22, 34], "0080": [22, 25], "0113": 22, "0021": [22, 42, 43, 45], "0045": 22, "global": [22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 62, 82, 87, 88, 108, 117, 118, 119, 120, 125, 126, 133], "global_effect_plot": [22, 23, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 89, 91, 92, 94, 96, 97, 108], "669": [22, 38], "plot_1_gam_cl": [22, 38], "gamregressor": [23, 91, 108], "californiahousing_trim2": [23, 25, 27, 29, 63, 73, 108], "medhousev": [23, 25, 27, 29, 63, 86, 90, 91, 95, 103], "0145": 23, "0867": 23, "7453": 23, "0152": [23, 43], "0883": 23, "7257": 23, "0007": [23, 24, 30, 34, 37, 40, 99], "0017": 23, "0196": 23, "medinc": [23, 29, 90, 91, 96], "312": [23, 38], "plot_1_gam_reg": [23, 38], "treeclassifi": [24, 55, 84, 95, 108], "max_depth": [24, 25, 26, 27, 49, 50, 52, 56, 65, 86, 90, 95, 105, 111, 115, 116, 125, 126, 129, 130], "8248": 24, "7716": 24, "3740": 24, "6985": 24, "4872": 24, "8255": 24, "7605": 24, "3601": 24, "6827": 24, "4715": 24, "0111": 24, "0140": 24, "0157": 24, "start": [24, 25, 73, 77, 90, 94, 95, 96, 108, 111], "root": [24, 25, 26, 27, 68, 90, 95, 108, 111, 112, 125, 126], "node": [24, 25, 72, 75, 84, 90, 94, 95, 96, 97, 108, 111, 113, 114, 115, 116, 125, 126, 127, 128, 129, 130], "tree_glob": [24, 25, 26, 27, 90, 95, 108], "depth": [24, 25, 26, 27, 75, 87, 88, 89, 90, 95, 100, 102, 108, 110, 111, 115, 116, 125, 126, 127, 128, 129, 130, 133], "th": [24, 75, 77, 79, 82, 84, 90, 91, 94, 96], "tree_loc": [24, 25, 26, 27, 90, 95, 108], "536": [24, 38], "plot_2_tree_cl": [24, 38], "treeregressor": [25, 84, 95, 108], "0184": 25, "0979": 25, "6762": 25, "0212": 25, "1059": 25, "6178": 25, "0028": [25, 26], "0584": 25, "338": [25, 38, 44], "plot_2_tree_reg": [25, 38], "figsclassifi": [26, 55, 90, 108], "max_it": [26, 27, 49, 89, 90, 115, 116, 117, 120], "8246": 26, "7891": 26, "3828": 26, "6908": 26, "4926": 26, "8218": [26, 32], "7637": 26, "3562": 26, "6638": 26, "4636": [26, 45], "0255": 26, "0266": 26, "0270": [26, 43], "0290": 26, "figs_heatmap": [26, 27, 90, 108], "tree_idx": [26, 27, 90, 108, 125, 126], "first": [26, 27, 63, 64, 65, 68, 70, 73, 74, 76, 77, 79, 80, 81, 82, 83, 84, 87, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 112, 118, 119, 125, 126], "814": [26, 38], "plot_3_figs_cl": [26, 38], "figsregressor": [27, 49, 90, 108], "0103": 27, "0705": 27, "8196": 27, "0114": 27, "0739": 27, "7941": 27, "0012": [27, 35, 43], "0034": [27, 42], "0256": 27, "987": [27, 38], "plot_3_figs_reg": [27, 38], "xgb1classifi": [28, 96, 108], "max_bin": [28, 29, 89, 96, 97, 105, 113, 114, 127, 128, 129, 130], "min_bin_s": [28, 29, 96, 127, 128], "01": [28, 29, 38, 58, 89, 96, 113, 114, 118, 119, 127, 128], "xgb1": [28, 29, 87, 96, 97, 108], "8512": 28, "9311": 28, "8342": 28, "8663": 28, "8499": 28, "8450": 28, "9028": 28, "8281": 28, "8457": 28, "8368": 28, "0062": [28, 32], "0283": [28, 43], "0060": [28, 35], "0206": [28, 45], "0131": [28, 29], "evid": [28, 29, 99, 102, 103, 108, 127, 128], "xgb1_woe": [28, 29, 96, 108], "inform": [28, 29, 68, 73, 74, 76, 87, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105, 108, 111, 112, 118, 119, 125, 127, 128], "xgb1_iv": [28, 29, 96, 108], "822": [28, 38], "plot_4_xgb1_cl": [28, 38], "xgb1regressor": [29, 96, 108], "0816": 29, "7704": 29, "0136": 29, "0822": 29, "7546": 29, "0005": [29, 31, 37, 41, 63, 99], "0006": [29, 33, 43, 45], "0159": [29, 45], "798": [29, 38], "plot_4_xgb1_reg": [29, 38], "xgb2classifi": [30, 40, 42, 44, 50, 52, 55, 97, 108], "8223": [30, 40, 99], "7970": [30, 40, 99], "3617": [30, 40, 99], "6924": [30, 40, 99], "4751": [30, 40, 99], "8288": [30, 40, 99], "7732": [30, 40, 99], "3624": [30, 40, 99], "7015": [30, 40, 99], "4779": [30, 40, 99], "0066": [30, 40, 45, 99], "0237": [30, 40, 99], "0091": [30, 40, 99], "0027": [30, 40, 99], "global_ei": [30, 31, 32, 33, 34, 35, 89, 92, 97, 108], "local_ei": [30, 31, 32, 33, 34, 35, 89, 92, 97, 108], "817": [30, 38], "plot_5_xgb2_cl": [30, 38], "0087": [31, 41, 45, 99], "0649": [31, 41, 99], "7469": [31, 41, 99], "0092": [31, 41, 99], "0668": [31, 41, 99], "7368": [31, 41, 99], "0018": [31, 41, 99], "0101": [31, 41, 99], "830": [31, 38], "plot_5_xgb2_reg": [31, 38], "explainableboostingclassifi": [32, 57, 69, 89, 108], "interact": [32, 33, 62, 63, 66, 75, 79, 80, 82, 84, 87, 93, 94, 101, 113, 114, 115, 116, 118, 119], "7885": [32, 44], "3680": 32, "6854": 32, "4789": 32, "8280": 32, "7764": 32, "3716": 32, "6896": [32, 42], "4830": 32, "0121": 32, "0036": [32, 36], "0042": 32, "0040": [32, 37], "591": [32, 38], "plot_6_ebm_cl": [32, 38], "explainableboostingregressor": [33, 89, 108], "0072": 33, "0589": 33, "7920": 33, "0078": 33, "0615": 33, "7782": 33, "0026": 33, "0138": [33, 37], "727": [33, 38], "plot_6_ebm_reg": [33, 38], "gaminetclassifi": [34, 92, 108], "8191": 34, "7751": 34, "3577": 34, "6768": 34, "4681": 34, "8258": 34, "7697": 34, "3554": 34, "6881": 34, "4687": 34, "0054": [34, 45], "0023": [34, 37], "53": [34, 38, 77], "428": [34, 38], "plot_7_gaminet_cl": [34, 38], "gaminetregressor": [35, 92, 108], "0056": 35, "0526": 35, "8372": 35, "0538": 35, "8289": 35, "0083": 35, "387": [35, 38], "plot_7_gaminet_reg": [35, 38], "matplotlib": [36, 106, 117, 118, 119, 120, 127, 128], "pyplot": [36, 117, 118, 119, 120, 127, 128], "plt": [36, 117, 118, 119, 120, 127, 128], "reludnnclassifi": [36, 48, 94, 108], "hidden_layer_s": [36, 37, 94, 123, 124], "l1_reg": [36, 37, 94, 123, 124], "0002": [36, 37, 43, 94], "learning_r": [36, 37, 89, 94, 113, 114, 115, 116, 118, 119, 123, 124], "8200": [36, 87], "7723": 36, "3619": 36, "6793": 36, "4722": 36, "8300": 36, "7708": 36, "3655": 36, "7064": 36, "4817": 36, "0100": [36, 42, 44], "0271": 36, "0095": 36, "llm": [36, 37, 108], "llm_summari": [36, 37, 94, 108], "count": [36, 37, 62, 70, 76, 79, 80, 81, 82, 83, 84, 89, 92, 93, 94, 96, 97, 99, 101, 102, 104, 105, 108, 123, 124], "respons": [36, 37, 40, 62, 63, 64, 65, 66, 68, 70, 73, 77, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "6535": 36, "1053": 36, "3069": 36, "6037": 36, "7349": 36, "4166": 36, "1066": 36, "3086": 36, "6477": 36, "6261": 36, "1307": 36, "2295": 36, "4207": 36, "5999": 36, "5003": 36, "1158": 36, "3100": 36, "4627": 36, "7819": 36, "7348": 36, "903": 36, "1595": 36, "3663": 36, "6118": 36, "5528": 36, "300": 36, "nan": [36, 37, 42], "7364": 36, "301": 36, "5529": 36, "302": 36, "7370": 36, "303": [36, 43], "7244": 36, "304": 36, "7134": 36, "305": 36, "parallel": [36, 37, 108, 113, 114, 118, 119], "coordin": [36, 37, 108], "llm_pc": [36, 37, 94, 108], "violin": [36, 37, 108], "llm_violin": [36, 37, 94, 108], "one": [36, 37, 62, 64, 65, 70, 72, 75, 76, 77, 79, 82, 83, 87, 89, 92, 93, 94, 95, 96, 97, 99, 100, 105, 106, 111, 113, 114, 118, 119, 125, 126], "44": [36, 38, 44, 80], "045": [36, 38], "plot_8_reludnn_cl": [36, 38], "0192": 37, "9784": 37, "0009": 37, "0199": 37, "9709": 37, "0075": 37, "215": [37, 77, 87], "4711": 37, "1584": 37, "0309": 37, "207": 37, "4700": 37, "1648": 37, "0327": 37, "185": 37, "4592": 37, "1754": 37, "0324": [37, 92], "148": [37, 43, 45, 101], "4698": 37, "1601": 37, "0003": 37, "0340": 37, "126": 37, "3969": 37, "1574": 37, "0186": 37, "106": 37, "3815": 37, "1582": 37, "0218": 37, "6136": 37, "1315": 37, "0013": 37, "0783": 37, "62": [37, 42, 52, 57, 64], "6301": 37, "1698": 37, "0008": [37, 43, 66, 93], "0750": 37, "3266": 37, "1242": 37, "0542": 37, "45": [37, 44, 83], "2920": 37, "1354": [37, 42, 105], "0551": 37, "43": 37, "6213": [37, 44], "1345": 37, "6046": 37, "1563": 37, "37": [37, 47], "2811": 37, "1128": 37, "0560": 37, "5604": 37, "1171": [37, 101], "0014": 37, "0784": 37, "35": 37, "2250": 37, "1211": 37, "0288": 37, "2636": 37, "1341": 37, "0604": 37, "5663": 37, "1579": 37, "0037": 37, "5213": 37, "1795": 37, "0010": 37, "0441": 37, "5491": 37, "1967": 37, "0451": 37, "6115": 37, "1256": 37, "5365": 37, "1195": 37, "4459": 37, "1685": 37, "0024": 37, "2393": 37, "1061": 37, "0342": 37, "3573": 37, "1770": 37, "0404": 37, "4821": 37, "1186": 37, "0135": 37, "25": [37, 42, 48, 52, 105], "5134": 37, "0839": 37, "0016": [37, 43, 45], "0625": [37, 44], "0238": 37, "27": [37, 55, 58], "4321": 37, "1450": 37, "0164": 37, "28": 37, "4558": 37, "0107": 37, "0240": 37, "29": [37, 52, 57], "1400": 37, "0890": 37, "0302": 37, "30": [37, 44, 65, 66, 68, 74, 76, 78, 87, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "2187": 37, "1037": 37, "0203": 37, "0751": 37, "1801": 37, "0305": 37, "0385": 37, "5209": 37, "0884": 37, "33": [37, 57, 65], "6258": 37, "0943": 37, "34": 37, "4773": [37, 45], "0875": 37, "x2": [37, 64, 73, 108], "210": [37, 38], "plot_8_reludnn_reg": [37, 38], "03": [38, 43, 58], "51": 38, "945": 38, "auto_examples_model": 38, "09": 38, "08": 38, "07": [38, 84, 92], "05": [38, 43, 44, 45, 101, 123, 124], "04": [38, 43, 84], "confus": [40, 99, 108], "matrix": [40, 72, 75, 77, 79, 94, 97, 99, 108, 110, 114, 115, 116, 119, 123, 124, 125, 126, 128, 130], "roc": [40, 99, 108], "accuracy_plot": [40, 55, 56, 68, 70, 99, 108], "residu": [40, 41, 87, 89, 90, 92, 102, 103, 104, 108, 114, 116, 119, 124, 126, 128, 130], "respect": [40, 41, 74, 77, 78, 81, 84, 90, 94, 100, 102, 104, 105, 108, 112, 118, 119], "accuracy_residu": [40, 41, 99, 108], "target_featur": [40, 41, 46, 47, 50, 51, 99, 102, 103, 108], "use_test": [40, 41, 42, 43, 44, 99, 101, 105, 108], "flagdefault_predict": 40, "765": 40, "plot_0_accuracy_cl": [40, 53], "cnt_predict": [41, 99], "278": 41, "plot_0_accuracy_reg": [41, 53], "slice_method": [42, 43, 44, 45, 55, 56, 68, 70, 101, 105, 108], "slice_featur": [42, 43, 44, 45, 55, 56, 68, 70, 101, 105, 108], "min_sampl": [42, 43, 44, 45, 101, 105, 108], "return_data": [42, 43, 44, 45, 46, 47, 52, 57, 69, 81, 89, 91, 92, 93, 96, 97, 100, 101, 102, 105, 108], "test_acc": [42, 44, 105], "train_acc": [42, 44, 105], "1265": [42, 105], "5090": [42, 105], "6957": 42, "0061": 42, "2500": 42, "191": [42, 105], "800": [42, 105], "6911": 42, "6787": 42, "0123": 42, "1111": [42, 44], "2222": [42, 44], "268": [42, 43, 105], "956": [42, 105], "7276": 42, "7176": 42, "3750": 42, "6250": 42, "322": [42, 105], "7205": 42, "7171": 42, "5556": 42, "351": [42, 105], "1430": [42, 105], "6125": 42, "6147": 42, "7500": 42, "82": [42, 104, 105], "360": [42, 105], "6220": 42, "0030": [42, 43, 45], "set": [42, 43, 44, 48, 55, 56, 62, 63, 64, 65, 66, 68, 70, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "4444": [42, 44], "test_auc": 42, "train_auc": 42, "752": 42, "2936": 42, "6444": 42, "7049": 42, "0605": 42, "3521": 42, "13975": 42, "6348": 42, "6958": 42, "0610": 42, "513": 42, "2154": 42, "5452": 42, "0896": 42, "5750": 42, "7060": 42, "1310": 42, "6410": 42, "4000": 42, "6786": 42, "121": 42, "7000": [42, 44], "6364": [42, 43], "0636": 42, "2778": 42, "582": 42, "2407": 42, "7268": 42, "7084": 42, "0185": 42, "1667": [42, 44], "6862": 42, "6798": 42, "0063": [42, 43], "4705": 42, "6824": 42, "488": 42, "1817": 42, "7377": 42, "7342": 42, "900": 42, "plot_1_weakspot_cl": [42, 53], "test_ms": [43, 45, 101], "train_ms": [43, 45, 101], "445": [43, 45, 101], "1736": [43, 45, 101], "0226": [43, 45], "0205": [43, 45], "290": 43, "1168": 43, "0277": 43, "0938e": 43, "85": 43, "377": 43, "0207": 43, "0200": 43, "3215e": 43, "8851e": 43, "155": 43, "538": 43, "0153": 43, "1004e": 43, "97": [43, 52, 57], "365": 43, "0108": 43, "7190e": 43, "test_ma": [43, 45], "train_ma": [43, 45], "1175": 43, "1122": 43, "0053": 43, "1026": 43, "4077": 43, "0931": 43, "0919": 43, "3261": [43, 45], "3696": [43, 45], "135": [43, 45, 101], "592": [43, 45, 101], "1947": 43, "1677": 43, "2826": [43, 45], "579": [43, 45, 101], "1130": 43, "1062": 43, "0068": 43, "8478": 43, "1630": 43, "6382": 43, "0827": 43, "0825": 43, "4545": 43, "1110": 43, "0753": 43, "0634": 43, "0119": 43, "6667": 43, "1239": 43, "0841": 43, "0778": 43, "5152": 43, "5303": 43, "127": 43, "452": 43, "0746": 43, "0738": 43, "6818": 43, "7273": 43, "146": 43, "555": 43, "0787": 43, "0803": 43, "74": 43, "307": 43, "0736": 43, "0756": 43, "0020": 43, "5909": 43, "294": 43, "1282": 43, "0790": 43, "0820": 43, "9848": [43, 45], "196": 43, "882": [43, 45], "0744": 43, "0808": 43, "474": 43, "plot_1_weakspot_reg": [43, 53], "3781": 44, "131": 44, "7561": 44, "8473": 44, "0912": 44, "7167": 44, "8037": 44, "117": 44, "6333": 44, "7350": 44, "1017": 44, "2814": 44, "3685": 44, "7083": 44, "8133": 44, "1050": 44, "9237": 44, "9558": 44, "69": 44, "5797": 44, "6893": 44, "1096": 44, "6715": 44, "73": 44, "6500": 44, "7808": 44, "1308": 44, "7632": 44, "7953": 44, "92": 44, "6000": 44, "7717": 44, "1717": 44, "1073": 44, "3453": 44, "296": 44, "8480": 44, "0480": 44, "9831": 44, "8182": 44, "1182": 44, "52": [44, 77], "198": 44, "8283": 44, "0398": [44, 45], "7228": 44, "7332": 44, "299": 44, "6933": 44, "7559": 44, "9807": 44, "8000": 44, "1000": [44, 90, 118, 119, 123, 124], "794": 44, "plot_2_overfit_cl": [44, 53], "1020": 45, "0146": 45, "0139": 45, "6636": 45, "103": 45, "366": 45, "0391": 45, "0325": 45, "2318": 45, "173": 45, "645": 45, "0260": 45, "1803": 45, "122": [45, 55, 58], "461": 45, "0058": 45, "1364": 45, "5606": 45, "240": 45, "0093": 45, "0077": 45, "197": [45, 87, 101], "4924": 45, "1649": 45, "6580": 45, "062": 45, "057": 45, "005": 45, "0495": 45, "0098": 45, "0177": 45, "255": 45, "plot_2_overfit_reg": [45, 53], "calcul": [46, 47, 68, 70, 74, 75, 77, 78, 79, 81, 83, 84, 89, 90, 91, 92, 93, 94, 96, 97, 99, 101, 102, 103, 104, 105, 108, 109, 111, 112, 118, 119, 125, 126], "each": [46, 47, 66, 68, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "between": [46, 47, 50, 51, 65, 68, 70, 72, 74, 75, 77, 78, 79, 80, 82, 83, 84, 89, 91, 92, 93, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 125, 126], "un": [46, 47, 108], "reliability_dist": [46, 47, 102, 108], "distance_metr": [46, 47, 50, 51, 102, 103, 108], "bandwidth": [46, 47, 55, 56, 80, 108], "against": [46, 47, 50, 51, 68, 69, 70, 75, 89, 92, 97, 99, 102, 104, 106, 108], "given": [46, 47, 75, 77, 81, 84, 89, 90, 92, 94, 96, 97, 101, 108, 110, 111, 113, 115, 117, 118, 119, 120, 123, 125, 127, 128, 129], "reliability_margin": [46, 47, 102, 108], "bin": [46, 47, 52, 55, 56, 65, 68, 70, 78, 79, 87, 89, 96, 97, 98, 101, 102, 103, 105, 108, 113, 114, 127, 128, 129, 130], "calibr": [46, 68, 108], "probabl": [46, 68, 82, 84, 94, 99, 102, 103, 104, 108, 113, 115, 118, 123, 124, 125, 127, 129], "v": [46, 63, 66, 77, 108, 114, 116, 119, 124, 126, 128, 130], "reliability_calibr": [46, 102, 108], "diagram": [46, 55, 95, 108, 111, 125, 126], "reliability_perf": [46, 55, 68, 102, 108], "brier": [46, 108], "reliability_t": [46, 47, 102, 108], "1258": [46, 102], "1276": [46, 102], "059": 46, "plot_3_reliability_cl": [46, 53], "empir": [47, 74, 97, 102, 108], "coverag": [47, 56, 108], "averag": [47, 65, 70, 75, 77, 79, 80, 81, 82, 83, 84, 90, 93, 94, 95, 96, 99, 101, 102, 105, 108, 110, 118, 119], "alpha": [47, 48, 49, 50, 51, 55, 56, 68, 70, 102, 103, 104, 108, 111, 112, 125, 126], "8892": 47, "2373": 47, "051": 47, "plot_3_reliability_reg": [47, 53], "default": [48, 55, 56, 62, 63, 64, 65, 66, 68, 70, 73, 74, 75, 77, 82, 83, 84, 87, 89, 90, 94, 95, 99, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "robustness_perf": [48, 49, 55, 56, 68, 70, 104, 108], "perturn": [48, 49], "perturb_featur": [48, 49, 68, 70, 104, 108], "size": [48, 49, 65, 68, 70, 75, 77, 82, 87, 94, 95, 96, 101, 104, 105, 108, 109, 111, 113, 114, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128], "perturb_s": [48, 49, 68, 70, 104, 108], "perturb_method": [48, 49, 68, 70, 104, 108], "worst": [48, 49, 50, 51, 55, 56, 102, 103, 108], "percent": [48, 49, 55, 56, 74], "robustness_perf_worst": [48, 49, 55, 56, 68, 70, 104, 108], "448": 48, "plot_4_robustness_cl": [48, 53], "being": [49, 79, 83, 84, 87, 96, 100, 103], "perturb": [49, 68, 70, 81, 87, 108], "224": 49, "plot_4_robustness_reg": [49, 53], "scenario": [50, 51, 55, 56, 68, 70, 74, 87, 102, 103], "resilience_perf": [50, 51, 55, 56, 68, 70, 103, 108], "resilience_method": [50, 51, 55, 56, 68, 70, 103, 108], "hard": [50, 51, 94, 103, 104, 108, 112, 123, 124], "cluster": [50, 51, 74, 90, 103, 108, 109, 111], "margin": [50, 51, 72, 81, 84, 87, 92, 93, 94, 108, 118, 119], "resilience_dist": [50, 51, 55, 56, 68, 70, 103, 108], "noneimmut": 50, "immu_featur": [50, 51, 55, 56, 68, 70, 103, 108], "n_cluster": [50, 51, 103, 108, 109], "resilience_shift_histogram": [50, 51, 103, 108], "resilience_shift_dens": [50, 51, 103, 108], "229": 50, "plot_5_resilience_cl": [50, 53], "immut": [51, 103, 108], "009": 51, "plot_5_resilience_reg": [51, 53], "simucredit": [52, 57, 65, 69, 73, 108], "race": [52, 57, 64, 65, 69, 100], "gender": [52, 57, 65, 69, 100], "approv": [52, 57, 65], "mono_increasing_list": [52, 96, 97, 118, 119, 127, 128, 129, 130], "mortgag": [52, 65, 73, 100, 108], "balanc": [52, 57, 65, 69, 96, 99, 100, 108, 125], "mono_decreasing_list": [52, 96, 118, 119, 127, 128, 129, 130], "amount": [52, 65, 100, 104, 112], "past": [52, 65, 100], "due": [52, 65, 68, 77, 78, 87, 91, 94, 97, 100, 104, 105], "util": [52, 65, 69, 70, 74, 75, 90, 99, 101, 102, 103, 104, 105, 108], "delinqu": [52, 65], "inquiri": [52, 65], "open": [52, 65, 87], "trade": [52, 65, 100, 108], "xgb2_monoton": [52, 100], "metrics_result": [52, 57, 69, 100], "model_fair": [52, 65, 100, 108], "air": [52, 57, 65, 69, 100, 108], "group_categori": [52, 57, 69, 100, 108], "reference_group": [52, 57, 69, 100, 108], "protected_group": [52, 57, 69, 100, 108], "favorable_threshold": [52, 57, 69, 100, 108], "performance_metr": [52, 100, 108], "group": [52, 57, 64, 65, 69, 81, 94, 100, 102, 103, 108], "index": [52, 57, 74, 78, 79, 90, 94, 102, 103, 108, 113, 114, 118, 119, 125, 126], "categori": [52, 57, 64, 65, 72, 74, 75, 76, 79, 93, 100, 104, 108, 118, 119], "refer": [52, 57, 59, 64, 65, 69, 73, 79, 82, 90, 91, 96, 100, 101, 102, 103, 108, 125, 126], "protect": [52, 57, 64, 65, 69, 100, 108], "603728": 52, "745063": 52, "segment": [52, 57, 64, 65, 67, 68, 72, 73, 87, 98, 103, 105, 108], "segmented_result": [52, 57, 69, 100], "segmented_featur": [52, 57, 69, 100, 108], "segmented_bin": [52, 57, 69, 100, 108], "lower": [52, 57, 65, 69, 70, 80, 91, 99, 102, 105, 110, 112], "bound": [52, 57, 89, 105], "upper": [52, 57, 73, 77, 89, 105, 108], "306": [52, 57], "451200": 52, "663992": 52, "601": [52, 57], "477974": 52, "640716": 52, "47": [52, 57], "1027": [52, 57], "623723": 52, "657706": 52, "1864": [52, 57], "639482": 52, "776867": 52, "94": [52, 57], "20384": [52, 57], "87": [52, 57], "849147": 52, "815034": 52, "binning_result": [52, 100, 127, 128], "binning_dict": [52, 100, 108], "id": [52, 90, 93, 95, 111], "configur": [52, 74, 80, 99, 100, 105, 108], "715171": 52, "000368": 52, "003484": 52, "505151": 52, "000873": 52, "998020": 52, "506629": 52, "003422": 52, "979733": 52, "511253": 52, "003826": 52, "940766": 52, "522427": 52, "580318": 52, "988035": 52, "360787": 52, "584574": 52, "975176": 52, "364127": 52, "591296": 52, "934952": 52, "373758": 52, "600570": 52, "839246": 52, "400689": 52, "419545": 52, "011075": 52, "397111": 52, "423988": 52, "997716": 52, "400796": 52, "442289": 52, "959378": 52, "410201": 52, "469471": 52, "865747": 52, "437757": 52, "460530": 52, "996881": 52, "421800": 52, "463408": 52, "987163": 52, "424344": 52, "480924": 52, "951194": 52, "433464": 52, "506623": 52, "868160": 52, "457202": 52, "472251": 52, "999380": 52, "411107": 52, "476458": 52, "988062": 52, "414268": 52, "489755": 52, "954747": 52, "422231": 52, "509819": 52, "878128": 52, "444284": 52, "thresholding_result": [52, 100], "331291": 52, "883245": 52, "6765": 52, "892292": 52, "433": [52, 53], "plot_6_fair": [52, 53], "auto_examples_test": 53, "39": [53, 87, 106], "model_compar": [55, 56, 62, 63, 66, 68, 70, 87, 108], "historgram": [55, 56], "slice": [55, 56, 68, 70, 87, 101, 105, 108], "reliability_bandwidth": [55, 56, 68, 70, 108], "565": [], "plot_0_compare_classif": [55, 58], "xgboost": [56, 65, 75, 87, 88, 100, 103, 105, 106, 108, 133], "xgbregressor": 56, "xgb7": [56, 65, 70], "reliability_coverag": [56, 70, 108], "plot_0_compare_regress": [56, 58], "model_fairness_compar": [57, 65, 69, 108], "glm_air": 57, "ebm_air": 57, "712368": 57, "647789": 57, "832585": 57, "781610": 57, "825086": 57, "439287": 57, "901729": 57, "703873": 57, "689973": 57, "545624": 57, "745220": 57, "642129": 57, "633800": 57, "687002": 57, "591785": 57, "701057": 57, "613486": 57, "721803": 57, "602803": 57, "826708": 57, "748971": 57, "890700": 57, "714674": 57, "835029": 57, "151": 57, "plot_1_compare_fair": [57, 58], "auto_examples_testing_compar": 58, "comparison": [58, 59, 61, 71, 87, 101, 105, 108, 115, 122, 125, 129, 133], "welcom": 59, "scikit": [59, 73, 77, 80, 82, 83, 87, 93, 94, 106, 108, 110, 112, 121, 122, 125, 126], "learn": [59, 62, 63, 66, 67, 69, 70, 73, 77, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 104, 105, 106, 108, 110, 112, 113, 114, 115, 116, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "instal": [59, 77, 87, 131], "api": [59, 64, 68, 70, 75, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 110, 112], "class": [59, 65, 93, 99, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "pipelin": [59, 86, 87, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 133], "post": [59, 62, 63, 66, 77, 83, 87, 108, 133], "hoc": [59, 62, 63, 66, 77, 83, 87, 108, 133], "explain": [59, 61, 75, 79, 80, 81, 82, 83, 84, 87, 88, 96, 99, 108, 112, 113, 114, 133], "outcom": [59, 61, 87, 100, 102, 108], "user": [59, 74, 75, 76, 77, 87, 90, 97, 100, 105, 107, 111], "guid": [59, 87, 107], "introduct": [59, 74, 77, 94, 133], "black": [59, 87, 89, 94, 97, 133], "diagnost": [59, 61, 67, 108, 133], "suit": [59, 76, 133], "case": [59, 64, 65, 74, 76, 81, 83, 90, 93, 96, 99, 101, 103, 104, 105, 110, 113, 114, 125, 126, 133], "studi": [59, 133], "frequent": 59, "ask": 59, "question": 59, "how": [60, 62, 63, 66, 68, 70, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105], "can": [60, 63, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 112, 114, 116, 119, 124, 125, 126, 128, 130], "read": [60, 87], "regist": [60, 62, 64, 65, 66, 87, 90, 92, 108, 133], "my": 60, "own": [60, 74, 125], "frame": [60, 91, 93], "get": [60, 65, 77, 78, 79, 81, 84, 89, 90, 91, 92, 93, 94, 96, 97, 100, 102, 106, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "chapter": 61, "includ": [61, 63, 66, 68, 70, 73, 74, 75, 76, 77, 78, 82, 87, 89, 91, 92, 95, 96, 97, 99, 100, 102, 103, 105, 106, 108, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "multipl": [61, 67, 75, 84, 87, 90, 92, 96, 100, 105, 108], "low": [61, 62, 63, 65, 66, 73, 83, 84, 87, 91, 95, 99, 108], "experiment": [61, 87, 108], "intepret": 61, "benchmark": 61, "californiah": [61, 91, 133], "simul": [61, 73, 81, 84, 91, 96, 100, 108, 133], "ml": [61, 73, 77, 87, 93, 108], "": [61, 62, 68, 75, 77, 78, 79, 80, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "descript": [61, 73, 87, 108], "demonstr": [62, 63, 64, 65, 66, 68, 69, 70, 74, 77, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105], "its": [62, 63, 66, 70, 75, 77, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 118, 119, 125], "mode": [62, 63, 66, 68, 73, 83, 87, 108, 118, 119, 125], "develop": [62, 63, 66, 70, 73, 79, 80, 81, 82, 83, 84, 87, 89, 92, 93, 94, 96, 97, 99, 101, 102, 104, 105, 108], "machin": [62, 63, 66, 67, 69, 70, 73, 77, 79, 80, 81, 82, 83, 84, 87, 88, 90, 92, 93, 96, 97, 99, 100, 101, 102, 104, 105, 108, 133], "uci": [62, 66, 68, 70, 73, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 108], "repositori": [62, 66, 68, 70, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105], "which": [62, 63, 66, 68, 70, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 110, 113, 115, 116, 118, 119, 123, 125, 126, 127, 128, 129, 130], "consist": [62, 63, 66, 70, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 109, 110, 112, 114, 116, 119, 124, 126, 128, 130], "389": [62, 70, 79, 80, 81, 82, 83, 84, 89, 92, 93, 96, 97, 99, 101, 102, 104, 105], "hourli": [62, 70, 79, 80, 81, 82, 83, 84, 89, 92, 93, 96, 97, 99, 101, 102, 104, 105], "rental": [62, 70, 79, 80, 81, 82, 83, 84, 89, 92, 93, 96, 97, 99, 101, 102, 104, 105], "capit": [62, 70, 79, 80, 81, 82, 83, 84, 89, 92, 93, 96, 97, 99, 101, 102, 104, 105], "system": [62, 70, 79, 80, 81, 82, 83, 84, 87, 89, 92, 93, 96, 97, 99, 101, 102, 104, 105], "see": [62, 63, 66, 69, 70, 75, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 112, 125, 126], "detail": [62, 63, 66, 68, 70, 75, 77, 85, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 102, 107, 125, 126], "here": [62, 63, 66, 68, 70, 74, 75, 77, 78, 79, 80, 82, 83, 89, 90, 92, 93, 97, 99, 103, 104, 111], "The": [62, 63, 64, 65, 66, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "continu": [62, 63, 70, 74, 75, 77, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 95, 96, 97, 99, 101, 102, 103, 104, 105, 118, 119], "problem": [62, 63, 64, 65, 66, 68, 70, 73, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 108, 125], "click": [62, 63, 64, 65, 66, 73, 106], "link": [62, 63, 64, 65, 66, 69, 72, 73, 74, 75, 76, 77, 78, 93, 100, 113, 114], "googl": [62, 63, 64, 65, 66, 73, 108], "colab": [62, 63, 64, 65, 66], "choos": [62, 63, 64, 65, 66, 73, 75, 96, 101, 103, 104, 105, 115, 116, 125, 126], "exploratori": [62, 63, 64, 65, 71, 108, 133], "need": [62, 70, 75, 76, 77, 79, 80, 82, 84, 87, 90, 96, 97, 99, 100, 105, 106, 112], "specif": [62, 63, 66, 68, 69, 70, 74, 75, 76, 78, 79, 80, 82, 83, 87, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 108, 125, 126], "inher": [62, 63, 66, 87, 92, 94, 108], "pairwis": [62, 63, 66, 72, 77, 79, 87, 89, 92, 97, 118, 119], "640": [63, 90, 91, 95, 103], "fetch": [63, 90, 91, 95, 103, 110], "sklearn": [63, 75, 77, 86, 87, 90, 91, 93, 95, 99, 102, 103, 108, 109, 125, 126], "three": [63, 68, 70, 72, 74, 76, 77, 87, 92, 93, 99, 100, 101, 102, 103, 104, 105], "version": [63, 78, 87, 102, 110, 113, 114, 116, 119, 124, 125, 126, 128, 130], "_raw": 63, "_trim1": 63, "trim": [63, 73], "onli": [63, 66, 70, 75, 78, 81, 83, 84, 87, 89, 91, 92, 93, 94, 95, 96, 97, 100, 103, 104, 105, 108, 109, 111, 112, 113, 114, 115, 116, 118, 119, 125, 126], "aveoccup": [63, 73, 90, 91, 96, 108], "_trim2": 63, "averoom": [63, 73, 96, 108], "avebedrm": [63, 73, 108], "popul": [63, 73, 78, 81, 93, 96, 102, 103, 105, 108], "price": [63, 91], "per": [63, 79, 84, 89, 94, 111, 113, 114, 118, 119, 127, 128, 129, 130], "block": [63, 118, 119], "log": [63, 82, 93, 96, 118, 119, 125], "Then": [63, 68, 70, 74, 77, 78, 86, 94, 103, 104], "l1": [63, 93, 94, 121, 122, 123, 124, 126, 127, 128, 129, 130], "reigster": 63, "integr": [64, 81, 82, 87, 89, 93, 94], "sola": [64, 73, 106, 108], "ai": [64, 73, 87, 106, 108], "solassimu1": [64, 73, 108], "modifi": [64, 73, 76, 89, 108], "demo": [64, 105, 108, 118, 119], "covari": [64, 73, 75, 77, 87, 104, 108], "ar": [64, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "x5": [64, 73, 108], "label": [64, 68, 73, 74, 76, 99, 103, 105, 108, 110, 113, 114, 115, 116, 118, 123, 124, 125, 126, 127, 129], "binari": [64, 65, 66, 68, 73, 74, 81, 82, 83, 84, 87, 91, 93, 94, 95, 96, 98, 100, 103, 104, 108, 115, 116], "rest": [64, 73, 75, 79, 80, 83, 89, 90, 92, 96, 108], "demograph": [64, 65, 69, 73, 100, 108], "contribut": [64, 73, 75, 80, 81, 83, 84, 91, 93, 96, 108, 113, 114, 117, 120, 127, 128], "minor": [64, 89], "major": 64, "grei": [64, 65], "color": [64, 65, 90], "when": [64, 65, 68, 69, 75, 77, 79, 80, 81, 83, 84, 90, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 108, 111, 112, 114, 116, 117, 118, 119, 120, 123, 124, 125, 126, 128, 130], "finish": 64, "suggest": [64, 70, 75, 79, 82, 84, 87, 91, 93, 102, 103], "procudur": 64, "add": [64, 65, 87, 97, 104, 108], "By": [64, 68, 70, 74, 75, 76, 77, 78, 80, 81, 83, 87, 89, 90, 91, 93, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 125, 126], "enter": [64, 76], "button": [64, 65, 73], "switch": [64, 96, 105], "other": [64, 66, 69, 74, 75, 76, 77, 79, 80, 82, 84, 87, 90, 91, 92, 93, 96, 99, 102, 105], "view": [64, 82, 83, 84, 89, 90, 92, 95, 102], "breakdown": 64, "model_fairness_sola": [64, 108], "we": [65, 68, 69, 70, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 111, 118, 119], "decis": [65, 68, 70, 73, 81, 84, 87, 88, 90, 100, 105, 108, 111, 125, 126, 133], "hypothes": 65, "statu": [65, 105, 111, 123, 124], "well": [65, 77, 90, 91, 93, 95, 96, 97, 99, 101, 102, 105, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "indic": [65, 68, 69, 73, 74, 75, 79, 80, 82, 83, 84, 89, 90, 91, 92, 93, 94, 96, 97, 99, 101, 102, 103, 104, 105, 108, 109, 110, 111, 113, 114, 118, 119, 125, 126, 127, 128, 129, 130], "20k": 65, "num": 65, "applic": [65, 73, 77, 87, 108], "last": [65, 68, 74, 77, 79, 103, 106, 118, 119, 123, 124], "month": 65, "card": [65, 66, 68, 73, 74, 76, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105, 108], "minimum": [65, 75, 76, 87, 96, 99, 101, 105, 106, 111, 113, 114, 115, 116, 125, 126, 127, 128, 129, 130], "requir": [65, 68, 74, 75, 76, 77, 79, 82, 84, 87, 89, 93, 97, 99, 101, 102, 103, 104, 105, 110, 112, 113, 114, 115, 116, 118, 123, 124, 125, 126, 127, 128, 129, 130], "payment": [65, 66], "wa": [65, 110], "appli": [65, 68, 70, 74, 84, 94, 96, 102, 103, 104, 105, 125, 126], "account": [65, 75, 84, 96, 102, 104], "date": 65, "ordin": [65, 74, 96, 108], "current": [65, 102, 106, 125, 126], "dai": [65, 79, 80, 82, 89, 92, 97, 99], "so": [65, 70, 76, 77, 81, 83, 84, 90, 91, 93, 97, 103, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "number": [65, 68, 70, 74, 75, 76, 77, 78, 79, 83, 84, 89, 90, 91, 94, 96, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "sum": [65, 75, 77, 78, 87, 88, 89, 91, 92, 93, 94, 96, 97, 104, 108, 113, 114, 115, 116, 119, 124, 125, 126, 128, 130, 133], "divid": [65, 72, 74, 75, 79, 89, 92, 95, 97, 99, 102, 105, 112], "limit": [65, 70, 77, 78, 79, 82, 90, 91, 94, 95], "cannot": [65, 69, 77, 93, 112], "kind": 65, "should": [65, 77, 79, 82, 83, 87, 93, 94, 99, 101, 102, 108, 110, 113, 114, 117, 118, 119, 120, 125, 126, 127, 128], "nearli": [65, 73, 108], "depth2": 65, "depth7": 65, "xgbclassifi": 65, "To": [65, 70, 74, 77, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 125, 126], "e": [65, 75, 77, 78, 79, 80, 82, 84, 87, 89, 90, 91, 92, 93, 94, 96, 97, 103, 104, 105, 108, 110, 111], "g": [65, 77, 78, 84, 87, 89, 90, 91, 92, 93, 96, 97, 102, 103, 104, 111], "favor": [65, 92, 108], "defaut": 65, "If": [65, 74, 75, 79, 82, 86, 90, 93, 96, 100, 102, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "find": [65, 89, 92, 94, 96, 101, 102, 125, 126], "higher": [65, 69, 70, 75, 82, 90, 91, 99, 103, 112], "debias": 65, "unfair": [65, 69, 100], "mitig": [65, 75, 77, 100, 101], "an": [65, 68, 70, 72, 74, 75, 76, 77, 79, 80, 81, 82, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 108, 109, 110, 112, 113, 114, 115, 116, 123, 124, 125, 126, 129, 130], "repeat": [65, 75, 77, 81, 83, 97, 117, 120], "mani": [65, 75, 79, 87, 93, 94, 99, 125, 126], "differ": [65, 67, 68, 69, 70, 72, 74, 77, 78, 79, 81, 82, 83, 84, 87, 89, 92, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 109, 112, 125, 126], "clear": [65, 79, 103], "could": [65, 73, 84, 92, 103, 118, 119], "record": [65, 68, 70, 80, 83, 104, 127, 128], "adjust": [65, 76, 79, 95, 101, 102, 103, 125], "vari": [65, 77, 80, 81, 99, 103, 125, 126], "For": [65, 68, 73, 75, 76, 77, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 103, 105, 108, 109, 110, 112, 114, 116, 118, 119, 124, 125, 126, 128, 130], "both": [65, 69, 70, 72, 75, 77, 79, 80, 83, 84, 87, 89, 90, 91, 92, 93, 96, 97, 99, 102, 104, 118, 119, 125], "good": [65, 94, 103, 105], "client": [66, 68, 73, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105, 108], "200504": 66, "200509": 66, "subject": [66, 77, 87, 93, 104, 118, 119, 127, 128, 129, 130], "slight": [66, 70, 103], "preprocess": [66, 68, 73, 74, 89, 90, 93, 97, 99, 101, 102, 104, 105, 108, 112], "histori": [66, 118, 119], "keep": [66, 79, 83, 94, 112, 114, 116, 119, 124, 126, 128, 130], "while": [66, 75, 77, 79, 80, 83, 84, 87, 89, 90, 91, 92, 93, 94, 96, 99, 100, 101, 102, 103, 104, 105, 125, 126], "l1_regular": 66, "compar": [67, 68, 69, 70, 75, 77, 78, 79, 81, 87, 90, 91, 92, 93, 96, 99, 102, 103, 104, 105, 108], "section": [68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 84, 94, 99, 100, 104], "describ": [68, 75, 77, 79, 82, 111], "basi": [], "In": [68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 110, 113, 115, 118, 119, 123, 125, 127, 129], "done": [68, 79, 81, 97], "function": [68, 69, 70, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 111, 113, 114, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "illustr": [68, 70, 79, 80, 82, 84, 96, 97, 99, 100, 102, 104, 105], "consid": [68, 69, 75, 82, 83, 84, 87, 92, 94, 95, 96, 97, 99, 101, 103, 104, 105, 110, 113, 114, 115, 116, 125, 126], "chosen": [68, 74, 90, 91, 92, 96, 105, 108, 125, 126], "chart": [68, 70, 72, 82, 93, 99], "below": [68, 69, 70, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108], "As": [68, 70, 76, 77, 79, 83, 84, 89, 91, 92, 94, 95, 96, 97, 102, 103, 104, 108, 118, 119], "legend": 68, "have": [68, 70, 74, 75, 76, 78, 79, 80, 82, 83, 84, 86, 87, 89, 90, 91, 92, 94, 95, 99, 101, 102, 103, 104, 105, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "similar": [68, 77, 79, 80, 81, 84, 89, 90, 91, 92, 94, 96, 97, 99, 101, 102, 103, 105, 118, 119], "ha": [68, 70, 75, 77, 78, 79, 81, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 103, 104, 108, 125, 126], "slightli": [68, 77, 89, 92, 97, 101], "better": [68, 70, 75, 80, 83, 89, 94, 95, 96, 99, 100, 102, 105], "under": [68, 70, 75, 77, 87, 93, 99, 102, 103, 104, 105, 108, 115, 116, 125, 126], "region": [68, 70, 87, 94, 101, 105, 108], "interest": [68, 70, 75, 79, 80, 81, 82, 87, 99, 100, 101, 102, 105, 108], "detect": [68, 70, 72, 75, 87, 89, 101, 105, 108, 112, 113, 114], "algorithm": [68, 70, 74, 75, 77, 85, 87, 89, 90, 94, 95, 97, 98, 100, 108, 109, 112, 115, 116, 125, 126, 127, 128, 129, 130], "found": [68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 89, 90, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 125, 126], "argument": [68, 70, 77, 78, 81, 82, 83, 84, 90, 92, 96, 99, 101, 102, 104, 105, 125, 126], "instead": [68, 70, 76, 77, 79, 82, 84, 87, 89, 90, 93, 96, 97, 102, 103, 105, 110, 112, 114, 116, 119, 124, 125, 126, 128, 130], "string": [68, 70, 76, 108, 111, 112, 118, 119, 125, 126], "repres": [68, 69, 70, 72, 75, 77, 79, 80, 81, 82, 84, 90, 91, 93, 94, 95, 96, 97, 99, 102, 103, 104, 105, 110, 123, 124], "follow": [68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 108, 125, 126], "keyword": [68, 70, 75, 77, 79, 81, 82, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103], "metricmetr": 70, "interv": [68, 70, 79, 94, 102], "quantifi": [68, 74, 75, 84, 102], "squar": [68, 75, 77, 93, 94, 99, 101, 102, 104, 105, 111, 112, 114, 116, 119, 122, 124, 126, 128, 130], "hat": [68, 77, 79, 80, 82, 89, 90, 91, 92, 96, 97, 99, 102, 104], "p": [68, 78, 82, 84, 96, 100, 102, 104, 108], "henc": [68, 77, 89, 94, 96], "shown": [68, 77, 78, 79, 84, 89, 90, 92, 93, 94, 95, 97, 100, 102], "actual": [68, 74, 75, 89, 91, 92, 95, 96, 97, 99, 102, 103, 104, 118, 119], "input": [68, 70, 73, 79, 80, 81, 82, 83, 84, 92, 93, 94, 99, 103, 104, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "normal": [68, 70, 75, 77, 84, 90, 91, 93, 94, 96, 97, 104, 108, 110, 115, 116, 118, 119, 125, 126], "nois": [68, 70, 81, 87, 104, 108], "step": [73, 75, 77, 83, 84, 89, 90, 92, 94, 95, 96, 97, 102, 103, 104, 105, 108, 115, 116], "abov": [68, 70, 75, 77, 79, 82, 83, 84, 89, 91, 92, 94, 96, 97, 100, 101, 102, 103, 104, 105], "On": [68, 70, 74, 79, 90, 99, 104, 105], "axi": [68, 69, 70, 81, 84, 89, 90, 92, 93, 94, 96, 97, 102, 103, 104, 105, 108], "y": [68, 69, 70, 77, 81, 84, 86, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 102, 104, 105, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "best": [68, 96, 97, 114, 115, 116, 118, 119, 124, 125, 126, 128, 130], "option": [68, 74, 75, 76, 78, 83, 84, 87, 94, 96, 99, 101, 102, 103, 104, 105, 106, 108, 112, 113, 114, 117, 118, 119, 120, 125, 126, 127, 128], "proport": [68, 70, 78, 93, 99, 102, 103, 104, 125], "degrad": [70, 83, 87, 104], "resilience_perf_worst": [], "high": [68, 70, 73, 75, 77, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 108, 125, 126], "compris": [68, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "april": [68, 87, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "2005": [68, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "septemb": [68, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "more": [68, 69, 70, 74, 75, 77, 78, 80, 82, 83, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 110, 112, 125, 126], "taiwancreditdata": [68, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "websit": [68, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "directli": [68, 69, 72, 83, 84, 89, 93, 94, 96, 97, 99, 101, 102, 104, 105, 106, 108], "although": [68, 75, 79, 89, 92, 93, 97, 99, 101, 102, 104, 105], "some": [68, 77, 82, 83, 89, 91, 92, 93, 94, 96, 97, 99, 101, 102, 103, 104, 105, 108, 112, 114, 116, 118, 119, 124, 126, 128, 130], "serv": [68, 75, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "deal": [77, 101, 105, 118, 119, 123, 124], "modul": [73, 74, 75, 76, 77, 86, 87, 93, 95, 106, 108, 118, 119], "assess": [69, 70, 72, 74, 83, 91, 99, 101, 102, 103, 104, 105], "bia": [69, 87, 94, 123, 124], "than": [68, 69, 70, 75, 76, 77, 79, 80, 81, 82, 84, 87, 90, 91, 93, 94, 96, 97, 99, 101, 102, 103, 104, 105, 108, 110, 112, 115, 116, 118, 119, 125, 126], "becaus": [79, 81, 93, 96, 99, 104, 114, 116, 119, 124, 126, 128, 130], "former": [69, 84, 104], "complex": [75, 77, 82, 89, 90, 91, 94, 95, 96, 101, 103, 105, 125, 126], "But": [75, 125, 126], "definit": [79, 89, 92, 94, 102], "made": 104, "note": [68, 69, 70, 74, 75, 77, 78, 79, 81, 82, 83, 84, 89, 90, 91, 92, 93, 95, 96, 97, 99, 101, 102, 103, 104, 105, 108, 110, 114, 116, 118, 119, 124, 125, 126, 128, 130], "ani": [69, 80, 83, 84, 87, 89, 90, 91, 97, 99, 102, 115, 116, 125, 126], "like": [69, 75, 79, 87, 89, 92, 94, 99, 105, 108, 110, 113, 114, 115, 116, 118, 119, 123, 124, 125, 126, 127, 128, 129, 130], "surrog": [81, 84, 103, 108], "relat": [68, 70, 77, 78, 90, 92, 96, 97, 101, 103, 106, 108, 125, 126], "left": [69, 74, 76, 77, 84, 89, 90, 92, 97, 99, 111, 115, 116, 125, 126], "african": [], "american": [], "white": [], "ones": [77, 82, 92], "right": [69, 77, 81, 84, 89, 90, 92, 93, 96, 97, 99, 111, 115, 116, 125, 126], "women": [], "men": [], "A": [73, 75, 77, 82, 87, 93, 94, 99, 102, 103, 104, 108, 110, 111, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 128, 130], "discrimin": 69, "practic": [69, 84, 90, 94], "less": [70, 76, 79, 80, 82, 84, 91, 96, 101, 102, 103, 105, 108, 125, 126], "figur": [69, 77, 78, 87, 89, 91, 92, 94, 96, 97, 100, 102, 104, 108, 111, 117, 118, 119, 120, 125, 126, 127, 128], "thei": [75, 77, 82, 84, 87, 89, 96, 97, 99, 102, 103, 104, 109, 112, 125, 126], "particular": [77, 78, 81, 84, 87, 91, 93, 94, 95, 96, 97, 101, 102, 103, 105, 110], "those": [69, 70, 100], "overal": [69, 75, 77, 79, 87, 90, 93, 95, 99, 104, 127, 128], "entir": [69, 70, 82, 84, 95, 103, 105], "also": [68, 69, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 102, 103, 104, 105, 110, 111, 118, 119, 125, 126], "within": [68, 69, 72, 74, 75, 90, 95, 97, 101, 102, 103, 105, 108, 118, 119, 125, 126], "appropri": [69, 74, 87, 95, 101], "subset": [69, 75, 77, 80, 82, 95, 102, 110, 113, 115, 118, 123, 125, 127, 129], "provid": [69, 74, 75, 76, 78, 80, 82, 83, 84, 87, 90, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 104, 105, 110, 111, 113, 114, 125, 126], "predictor": [69, 74, 80, 81, 82, 83, 87, 89, 91, 92, 93, 97, 105], "especi": [70, 77, 90, 91, 93, 115, 116, 125, 126], "larg": [68, 75, 77, 81, 84, 90, 91, 93, 94, 99, 101, 109, 118, 119, 123, 124], "That": [79, 103, 125, 126], "rel": [70, 75, 77, 89, 91, 93, 94, 96, 99, 103, 104, 105, 112, 125, 126], "increas": [70, 75, 77, 80, 83, 84, 87, 89, 91, 92, 93, 94, 96, 97, 101, 102, 103, 104, 105, 118, 119, 127, 128, 129, 130], "conclus": [70, 102], "hold": [93, 103], "plotfirst": [], "observ": [69, 75, 77, 80, 82, 89, 90, 91, 92, 93, 97, 99, 100, 101, 102, 103, 104, 110], "se": [], "y_i": 77, "_i": [], "boxplot": 70, "mark": [70, 75, 77, 93, 94, 103], "circl": [70, 75], "same": [70, 75, 87, 89, 90, 92, 94, 97, 100, 103, 104, 108, 113, 114, 125], "befor": [74, 77, 93, 103, 113, 114, 118, 119, 123, 124, 125, 126, 129], "third": [74, 76, 94, 101, 103, 118, 119], "term": [69, 81, 84, 87, 90, 91, 93, 94, 97, 99, 113, 114, 115, 116, 117, 127, 128, 129, 130], "again": [], "ae": [], "purpos": [75, 77, 79, 82, 84, 87, 93, 97, 102, 103, 105], "outsid": [70, 79, 82, 102, 108], "unperturb": [], "most": [74, 77, 80, 81, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 101, 106, 108, 118, 119], "extern": [71, 108], "statist": [71, 77, 78, 80, 87, 93, 94, 99, 108], "manipul": 71, "basic": [71, 76, 108], "isol": 110, "forest": [83, 110], "outlier": [70, 72, 89, 108, 109, 110, 112], "factor": [84, 96, 103, 105, 109], "princip": 112, "compon": [92, 94, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "kmeanstre": 108, "support": [70, 72, 73, 74, 79, 84, 87, 96, 97, 99, 100, 102, 103, 104, 106, 108, 109, 110, 112, 115, 116, 125, 126], "allow": [72, 74, 75, 76, 82, 84, 91, 96, 99, 100, 101, 102, 103, 105, 108, 117, 120, 125, 126], "visual": [72, 75, 79, 80, 82, 87, 89, 90, 92, 93, 94, 97, 101, 102, 103, 105], "explor": [70, 72], "identif": [72, 87, 101, 103], "potenti": [72, 75, 91, 99, 100, 103, 126], "These": [70, 72, 73, 74, 77, 99, 104, 105], "aid": [72, 96], "understand": [72, 80, 87, 91, 93, 94, 96, 100, 101, 102, 103], "rang": [72, 75, 77, 79, 90, 94, 96, 97, 99, 100, 101, 103, 105, 108], "deviat": [72, 75, 76, 103, 104, 108, 118, 119], "pattern": [72, 75, 80, 87, 89, 91, 94, 99, 101, 104], "presenc": [72, 75, 101, 105], "space": [72, 75, 77, 78, 90, 91, 100, 104, 105, 108], "frequenc": [72, 76, 102, 104, 125], "graphic": [72, 80, 87], "represent": [72, 75, 91, 92, 94, 97, 101, 105, 115, 116], "relationship": [72, 75, 77, 79, 80, 82, 83, 84, 91, 93, 94, 96, 99, 102, 104], "combin": [72, 75, 77, 84, 90, 93, 99, 100], "collect": [72, 90, 96, 97], "point": [72, 75, 77, 79, 81, 84, 91, 94, 96, 99, 102, 104, 105, 108, 110, 115, 116, 118, 119, 125, 126, 127, 128, 129, 130], "dimension": [72, 75, 93], "There": [72, 73, 77, 87, 93, 100], "altern": [72, 77, 78, 79, 84, 104, 125, 126], "connect": [72, 105], "line": [70, 72, 75, 77, 80, 87, 94, 99, 100, 102, 103, 105, 108], "introduc": [73, 75, 84, 91, 94, 99, 100, 103], "loader": [73, 118, 119], "usual": [73, 79, 83, 84, 87, 90, 100, 103, 108], "whole": [73, 74], "sever": [70, 73, 77, 84, 92, 96, 102, 108, 110, 125, 126], "alreadi": [73, 83, 86, 94], "upload": 73, "gaussian": [73, 75, 77, 104, 108, 109], "spheric": [73, 108], "archiv": [73, 108], "edu": [73, 108], "californiahousing_raw": [73, 86, 108], "crash": [73, 108], "cours": [73, 108], "californiahousing_trim1": [73, 108], "98": [73, 108], "solasai": [73, 108], "dispar": [73, 87, 99, 100, 108], "solashmda": [73, 108], "2018": [73, 84, 87, 108], "home": [73, 90, 91, 95, 103, 108], "disclosur": [73, 108], "act": [73, 108], "hmda": [73, 108], "about": [73, 79, 87, 108], "everi": [73, 90, 108, 117, 120, 125], "unit": [73, 93, 94, 108, 112], "you": [73, 74, 76, 77, 81, 84, 86, 87, 89, 91, 92, 93, 95, 96, 97, 100, 101, 102, 103, 104, 105, 106, 108, 111, 113, 115, 118, 123, 125, 126, 127, 129], "wai": [70, 73, 77, 84, 87, 91, 92, 94, 97, 108], "just": [73, 79, 84], "new": [73, 75, 87, 90, 91, 125, 126], "wrap": [73, 77], "abil": [74, 75, 99, 101], "variou": [68, 70, 74, 75, 84, 87, 89, 92, 93, 99, 100, 103, 106, 108], "aspect": [74, 75, 87, 92], "addition": [74, 76, 96, 97, 99, 101, 102], "specifi": [68, 70, 74, 76, 77, 79, 82, 83, 84, 87, 89, 90, 92, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 112, 125, 127, 128, 129, 130], "paramet": [70, 74, 75, 76, 77, 79, 80, 81, 83, 84, 87, 89, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "seed": [74, 108, 109, 111, 112, 115, 116, 118, 119, 127, 128, 129, 130], "greater": [68, 74, 75, 76, 77, 80, 101, 102, 105, 108, 112, 115, 116, 118, 119, 125, 126], "control": [74, 76, 90, 91, 94, 95, 96, 100, 103, 112, 125, 126], "flexibl": [74, 76, 83, 87, 91, 92, 96, 105], "accord": [74, 87, 94, 96, 100, 103, 108, 110, 118, 119], "prefer": 74, "typic": [74, 83, 93], "howev": [69, 70, 74, 75, 77, 80, 81, 82, 83, 84, 87, 89, 90, 91, 93, 94, 96, 97, 99, 101, 102, 103, 104, 105], "locat": [74, 75], "explicitli": [74, 76, 84], "identifi": [74, 75, 77, 80, 84, 87, 91, 93, 96, 97, 99, 101, 103, 104, 105, 108, 110], "desir": [74, 75, 96, 99, 100, 102, 105], "ensur": [74, 76, 91, 95, 96, 97, 100, 101, 112], "correct": [74, 89, 99, 105, 106], "automat": [74, 76, 77, 87, 96, 108, 113, 114, 125], "determin": [74, 75, 76, 77, 78, 82, 84, 90, 91, 99, 101, 102, 103, 104, 105, 108, 114, 116, 119, 123, 124, 126, 128, 130], "assum": [74, 77, 82, 83, 84, 86, 91, 94, 95, 102, 104, 105, 118, 119], "hand": [74, 79, 87, 90, 99, 102], "suitabl": [74, 75, 93, 96, 104, 105], "handl": [74, 75, 77, 99, 103], "assign": [74, 81, 93, 95, 100, 103, 109, 112], "certain": [70, 74, 75, 76, 82, 84, 92, 105], "carri": [74, 125, 126], "signific": [70, 74, 77, 83, 84, 87, 89, 92, 101, 103], "process": [70, 74, 75, 81, 82, 87, 90, 94, 96, 97, 99, 100, 102, 104, 105, 113, 114, 125, 126], "n": [74, 76, 77, 79, 82, 84, 99, 102, 104, 125, 126], "style": [74, 76, 108], "width": [74, 76, 78, 99, 100, 102], "pa": [74, 76], "encod": [74, 87, 93, 96, 108], "standard": [74, 76, 77, 79, 87, 89, 93, 100, 104, 108, 109, 110, 111, 112, 118, 119], "scaler": [74, 117, 118, 119, 120, 127, 128], "onc": [74, 79, 90, 95, 97, 100], "conduct": [74, 77, 101, 105], "dissimilar": [74, 75], "edf": 74, "reduc": [74, 75, 77, 79, 83, 84, 90, 94, 97, 101, 110], "comput": [74, 75, 77, 79, 80, 82, 83, 84, 94, 96, 99, 101, 102, 103, 105, 108, 109, 110, 112, 118, 119, 123, 124, 125, 126], "burden": [74, 75, 77, 101], "subsampl": [74, 75, 82, 84, 108], "transform": [74, 75, 77, 84, 91, 93, 94, 96, 104, 112], "would": [74, 77, 93, 94, 95, 99, 100, 102, 105, 114, 116, 118, 119, 124, 125, 126, 128, 130], "list": [70, 74, 76, 77, 87, 92, 94, 101, 104, 105, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "euclidean": [74, 75, 77, 103, 108, 111], "far": [74, 75, 82], "awai": 74, "farthest": 74, "fit": [74, 75, 77, 79, 80, 81, 82, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 133], "randomli": [70, 74, 75, 81, 83, 84, 125, 126], "remain": [74, 77, 80, 81, 84, 93, 94, 102, 103, 104], "length": [74, 75, 94, 110, 113, 114, 117, 120], "contain": [74, 75, 77, 83, 90, 91, 93, 101, 105, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "element": [74, 79, 81, 99, 123, 124, 125, 126], "distinct": [69, 74, 75, 103], "characterist": [74, 75, 103], "over": [74, 76, 77, 79, 84, 89, 92, 97, 123, 124], "aforement": [74, 105], "defin": [74, 77, 78, 80, 82, 83, 84, 94, 100, 102, 103, 108, 110, 111, 114, 116, 119, 124, 125, 126, 128, 130], "composit": 74, "focus": [69, 75], "address": [75, 93, 100, 101, 105], "after": [75, 79, 86, 87, 93, 94, 101, 102, 103, 104, 106, 117, 118, 119, 120, 127, 128], "help": [75, 77, 82, 84, 91, 93, 94, 96, 99, 105], "enhanc": [75, 77, 87, 94, 101, 103, 105], "subsequ": [75, 103, 105], "adopt": [75, 87], "uniqu": [75, 76, 87, 94, 96, 97, 100, 105, 125, 126], "approach": [75, 77, 84, 87, 90, 93, 99, 101, 102, 103, 105], "liu2008": 75, "It": [68, 69, 70, 75, 76, 77, 78, 79, 81, 84, 87, 89, 90, 91, 92, 93, 95, 96, 97, 99, 101, 102, 103, 104, 105, 108, 112, 118, 119, 123, 124, 125, 126], "begin": [75, 77, 78, 79, 80, 82, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 102, 105, 111], "maximum": [75, 76, 77, 78, 89, 90, 95, 96, 97, 101, 110, 113, 114, 117, 120, 125, 126, 127, 128, 129, 130], "recurs": [75, 82, 94, 95, 111], "construct": [75, 102], "until": [75, 89, 97, 125, 126], "instanc": [75, 76, 80, 81, 84, 89, 90, 93, 99, 101, 102, 103, 105, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "measur": [75, 77, 78, 83, 93, 96, 99, 101, 102, 103, 110, 111, 125, 126], "anomali": [75, 109, 110, 112], "path": [75, 84, 87, 90, 95, 108, 110, 111, 118, 119, 125, 126], "shorter": 75, "easier": [75, 95, 96], "separ": [75, 76, 93, 96, 99], "contrast": [75, 89, 90, 93, 96, 97, 99], "longer": [75, 93], "effici": [75, 87, 110, 112], "doe": [75, 81, 83, 101, 102, 105, 125, 126], "reli": [75, 76, 99], "make": [75, 77, 80, 81, 83, 87, 89, 91, 92, 93, 94, 95, 97, 99, 100, 105, 112, 118, 119, 127, 128, 129, 130], "isolationforest": [75, 108], "wrapper": [75, 95, 97, 110, 117, 120, 121, 122, 125, 126], "implement": [75, 77, 80, 81, 90, 93, 94, 101, 103, 115, 116], "ensembl": [75, 84, 90, 91, 105, 110], "propos": [75, 89, 90, 97], "he2003": 75, "partit": [75, 80, 82, 105, 125, 126, 127, 128, 129, 130], "mixtur": [75, 77, 109], "classifi": [75, 87, 93, 99, 103, 105, 108, 110, 113, 115, 117, 118, 121, 123, 125], "small": [75, 79, 84, 89, 90, 92, 94, 99, 104, 109], "belong": [75, 94, 102], "correspond": [75, 77, 84, 89, 90, 91, 92, 93, 94, 96, 97, 99, 101, 104, 105, 108, 123, 124, 125, 126], "centroid": 75, "nearest": [75, 101, 104], "multipli": [75, 102, 112, 125], "emphas": 75, "impact": [69, 75, 79, 84, 96, 97, 100, 101, 108], "larger": [70, 75, 79, 80, 83, 90, 91, 93, 94, 108, 109, 112, 117, 118, 119, 120], "neighbor": [75, 101], "comprehens": [75, 87, 99, 100, 103], "reduct": [75, 84, 125, 126, 127, 128, 129, 130], "techniqu": [75, 87, 96, 101, 105], "mahalanobi": [75, 112], "error": [75, 87, 99, 101, 102, 104, 105, 106, 108, 126], "reconstruct": 75, "elabor": 75, "take": [75, 77, 84, 87, 89, 92, 96, 97, 101, 104, 105], "structur": [75, 84, 87, 89, 92, 94, 99], "got": [75, 106], "easili": [75, 87, 90], "formula": [75, 77, 79, 84, 94, 99, 102], "shyu2003": 75, "md": 75, "z_": [75, 79], "lambda_": 75, "eigenvalu": 75, "varianc": [75, 84, 89, 90, 91, 92, 93, 96, 97, 99, 112, 118, 119, 126], "give": [75, 83, 94, 96, 107, 118, 119], "u": [75, 79, 82, 83, 96, 99, 101, 102, 103, 104, 105, 106, 114, 116, 119, 124, 126, 128, 130], "obtain": [70, 75, 76, 82, 84, 89, 94, 96, 99, 101, 102, 104, 105, 118, 119, 125, 126, 127, 128], "x_": [75, 79, 80, 82, 89, 91, 92, 94, 96, 97, 102, 117, 118, 119, 120, 127, 128], "final": [75, 77, 79, 80, 83, 84, 89, 91, 92, 94, 96, 97, 104, 127, 128], "among": [75, 77, 84, 93, 125, 126], "mutual": [75, 92], "author": [75, 90], "advantag": [75, 77, 87, 89, 90], "outlin": [75, 100, 103], "iter": [75, 77, 83, 89, 90, 94, 97, 104, 108, 112, 115, 116, 117, 118, 119, 120, 123, 124], "met": 75, "reach": [75, 79, 103], "level": [69, 75, 77, 84, 87, 89, 92, 97, 100, 102, 104], "child": [75, 111, 125, 126], "leav": [75, 111, 115, 116, 125, 126], "behavior": [75, 93, 101], "capabl": [75, 77, 87, 93, 103], "aim": [70, 75, 77, 79, 101, 102, 103], "homogen": 75, "further": [75, 77, 92, 96, 102, 107, 127, 128, 129, 130], "pleas": [75, 79, 80, 83, 84, 92, 94, 107], "subsect": 75, "briefli": [75, 91, 94], "kei": [75, 82, 89, 91, 92, 96, 100], "decid": [75, 108], "whether": [75, 77, 82, 90, 96, 99, 108, 109, 110, 111, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130], "red": [75, 84, 90, 102, 103, 105], "dot": [70, 75, 102, 103, 105, 108], "mai": [75, 77, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91, 93, 94, 95, 96, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 114, 115, 116, 119, 124, 125, 126, 128, 130], "fall": [70, 75, 102, 105], "still": [75, 79, 80, 89, 92, 94, 96, 97, 103], "context": [75, 82, 84, 95, 97, 100, 102], "phenomenon": 75, "highlight": [75, 77, 95, 101, 103], "t": [75, 86, 108, 118, 119, 123, 124, 125, 126], "sne": [75, 108], "dimens": [75, 105, 112], "worth": [75, 84, 90], "meaning": [75, 99, 102], "insight": [75, 83, 92, 99, 101, 103, 105], "mention": [75, 87], "reveal": [68, 70, 75, 83, 89, 97, 99, 101, 105], "notic": [75, 99, 103], "discrep": [75, 99, 104, 105], "fei": 75, "toni": 75, "liu": [75, 77], "kai": 75, "ming": 75, "ting": 75, "zhi": 75, "hua": 75, "zhou": 75, "2008": 75, "eighth": 75, "ieee": [75, 87], "intern": [75, 87, 110, 123, 124, 125, 126], "confer": [75, 87], "mine": [75, 87], "pisa": 75, "itali": 75, "pp": [75, 77, 87], "413": 75, "422": 75, "doi": [75, 87], "1109": 75, "icdm": 75, "zengyou": 75, "he": [75, 87], "xiaofei": 75, "xu": 75, "shengchun": 75, "deng": 75, "2003": 75, "discov": 75, "recognit": [75, 87], "letter": 75, "1641": 75, "1650": 75, "mei": 75, "ling": [75, 77], "shyu": 75, "shu": 75, "ching": 75, "chen": [75, 87], "kanoksri": 75, "sarinnapakorn": 75, "liwu": 75, "novel": 75, "scheme": [75, 78, 90], "miami": 75, "univ": 75, "coral": 75, "gabl": 75, "fl": 75, "dept": 75, "electr": 75, "engin": [75, 87], "involv": [68, 70, 76, 83, 93, 96, 101, 103, 104, 105], "summar": [70, 76, 90, 104, 108], "meta": 76, "overview": [76, 94, 104], "enabl": [76, 87, 95, 96, 101, 112], "present": [68, 69, 70, 76, 84, 99, 100, 101, 105, 110, 112], "panel": [76, 87], "anoth": [76, 79, 89, 96, 103, 111], "otherwis": [68, 70, 76, 84, 90, 96, 101, 105, 108, 112, 127, 128], "regard": [76, 87, 102, 105], "miss": [76, 84, 89], "quartil": 76, "highest": [76, 79, 84, 103, 104], "top": [68, 70, 76, 77, 78, 81, 89, 91, 92, 93, 94, 96, 97, 99, 103, 104, 118, 119], "call": [70, 76, 77, 79, 82, 87, 89, 93, 94, 96, 100, 106, 110, 112, 113, 114, 116, 119, 124, 126, 128, 130], "attribu": 76, "offer": [69, 70, 76, 79, 84, 94, 95, 99, 101, 103, 105], "sensit": [70, 76, 84, 93, 94, 99, 100], "must": [76, 79, 81, 117, 120, 121, 122], "format": [76, 96], "sole": [76, 84, 99, 101, 105], "avail": [76, 80, 82, 84, 87, 96, 100, 101, 102, 103, 104, 105, 108, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "want": [76, 82, 84, 86, 90, 93, 97, 104, 105], "do": [76, 77, 79, 83, 84, 93, 100, 102, 103, 125, 126], "align": [76, 77, 78, 79, 80, 82, 84, 89, 90, 91, 92, 93, 94, 96, 97, 99, 100, 102], "relev": [77, 80, 93, 95, 102], "avoid": [77, 93, 94, 118, 119, 123, 124], "moreov": [77, 79, 84, 103, 105], "benefici": 77, "distinguish": [77, 90, 92, 99, 102, 105, 108], "treatment": 77, "rigor": 77, "mathemat": [77, 87], "rho_": 77, "frac": [77, 78, 79, 82, 84, 96, 97, 99, 100, 102, 114, 116, 119, 124, 126, 128, 130], "sum_": [77, 78, 79, 82, 84, 90, 94, 99], "x_i": 77, "sqrt": [77, 102, 125, 126], "sign": [77, 101], "denot": [77, 80, 83, 84, 94, 100, 102, 103], "direct": [77, 91, 93, 96, 99], "magnitud": [77, 87, 93, 99, 104], "strength": [77, 91, 93, 94, 96, 108, 117, 118, 119, 120, 121, 122], "straightforward": [77, 81, 82], "up": [77, 79, 82, 87, 97, 108, 125, 126], "command": [77, 87, 93, 106], "blue": [77, 84, 90], "orang": 77, "posit": [77, 89, 91, 92, 93, 94, 97, 99, 100, 108, 110, 117, 118, 119, 120], "neg": [77, 79, 83, 89, 91, 92, 93, 96, 97, 99, 110, 114, 116, 117, 119, 120, 121, 122, 124, 125, 126, 128, 130], "bottom": [77, 81, 89, 91, 92, 96], "text": 77, "easi": [77, 87, 95, 108], "One": [77, 87, 106], "rank": [68, 70, 77, 83, 87, 93, 96, 103, 108], "r_": 77, "mathrm": [77, 80, 82, 96], "r": [77, 87, 94, 99, 100, 104, 105, 114, 116, 118, 119, 124, 126, 128, 130], "d_i": 77, "them": [77, 90, 91, 96, 101, 105, 125, 126], "monoton": [77, 82, 92, 94, 96, 97, 100, 103, 118, 119, 127, 128, 129, 130], "perfect": [77, 99], "occur": [77, 97, 101, 104], "except": [77, 84, 97, 114, 116, 119, 124, 126, 128, 130], "replac": [77, 84, 100], "pair": [77, 97, 100, 118, 119, 125], "vector": [77, 79, 84, 94, 97, 112, 123, 124], "a_": 77, "j": [77, 79, 84, 89, 91, 92, 93, 96, 97], "x_j": [77, 89, 93], "x_k": 77, "quad": 77, "ldot": [77, 84, 91, 93, 94, 102, 103], "b_": 77, "y_j": 77, "y_k": 77, "matric": [77, 109, 110, 112], "_": [77, 78, 79, 80, 82, 89, 92, 97, 99, 102], "cdot": [77, 93, 99], "b": [77, 78, 87, 94, 103, 104, 118, 119], "arithmet": 77, "product": [77, 118, 119], "dcov": 77, "dvar": 77, "operatornam": 77, "alwai": [77, 91, 99, 101, 114, 116, 119, 124, 125, 126, 128, 130], "absolut": [77, 78, 84, 93, 94, 99, 103, 104, 105, 108, 126], "captur": [77, 81, 89, 91, 92, 93, 99, 104], "computation": 77, "veri": [69, 77, 79, 81, 83, 92, 118, 119, 123, 124], "expens": [77, 108], "scalabl": [77, 118, 119], "big": 77, "downsampl": [77, 84, 101], "statsmodel": [77, 106], "packag": [77, 79, 80, 81, 82, 84, 87, 89, 90, 91, 93, 94, 96, 97, 106], "speed": [77, 82], "consider": [70, 77, 99], "compos": 77, "sort": [77, 103], "descend": [77, 94, 103], "order": [77, 79, 87, 91, 93, 94, 96, 102, 103, 105, 110, 117, 118, 119, 120, 125], "pre": [77, 84, 87, 113, 114], "org": [77, 112], "stabl": [77, 91, 93, 96, 112], "inspect": [77, 87, 125, 126], "permutation_import": [77, 83, 125, 126], "valid": [77, 87, 92, 102, 113, 114, 118, 119, 123, 124, 125, 126], "percentag": [77, 112], "concern": 77, "ii": 77, "iii": 77, "underfit": [77, 87, 89], "minim": [77, 99, 104, 108, 125, 126], "power": [77, 87, 94, 95, 96, 112], "probabilist": 77, "incorpor": [77, 92, 102, 103], "z": [77, 84, 94, 97], "goal": [77, 84, 87, 101], "perp": 77, "mid": 77, "highli": [77, 79, 82, 84, 95, 96], "kcit": 77, "zhang2012": 77, "kernel": [77, 84, 114, 116, 119, 124, 126, 128, 130], "work": [77, 82, 84, 87, 96, 97, 99, 100, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "arbitrari": [77, 87, 93, 108, 133], "strobl2019": 77, "fast": [77, 87, 88, 89, 92, 94, 108, 115, 116, 133], "approxim": [77, 82, 84, 89, 90, 92, 96, 99, 101, 102, 103, 105], "fourier": [77, 108], "reproduc": 77, "hibert": 77, "therefor": [77, 79, 81, 84, 93, 94, 103], "null": [77, 99], "hypothesi": 77, "equival": [77, 94, 97, 110], "zero": [77, 79, 83, 89, 90, 91, 93, 94, 97, 99, 112, 113, 114, 125, 126], "cross": 77, "sigma_": 77, "sigma": [77, 94], "_f": 77, "gamma": [77, 96, 97, 127, 128, 129, 130], "asymptot": 77, "lambda_i": 77, "z_i": 77, "d": [77, 78, 91, 93, 94, 104], "lindsai": 77, "pilla": 77, "basak": 77, "lpb": 77, "lindsayl2000": 77, "cdf": 77, "finit": 77, "borboudakis2019": 77, "elimin": 77, "delet": 77, "insignific": 77, "predefin": [77, 102], "candid": [77, 92, 105], "p_valu": 77, "ad": [68, 70, 77, 97, 104, 110, 118, 119], "stop": [77, 87, 90, 108, 113, 114, 115, 116, 118, 119, 123, 124, 125, 126], "phase": [77, 123, 124], "charact": 77, "recommend": [77, 94], "yu2020": 77, "twice": 77, "temporarili": 77, "temporari": [77, 102], "perman": 77, "formul": [77, 87, 88], "smaller": [77, 90, 94, 95, 96, 99, 102, 103, 104, 105, 108, 118, 119, 125, 126], "fewer": [77, 118, 119], "procedur": [77, 96], "seven": 77, "deep": [77, 87, 90, 94, 95, 108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "causal": [77, 102], "disadvantag": 77, "sequenti": [77, 118, 119], "kun": 77, "zhang": [77, 87], "jona": 77, "peter": [77, 87, 93], "dominik": 77, "janz": 77, "bernhard": 77, "schoelkopf": 77, "2012": 77, "discoveri": [77, 87], "arxiv": [77, 84, 87], "preprint": [77, 84, 87], "1202": 77, "3775": 77, "eric": 77, "strobl": 77, "shyam": 77, "visweswaran": 77, "2019": [77, 87], "parametr": [77, 91], "journal": [77, 80, 87], "infer": [77, 96, 118, 119, 123, 124, 125, 126], "bruce": 77, "ramani": 77, "prasanta": 77, "moment": [77, 84], "theori": 77, "annal": 77, "institut": 77, "230": 77, "giorgo": 77, "borboudaki": 77, "ioanni": 77, "tsamardino": 77, "research": [77, 87, 89], "276": 77, "314": 77, "kui": 77, "yu": [77, 87], "xianji": 77, "guo": 77, "lin": 77, "jiuyong": 77, "li": [77, 87, 97], "hao": [77, 87], "wang": [77, 87], "zhaolong": 77, "xindong": 77, "wu": [77, 87], "2020": [77, 87], "acm": [77, 87], "survei": 77, "csur": 77, "stabil": [78, 102, 103, 108], "extent": [78, 104], "discret": [78, 100, 102, 104], "kullback": 78, "leibler": 78, "l": [78, 83, 94], "q": [78, 102], "d_": 78, "kl": 78, "p_i": 78, "ln": 78, "q_i": 78, "asymmetr": 78, "resect": 78, "equal": [78, 84, 89, 91, 93, 94, 99, 100, 102, 103, 105, 108, 110, 112, 115, 116, 117, 118, 119, 120, 125, 126], "fix": [78, 79, 84, 106, 118, 119, 125, 126], "wasserstein": [78, 108], "cumul": 78, "f": [78, 79, 80, 82, 83, 84, 91, 92, 96, 97, 102, 104], "w": [78, 87, 94, 118, 119], "int": [78, 82, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130], "dx": 78, "kolmogorov": [78, 108], "smirnov": [78, 108], "wasserstein_dist": 78, "ks_2samp": 78, "scipi": [78, 106, 112], "stat": 78, "sup_x": 78, "largest": [68, 70, 78, 81, 89, 91, 92, 93, 94, 96, 97, 102, 103, 104, 125, 126], "apley2016": [79, 87], "Its": [79, 99, 102], "bias": [79, 94, 100, 105], "overcom": 79, "quicker": 79, "unbias": 79, "let": [79, 80, 94, 102, 104, 105], "n_": [79, 94, 100], "uncent": [79, 81, 93], "h": [79, 89, 92, 97], "k_": 79, "textbf": [79, 89, 90, 91, 92, 93, 94, 96, 97], "tag": [79, 82, 84, 89, 90, 91, 92, 93, 94, 96, 97, 99], "faster": [79, 82, 89, 90], "too": [70, 79, 84, 94, 96, 117, 120, 125, 126], "might": [79, 95], "accur": [79, 87, 95, 96, 99, 101, 105], "curv": [79, 99, 102, 103, 104, 105], "down": [79, 84], "paper": [79, 87, 110], "pyal": 79, "strongli": 79, "across": [79, 80, 84, 93, 99, 100, 103, 125, 126], "extrapol": [79, 82], "beyond": [79, 87], "envelop": [79, 82], "move": 79, "unreli": [79, 102], "lead": [70, 79, 81, 87, 89, 91, 93, 96, 100, 112], "word": 79, "tell": [79, 90, 96, 104, 110], "peak": [79, 89, 92, 97, 99, 103], "rush": [79, 89, 92, 99, 102], "hour": [79, 89, 92, 93, 97, 99, 102], "around": [70, 79, 80, 89, 92, 97, 99, 103, 105], "draw": [79, 84, 89, 90, 92, 96, 97, 102, 103, 108, 111], "previou": [70, 79, 80, 102, 103], "creat": [79, 81, 94, 100, 103, 105, 110, 125, 126], "light": [79, 90], "rain": 79, "etc": [79, 96, 113, 114], "heavi": 79, "significantli": [70, 79, 81, 93, 99, 103], "simpl": [79, 94, 105, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "much": [70, 79, 80, 84, 90, 93, 99, 103, 104], "technic": 79, "subtract": [79, 81, 93, 97], "lighter": 79, "shade": [79, 90], "darker": [79, 90], "quit": [79, 89, 96, 97], "mind": 79, "dure": [79, 80, 81, 82, 90, 92, 96, 99, 102, 105, 125, 126], "g2015": 80, "focu": [80, 93, 101, 103, 105], "complement": [80, 82], "c": [80, 82, 94, 104, 106], "document": [80, 83, 103], "snippet": 80, "global_ic": 80, "produc": 80, "constant": [80, 89, 91, 93, 96, 97, 99, 114, 116, 119, 124, 126, 128, 130], "examin": [80, 99, 102], "our": [80, 81, 83, 87, 90, 101, 103, 105], "apart": 80, "period": [80, 102], "goldstein": 80, "alex": 80, "adam": [80, 118, 119], "kapeln": 80, "justin": 80, "bleich": 80, "emil": 80, "pitkin": 80, "2015": [80, 87], "ribeiro2016": [81, 87], "tool": [81, 82, 84, 87, 99, 108], "lasso": [81, 87, 93, 122], "proxim": 81, "predict_proba": [81, 108, 113, 115, 117, 118, 123, 125, 127, 129], "close": [70, 81, 89, 93, 94, 99, 102], "greatli": [81, 84], "judgment": 81, "sens": 81, "crucial": [81, 95, 99, 101, 102, 103], "itself": [81, 93, 113, 114], "unchang": [81, 83, 93, 104], "essenti": [81, 93, 99, 100, 105], "rather": [81, 93], "becom": [81, 84, 87, 90, 91, 93, 99, 101, 103, 104, 105], "neglig": [81, 93], "am": [70, 81, 89, 92], "now": [81, 93], "mainli": [81, 93], "intercept": [81, 90, 93, 94, 96, 97, 115, 116, 122, 127, 128], "hastie2015": [82, 87], "assumpt": [82, 91, 93, 96, 104, 112], "odd": [82, 93, 108], "suppos": [82, 84, 125], "x_c": 82, "mathbb": [82, 89, 90, 91, 92, 93, 94, 96, 97], "dx_": 82, "commonli": [82, 95, 96, 97, 99], "brute": 82, "partial_depend": 82, "few": [82, 96], "inaccur": 82, "inconsist": [68, 82], "accomplish": [82, 102], "trigger": [82, 93, 94, 96, 113, 114, 115, 116, 118, 119], "tend": [82, 87, 91, 94, 97, 103, 105], "substanti": [82, 101], "4th": 82, "joint": 82, "daytim": 82, "nighttim": 82, "influenc": [69, 83, 91, 103, 114, 116, 119, 124, 126, 128, 130], "loss": [83, 90, 96, 108, 118, 119, 123, 124, 126, 127, 128, 129, 130], "l2001": 83, "shuffl": 83, "broken": 83, "drop": [83, 93, 104, 105], "relianc": 83, "fulli": [83, 87, 102], "either": [83, 87, 89, 90, 95, 97, 99, 102, 113, 114, 125, 126], "futur": [83, 86, 133], "releas": 83, "next": [83, 90, 91, 95, 96, 102, 103, 104, 105], "achiev": [83, 92, 94, 96, 99, 102, 103, 104], "truncat": [83, 112, 117, 120, 125, 126], "site": 83, "repetit": [83, 104, 108], "valuabl": [83, 96, 99, 103], "appear": [83, 96, 99], "seem": [83, 84], "surpris": 83, "breiman": 83, "2001": [83, 87], "lundberg2017": [84, 87], "lundberg2018": 84, "concept": 84, "sport": 84, "analogi": 84, "won": 84, "soccer": 84, "game": 84, "winner": 84, "bonu": 84, "fairli": 84, "team": 84, "member": [84, 110], "know": [84, 93, 125, 126], "five": 84, "player": 84, "who": 84, "plai": 84, "role": [84, 89, 97], "victori": 84, "recogn": [84, 101], "come": [84, 87], "success": [84, 94], "imlbook": 84, "shapblog": 84, "possess": 84, "attract": 84, "properti": [84, 94, 110, 125, 126], "missing": 84, "decompos": [84, 97], "prime": 84, "phi_0": 84, "phi_j": 84, "z_j": 84, "coalit": 84, "off": [84, 94, 99, 100, 108, 111], "phi_": 84, "shap_": 84, "possibl": [69, 84, 93, 99, 100, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "subseteq": 84, "val": 84, "cup": 84, "return": [84, 91, 100, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "accept": [84, 109, 112], "problemat": 84, "affect": [84, 93, 101, 104, 105], "common": [84, 91, 93], "background": 84, "mere": [84, 102], "challeng": [84, 99], "latter": [84, 104, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "break": 84, "interven": 84, "intervent": 84, "inspir": 84, "particularli": [84, 87], "ignor": [84, 101, 105, 106, 108, 110, 112, 125, 126], "put": [84, 86], "unlik": [68, 70, 84, 90, 101], "guarante": 84, "lot": 84, "linearshap": 84, "treeshap": 84, "paragraph": 84, "benefit": 84, "math": 84, "coef": 84, "design": [84, 92, 103, 133], "leaf": [84, 90, 96, 97, 110, 111, 113, 114, 115, 116, 125, 126, 127, 128, 129, 130], "went": 84, "exactli": [84, 91, 96], "bit": 84, "slower": [84, 90, 110], "ll": 84, "i_j": 84, "consum": 84, "place": 84, "had": 84, "greatest": 84, "pdf": 84, "spap": 84, "lundberg": [84, 87], "scott": [84, 87], "m": 84, "gabriel": 84, "erion": 84, "su": [84, 87], "lee": [84, 87], "1802": 84, "03888": 84, "object": [86, 91, 93, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "lightgbm": 86, "lgbmregressor": 86, "lgbm2": 86, "lgbm_2": 86, "abl": [86, 90, 91], "extract": [86, 94, 97, 112, 117, 118, 119, 120, 127, 128], "model_sav": [86, 108], "ch_lgmb_2": 86, "pkl": [86, 108], "pickl": [86, 108], "make_pipelin": [86, 108], "lgmb_2_load": 86, "don": [86, 125, 126], "model_select": 86, "train_test_split": 86, "train_x": [86, 108], "test_x": [86, 108], "train_i": [86, 108], "test_i": [86, 108], "test_siz": 86, "lgbm7": 86, "ravel": 86, "lgmb_7": 86, "pi": [87, 94], "pai": 87, "em": 87, "el": 87, "access": 87, "workflow": [87, 94, 96, 108, 125, 126], "grow": [87, 90, 125, 126], "weak": [87, 101, 105], "uncertainti": [70, 87, 102], "exist": [87, 89, 90, 92, 93, 97, 99, 105, 108], "mlop": 87, "platform": [87, 106], "assur": 87, "furthermor": [70, 87, 90, 99], "bank": 87, "project": 87, "supervis": [87, 105], "increasingli": 87, "domain": 87, "consequ": [69, 87, 105], "lack": 87, "difficult": 87, "trust": 87, "emerg": 87, "pedregosa2011": 87, "kokhlikyan2020": 87, "klaise2021": 87, "baniecki2021": 87, "li2022": 87, "known": [87, 93, 94, 95, 99, 103, 125, 126], "pitfal": 87, "rudin2019": 87, "molnar2020": 87, "yang2021a": 87, "yang2021b": [87, 92], "sudjianto2020": [87, 94], "interpretml": 87, "nori2013": [87, 89], "microsoft": [87, 89], "promot": [87, 100], "boost": [87, 88, 90, 96, 108, 113, 114, 127, 128, 129, 130, 133], "ga2m": 87, "lou2013": [87, 89], "sudjianto2021": 87, "discuss": [87, 99, 104], "meantim": 87, "chung2019": 87, "pycaret": 87, "tensorflow": 87, "finra": 87, "toolkit": 87, "Such": [87, 94, 104], "sometim": [87, 112], "demand": [87, 99], "risk": [87, 96], "manag": [87, 108], "routin": 87, "exercis": 87, "conceptu": 87, "sound": 87, "angl": 87, "been": [87, 90, 91, 94, 95], "sinc": [69, 70, 87, 90, 96, 99, 113, 115, 118, 123, 125, 127, 129], "launch": 87, "2022": 87, "interfac": [87, 108], "widget": 87, "dashboard": 87, "lab": 87, "conveni": [70, 87], "data_qu": 87, "choic": [87, 93, 94], "parameter": 87, "action": 87, "through": [70, 87, 90, 92, 94, 125, 126], "cell": 87, "termin": [87, 126], "autom": 87, "registr": [87, 108], "mandatori": 87, "unifi": 87, "glass": 87, "section_3": 87, "section_4": 87, "cover": 87, "treat": [87, 103], "even": [87, 90, 94, 103, 125, 126], "though": 87, "simplif": 87, "worthwhil": 87, "enough": [87, 94, 107], "backend": 87, "simplic": 87, "citep": [], "pimldoc": [], "v0": 87, "latest": 87, "updat": [87, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "2023": 87, "ell_1": 87, "ell_2": 87, "regular": [87, 91, 92, 93, 94, 101, 118, 119, 123, 124, 127, 128, 129, 130], "spline": [87, 91, 96, 117, 118, 119, 120], "serven2018": 87, "greedi": [87, 88, 108, 115, 116, 133], "tan2022": [87, 90], "extrem": [87, 90, 94], "gradient": [87, 89, 94, 127, 128, 129, 130], "optim": [87, 96, 99, 108, 118, 119, 127, 128], "chen2015": 87, "guillermo2020": 87, "purifi": [87, 97], "lengerich2020": [87, 96, 97], "network": [87, 88, 91, 92, 118, 119, 123, 124, 133], "aletheia": [87, 94, 123, 124], "unwrapp": [87, 123, 124], "sparsif": 87, "brief": [87, 94], "popular": [87, 93], "quantif": [87, 101], "conform": [87, 102, 108], "cui2023": 87, "out": [87, 94, 96, 103, 105, 118, 119, 123, 124], "de": [87, 94], "art": 87, "improv": [87, 96, 99, 101, 103, 112, 113, 114, 123, 124, 125, 126], "expand": [87, 125, 126], "track": 87, "report": 87, "fabian": 87, "pedregosa": 87, "ga\u00ebl": 87, "varoquaux": 87, "alexandr": 87, "gramfort": 87, "vincent": 87, "michel": 87, "bertrand": 87, "thirion": 87, "olivi": 87, "grisel": 87, "mathieu": 87, "blondel": 87, "prettenhof": 87, "ron": 87, "weiss": 87, "dubourg": 87, "jake": 87, "vanderpla": 87, "passo": 87, "david": 87, "cournapeau": 87, "matthieu": 87, "brucher": 87, "perrot": 87, "\u00e9douard": 87, "duchesnai": 87, "2011": 87, "2825": 87, "2830": 87, "narin": 87, "kokhlikyan": 87, "vivek": 87, "miglani": 87, "miguel": 87, "martin": 87, "edward": 87, "bilal": 87, "alsallakh": 87, "jonathan": 87, "reynold": 87, "alexand": 87, "melnikov": 87, "natalia": 87, "kliushkina": 87, "carlo": 87, "araya": 87, "siqi": 87, "yan": 87, "orion": 87, "reblitz": 87, "richardson": 87, "captum": 87, "librari": [87, 102], "pytorch": [87, 123, 124], "2009": 87, "07896": 87, "jani": 87, "klais": 87, "arnaud": 87, "van": 87, "looveren": 87, "giovanni": 87, "vacanti": 87, "alexandru": 87, "coca": 87, "2021": 87, "alibi": 87, "8194": 87, "hubert": 87, "baniecki": 87, "wojciech": 87, "kretowicz": 87, "piotr": 87, "piatyszek": 87, "jakub": 87, "wisniewski": 87, "przemyslaw": 87, "biecek": 87, "dalex": 87, "9759": 87, "9765": 87, "xuhong": 87, "haoyi": 87, "xiong": 87, "xingjian": 87, "xuanyu": 87, "zeyu": 87, "deje": 87, "dou": 87, "interpretdl": 87, "paddlepaddl": 87, "cynthia": 87, "rudin": 87, "stake": 87, "natur": [87, 103, 105], "ntellig": 87, "206": 87, "christoph": 87, "molnar": 87, "gunnar": 87, "k\u00f6nig": 87, "julia": 87, "herbing": 87, "timo": 87, "freiesleben": 87, "susann": 87, "dandl": 87, "christian": 87, "scholbeck": 87, "giusepp": 87, "casalicchio": 87, "moritz": 87, "gross": 87, "wentrup": 87, "bernd": 87, "bischl": 87, "xxai": 87, "workshop": 87, "held": 87, "conjunct": [87, 103], "icml": 87, "juli": 87, "vienna": 87, "austria": 87, "revis": 87, "extend": [87, 90], "68": 87, "cham": 87, "springer": 87, "publish": 87, "harsha": 87, "nori": 87, "samuel": 87, "jenkin": 87, "paul": 87, "koch": 87, "rich": 87, "caruana": 87, "framework": [87, 102], "1909": 87, "09223": 87, "yin": 87, "lou": 87, "johann": 87, "gehrk": 87, "gile": 87, "hooker": 87, "2013": 87, "intellig": 87, "proceed": 87, "19th": 87, "sigkdd": 87, "knowledg": 87, "623": 87, "631": 87, "agu": 87, "sudjianto": 87, "aijun": 87, "2111": 87, "01743": 87, "yeounoh": 87, "chung": 87, "tim": 87, "kraska": 87, "neokli": 87, "polyzoti": 87, "ki": 87, "hyun": 87, "tae": 87, "steven": 87, "euijong": 87, "whang": 87, "finder": 87, "35th": 87, "icd": 87, "1550": 87, "1553": 87, "daniel": 87, "aplei": 87, "jingyu": 87, "zhu": 87, "2016": 87, "1612": 87, "08468": 87, "marco": 87, "tulio": 87, "ribeiro": 87, "sameer": 87, "singh": 87, "guestrin": 87, "why": [87, 96], "22nd": 87, "2017": 87, "advanc": 87, "neural": [87, 88, 91, 92, 133], "trevor": 87, "hasti": 87, "robert": 87, "tibshirani": 87, "wainwright": 87, "sparsiti": [87, 92, 112], "crc": 87, "press": 87, "serv\u00e9n": 87, "charli": 87, "brummitt": 87, "pygam": [87, 91, 106, 117, 120], "zenodo": 87, "5281": 87, "1208723": 87, "shuo": 87, "tan": 87, "chandan": 87, "keyan": 87, "nasseri": 87, "abhineet": 87, "agarw": 87, "2201": 87, "11931": 87, "benjamin": 87, "lengerich": 87, "sarah": 87, "chun": 87, "june": 87, "anova": [87, 97, 113, 114, 127, 128, 129, 130], "recov": 87, "artifici": 87, "2402": 87, "2412": 87, "pmlr": 87, "tianqi": 87, "tong": 87, "william": 87, "knauth": 87, "rahul": 87, "zebin": 87, "yang": 87, "unwrap": [87, 94], "04041": 87, "shiji": 87, "cui": 87, "runz": 87, "hot": [87, 93, 96], "2304": 87, "13761": 87, "architectur": [87, 118, 119], "constraint": [87, 92, 96, 97, 105, 115, 116, 118, 119, 127, 128, 129, 130], "transact": 87, "2610": 87, "2621": 87, "120": 87, "108192": 87, "nava": 87, "palencia": 87, "guillermo": 87, "program": [87, 108], "08025": 87, "mu": [89, 90, 91, 92, 93, 96, 97], "limits_": [89, 92, 96, 97], "h_": [89, 92, 96, 97], "f_": [89, 90, 91, 92, 97], "jk": [89, 92, 97], "shallow": [89, 95], "round": [89, 104, 113, 114], "fashion": [89, 125, 126], "cut": [89, 108], "pick": 89, "converg": [89, 94, 97, 117, 120], "piecewis": [89, 91, 92, 96, 97], "hyperparamet": [89, 90, 91, 92, 93, 94, 95, 96, 97], "sacrific": [89, 100], "rate": [89, 94, 99, 100, 108, 113, 114, 115, 116, 118, 119, 123, 124, 127, 128, 129, 130], "256": [89, 113, 114, 127, 128, 129, 130], "perspect": [69, 89], "togeth": [89, 91, 92, 93, 94, 115, 116, 118, 119], "pm": [89, 92], "somehow": 89, "night": 89, "spring": 89, "domin": [89, 97], "part": [89, 90, 97], "0818": 89, "06": [89, 92, 97], "complet": [89, 92, 99, 100], "similarli": [70, 89, 90, 94, 97, 102], "almost": 89, "recent": [90, 106], "cart": 90, "special": [90, 94, 96], "f_k": 90, "mathbf": 90, "manner": [90, 103, 108], "pseudo": 90, "express": [90, 91, 94, 97, 118, 119], "form": [90, 93, 94, 95, 97, 99, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "search": [90, 100, 125, 126], "whichev": 90, "imodel": [90, 115, 116], "re": [90, 96, 110, 115, 116], "integ": [90, 113, 114, 125, 126], "unlimit": [90, 125, 126], "criteria": [90, 103, 125, 126], "hardli": 90, "complic": [90, 94], "gain": [90, 99, 101, 103, 125], "along": [90, 99, 104, 105], "hierarch": 90, "dendrogram": 90, "subplot": [90, 94, 99], "middl": [90, 99], "thu": [90, 110], "deeper": [90, 102], "rightmost": 90, "convei": 90, "dark": 90, "necessari": [90, 100, 102], "decsion_tre": 90, "099": 90, "094": 90, "primari": 91, "equat": [91, 94, 125, 126], "unknown": 91, "smooth": [91, 92, 99, 115, 116, 117, 120, 125, 126], "varieti": 91, "degre": [91, 101], "polynomi": 91, "quadrat": 91, "cubic": 91, "knot": 91, "anchor": 91, "With": [91, 93, 96, 103], "intric": [69, 91], "poorer": [91, 103], "penalti": [91, 93, 94, 117, 120], "prevent": [91, 101], "encourag": 91, "simpler": [91, 94, 96], "generaliz": 91, "smoother": 91, "convers": [69, 91], "rougher": 91, "slope": 91, "flat": 91, "steep": 91, "sharp": 91, "incom": 91, "area": [91, 99, 100, 101, 103, 104, 105], "_j": [91, 96], "latitud": [91, 96], "longitud": [91, 96], "strongest": 91, "drive": 91, "3804": 91, "reformul": 92, "disentangl": [92, 94], "feedforward": [92, 94], "subnetwork": [92, 118, 119], "hidden": [92, 94, 118, 119, 123, 124], "layer": [92, 94, 118, 119, 123, 124], "parsimoni": [92, 97], "hered": [92, 118, 119], "least": [92, 94, 96, 115, 116, 122, 125, 126], "parent": 92, "clariti": [92, 118, 119], "purif": [92, 97, 117, 118, 119, 120, 127, 128], "constrain": [92, 96, 99], "decreas": [92, 96, 103, 115, 116, 118, 119, 125, 126, 127, 128, 129, 130], "impos": [92, 118, 119, 123, 124], "gaminet": 92, "prune": [92, 97, 118, 119, 125, 126], "trivial": [92, 94, 97], "retrain": 92, "simultan": 92, "fine": [92, 105, 118, 119], "tune": [92, 96, 108, 118, 119], "activ": [92, 94, 97, 118, 119, 123, 124], "saturdai": 92, "sundai": 92, "mondai": 92, "fridai": 92, "aggreg": [92, 93, 97, 105, 117, 118, 119, 120, 127, 128], "literatur": 93, "reader": 93, "consult": 93, "mccullagh1989": 93, "w_1": 93, "x_1": 93, "w_2": 93, "x_2": 93, "w_d": 93, "x_d": 93, "analyz": [93, 99, 100, 102, 105], "ident": [93, 94, 99, 102, 125, 126], "logit": 93, "l2": [93, 121, 122, 126, 127, 128, 129, 130], "l1_regularz": [93, 121, 122], "penal": [93, 94, 118, 119], "l2_regularz": [93, 121, 122], "shrink": [93, 94], "toward": [93, 94], "spars": [68, 93, 109, 110, 112, 125, 126], "shrunk": 93, "variant": [93, 96], "linear_model": 93, "linearregress": 93, "constrainst": 93, "ridg": [93, 122], "elasticnet": [93, 122], "elast": 93, "logisticregress": 93, "adapt": [93, 96], "issu": [70, 93, 100, 101, 104, 118, 119, 123, 124], "associ": [69, 93, 102, 125], "opposit": [93, 110], "temperatur": [93, 97], "humid": 93, "convert": [93, 104, 110, 112, 125, 126], "dummi": 93, "season_4": 93, "overparameter": 93, "fourth": 93, "nonlinear": [93, 94], "print": 93, "screen": [93, 118, 119], "export": 93, "w_j": 93, "stem": 93, "absorb": 93, "unstabl": [93, 94, 104], "turn": [93, 96, 118, 119], "mccullagh": 93, "john": 93, "nelder": 93, "1989": 93, "chapman": 93, "hall": 93, "edit": 93, "rectifi": 94, "remark": 94, "appeal": 94, "excel": 94, "intrins": 94, "neuron": 94, "chi": 94, "mbox": 94, "eta": [94, 96, 97, 127, 128, 129, 130], "sigmoid": [94, 118, 119], "despit": 94, "said": 94, "equiv": 94, "n_l": 94, "exhibit": [94, 99, 101, 103, 104], "simplifi": [94, 96], "tild": 94, "oper": [94, 95, 102], "tupl": [94, 108, 111, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "poor": [94, 101, 103], "1e": [94, 108, 113, 114, 118, 119, 123, 124], "descent": 94, "unpen": 94, "float": [94, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "critic": 94, "unnecessarili": 94, "long": [94, 104, 117, 120, 125, 126], "wherea": 94, "5153": 94, "105570": 94, "584421": 94, "735054": 94, "static": 94, "wide": 94, "roughli": 94, "vice": 94, "versa": 94, "impli": [69, 94, 103], "upon": [94, 99], "eleg": 94, "diagon": [94, 99], "decomposit": [94, 96], "uniformli": [94, 118, 119], "sin": 94, "epsilon": 94, "n_featur": [94, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "influenti": 95, "render": 95, "decisiontreeregressor": 95, "often": 95, "suffer": [70, 95], "rule": [95, 111, 115, 116], "criterion": [95, 125, 126], "branch": [95, 115, 116, 125, 126], "restrict": 96, "stump": 96, "deriv": [70, 96, 118, 119], "stage": [96, 113, 114, 118, 119, 123, 124], "optbin": [96, 106, 127, 128], "woe": 96, "refit": [96, 127, 128], "firstli": 96, "arrang": 96, "taken": [70, 96], "inherit": [96, 97], "tree_method": [96, 97, 105, 127, 128, 129, 130], "reg_lambda": [96, 97, 127, 128, 129, 130], "reg_alpha": [96, 97, 127, 128, 129, 130], "feature_nam": [96, 105, 108, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "correctli": [96, 99, 113, 115, 118, 123, 125, 127, 129], "max_n_bin": 96, "strike": 96, "difficulti": [96, 103], "fit_method": 96, "iv": 96, "accompani": [96, 103, 105], "trend": [96, 99, 103], "plateau": 96, "geograph": 96, "amplifi": 96, "lontitud": 96, "restructur": 97, "proce": [97, 104], "superior": [69, 97], "enforc": [97, 117, 120], "feel": 97, "celsiu": 97, "50": [97, 104, 111, 113, 114, 123, 124], "comfort": 97, "outdoor": 97, "cooler": 97, "hotter": 97, "peopl": 97, "willing": 97, "ride": 97, "bicycl": 97, "0606": 97, "summat": 97, "plu": [97, 99], "sklearn_metr": [], "y_": [99, 102, 117, 118, 119, 120, 127, 128], "character": 101, "ideal": [99, 102], "band": 99, "residual_plot": 99, "And": [118, 119], "appar": [], "notabl": [69, 99], "heterogen": [], "reason": [], "evenli": 99, "noteworthi": [], "_predict": 99, "variat": [103, 104], "imbalanc": 99, "alon": [], "whose": 102, "incorrect": [99, 104, 105], "guess": [99, 112], "harmon": 99, "2tp": 99, "fp": 99, "fn": 99, "resembl": [], "scatterplot": 99, "lowess": 99, "thorough": [], "mislabel": 99, "tpr": 99, "fpr": 99, "tradeoff": 99, "irrelev": 99, "imparti": 100, "were": 104, "ethnic": 100, "sexual": 100, "orient": 100, "disabl": [100, 108], "advers": [69, 100, 104, 108], "tp_": 100, "fn_": 100, "tp": 99, "smd": [100, 108], "outcome_x": [], "fp_": 100, "bucket": [100, 108], "span": [100, 101], "dictionari": [100, 115, 116, 117, 120, 125, 126], "accuracy_scor": [], "f1_score": [], "dash": 100, "ax": 100, "fail": 68, "unseen": 101, "cost": [101, 118, 119, 125, 126], "previous": 104, "warn": [101, 105, 125, 126], "messag": [101, 105, 106], "biksshar": 101, "017079": 101, "015575": 101, "001504": 101, "285": 101, "005226": 101, "004305": 101, "000921": 101, "1743": 101, "006050": 101, "005585": 101, "000465": 101, "7am": 101, "9am": 101, "0171": 101, "0156": 101, "seen": [], "pure": [125, 126], "2am": 101, "55": [101, 103], "326087": 101, "369565": 101, "98480": 101, "036693": 101, "029954": 101, "006739": 101, "282609": 101, "013106": 101, "011935": 101, "001172": 101, "000000": [101, 105], "065217": 101, "55305": 101, "831": 101, "001208": 101, "000855": 101, "000353": 101, "trustworthi": [], "field": [], "healthcar": [], "financ": [], "safeti": [], "crqr": 102, "exchang": [], "epsilon_": 102, "s_": 102, "confid": 102, "gbdt": 102, "88705": 102, "232974": 102, "88": [102, 105], "233": 102, "2563": 102, "wise": [102, 112], "conclud": [], "matur": 102, "isoton": 102, "maintain": 99, "unexpect": [103, 104], "situat": [], "likelihood": 103, "bad": 108, "mostli": [], "akin": [], "steadili": [], "declin": 103, "unsupervis": [103, 105, 111, 112], "necessarili": 112, "lowest": [70, 103], "thought": 103, "recalcul": 103, "moder": 103, "encount": 104, "noisi": 104, "drift": 104, "aris": 105, "alter": 104, "underli": [104, 125, 126], "showcas": 99, "leverag": [100, 101, 105], "lambda": [104, 123, 124], "var": 104, "sai": 105, "86": [], "invers": 125, "ten": 104, "encapsul": [], "look": [108, 125, 126], "wors": [104, 114, 116, 119, 124, 126, 128, 130], "poorli": 104, "underperform": 105, "inadequ": 105, "inappropri": [], "insuffici": [101, 105], "filter": 105, "merg": 105, "min_samples_leaf": [105, 111, 113, 114, 115, 116, 125, 126], "n_estimaor": 105, "hist": [105, 127, 128, 129, 130], "granular": 100, "723": 105, "boolean": [105, 115, 116], "annot": 105, "695652": 105, "689587": 105, "006065": 105, "test_metr": 105, "train_metr": 105, "No": [105, 106, 123, 124], "250000": 105, "691099": 105, "678750": 105, "012349": 105, "111111": 105, "222222": 105, "727612": 105, "717573": 105, "010039": 105, "375000": 105, "625000": 105, "720497": 105, "717134": 105, "003362": 105, "333333": 105, "555556": 105, "612536": 105, "614685": 105, "002150": 105, "750000": 105, "621951": 105, "003049": 105, "o": 106, "py37": 106, "py38": 106, "py39": 106, "py310": 106, "win": 106, "linux": 106, "maco": 106, "environ": 106, "pip": 106, "ipywidget": 106, "joblib": 106, "ipython": 106, "seaborn": 106, "xlrd": 106, "torch": [106, 118, 119], "natsort": 106, "psutil": 106, "dill": 106, "ortool": 106, "momentchi2": 106, "match": [99, 106], "possbl": 106, "upgrad": 106, "reinstal": 106, "try": 106, "conda": 106, "forg": 106, "runtimeerror": 106, "traceback": 106, "compil": 106, "0x10": 106, "0xf": 106, "restart": 106, "runtim": 106, "guidelin": 107, "str": [108, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "bool": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "css": 108, "ingest": 108, "union": 108, "pass": [108, 112, 117, 120, 125, 126], "trime": 108, "preview": 108, "unicod": 108, "wheter": 108, "arrai": [108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "n_samples_train": 108, "n_samples_test": 108, "dict": [108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "99": 108, "forward": 108, "backward": 108, "use": 108, "earli": [108, 113, 114, 115, 116, 118, 119, 123, 124], "fbedk": 108, "get_data": 108, "ndarrai": [108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "n_sampl": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 129, 130], "workfolw": 108, "Not": [108, 110, 112], "get_feature_nam": 108, "get_feature_typ": 108, "get_model": 108, "modelpipelin": 108, "get_model_config": 108, "get_raw_data": 108, "datatupl": 108, "train_sample_weight": 108, "test_sample_weight": 108, "target_nam": 108, "get_target_nam": 108, "normalize_strategi": 108, "encode_strategi": 108, "excluded_featur": 108, "minmax": 108, "unit_norm": 108, "one_hot": 108, "xndarrai": 108, "param": [108, 110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "regressor": [108, 114, 116, 119, 120, 122, 124, 126, 128, 130], "insid": 108, "whther": 108, "testdataresult": [108, 117, 118, 119, 120, 125, 126, 127, 128], "diagnos": 108, "repeatit": 108, "substract": 108, "metric_threshold": 108, "favorable_class": 108, "thresholding_bin": 108, "by_weight": 108, "binar": [100, 108], "segement": 108, "rsmd": 108, "categorical_feature_nam": 108, "savedmodel": 108, "save": [108, 118, 119, 133], "self": [108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "get_all_supported_model": 108, "model_tun": 108, "iqr_scal": [109, 110, 111, 112], "clustering_method": 109, "clustering_threshold": 109, "use_weight": 109, "gmm": 109, "base_estimator_": 109, "is_fitted_": [109, 111, 118, 119, 123, 124, 127, 128, 129, 130], "cluster_centers_": 109, "cluster_sizes_": 109, "small_cluster_labels_": 109, "large_cluster_labels_": 109, "decision_funct": [109, 110, 111, 112, 113, 114, 115, 117, 118, 123, 127, 129], "detector": [109, 112], "anomaly_scor": 109, "max_sampl": 110, "auto": [110, 112, 118, 119, 125, 126, 127, 128, 129, 130], "max_featur": [110, 125, 126], "bootstrap": 110, "n_job": [110, 113, 114, 118, 119], "verbos": [110, 118, 119, 123, 124], "warm_start": [110, 118, 119], "estimators_samples_": 110, "drawn": 110, "n_features_": [110, 125, 126], "deprec": [110, 125, 126], "n_left": 110, "dtype": [110, 125, 126], "float32": [110, 125, 126], "csr_matrix": [110, 125, 126], "abnorm": 110, "inlier": 110, "dynam": 110, "bag": [110, 113, 114], "footprint": 110, "store": 110, "csc_matrix": [110, 125, 126], "convent": [110, 112], "fit_predict": 110, "get_param": [110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "subobject": [110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "map": [110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "n_features_in_": [110, 111, 115, 116, 118, 119, 123, 124, 125, 126, 127, 128, 129, 130], "is_inli": 110, "score_sampl": 110, "set_param": [110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "nest": [110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "__": [110, 111, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "n_compon": [111, 112], "d_reduction_method": [111, 112], "max_leav": [111, 113, 114], "min_dist": 111, "distance_measur": 111, "reconsterr": 111, "distance_measure_param": 111, "splite": [111, 115, 116], "deafult": 111, "64": 111, "callabl": 111, "n_samples1": 111, "n_samples2": 111, "tree_": [111, 125, 126], "node_count_": 111, "totoal": [111, 127, 128, 129, 130], "leaf_idx_list_": 111, "calculate_spca": 111, "dist": 111, "decision_path": [111, 125, 126], "path_al": 111, "node_count": [111, 125, 126], "get_rul": 111, "node_id": 111, "defulat": 111, "whihc": 111, "inequ": 111, "plot_tre": 111, "draw_depth": 111, "inf": 111, "start_node_id": 111, "predict_leaf_id": 111, "n_selected_compon": 112, "cumulative_vari": 112, "score_typ": 112, "copi": 112, "whiten": 112, "svd_solver": 112, "tol": 112, "iterated_pow": 112, "basd": 112, "kept": [104, 112], "mle": 112, "minka": 112, "arpack": 112, "overwritten": 112, "yield": [104, 112], "fit_transform": 112, "components_": 112, "singular": 112, "uncorrel": 112, "signal": 112, "downstream": 112, "wire": 112, "solver": [112, 117, 120], "polici": 112, "500x500": 112, "smallest": [70, 112, 113, 114], "exact": [112, 127, 128, 129, 130], "svd": 112, "afterward": 112, "lapack": 112, "linalg": 112, "postprocess": 112, "strictli": 112, "halko": 112, "et": 112, "toler": [112, 113, 114, 118, 119], "sparser": 112, "auto_exampl": 112, "plot_scaling_import": 112, "max_interaction_bin": [113, 114], "outer_bag": [113, 114], "inner_bag": [113, 114], "validation_s": [113, 114], "early_stopping_round": [113, 114], "early_stopping_toler": [113, 114], "0001": [113, 114, 118, 119], "max_round": [113, 114], "quantile_human": [113, 114], "inner": [113, 114], "dictat": [113, 114], "delta": [104, 113, 114], "job": [113, 114], "cpu": [113, 114, 118, 119, 123, 124], "arg": [113, 114, 117, 120, 121, 127, 128], "model_unwrapp": [113, 114, 123, 124, 129, 130], "placehold": [113, 114], "unp": [113, 114, 123, 124, 129, 130], "ebmexplain": [113, 114], "multi": [113, 115, 118, 123, 124, 125, 127, 129], "harsh": [113, 115, 118, 123, 125, 127, 129], "n_output": [113, 114, 115, 116, 118, 119, 123, 124, 125, 126, 127, 128, 129, 130], "wrt": [113, 114, 115, 116, 118, 119, 123, 124, 125, 126, 127, 128, 129, 130], "y_true": [114, 116, 119, 124, 126, 128, 130], "y_pred": [114, 116, 119, 124, 126, 128, 130], "arbitrarili": [114, 116, 119, 124, 126, 128, 130], "disregard": [114, 116, 119, 124, 126, 128, 130], "precomput": [114, 116, 119, 124, 126, 128, 130], "n_samples_fit": [114, 116, 119, 124, 126, 128, 130], "multioutput": [114, 116, 119, 124, 125, 126, 128, 130], "uniform_averag": [114, 116, 119, 124, 126, 128, 130], "r2_score": [114, 116, 119, 124, 126, 128, 130], "multioutputregressor": [114, 116, 119, 124, 126, 128, 130], "splitter": [115, 116, 125, 126], "min_impurity_decreas": [115, 116, 125, 126], "concis": [115, 116], "csinva": [115, 116], "induc": [115, 116, 125, 126], "impur": [115, 116, 125, 126], "feature_names_": [115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "feature_types_": [115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "intercept_": [115, 116, 127, 128], "trees_": [115, 116], "n_tree_": [115, 116], "n_iter_": [115, 116], "iteract": [115, 116], "early_stop_": [115, 116], "tree_importance_": [115, 116], "explain_tre": [115, 116], "get_tree_diag": [115, 116, 125, 126], "get_tree_heatmap": [115, 116], "global_explain": [115, 116, 117, 118, 119, 120], "global_interpret": [115, 116, 117, 118, 119, 120, 125, 126, 127, 128], "interpret_local_tre": [115, 116, 125, 126], "local_explain": [115, 116], "plot_feature_importance_heatmap": [115, 116], "plot_local_tre": [115, 116, 125, 126], "plot_tree_diag": [115, 116, 125, 126], "get_binary_matrix": [115, 116], "get_binary_represent": [115, 116], "get_depth": [115, 116, 125, 126], "get_depths_interact": [115, 116], "pred": [115, 116, 118, 119, 123, 124, 127, 128, 129, 130], "pred_proba": [115, 118, 123, 127, 129], "proba": [115, 118, 125, 127, 129], "update_tree_import": [115, 116], "stronger": [117, 120], "get_interaction_effect": [117, 118, 119, 120, 127, 128], "interpret_effect": [117, 118, 119, 120, 127, 128], "interpret_ei": [117, 118, 119, 120, 127, 128], "interpret_local_ei": [117, 118, 119, 120, 127, 128], "plot_ei": [117, 118, 119, 120, 127, 128], "plot_interaction_effect": [117, 118, 119, 120, 127, 128], "plot_local_ei": [117, 118, 119, 120, 127, 128], "plot_main_effect": [117, 118, 119, 120, 127, 128], "get_main_effect": [117, 118, 119, 120, 127, 128], "truncate_dict": [117, 120, 125, 126], "interpret_fi": [117, 118, 119, 120, 127, 128], "interpret_local_fi": [117, 118, 119, 120, 127, 128], "local_feature_explain": [117, 118, 119, 120, 127, 128], "plot_fi": [117, 118, 119, 120, 127, 128], "interpret_result": [117, 118, 119, 120, 125, 126, 127, 128], "max_show": [117, 118, 119, 120, 127, 128], "return_fig": [117, 118, 119, 120, 125, 126, 127, 128], "plot_local_fi": [117, 118, 119, 120, 127, 128], "interact_num": [118, 119], "subnet_size_main_effect": [118, 119], "subnet_size_interact": [118, 119], "activation_func": [118, 119], "max_epoch": [118, 119, 123, 124], "early_stop_thr": [118, 119], "batch_siz": [118, 119, 123, 124], "batch_size_infer": [118, 119, 123, 124], "max_iter_per_epoch": [118, 119], "val_ratio": [118, 119, 123, 124], "gam_sample_s": [118, 119], "mlp_sample_s": [118, 119], "reg_clar": [118, 119], "loss_threshold": [118, 119], "reg_mono": [118, 119], "mono_sample_s": [118, 119], "include_interaction_list": [118, 119], "boundary_clip": [118, 119], "devic": [118, 119, 123, 124], "tanh": [118, 119], "epoch": [118, 119, 123, 124], "batch": [118, 119, 123, 124], "init": [118, 119], "clip": [118, 119], "reshuffl": [118, 119], "ratiom": [118, 119], "rough": [118, 119], "tensor": [118, 119], "teacher": [118, 119], "sub": [118, 119], "achiv": [118, 119], "spacec": [118, 119], "feature_name1": [118, 119], "feature_name2": [118, 119], "core": [118, 119], "hardwar": [118, 119], "net_": [118, 119, 123, 124], "data_dict_density_": [118, 119], "err_train_main_effect_training_": [118, 119], "err_val_main_effect_training_": [118, 119], "err_train_interaction_training_": [118, 119], "err_val_interaction_training_": [118, 119], "err_train_tuning_": [118, 119], "err_val_tuning_": [118, 119], "interaction_list_": [118, 119], "active_main_effect_index_": [118, 119], "active_interaction_index_": [118, 119], "main_effect_val_loss_": [118, 119], "interaction_val_loss_": [118, 119], "time_cost_": [118, 119], "clarity_": [118, 119], "monotonicity_": [118, 119], "n_interactions_": [118, 119], "dummy_values_": [118, 119], "cfeature_num_": [118, 119], "nfeature_num_": [118, 119], "cfeature_names_": [118, 119], "nfeature_names_": [118, 119], "cfeature_index_list_": [118, 119], "nfeature_index_list_": [118, 119], "num_classes_list_": [118, 119], "mu_list_": [118, 119], "std_list_": [118, 119], "min_value_": [118, 119, 127, 128], "max_value_": [118, 119, 127, 128], "mono_increasing_list_index_": [118, 119], "mono_decreasing_list_index_": [118, 119], "include_interaction_list_index_": [118, 119], "training_generator_": [118, 119], "fasttensordataload": [118, 119], "validation_generator_": [118, 119], "warm_init_main_effect_data_": [118, 119], "warm": [118, 119], "warm_init_interaction_data_": [118, 119], "main_effect_norm_": [118, 119], "interaction_norm_": [118, 119], "feature_importance_": [118, 119, 127, 128, 129, 130], "data_dict_global_": [118, 119], "certify_mono": [118, 119], "certifi": [118, 119], "satisfi": [118, 119], "mono_statu": [118, 119], "main_effect": [118, 119], "softmax": [118, 123, 124, 129], "fine_tune_select": [118, 119], "main_effect_list": [118, 119], "interaction_list": [118, 119], "lr": [118, 119], "unselect": [118, 119], "norm": [118, 119], "get_aggregate_output": [118, 119], "get_clarity_loss": [118, 119], "clarity_loss": [118, 119], "get_effect_import": [118, 119], "get_feature_import": [118, 119], "get_global_effects_": [118, 119], "main_grid_s": [118, 119], "interact_grid_s": [118, 119], "grid": [100, 118, 119], "get_interaction_raw_output": [118, 119], "n_interact": [118, 119], "get_main_effect_raw_output": [118, 119], "get_mono_loss": [118, 119], "mono_loss": [118, 119], "folder": [118, 119], "disk": [118, 119], "local_effect_explain": [118, 119], "partial_deriv": [118, 119], "plote": [118, 119], "update_effect_import": [118, 119], "update_feature_import": [118, 119, 127, 128], "kwarg": 121, "regularz": [121, 122], "fit_intercept": 122, "ordinari": 122, "dropout_prob": [123, 124], "n_epoch_no_chang": [123, 124], "iht": [123, 124], "phase_epoch": [123, 124], "perceptron": [123, 124], "dropout": [123, 124], "doesn": [123, 124], "early_stop": [123, 124], "cuda": [123, 124], "statit": [123, 124], "coefs_": [123, 124], "len": [123, 124], "ith": [123, 124], "intercepts_": [123, 124], "no_improved_count_": [123, 124], "train_epoch_loss_": [123, 124], "valid_epoch_loss_": [123, 124], "get_raw_output": [123, 124], "unwrapperclassifi": 123, "funciton": [123, 124], "unwrapperregressor": 124, "min_samples_split": [125, 126], "min_weight_fraction_leaf": [125, 126], "max_leaf_nod": [125, 126], "ccp_alpha": [125, 126], "docstr": [125, 126], "gini": [125, 126], "entropi": 125, "log_loss": 125, "shannon": 125, "fraction": [125, 126, 127, 128], "ceil": [125, 126], "log2": [125, 126], "randomst": [125, 126], "determinist": [125, 126], "behaviour": [125, 126], "n_t": [125, 126], "n_t_r": [125, 126], "right_impur": [125, 126], "n_t_l": [125, 126], "left_impur": [125, 126], "class_weight": 125, "class_label": 125, "multilabel": 125, "n_class": 125, "bincount": 125, "subtre": [125, 126], "classes_": 125, "feature_importances_": [125, 126], "max_features_": [125, 126], "n_classes_": 125, "n_outputs_": [125, 126], "check_input": [125, 126], "bypass": [125, 126], "unless": [68, 70, 125, 126], "what": [125, 126], "x_leav": [125, 126], "datapoint": [125, 126], "possibli": [125, 126], "cost_complexity_pruning_path": [125, 126], "minimal_cost_complexity_prun": [125, 126], "ccp_path": [125, 126], "bunch": [125, 126], "n_node": [125, 126], "csr": [125, 126], "goe": [125, 126], "brought": [125, 126], "mislead": [125, 126], "cardin": [125, 126], "get_n_leav": [125, 126], "n_leav": [125, 126], "useless": [125, 126], "predict_log_proba": 125, "squared_error": 126, "friedman_ms": 126, "absolute_error": 126, "poisson": 126, "devianc": 126, "refit_method": [127, 128], "max_bin_s": [127, 128], "true_to_data": [127, 128], "xgboostclassifi": [127, 129], "approx": [127, 128, 129, 130], "gpu_hist": [127, 128, 129, 130], "split_info_": [127, 128, 129, 130], "n_splits_raw_": [127, 128, 129, 130], "n_splits_": [127, 128, 129, 130], "xgb_params_": [127, 128, 129, 130], "effects_": [127, 128], "get_binning_result": [127, 128], "get_global_effect": [127, 128], "global_visualize_dict": [127, 128], "interpret_iv": [127, 128], "include_intercept": [127, 128], "plot_iv": [127, 128], "plot_wo": [127, 128], "xgboostregressor": [128, 130], "xgbunwrapperclassifi": 129, "xgbunwrapperregressor": 130, "quick": 131, "troubleshoot": 131, "plan": 133, "methodologi": 71, "regardless": 99, "emploi": [70, 99, 100, 101, 102, 103, 105], "wider": 99, "logic": 99, "lastli": 99, "depict": [69, 99, 103], "earlier": 99, "tn": 99, "maxim": 99, "closer": 99, "corner": 99, "prone": 105, "unsuit": 105, "suffici": 105, "accordingli": 105, "grain": 105, "simpli": 105, "preval": 101, "strong": 101, "allevi": 101, "empow": 101, "pinpoint": 101, "promin": 101, "tendenc": 101, "therebi": 101, "emphasi": 101, "exce": [101, 102], "retain": [101, 105], "interchang": 102, "dedic": [69, 102], "histgradientboostingregressor": 102, "delv": 102, "clarifi": 102, "establish": 102, "notion": 102, "yet": 102, "analog": 102, "perofrm": [], "throughout": 104, "forthcom": 104, "invalid": 104, "skew": 104, "tail": 104, "chose": [], "solv": 104, "labmda": [], "back": 104, "xquantil": [], "subscript": 100, "classificaiton": [], "sustain": 103, "face": 103, "verifi": 103, "facilit": 103, "At": 103, "divers": 103, "refin": 103, "sophist": 103, "harder": 103, "inde": 103, "poorest": 103, "increment": 103, "tailor": 103, "signifi": [69, 103], "hover": 103, "interestingli": 103, "gradual": 103, "plausibl": 103, "outperform": 103, "fluctuat": 103, "mitgat": [], "enumer": 100, "109": [55, 58], "161": [56, 58], "271": 58, "undergo": [68, 70], "crowd": 70, "extra": 70}, "objects": {"piml": [[108, 0, 1, "", "Experiment"]], "piml.Experiment": [[108, 1, 1, "", "data_loader"], [108, 1, 1, "", "data_prepare"], [108, 1, 1, "", "data_quality_check"], [108, 1, 1, "", "data_summary"], [108, 1, 1, "", "eda"], [108, 1, 1, "", "feature_select"], [108, 1, 1, "", "get_data"], [108, 1, 1, "", "get_feature_names"], [108, 1, 1, "", "get_feature_types"], [108, 1, 1, "", "get_model"], [108, 1, 1, "", "get_model_config"], [108, 1, 1, "", "get_raw_data"], [108, 1, 1, "", "get_target_name"], [108, 1, 1, "", "make_pipeline"], [108, 1, 1, "", "model_compare"], [108, 1, 1, "", "model_diagnose"], [108, 1, 1, "", "model_explain"], [108, 1, 1, "", "model_fairness"], [108, 1, 1, "", "model_fairness_compare"], [108, 1, 1, "", "model_fairness_solas"], [108, 1, 1, "", "model_interpret"], [108, 1, 1, "", "model_save"], [108, 1, 1, "", "model_train"], [108, 1, 1, "", "model_tune"], [108, 1, 1, "", "register"], [108, 1, 1, "", "twosample_test"]], "piml.data.outlier_detection": [[109, 0, 1, "", "CBLOF"], [110, 0, 1, "", "IsolationForest"], [111, 0, 1, "", "KMeansTree"], [112, 0, 1, "", "PCA"]], "piml.data.outlier_detection.CBLOF": [[109, 1, 1, "", "decision_function"]], "piml.data.outlier_detection.IsolationForest": [[110, 1, 1, "", "decision_function"], [110, 2, 1, "", "estimators_samples_"], [110, 1, 1, "", "fit"], [110, 1, 1, "", "fit_predict"], [110, 1, 1, "", "get_params"], [110, 2, 1, "", "n_features_"], [110, 1, 1, "", "predict"], [110, 1, 1, "", "score_samples"], [110, 1, 1, "", "set_params"]], "piml.data.outlier_detection.KMeansTree": [[111, 1, 1, "", "decision_path"], [111, 1, 1, "", "fit"], [111, 1, 1, "", "get_params"], [111, 1, 1, "", "get_rule"], [111, 1, 1, "", "plot_tree"], [111, 1, 1, "", "predict_leaf_id"], [111, 1, 1, "", "set_params"]], "piml.data.outlier_detection.PCA": [[112, 1, 1, "", "decision_function"], [112, 1, 1, "", "fit"]], "piml.models": [[113, 0, 1, "", "ExplainableBoostingClassifier"], [114, 0, 1, "", "ExplainableBoostingRegressor"], [115, 0, 1, "", "FIGSClassifier"], [116, 0, 1, "", "FIGSRegressor"], [117, 0, 1, "", "GAMClassifier"], [118, 0, 1, "", "GAMINetClassifier"], [119, 0, 1, "", "GAMINetRegressor"], [120, 0, 1, "", "GAMRegressor"], [121, 0, 1, "", "GLMClassifier"], [122, 0, 1, "", "GLMRegressor"], [123, 0, 1, "", "ReluDNNClassifier"], [124, 0, 1, "", "ReluDNNRegressor"], [125, 0, 1, "", "TreeClassifier"], [126, 0, 1, "", "TreeRegressor"], [127, 0, 1, "", "XGB1Classifier"], [128, 0, 1, "", "XGB1Regressor"], [129, 0, 1, "", "XGB2Classifier"], [130, 0, 1, "", "XGB2Regressor"]], "piml.models.ExplainableBoostingClassifier": [[113, 1, 1, "", "decision_function"], [113, 1, 1, "", "fit"], [113, 1, 1, "", "get_params"], [113, 1, 1, "", "model_unwrapper"], [113, 1, 1, "", "predict"], [113, 1, 1, "", "predict_proba"], [113, 1, 1, "", "score"], [113, 1, 1, "", "set_params"]], "piml.models.ExplainableBoostingRegressor": [[114, 1, 1, "", "decision_function"], [114, 1, 1, "", "fit"], [114, 1, 1, "", "get_params"], [114, 1, 1, "", "model_unwrapper"], [114, 1, 1, "", "predict"], [114, 1, 1, "", "score"], [114, 1, 1, "", "set_params"]], "piml.models.FIGSClassifier": [[115, 1, 1, "", "decision_function"], [115, 1, 1, "", "fit"], [115, 1, 1, "", "get_binary_matrix"], [115, 1, 1, "", "get_binary_representation"], [115, 1, 1, "", "get_depths"], [115, 1, 1, "", "get_depths_interactions"], [115, 1, 1, "", "get_params"], [115, 1, 1, "", "predict"], [115, 1, 1, "", "predict_proba"], [115, 1, 1, "", "score"], [115, 1, 1, "", "set_params"], [115, 1, 1, "", "update_tree_importance"]], "piml.models.FIGSRegressor": [[116, 1, 1, "", "fit"], [116, 1, 1, "", "get_binary_matrix"], [116, 1, 1, "", "get_binary_representation"], [116, 1, 1, "", "get_depths"], [116, 1, 1, "", "get_depths_interactions"], [116, 1, 1, "", "get_params"], [116, 1, 1, "", "predict"], [116, 1, 1, "", "score"], [116, 1, 1, "", "set_params"], [116, 1, 1, "", "update_tree_importance"]], "piml.models.GAMClassifier": [[117, 1, 1, "", "fit"], [117, 1, 1, "", "get_main_effect"], [117, 1, 1, "", "get_params"], [117, 1, 1, "", "global_interpret"], [117, 1, 1, "", "interpret_fi"], [117, 1, 1, "", "interpret_local_fi"], [117, 1, 1, "", "local_feature_explain"], [117, 1, 1, "", "plot_fi"], [117, 1, 1, "", "plot_local_fi"], [117, 1, 1, "", "set_params"]], "piml.models.GAMINetClassifier": [[118, 1, 1, "", "certify_mono"], [118, 1, 1, "", "decision_function"], [118, 1, 1, "", "fine_tune_selected"], [118, 1, 1, "", "fit"], [118, 1, 1, "", "get_aggregate_output"], [118, 1, 1, "", "get_clarity_loss"], [118, 1, 1, "", "get_effect_importance"], [118, 1, 1, "", "get_feature_importance"], [118, 1, 1, "", "get_global_effects_"], [118, 1, 1, "", "get_interaction_raw_output"], [118, 1, 1, "", "get_main_effect"], [118, 1, 1, "", "get_main_effect_raw_output"], [118, 1, 1, "", "get_mono_loss"], [118, 1, 1, "", "get_params"], [118, 1, 1, "", "interpret_fi"], [118, 1, 1, "", "interpret_local_fi"], [118, 1, 1, "", "load"], [118, 1, 1, "", "local_effect_explain"], [118, 1, 1, "", "local_feature_explain"], [118, 1, 1, "", "partial_derivatives"], [118, 1, 1, "", "plot_fi"], [118, 1, 1, "", "plot_local_fi"], [118, 1, 1, "", "predict"], [118, 1, 1, "", "predict_proba"], [118, 1, 1, "", "save"], [118, 1, 1, "", "score"], [118, 1, 1, "", "set_params"], [118, 1, 1, "", "update_effect_importance"], [118, 1, 1, "", "update_feature_importance"]], "piml.models.GAMINetRegressor": [[119, 1, 1, "", "certify_mono"], [119, 1, 1, "", "fine_tune_selected"], [119, 1, 1, "", "fit"], [119, 1, 1, "", "get_aggregate_output"], [119, 1, 1, "", "get_clarity_loss"], [119, 1, 1, "", "get_effect_importance"], [119, 1, 1, "", "get_feature_importance"], [119, 1, 1, "", "get_global_effects_"], [119, 1, 1, "", "get_interaction_raw_output"], [119, 1, 1, "", "get_main_effect"], [119, 1, 1, "", "get_main_effect_raw_output"], [119, 1, 1, "", "get_mono_loss"], [119, 1, 1, "", "get_params"], [119, 1, 1, "", "interpret_fi"], [119, 1, 1, "", "interpret_local_fi"], [119, 1, 1, "", "load"], [119, 1, 1, "", "local_effect_explain"], [119, 1, 1, "", "local_feature_explain"], [119, 1, 1, "", "partial_derivatives"], [119, 1, 1, "", "plot_fi"], [119, 1, 1, "", "plot_local_fi"], [119, 1, 1, "", "predict"], [119, 1, 1, "", "save"], [119, 1, 1, "", "score"], [119, 1, 1, "", "set_params"], [119, 1, 1, "", "update_effect_importance"], [119, 1, 1, "", "update_feature_importance"]], "piml.models.GAMRegressor": [[120, 1, 1, "", "fit"], [120, 1, 1, "", "get_main_effect"], [120, 1, 1, "", "get_params"], [120, 1, 1, "", "global_interpret"], [120, 1, 1, "", "interpret_fi"], [120, 1, 1, "", "interpret_local_fi"], [120, 1, 1, "", "local_feature_explain"], [120, 1, 1, "", "plot_fi"], [120, 1, 1, "", "plot_local_fi"], [120, 1, 1, "", "set_params"]], "piml.models.GLMClassifier": [[121, 1, 1, "", "get_params"], [121, 1, 1, "", "set_params"]], "piml.models.GLMRegressor": [[122, 1, 1, "", "get_params"], [122, 1, 1, "", "set_params"]], "piml.models.ReluDNNClassifier": [[123, 1, 1, "", "decision_function"], [123, 1, 1, "", "fit"], [123, 1, 1, "", "get_params"], [123, 1, 1, "", "get_raw_output"], [123, 1, 1, "", "model_unwrapper"], [123, 1, 1, "", "predict"], [123, 1, 1, "", "predict_proba"], [123, 1, 1, "", "score"], [123, 1, 1, "", "set_params"]], "piml.models.ReluDNNRegressor": [[124, 1, 1, "", "fit"], [124, 1, 1, "", "get_params"], [124, 1, 1, "", "get_raw_output"], [124, 1, 1, "", "model_unwrapper"], [124, 1, 1, "", "predict"], [124, 1, 1, "", "score"], [124, 1, 1, "", "set_params"]], "piml.models.TreeClassifier": [[125, 1, 1, "", "apply"], [125, 1, 1, "", "cost_complexity_pruning_path"], [125, 1, 1, "", "decision_path"], [125, 2, 1, "", "feature_importances_"], [125, 1, 1, "", "fit"], [125, 1, 1, "", "get_depth"], [125, 1, 1, "", "get_n_leaves"], [125, 1, 1, "", "get_params"], [125, 1, 1, "", "get_tree_diag"], [125, 1, 1, "", "global_interpret"], [125, 1, 1, "", "interpret_local_tree"], [125, 2, 1, "", "n_features_"], [125, 1, 1, "", "plot_local_tree"], [125, 1, 1, "", "plot_tree_diag"], [125, 1, 1, "", "predict"], [125, 1, 1, "", "predict_log_proba"], [125, 1, 1, "", "predict_proba"], [125, 1, 1, "", "score"], [125, 1, 1, "", "set_params"]], "piml.models.TreeRegressor": [[126, 1, 1, "", "apply"], [126, 1, 1, "", "cost_complexity_pruning_path"], [126, 1, 1, "", "decision_path"], [126, 2, 1, "", "feature_importances_"], [126, 1, 1, "", "fit"], [126, 1, 1, "", "get_depth"], [126, 1, 1, "", "get_n_leaves"], [126, 1, 1, "", "get_params"], [126, 1, 1, "", "get_tree_diag"], [126, 1, 1, "", "global_interpret"], [126, 1, 1, "", "interpret_local_tree"], [126, 2, 1, "", "n_features_"], [126, 1, 1, "", "plot_local_tree"], [126, 1, 1, "", "plot_tree_diag"], [126, 1, 1, "", "predict"], [126, 1, 1, "", "score"], [126, 1, 1, "", "set_params"]], "piml.models.XGB1Classifier": [[127, 1, 1, "", "decision_function"], [127, 1, 1, "", "fit"], [127, 1, 1, "", "get_main_effect"], [127, 1, 1, "", "get_params"], [127, 1, 1, "", "interpret_fi"], [127, 1, 1, "", "interpret_iv"], [127, 1, 1, "", "interpret_local_fi"], [127, 1, 1, "", "local_feature_explain"], [127, 1, 1, "", "plot_fi"], [127, 1, 1, "", "plot_iv"], [127, 1, 1, "", "plot_local_fi"], [127, 1, 1, "", "plot_woe"], [127, 1, 1, "", "predict"], [127, 1, 1, "", "predict_proba"], [127, 1, 1, "", "score"], [127, 1, 1, "", "set_params"], [127, 1, 1, "", "update_feature_importance"]], "piml.models.XGB1Regressor": [[128, 1, 1, "", "fit"], [128, 1, 1, "", "get_main_effect"], [128, 1, 1, "", "get_params"], [128, 1, 1, "", "interpret_fi"], [128, 1, 1, "", "interpret_iv"], [128, 1, 1, "", "interpret_local_fi"], [128, 1, 1, "", "local_feature_explain"], [128, 1, 1, "", "plot_fi"], [128, 1, 1, "", "plot_iv"], [128, 1, 1, "", "plot_local_fi"], [128, 1, 1, "", "plot_woe"], [128, 1, 1, "", "predict"], [128, 1, 1, "", "score"], [128, 1, 1, "", "set_params"], [128, 1, 1, "", "update_feature_importance"]], "piml.models.XGB2Classifier": [[129, 1, 1, "", "decision_function"], [129, 1, 1, "", "fit"], [129, 1, 1, "", "get_params"], [129, 1, 1, "", "model_unwrapper"], [129, 1, 1, "", "predict"], [129, 1, 1, "", "predict_proba"], [129, 1, 1, "", "score"], [129, 1, 1, "", "set_params"]], "piml.models.XGB2Regressor": [[130, 1, 1, "", "fit"], [130, 1, 1, "", "get_params"], [130, 1, 1, "", "model_unwrapper"], [130, 1, 1, "", "predict"], [130, 1, 1, "", "score"], [130, 1, 1, "", "set_params"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"]}, "titleterms": {"data": [0, 1, 2, 3, 5, 6, 18, 62, 63, 64, 65, 66, 71, 73, 74, 75, 76, 86, 102, 107, 109, 110, 111, 112], "pipelin": [0, 18, 71, 107], "load": [1, 2, 62, 63, 64, 65, 66, 73, 86, 106], "built": [1, 73], "dataset": [1, 73], "panda": [2, 73], "datafram": [2, 73], "summari": [3, 76, 84, 94], "eda": 4, "prepar": [5, 62, 63, 64, 65, 66, 74], "qualiti": [6, 75], "check": 6, "featur": [7, 11, 76, 77, 83, 84, 89, 90, 91, 92, 93, 94, 96, 97, 104], "select": [7, 77], "two": [8, 78, 79, 82, 101, 105], "sampl": [8, 68, 70, 74, 78, 104], "test": [8, 18, 39, 52, 62, 63, 64, 65, 66, 74, 77, 78, 104, 107], "comput": [9, 17, 38, 53, 58], "time": [9, 17, 38, 53, 58], "post": [10, 18, 85, 107], "hoc": [10, 18, 85, 107], "explain": [10, 18, 62, 63, 66, 85, 89, 107], "permut": [11, 83], "import": [11, 77, 83, 84, 89, 90, 91, 92, 93, 94, 96, 97, 106], "partial": [12, 82], "depend": [12, 82, 84, 106], "plot": [12, 72, 78, 82, 84, 89, 91, 92, 94, 96, 97, 99, 101, 105], "individu": [13, 80], "condit": [13, 77, 80], "expect": [13, 80], "accumul": [14, 79], "local": [14, 15, 75, 79, 81, 85, 89, 90, 91, 92, 93, 94, 95, 96, 97], "effect": [14, 79, 89, 91, 92, 96, 97], "interpret": [15, 18, 19, 62, 63, 66, 81, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 107], "model": [15, 18, 19, 54, 55, 56, 62, 63, 64, 65, 66, 67, 81, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 107, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "agnost": [15, 81], "explan": [15, 16, 81, 84], "shaplei": [16, 84], "addit": [16, 84, 91], "exampl": [18, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 115, 122, 125, 129], "outcom": [18, 39, 62, 63, 66, 107], "comparison": [18, 54, 55, 56, 57, 62, 63, 65, 66, 67, 68, 69, 70, 75, 78, 103], "glm": [20, 21], "logist": 20, "regress": [20, 21, 23, 25, 27, 29, 31, 33, 35, 37, 41, 43, 45, 47, 49, 51, 56, 70, 93, 99, 102], "taiwan": [20, 26, 30, 32, 34, 36, 68, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "credit": [20, 26, 30, 32, 34, 36, 68, 89, 90, 92, 93, 94, 95, 97, 99, 101, 102, 103, 104, 105], "linear": [21, 93, 94], "bike": [21, 31, 33, 35, 79, 80, 81, 82, 83, 84, 93], "share": [21, 31, 33, 35, 79, 80, 81, 82, 83, 84, 93], "gam": [22, 23], "classif": [22, 24, 26, 28, 30, 32, 34, 36, 40, 42, 44, 46, 48, 50, 55, 68, 99, 102], "cocircl": [22, 28, 91, 96], "california": [23, 25, 27, 29, 91], "hous": [23, 25, 27, 29, 91], "tree": [24, 25, 90, 95], "taiwancredit": [24, 66], "fig": [26, 27], "xgb": [28, 29, 30, 31], "1": [28, 29, 64, 68, 70, 73, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105], "2": [30, 31, 65, 73, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105], "ebm": [32, 33], "gami": [34, 35, 92], "net": [34, 35, 92], "relu": [36, 37, 94], "dnn": [36, 37], "friedman": [37, 94], "accuraci": [40, 41, 68, 70, 99], "weakspot": [42, 43, 105], "overfit": [44, 45, 68, 70, 101], "reliabl": [46, 47, 68, 70, 102], "robust": [48, 49, 68, 70, 104], "resili": [50, 51, 68, 70, 103], "fair": [52, 57, 64, 65, 69, 100], "xgb2": 52, "tabl": [59, 94, 99, 102], "Of": 59, "content": 59, "frequent": 60, "ask": 60, "question": 60, "case": 61, "studi": [61, 64, 65], "bikeshar": [62, 70, 89, 92, 96, 97, 99, 101, 102, 104, 105], "train": [62, 63, 64, 65, 66, 74, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97], "intepret": [62, 63, 66], "diagnost": [62, 63, 66, 87, 98], "benchmark": [62, 63, 66], "californiah": [63, 90, 95, 103], "simul": [64, 65], "ml": [64, 65], "": [64, 65], "descript": 65, "score": [68, 70, 75, 102], "auc": 68, "f1": 68, "bandwidth": [68, 70, 102], "diagram": [68, 90, 102], "perform": [68, 70, 103], "worst": [68, 70, 104], "metric": [69, 78, 100], "segment": [69, 100], "mean": 70, "squar": 70, "error": 70, "absolut": 70, "r": 70, "coverag": [70, 102], "exploratori": 72, "analysi": [72, 75], "univari": 72, "bivari": 72, "multivari": 72, "extern": 73, "from": 73, "basic": 74, "set": 74, "split": 74, "random": [74, 77], "outer": 74, "base": [74, 75], "kmean": 74, "manual": 74, "isol": 75, "forest": 75, "cluster": 75, "outlier": [75, 107], "factor": 75, "cblof": [75, 109], "princip": 75, "compon": 75, "kmeanstre": [75, 111], "distribut": 75, "margin": [75, 78, 102, 103], "differ": 75, "method": [75, 107], "refer": [75, 77, 80, 83, 84, 87, 93, 107], "statist": 76, "numer": [76, 104], "categor": [76, 104], "manipul": 76, "remov": 76, "chang": 76, "type": 76, "correl": 77, "distanc": [68, 70, 77, 78, 102, 103], "us": [77, 108, 115, 122, 125, 129], "independ": 77, "rcit": 77, "forward": 77, "backward": 77, "earli": 77, "drop": 77, "fbedk": 77, "usag": [78, 79, 80, 81, 82, 83, 84, 101, 103, 104, 105], "densiti": [78, 103], "al": 79, "algorithm": [79, 80, 81, 82, 83, 84, 101, 103, 104, 105], "detail": [79, 80, 81, 82, 83, 84, 101, 103, 104, 105], "One": [79, 82, 101, 105], "wai": [79, 82, 101, 105], "ic": 80, "lime": 81, "pdp": 82, "pfi": 83, "shap": 84, "exact": 84, "solut": 84, "kernelshap": 84, "specif": 84, "The": 84, "waterfal": 84, "global": [85, 89, 90, 91, 92, 93, 94, 95, 96, 97], "black": 86, "box": 86, "regist": 86, "save": 86, "fit": 86, "arbitrari": 86, "introduct": 87, "toolbox": 87, "design": 87, "suit": [87, 98], "futur": 87, "plan": 87, "boost": 89, "machin": 89, "main": [89, 91, 92, 96, 97], "interact": [89, 92, 97], "contribut": [89, 92, 94, 97], "fast": 90, "greedi": 90, "sum": 90, "heatmap": 90, "gener": [91, 93], "coeffici": 93, "origin": 93, "scale": 93, "option": 93, "center": 93, "neural": 94, "network": 94, "formul": 94, "llm": 94, "parallel": 94, "coordin": 94, "violin": 94, "profil": 94, "pairwis": 94, "decis": 95, "xgboost": [96, 97], "depth": [96, 97], "weight": 96, "evid": 96, "inform": 96, "valu": 96, "task": [99, 102], "residu": 99, "binari": [99, 102], "bin": 100, "threshold": 100, "un": 102, "classifi": 102, "calibr": 102, "brier": 102, "histogram": 103, "perturb": 104, "For": 104, "variabl": 104, "whole": 104, "instal": 106, "quick": 106, "troubleshoot": 106, "could": 106, "find": 106, "version": 106, "satisfi": 106, "requir": 106, "piml": [106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "cannot": 106, "uninstal": 106, "llvmlite": 106, "librari": 106, "libxgboost": 106, "so": 106, "colab": 106, "api": 107, "experi": [107, 108], "class": 107, "function": 107, "detect": 107, "outlier_detect": [109, 110, 111, 112], "isolationforest": 110, "pca": 112, "explainableboostingclassifi": 113, "explainableboostingregressor": 114, "figsclassifi": 115, "figsregressor": 116, "gamclassifi": 117, "gaminetclassifi": 118, "gaminetregressor": 119, "gamregressor": 120, "glmclassifi": 121, "glmregressor": 122, "reludnnclassifi": 123, "reludnnregressor": 124, "treeclassifi": 125, "treeregressor": 126, "xgb1classifi": 127, "xgb1regressor": 128, "xgb2classifi": 129, "xgb2regressor": 130, "welcom": 131, "scikit": 131, "learn": 131, "user": 133, "guid": 133, "methodologi": 75}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"Data Pipeline": [[0, "data-pipeline"], [71, "data-pipeline"], [107, "data-pipeline"], [18, "data-pipeline"]], "Data Load (Built-in Dataset)": [[1, "data-load-built-in-dataset"]], "Data Load (Pandas DataFrame)": [[2, "data-load-pandas-dataframe"]], "Data Summary": [[3, "data-summary"], [76, "data-summary"]], "EDA": [[4, "eda"]], "Data Preparation": [[5, "data-preparation"], [74, "data-preparation"]], "Data Quality Check": [[6, "data-quality-check"]], "Feature Selection": [[7, "feature-selection"], [77, "feature-selection"]], "Two Sample Test": [[8, "two-sample-test"], [78, "two-sample-test"]], "Computation times": [[9, "computation-times"], [17, "computation-times"], [38, "computation-times"], [53, "computation-times"], [58, "computation-times"]], "Post hoc Explainability": [[10, "post-hoc-explainability"], [18, "post-hoc-explainability"]], "Permutation Feature Importance": [[11, "permutation-feature-importance"]], "Partial Dependence Plot": [[12, "partial-dependence-plot"]], "Individual Conditional Expectation": [[13, "individual-conditional-expectation"]], "Accumulated Local Effects": [[14, "accumulated-local-effects"]], "Local Interpretable Model-Agnostic Explanation": [[15, "local-interpretable-model-agnostic-explanation"]], "SHapley Additive exPlanations": [[16, "shapley-additive-explanations"]], "Interpretable Models": [[19, "interpretable-models"], [88, "interpretable-models"], [107, "interpretable-models"], [87, "interpretable-models"], [18, "interpretable-models"]], "GLM Logistic Regression (Taiwan Credit)": [[20, "glm-logistic-regression-taiwan-credit"]], "GLM Linear Regression (Bike Sharing)": [[21, "glm-linear-regression-bike-sharing"]], "GAM Classification (CoCircles)": [[22, "gam-classification-cocircles"]], "GAM Regression (California Housing)": [[23, "gam-regression-california-housing"]], "Tree Classification (TaiwanCredit)": [[24, "tree-classification-taiwancredit"]], "Tree Regression (California Housing)": [[25, "tree-regression-california-housing"]], "FIGS Classification (Taiwan Credit)": [[26, "figs-classification-taiwan-credit"]], "FIGS Regression (California Housing)": [[27, "figs-regression-california-housing"]], "XGB-1 Classification (CoCircles)": [[28, "xgb-1-classification-cocircles"]], "XGB-1 Regression (California Housing)": [[29, "xgb-1-regression-california-housing"]], "XGB-2 Classification (Taiwan Credit)": [[30, "xgb-2-classification-taiwan-credit"]], "XGB-2 Regression (Bike Sharing)": [[31, "xgb-2-regression-bike-sharing"]], "EBM Classification (Taiwan Credit)": [[32, "ebm-classification-taiwan-credit"]], "EBM Regression (Bike Sharing)": [[33, "ebm-regression-bike-sharing"]], "GAMI-Net Classification (Taiwan Credit)": [[34, "gami-net-classification-taiwan-credit"]], "GAMI-Net Regression (Bike Sharing)": [[35, "gami-net-regression-bike-sharing"]], "ReLU DNN Classification (Taiwan Credit)": [[36, "relu-dnn-classification-taiwan-credit"]], "ReLU DNN Regression (Friedman)": [[37, "relu-dnn-regression-friedman"]], "Outcome Testing": [[39, "outcome-testing"], [107, "outcome-testing"], [18, "outcome-testing"]], "Accuracy: Classification": [[40, "accuracy-classification"]], "Accuracy: Regression": [[41, "accuracy-regression"]], "WeakSpot: Classification": [[42, "weakspot-classification"]], "WeakSpot: Regression": [[43, "weakspot-regression"]], "Overfit: Classification": [[44, "overfit-classification"]], "Overfit: Regression": [[45, "overfit-regression"]], "Reliability: Classification": [[46, "reliability-classification"]], "Reliability: Regression": [[47, "reliability-regression"]], "Robustness: Classification": [[48, "robustness-classification"]], "Robustness:  Regression": [[49, "robustness-regression"]], "Resilience:  Classification": [[50, "resilience-classification"]], "Resilience - Regression": [[51, "resilience-regression"]], "Fairness Test: XGB2": [[52, "fairness-test-xgb2"]], "Fairness Comparison": [[57, "fairness-comparison"], [69, "fairness-comparison"]], "Table Of Contents": [[59, "table-of-contents"]], "Frequently Asked Questions": [[60, "frequently-asked-questions"]], "Case Studies": [[61, "case-studies"]], "BikeSharing Data": [[62, "BikeSharing-Data"]], "Load and Prepare Data": [[62, "Load-and-Prepare-Data"], [63, "Load-and-Prepare-Data"], [64, "Load-and-Prepare-Data"], [66, "Load-and-Prepare-Data"]], "Train Intepretable Models": [[62, "Train-Intepretable-Models"], [63, "Train-Intepretable-Models"], [66, "Train-Intepretable-Models"]], "Interpretability and Explainability": [[62, "Interpretability-and-Explainability"], [63, "Interpretability-and-Explainability"], [66, "Interpretability-and-Explainability"]], "Model Diagnostics and Outcome Testing": [[62, "Model-Diagnostics-and-Outcome-Testing"], [63, "Model-Diagnostics-and-Outcome-Testing"], [66, "Model-Diagnostics-and-Outcome-Testing"]], "Model Comparison and Benchmarking": [[62, "Model-Comparison-and-Benchmarking"], [63, "Model-Comparison-and-Benchmarking"], [66, "Model-Comparison-and-Benchmarking"]], "CaliforniaHousing Data": [[63, "CaliforniaHousing-Data"]], "Fairness Simulation Study 1": [[64, "Fairness-Simulation-Study-1"]], "Train ML Model(s)": [[64, "Train-ML-Model(s)"], [65, "Train-ML-Model(s)"]], "Fairness Testing": [[64, "Fairness-Testing"], [65, "Fairness-Testing"]], "Fairness Simulation Study 2": [[65, "Fairness-Simulation-Study-2"]], "Data Description": [[65, "Data-Description"]], "Load and Prepare data": [[65, "Load-and-Prepare-data"]], "Fairness Testing Comparison": [[65, "Fairness-Testing-Comparison"]], "TaiwanCredit Data": [[66, "TaiwanCredit-Data"]], "Model Comparison": [[67, "model-comparison"], [18, "model-comparison"], [54, "model-comparison"]], "Examples": [[72, "examples"], [73, "examples"], [74, "examples"], [75, "examples"], [76, "examples"], [77, "examples"], [78, "examples"], [79, "examples"], [80, "examples"], [81, "examples"], [82, "examples"], [84, "examples"], [89, "examples"], [90, "examples"], [92, "examples"], [93, "examples"], [94, "examples"], [95, "examples"], [96, "examples"], [97, "examples"], [99, "examples"], [100, "examples"], [101, "examples"], [102, "examples"], [103, "examples"], [104, "examples"], [105, "examples"], [18, "examples"], [70, "examples"], [68, "examples"], [69, "examples"]], "Example": [[72, null], [74, null], [75, null], [76, null], [77, null], [78, null], [83, "example"], [91, "example"], [100, null], [69, null]], "Exploratory Analysis": [[72, "exploratory-analysis"]], "Univariate Plots": [[72, "univariate-plots"]], "Bivariate Plots": [[72, "bivariate-plots"]], "Multivariate Plots": [[72, "multivariate-plots"]], "Data Load": [[73, "data-load"]], "Built-in Dataset": [[73, "built-in-dataset"]], "External Dataset": [[73, "external-dataset"]], "Example 1: Load built-in datasets": [[73, null]], "Example 2: Load data from pandas DataFrame": [[73, null]], "Basic Settings": [[74, "basic-settings"]], "Train-test Splits": [[74, "train-test-splits"]], "Random Split": [[74, "random-split"]], "Outer-sample-based Split": [[74, "outer-sample-based-split"]], "KMeans-based Split": [[74, "kmeans-based-split"]], "Manual Split": [[74, "manual-split"]], "Data Quality": [[75, "data-quality"]], "Methodology": [[75, "methodology"]], "Isolation Forest": [[75, "isolation-forest"]], "Cluster-Based Local Outlier Factor (CBLOF)": [[75, "cluster-based-local-outlier-factor-cblof"]], "Principal Component Analysis": [[75, "principal-component-analysis"]], "KmeansTree": [[75, "kmeanstree"]], "Analysis and Comparison": [[75, "analysis-and-comparison"]], "Outlier Score distribution": [[75, "outlier-score-distribution"]], "Marginal Distribution of Outliers": [[75, "marginal-distribution-of-outliers"]], "Comparison of Different Methods": [[75, "comparison-of-different-methods"]], "References": [[75, null], [77, null], [80, null], [83, null], [84, null], [93, null], [87, null]], "Summary Statistics": [[76, "summary-statistics"]], "Numerical Features": [[76, "numerical-features"]], "Categorical Features": [[76, "categorical-features"]], "Feature Manipulation": [[76, "feature-manipulation"]], "Remove Features": [[76, "remove-features"]], "Change Feature Types": [[76, "change-feature-types"]], "Correlations": [[77, "correlations"]], "Distance Correlation": [[77, "distance-correlation"]], "Use of Feature Importance": [[77, "use-of-feature-importance"]], "Randomized Conditional Independence Test": [[77, "randomized-conditional-independence-test"]], "RCIT Test": [[77, "rcit-test"]], "Forward-Backward selection with Early Dropping (FBEDk):": [[77, "forward-backward-selection-with-early-dropping-fbedk"]], "Distance Metrics": [[78, "distance-metrics"]], "Usage": [[78, "usage"], [79, "usage"], [80, "usage"], [81, "usage"], [82, "usage"], [83, "usage"], [84, "usage"], [101, "usage"], [103, "usage"], [104, "usage"], [105, "usage"]], "Distance Metric Plot": [[78, "distance-metric-plot"]], "Marginal Density Comparison": [[78, "marginal-density-comparison"], [103, "marginal-density-comparison"]], "ALE (Accumulated Local Effects)": [[79, "ale-accumulated-local-effects"]], "Algorithm Details": [[79, "algorithm-details"], [80, "algorithm-details"], [81, "algorithm-details"], [82, "algorithm-details"], [83, "algorithm-details"], [84, "algorithm-details"], [101, "algorithm-details"], [103, "algorithm-details"], [104, "algorithm-details"], [105, "algorithm-details"]], "One-way ALE": [[79, "one-way-ale"]], "Two-way ALE": [[79, "two-way-ale"]], "Example 1: Bike Sharing": [[79, null], [80, null], [81, null], [82, null], [83, null], [84, null], [93, null]], "ICE (Individual Conditional Expectation)": [[80, "ice-individual-conditional-expectation"]], "LIME (Local Interpretable Model-Agnostic Explanation)": [[81, "lime-local-interpretable-model-agnostic-explanation"]], "PDP (Partial Dependence Plot)": [[82, "pdp-partial-dependence-plot"]], "One-way PDPs": [[82, "one-way-pdps"]], "Two-way PDPs": [[82, "two-way-pdps"]], "PFI (Permutation Feature Importance)": [[83, "pfi-permutation-feature-importance"]], "SHAP (SHapley Additive exPlanations)": [[84, "shap-shapley-additive-explanations"]], "Exact Solution": [[84, "exact-solution"]], "KernelSHAP": [[84, "kernelshap"]], "Algorithms for specific models": [[84, "algorithms-for-specific-models"]], "The Waterfall plot": [[84, "the-waterfall-plot"]], "SHAP Feature importance": [[84, "shap-feature-importance"]], "SHAP Summary plot": [[84, "shap-summary-plot"]], "SHAP Dependence Plot": [[84, "shap-dependence-plot"]], "Post-hoc Explainability": [[85, "post-hoc-explainability"], [107, "post-hoc-explainability"]], "Global Explainability": [[85, "global-explainability"]], "Local Explainability": [[85, "local-explainability"]], "Black-box Models": [[86, "black-box-models"]], "Train and Register Models": [[86, "train-and-register-models"]], "Save Fitted Models": [[86, "save-fitted-models"]], "Load and Register Fitted Models": [[86, "load-and-register-fitted-models"]], "Register Arbitrary Models and Data": [[86, "register-arbitrary-models-and-data"]], "Example 1: BikeSharing": [[89, null], [92, null], [96, null], [97, null], [99, null], [101, null], [102, null], [104, null], [105, null], [70, null]], "Explainable Boosting Machines": [[89, "explainable-boosting-machines"]], "Model Training": [[89, "model-training"], [90, "model-training"], [91, "model-training"], [92, "model-training"], [93, "model-training"], [94, "model-training"], [95, "model-training"], [96, "model-training"], [97, "model-training"]], "Global Interpretation": [[89, "global-interpretation"], [90, "global-interpretation"], [91, "global-interpretation"], [92, "global-interpretation"], [93, "global-interpretation"], [94, "global-interpretation"], [95, "global-interpretation"], [96, "global-interpretation"], [97, "global-interpretation"]], "Main Effect Plot": [[89, "main-effect-plot"], [91, "main-effect-plot"], [92, "main-effect-plot"], [96, "main-effect-plot"], [97, "main-effect-plot"]], "Interaction Plot": [[89, "interaction-plot"], [92, "interaction-plot"], [97, "interaction-plot"]], "Effect Importance": [[89, "effect-importance"], [92, "effect-importance"], [97, "effect-importance"]], "Feature Importance": [[89, "feature-importance"], [91, "feature-importance"], [92, "feature-importance"], [93, "feature-importance"], [96, "feature-importance"], [97, "feature-importance"]], "Local Interpretation": [[89, "local-interpretation"], [90, "local-interpretation"], [91, "local-interpretation"], [92, "local-interpretation"], [93, "local-interpretation"], [94, "local-interpretation"], [95, "local-interpretation"], [96, "local-interpretation"], [97, "local-interpretation"]], "Local Effect Contribution": [[89, "local-effect-contribution"], [92, "local-effect-contribution"], [97, "local-effect-contribution"]], "Local Feature Contribution": [[89, "local-feature-contribution"], [92, "local-feature-contribution"], [97, "local-feature-contribution"]], "Examples 2: Taiwan Credit": [[89, null], [90, null], [92, null], [94, null], [95, null], [97, null], [99, null], [101, null], [102, null], [103, null], [104, null], [105, null]], "Fast Interpretable Greedy-tree Sums": [[90, "fast-interpretable-greedy-tree-sums"]], "Feature Importance Heatmap": [[90, "feature-importance-heatmap"]], "Tree Diagram": [[90, "tree-diagram"]], "Example 1: CaliforniaHousing": [[90, null], [95, null], [103, null]], "Generalized Additive Model": [[91, "generalized-additive-model"]], "Example 1: California Housing": [[91, null]], "Example 2: CoCircles": [[91, null], [96, null]], "GAMI-Net": [[92, "gami-net"]], "Generalized Linear Models": [[93, "generalized-linear-models"]], "Regression Coefficients": [[93, "regression-coefficients"]], "Original Scale Option": [[93, "original-scale-option"]], "Centered Option": [[93, "centered-option"]], "Example 2: Taiwan Credit": [[93, null]], "ReLU Neural Network": [[94, "relu-neural-network"]], "Model Formulation": [[94, "model-formulation"]], "Local Linear Models": [[94, "local-linear-models"]], "LLM Summary Table": [[94, "llm-summary-table"]], "Parallel Coordinate Plot": [[94, "parallel-coordinate-plot"]], "LLM Violin Plot": [[94, "llm-violin-plot"]], "Feature Importance Plot": [[94, "feature-importance-plot"]], "LLM profile plot": [[94, "llm-profile-plot"]], "LLM pairwise plot": [[94, "llm-pairwise-plot"]], "Local Feature Contribution plot": [[94, "local-feature-contribution-plot"]], "Example 1: Friedman": [[94, null]], "Decision Tree": [[95, "decision-tree"]], "XGBoost Depth 1": [[96, "xgboost-depth-1"]], "Weight of Evidence Plot": [[96, "weight-of-evidence-plot"]], "Information Value Plot": [[96, "information-value-plot"]], "XGBoost Depth 2": [[97, "xgboost-depth-2"]], "Diagnostic Suite": [[98, "diagnostic-suite"], [87, "diagnostic-suite"]], "Installation": [[106, "installation"]], "Quick Install": [[106, "quick-install"]], "Dependencies": [[106, "dependencies"]], "Troubleshooting": [[106, "troubleshooting"]], "Could not find a version that satisfies the requirement PiML": [[106, "could-not-find-a-version-that-satisfies-the-requirement-piml"]], "Cannot uninstall \u201cllvmlite\u201d.": [[106, "cannot-uninstall-llvmlite"]], "Library \u201clibxgboost.so\u201d not loaded": [[106, "library-libxgboost-so-not-loaded"]], "Cannot import PiML on Colab": [[106, "cannot-import-piml-on-colab"]], "API Reference": [[107, "api-reference"]], "Experiment Class": [[107, "experiment-class"]], "Functions": [[107, "functions"], [107, "id1"]], "Outlier Detection Methods": [[107, "outlier-detection-methods"]], "Model Classes": [[107, "model-classes"]], "piml.data.outlier_detection.CBLOF": [[109, "piml-data-outlier-detection-cblof"]], "piml.data.outlier_detection.IsolationForest": [[110, "piml-data-outlier-detection-isolationforest"]], "piml.data.outlier_detection.KMeansTree": [[111, "piml-data-outlier-detection-kmeanstree"]], "piml.data.outlier_detection.PCA": [[112, "piml-data-outlier-detection-pca"]], "piml.models.ExplainableBoostingClassifier": [[113, "piml-models-explainableboostingclassifier"]], "piml.models.ExplainableBoostingRegressor": [[114, "piml-models-explainableboostingregressor"]], "piml.models.FIGSRegressor": [[116, "piml-models-figsregressor"]], "piml.models.GAMClassifier": [[117, "piml-models-gamclassifier"]], "piml.models.GAMINetClassifier": [[118, "piml-models-gaminetclassifier"]], "piml.models.GAMINetRegressor": [[119, "piml-models-gaminetregressor"]], "piml.models.GAMRegressor": [[120, "piml-models-gamregressor"]], "piml.models.GLMClassifier": [[121, "piml-models-glmclassifier"]], "piml.models.ReluDNNClassifier": [[123, "piml-models-reludnnclassifier"]], "piml.models.ReluDNNRegressor": [[124, "piml-models-reludnnregressor"]], "piml.models.TreeRegressor": [[126, "piml-models-treeregressor"]], "piml.models.XGB1Classifier": [[127, "piml-models-xgb1classifier"]], "piml.models.XGB1Regressor": [[128, "piml-models-xgb1regressor"]], "piml.models.XGB2Regressor": [[130, "piml-models-xgb2regressor"]], "Welcome to scikit-learn": [[131, "welcome-to-scikit-learn"]], "User Guide": [[133, "user-guide"]], "Introduction": [[87, "introduction"], [87, "id1"]], "Toolbox Design": [[87, "toolbox-design"]], "Future Plan": [[87, "future-plan"]], "Accuracy": [[99, "accuracy"]], "Regression Tasks": [[99, "regression-tasks"]], "Accuracy Table": [[99, "accuracy-table"], [99, "id1"]], "Residual Plot": [[99, "residual-plot"], [99, "id2"]], "Binary Classification": [[99, "binary-classification"]], "Accuracy Plot": [[99, "accuracy-plot"]], "Fairness Metrics": [[100, "fairness-metrics"], [69, "fairness-metrics"]], "Fairness": [[100, "fairness"]], "Fairness Segmented": [[100, "fairness-segmented"]], "Fairness Binning": [[100, "fairness-binning"]], "Fairness Thresholding": [[100, "fairness-thresholding"]], "Overfit": [[101, "overfit"]], "One-way Overfit Plot": [[101, "one-way-overfit-plot"]], "Two-way Overfit Plot": [[101, "two-way-overfit-plot"]], "Reliability": [[102, "reliability"]], "Reliability for Regression Tasks": [[102, "reliability-for-regression-tasks"]], "Coverage and Bandwidth Table": [[102, "coverage-and-bandwidth-table"]], "Distance of Reliable and Un-reliable Data": [[102, "distance-of-reliable-and-un-reliable-data"], [102, "id1"]], "Marginal Bandwidth": [[102, "marginal-bandwidth"], [102, "id2"]], "Reliability for Binary Classification": [[102, "reliability-for-binary-classification"]], "Classifier Calibration": [[102, "classifier-calibration"]], "Reliability Diagram": [[102, "reliability-diagram"]], "Brier Score Table": [[102, "brier-score-table"]], "Resilience Performance": [[103, "resilience-performance"], [70, "resilience-performance"], [68, "resilience-performance"]], "Resilience": [[103, "resilience"]], "Resilience Distance": [[103, "resilience-distance"], [70, "resilience-distance"], [68, "resilience-distance"]], "Marginal Histogram Comparison": [[103, "marginal-histogram-comparison"]], "Robustness": [[104, "robustness"]], "Perturbation For Numerical Features": [[104, "perturbation-for-numerical-features"]], "Perturbation for Categorical Variable": [[104, "perturbation-for-categorical-variable"]], "Robustness on the whole test sample": [[104, "robustness-on-the-whole-test-sample"]], "Robustness on worst test samples": [[104, "robustness-on-worst-test-samples"]], "WeakSpot": [[105, "weakspot"]], "One-way WeakSpot Plot": [[105, "one-way-weakspot-plot"]], "Two-way WeakSpot Plot": [[105, "two-way-weakspot-plot"]], "Model Comparison: Classification": [[55, "model-comparison-classification"]], "Model Comparison: Regression": [[56, "model-comparison-regression"]], "Accuracy Comparison": [[70, "accuracy-comparison"], [68, "accuracy-comparison"]], "Overfit Comparison": [[70, "overfit-comparison"], [68, "overfit-comparison"]], "Reliability Comparison": [[70, "reliability-comparison"], [68, "reliability-comparison"]], "Bandwidth Comparison": [[70, "bandwidth-comparison"], [68, "bandwidth-comparison"]], "Robustness Comparison": [[70, "robustness-comparison"], [68, "robustness-comparison"]], "Robustness Performance": [[70, "robustness-performance"], [68, "robustness-performance"]], "Robustness Performance on Worst Samples": [[70, "robustness-performance-on-worst-samples"], [68, "robustness-performance-on-worst-samples"]], "Resilience Comparison": [[70, "resilience-comparison"], [68, "resilience-comparison"]], "Comparison for Regression": [[70, "comparison-for-regression"]], "Mean Squared Error": [[70, "mean-squared-error"]], "Mean Absolute Error": [[70, "mean-absolute-error"]], "R-squared Score": [[70, "r-squared-score"]], "Coverage Comparison": [[70, "coverage-comparison"]], "piml.Experiment": [[108, "piml-experiment"]], "Examples using piml.Experiment": [[108, "examples-using-piml-experiment"]], "piml.models.FIGSClassifier": [[115, "piml-models-figsclassifier"]], "Examples using piml.models.FIGSClassifier": [[115, "examples-using-piml-models-figsclassifier"]], "piml.models.GLMRegressor": [[122, "piml-models-glmregressor"]], "Examples using piml.models.GLMRegressor": [[122, "examples-using-piml-models-glmregressor"]], "piml.models.TreeClassifier": [[125, "piml-models-treeclassifier"]], "Examples using piml.models.TreeClassifier": [[125, "examples-using-piml-models-treeclassifier"]], "piml.models.XGB2Classifier": [[129, "piml-models-xgb2classifier"]], "Examples using piml.models.XGB2Classifier": [[129, "examples-using-piml-models-xgb2classifier"]], "Comparison for Classification": [[68, "comparison-for-classification"]], "Accuracy Score": [[68, "accuracy-score"]], "AUC Score": [[68, "auc-score"]], "F1 Score": [[68, "f1-score"]], "Reliability Diagram Comparison": [[68, "reliability-diagram-comparison"]], "Examples 1: Taiwan Credit": [[68, null]], "Segmented": [[69, "segmented"]]}, "indexentries": {}})