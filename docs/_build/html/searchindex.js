Search.setIndex({"docnames": ["auto_examples/data/index", "auto_examples/data/plot_0_data_loader", "auto_examples/data/plot_1_data_summary", "auto_examples/data/plot_2_data_eda", "auto_examples/data/plot_3_data_prepare", "auto_examples/data/plot_4_data_quality", "auto_examples/data/plot_5_feature_select", "auto_examples/data/plot_6_twosample_test", "auto_examples/data/sg_execution_times", "auto_examples/explain/index", "auto_examples/explain/plot_0_pfi", "auto_examples/explain/plot_1_pdp", "auto_examples/explain/plot_2_ice", "auto_examples/explain/plot_3_ale", "auto_examples/explain/plot_4_lime", "auto_examples/explain/plot_5_shap", "auto_examples/explain/sg_execution_times", "auto_examples/index", "auto_examples/models/index", "auto_examples/models/plot_0_glm_cls", "auto_examples/models/plot_0_glm_reg", "auto_examples/models/plot_1_gam_cls", "auto_examples/models/plot_1_gam_reg", "auto_examples/models/plot_2_tree_cls", "auto_examples/models/plot_2_tree_reg", "auto_examples/models/plot_3_figs_cls", "auto_examples/models/plot_3_figs_reg", "auto_examples/models/plot_4_xgb1_cls", "auto_examples/models/plot_4_xgb1_reg", "auto_examples/models/plot_5_xgb2_cls", "auto_examples/models/plot_5_xgb2_reg", "auto_examples/models/plot_6_ebm_cls", "auto_examples/models/plot_6_ebm_reg", "auto_examples/models/plot_7_gaminet_cls", "auto_examples/models/plot_7_gaminet_reg", "auto_examples/models/plot_8_reludnn_cls", "auto_examples/models/plot_8_reludnn_reg", "auto_examples/models/sg_execution_times", "auto_examples/testing/index", "auto_examples/testing/plot_0_accuracy_cls", "auto_examples/testing/plot_0_accuracy_reg", "auto_examples/testing/plot_1_weakspot_cls", "auto_examples/testing/plot_1_weakspot_reg", "auto_examples/testing/plot_2_overfit_cls", "auto_examples/testing/plot_2_overfit_reg", "auto_examples/testing/plot_3_reliability_cls", "auto_examples/testing/plot_3_reliability_reg", "auto_examples/testing/plot_4_robustness_cls", "auto_examples/testing/plot_4_robustness_reg", "auto_examples/testing/plot_5_resilience_cls", "auto_examples/testing/plot_5_resilience_reg", "auto_examples/testing/plot_6_fairness", "auto_examples/testing/sg_execution_times", "auto_examples/testing_compare/index", "auto_examples/testing_compare/plot_0_compare_classification", "auto_examples/testing_compare/plot_0_compare_regression", "auto_examples/testing_compare/plot_1_compare_fairness", "auto_examples/testing_compare/sg_execution_times", "contents", "faq", "guides/cases", "guides/cases/Example_BikeSharing", "guides/cases/Example_CaliforniaHousing", "guides/cases/Example_Fairness_SimuStudy1", "guides/cases/Example_Fairness_SimuStudy2", "guides/cases/Example_TaiwanCredit", "guides/comparison", "guides/comparison/compare_classification", "guides/comparison/compare_fairness", "guides/comparison/compare_regression", "guides/data", "guides/data/data_eda", "guides/data/data_load", "guides/data/data_prepare", "guides/data/data_quality", "guides/data/data_summary", "guides/data/feature_select", "guides/data/twosample_test", "guides/explain/ale", "guides/explain/ice", "guides/explain/lime", "guides/explain/pdp", "guides/explain/pfi", "guides/explain/shap", "guides/explainability", "guides/extmodels", "guides/introduction", "guides/models", "guides/models/ebm", "guides/models/figs", "guides/models/gam", "guides/models/gaminet", "guides/models/glm", "guides/models/reludnn", "guides/models/tree", "guides/models/xgb1", "guides/models/xgb2", "guides/testing", "guides/testing/accuracy", "guides/testing/fairness", "guides/testing/overfit", "guides/testing/reliability", "guides/testing/resilience", "guides/testing/robustness", "guides/testing/weakspot", "install", "modules/classes", "modules/generated/piml.Experiment", "modules/generated/piml.models.ExplainableBoostingClassifier", "modules/generated/piml.models.ExplainableBoostingRegressor", "modules/generated/piml.models.FIGSClassifier", "modules/generated/piml.models.FIGSRegressor", "modules/generated/piml.models.GAMClassifier", "modules/generated/piml.models.GAMINetClassifier", "modules/generated/piml.models.GAMINetRegressor", "modules/generated/piml.models.GAMRegressor", "modules/generated/piml.models.GLMClassifier", "modules/generated/piml.models.GLMRegressor", "modules/generated/piml.models.ReluDNNClassifier", "modules/generated/piml.models.ReluDNNRegressor", "modules/generated/piml.models.TreeClassifier", "modules/generated/piml.models.TreeRegressor", "modules/generated/piml.models.XGB1Classifier", "modules/generated/piml.models.XGB1Regressor", "modules/generated/piml.models.XGB2Classifier", "modules/generated/piml.models.XGB2Regressor", "preface", "tune_toc", "user_guide"], "filenames": ["auto_examples\\data\\index.rst", "auto_examples\\data\\plot_0_data_loader.rst", "auto_examples\\data\\plot_1_data_summary.rst", "auto_examples\\data\\plot_2_data_eda.rst", "auto_examples\\data\\plot_3_data_prepare.rst", "auto_examples\\data\\plot_4_data_quality.rst", "auto_examples\\data\\plot_5_feature_select.rst", "auto_examples\\data\\plot_6_twosample_test.rst", "auto_examples\\data\\sg_execution_times.rst", "auto_examples\\explain\\index.rst", "auto_examples\\explain\\plot_0_pfi.rst", "auto_examples\\explain\\plot_1_pdp.rst", "auto_examples\\explain\\plot_2_ice.rst", "auto_examples\\explain\\plot_3_ale.rst", "auto_examples\\explain\\plot_4_lime.rst", "auto_examples\\explain\\plot_5_shap.rst", "auto_examples\\explain\\sg_execution_times.rst", "auto_examples\\index.rst", "auto_examples\\models\\index.rst", "auto_examples\\models\\plot_0_glm_cls.rst", "auto_examples\\models\\plot_0_glm_reg.rst", "auto_examples\\models\\plot_1_gam_cls.rst", "auto_examples\\models\\plot_1_gam_reg.rst", "auto_examples\\models\\plot_2_tree_cls.rst", "auto_examples\\models\\plot_2_tree_reg.rst", "auto_examples\\models\\plot_3_figs_cls.rst", "auto_examples\\models\\plot_3_figs_reg.rst", "auto_examples\\models\\plot_4_xgb1_cls.rst", "auto_examples\\models\\plot_4_xgb1_reg.rst", "auto_examples\\models\\plot_5_xgb2_cls.rst", "auto_examples\\models\\plot_5_xgb2_reg.rst", "auto_examples\\models\\plot_6_ebm_cls.rst", "auto_examples\\models\\plot_6_ebm_reg.rst", "auto_examples\\models\\plot_7_gaminet_cls.rst", "auto_examples\\models\\plot_7_gaminet_reg.rst", "auto_examples\\models\\plot_8_reludnn_cls.rst", "auto_examples\\models\\plot_8_reludnn_reg.rst", "auto_examples\\models\\sg_execution_times.rst", "auto_examples\\testing\\index.rst", "auto_examples\\testing\\plot_0_accuracy_cls.rst", "auto_examples\\testing\\plot_0_accuracy_reg.rst", "auto_examples\\testing\\plot_1_weakspot_cls.rst", "auto_examples\\testing\\plot_1_weakspot_reg.rst", "auto_examples\\testing\\plot_2_overfit_cls.rst", "auto_examples\\testing\\plot_2_overfit_reg.rst", "auto_examples\\testing\\plot_3_reliability_cls.rst", "auto_examples\\testing\\plot_3_reliability_reg.rst", "auto_examples\\testing\\plot_4_robustness_cls.rst", "auto_examples\\testing\\plot_4_robustness_reg.rst", "auto_examples\\testing\\plot_5_resilience_cls.rst", "auto_examples\\testing\\plot_5_resilience_reg.rst", "auto_examples\\testing\\plot_6_fairness.rst", "auto_examples\\testing\\sg_execution_times.rst", "auto_examples\\testing_compare\\index.rst", "auto_examples\\testing_compare\\plot_0_compare_classification.rst", "auto_examples\\testing_compare\\plot_0_compare_regression.rst", "auto_examples\\testing_compare\\plot_1_compare_fairness.rst", "auto_examples\\testing_compare\\sg_execution_times.rst", "contents.rst", "faq.rst", "guides\\cases.rst", "guides\\cases\\Example_BikeSharing.ipynb", "guides\\cases\\Example_CaliforniaHousing.ipynb", "guides\\cases\\Example_Fairness_SimuStudy1.ipynb", "guides\\cases\\Example_Fairness_SimuStudy2.ipynb", "guides\\cases\\Example_TaiwanCredit.ipynb", "guides\\comparison.rst", "guides\\comparison\\compare_classification.rst", "guides\\comparison\\compare_fairness.rst", "guides\\comparison\\compare_regression.rst", "guides\\data.rst", "guides\\data\\data_eda.rst", "guides\\data\\data_load.rst", "guides\\data\\data_prepare.rst", "guides\\data\\data_quality.rst", "guides\\data\\data_summary.rst", "guides\\data\\feature_select.rst", "guides\\data\\twosample_test.rst", "guides\\explain\\ale.rst", "guides\\explain\\ice.rst", "guides\\explain\\lime.rst", "guides\\explain\\pdp.rst", "guides\\explain\\pfi.rst", "guides\\explain\\shap.rst", "guides\\explainability.rst", "guides\\extmodels.rst", "guides\\introduction.rst", "guides\\models.rst", "guides\\models\\ebm.rst", "guides\\models\\figs.rst", "guides\\models\\gam.rst", "guides\\models\\gaminet.rst", "guides\\models\\glm.rst", "guides\\models\\reludnn.rst", "guides\\models\\tree.rst", "guides\\models\\xgb1.rst", "guides\\models\\xgb2.rst", "guides\\testing.rst", "guides\\testing\\accuracy.rst", "guides\\testing\\fairness.rst", "guides\\testing\\overfit.rst", "guides\\testing\\reliability.rst", "guides\\testing\\resilience.rst", "guides\\testing\\robustness.rst", "guides\\testing\\weakspot.rst", "install.rst", "modules\\classes.rst", "modules\\generated\\piml.Experiment.rst", "modules\\generated\\piml.models.ExplainableBoostingClassifier.rst", "modules\\generated\\piml.models.ExplainableBoostingRegressor.rst", "modules\\generated\\piml.models.FIGSClassifier.rst", "modules\\generated\\piml.models.FIGSRegressor.rst", "modules\\generated\\piml.models.GAMClassifier.rst", "modules\\generated\\piml.models.GAMINetClassifier.rst", "modules\\generated\\piml.models.GAMINetRegressor.rst", "modules\\generated\\piml.models.GAMRegressor.rst", "modules\\generated\\piml.models.GLMClassifier.rst", "modules\\generated\\piml.models.GLMRegressor.rst", "modules\\generated\\piml.models.ReluDNNClassifier.rst", "modules\\generated\\piml.models.ReluDNNRegressor.rst", "modules\\generated\\piml.models.TreeClassifier.rst", "modules\\generated\\piml.models.TreeRegressor.rst", "modules\\generated\\piml.models.XGB1Classifier.rst", "modules\\generated\\piml.models.XGB1Regressor.rst", "modules\\generated\\piml.models.XGB2Classifier.rst", "modules\\generated\\piml.models.XGB2Regressor.rst", "preface.rst", "tune_toc.rst", "user_guide.rst"], "titles": ["Data Pipeline", "Data Load", "Data Summary", "EDA", "Data Prepare", "Data Quality Check", "Feature Selection", "Two Sample Test", "Computation times", "Post hoc Explainability", "Permutation Feature Importance", "Partial Dependence Plot", "Individual Conditional Expectation", "Accumulated Local Effects", "Local Interpretable Model-Agnostic Explanation", "SHapley Additive exPlanations", "Computation times", "Examples", "Interpretable Models", "GLM Logistic Regression (Taiwan Credit)", "GLM Linear Regression (Bike Sharing)", "GAM Classification (CoCircles)", "GAM Regression (California Housing)", "Tree Classification (TaiwanCredit)", "Tree Regression (California Housing)", "FIGS Classification (Taiwan Credit)", "FIGS Regression (California Housing)", "XGB-1 Classification (CoCircles)", "XGB-1 Regression (California Housing)", "XGB-2 Classification (Taiwan Credit)", "XGB-2 Regression (Bike Sharing)", "EBM Classification (Taiwan Credit)", "EBM Regression (Bike Sharing)", "GAMI-Net Classification (Taiwan Credit)", "GAMI-Net Regression (Bike Sharing)", "ReLU DNN Classification (Taiwan Credit)", "ReLU DNN Regression (Friedman)", "Computation times", "Outcome Testing", "Accuracy: Classification", "Accuracy: Regression", "WeakSpot: Classification", "WeakSpot: Regression", "Overfit: Classification", "Overfit: Regression", "Reliability: Classification", "Reliability: Regression", "Robustness: Classification", "Robustness:  Regression", "Resilience:  Classification", "Resilience - Regression", "Fairness Test: XGB2", "Computation times", "Model Comparison", "Model Comparison: Classification", "Model Comparison: Regression", "Fairness Comparison", "Computation times", "Table Of Contents", "Frequently Asked Questions", "<span class=\"section-number\">8. </span>Case Studies", "<span class=\"section-number\">8.1. </span>BikeSharing Data", "<span class=\"section-number\">8.2. </span>CaliforniaHousing Data", "<span class=\"section-number\">8.4. </span>Fairness Simulation Study 1", "<span class=\"section-number\">8.5. </span>Fairness Simulation Study 2", "<span class=\"section-number\">8.3. </span>TaiwanCredit Data", "<span class=\"section-number\">7. </span>Model Comparison", "<span class=\"section-number\">7.2. </span>Comparison for Classification", "<span class=\"section-number\">7.3. </span>Fairness Comparison", "<span class=\"section-number\">7.1. </span>Comparison for Regression", "<span class=\"section-number\">2. </span>Data Pipeline", "<span class=\"section-number\">2.4. </span>Exploratory Analysis", "<span class=\"section-number\">2.1. </span>Data Load", "<span class=\"section-number\">2.3. </span>Data Prepare", "<span class=\"section-number\">2.5. </span>Data Quality", "<span class=\"section-number\">2.2. </span>Data Summary", "<span class=\"section-number\">2.6. </span>Feature Selection", "<span class=\"section-number\">2.7. </span>Two Sample Test", "<span class=\"section-number\">4.1.4. </span>ALE (Accumulated Local Effects)", "<span class=\"section-number\">4.1.3. </span>ICE (Individual Conditional Expectation)", "<span class=\"section-number\">4.2.1. </span>LIME (Local Interpretable Model-Agnostic Explanation)", "<span class=\"section-number\">4.1.2. </span>PDP (Partial Dependence Plot)", "<span class=\"section-number\">4.1.1. </span>PFI (Permutation Feature Importance)", "<span class=\"section-number\">4.2.2. </span>SHAP (SHapley Additive exPlanations)", "<span class=\"section-number\">4. </span>Post-hoc Explainability", "<span class=\"section-number\">3. </span>Black-box Models", "<span class=\"section-number\">1. </span>Introduction", "<span class=\"section-number\">5. </span>Interpretable Models", "<span class=\"section-number\">5.7. </span>Explainable Boosting Machines", "<span class=\"section-number\">5.4. </span>Fast Interpretable Greedy-tree Sums", "<span class=\"section-number\">5.2. </span>Generalized Additive Model", "<span class=\"section-number\">5.8. </span>GAMI-Net", "<span class=\"section-number\">5.1. </span>Generalized Linear Models", "<span class=\"section-number\">5.9. </span>ReLU Neural Network", "<span class=\"section-number\">5.3. </span>Decision Tree", "<span class=\"section-number\">5.5. </span>XGBoost Depth 1", "<span class=\"section-number\">5.6. </span>XGBoost Depth 2", "<span class=\"section-number\">6. </span>Diagnostic Suite", "<span class=\"section-number\">6.1. </span>Accuracy", "<span class=\"section-number\">6.7. </span>Fairness", "<span class=\"section-number\">6.3. </span>Overfit", "<span class=\"section-number\">6.4. </span>Reliability", "<span class=\"section-number\">6.6. </span>Resilience", "<span class=\"section-number\">6.5. </span>Robustness", "<span class=\"section-number\">6.2. </span>WeakSpot", "Installation", "API Reference", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml</span></code>.Experiment", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ExplainableBoostingClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ExplainableBoostingRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.FIGSClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.FIGSRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMINetClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMINetRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GAMRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GLMClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.GLMRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ReluDNNClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.ReluDNNRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.TreeClassifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.TreeRegressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB1Classifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB1Regressor", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB2Classifier", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">piml.models</span></code>.XGB2Regressor", "Welcome to scikit-learn", "&lt;no title&gt;", "User guide: contents"], "terms": {"loader": [1, 72, 113, 114], "summari": [0, 8, 15, 17, 35, 36, 70, 89, 98, 103, 104, 107, 128], "eda": [0, 8, 17, 61, 62, 63, 64, 65, 71, 86, 107], "prepar": [0, 1, 2, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 60, 70, 82, 85, 90, 92, 93, 94, 107, 128], "qualiti": [0, 8, 17, 70, 86, 99, 101, 107, 120, 121, 128], "featur": [0, 5, 7, 8, 9, 15, 16, 17, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 61, 62, 63, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 84, 86, 94, 98, 99, 100, 101, 102, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 128], "select": [0, 5, 8, 17, 63, 64, 67, 69, 70, 74, 78, 91, 93, 94, 95, 100, 102, 103, 107, 113, 114, 120, 121, 128], "two": [0, 8, 17, 35, 36, 41, 42, 43, 44, 64, 68, 70, 71, 72, 73, 74, 76, 79, 80, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 101, 103, 107, 128], "sampl": [0, 4, 8, 17, 47, 48, 49, 50, 54, 55, 61, 62, 64, 70, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 128], "test": [0, 4, 6, 8, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 47, 48, 52, 58, 59, 60, 67, 68, 69, 70, 72, 82, 86, 92, 98, 99, 100, 101, 102, 104, 107, 108, 109, 110, 111, 113, 114, 118, 119, 120, 121, 122, 123, 124, 125, 128], "go": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56], "end": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 76, 77, 78, 79, 81, 83, 86, 88, 89, 90, 91, 92, 93, 95, 96, 98, 99, 101, 120, 121], "download": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56], "full": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 68, 70, 78, 80, 86, 88, 90, 91, 92, 93, 95, 96, 99, 101, 102, 103, 106, 107], "exampl": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 60, 61, 62, 63, 64, 65, 66, 70, 84, 86, 87, 97], "code": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 60, 61, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107], "run": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 61, 62, 63, 64, 65, 67, 69, 76, 86, 99, 102, 103, 105, 107, 108, 109, 120, 121], "thi": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "your": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 64, 72, 95, 105], "browser": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56], "via": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 72, 76, 78, 86, 88, 93, 107], "binder": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56], "experi": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 61, 62, 63, 64, 65, 72, 73, 76, 85, 86, 99, 105], "initi": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 74, 76, 85, 86, 95, 99, 107, 113, 114, 118, 119], "from": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 59, 61, 62, 63, 64, 65, 67, 68, 69, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 111, 113, 114, 119, 121, 122, 123, 125], "piml": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 106], "import": [1, 2, 3, 4, 5, 6, 7, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 61, 62, 63, 64, 65, 70, 74, 84, 85, 86, 94, 107, 110, 111, 112, 113, 114, 115, 120, 121, 122, 123, 124, 125], "panda": [1, 72, 105, 107], "pd": [1, 72, 81, 107], "exp": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105], "data_load": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 61, 62, 63, 64, 65, 72, 85, 86, 107], "cocircl": [1, 17, 18, 37, 72, 107, 112, 122], "load": [0, 8, 17, 43, 60, 67, 70, 86, 88, 92, 96, 98, 100, 101, 103, 104, 107, 113, 114, 128], "bikeshar": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 20, 30, 32, 34, 40, 42, 44, 46, 48, 50, 55, 60, 67, 72, 76, 78, 79, 80, 81, 82, 83, 92, 107, 128], "dataset": [1, 2, 3, 4, 5, 6, 61, 62, 63, 64, 65, 67, 68, 70, 71, 73, 74, 76, 78, 79, 80, 81, 82, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 113, 114, 118, 119], "internet": 1, "data_panda": [1, 72], "read_csv": [1, 72], "http": [1, 72, 76, 86, 99, 107, 110, 111], "github": [1, 72, 86, 107, 110, 111], "com": [1, 72, 86, 107, 110, 111], "selfexplainml": [1, 72, 86], "toolbox": [1, 72, 128], "blob": [1, 72], "main": [1, 61, 62, 65, 72, 76, 78, 93, 108, 109, 112, 113, 114, 115, 122, 123], "csv": [1, 72], "raw": [1, 48, 67, 69, 72, 95, 96, 101, 103, 106, 107, 110, 112, 113, 114, 115, 118, 119, 122, 123, 124, 125], "true": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 68, 72, 78, 79, 80, 81, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "x0": [1, 21, 27, 36, 72, 95, 107], "x1": [1, 21, 27, 63, 72, 95, 107], "target": [1, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 64, 72, 73, 77, 78, 81, 82, 85, 92, 95, 103, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "0": [1, 2, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 62, 64, 65, 67, 68, 69, 72, 73, 74, 75, 76, 78, 80, 81, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "783526": [1, 72], "502161": [1, 72], "1": [1, 2, 3, 4, 6, 8, 10, 14, 16, 17, 18, 19, 20, 22, 25, 26, 35, 36, 37, 41, 42, 43, 44, 45, 46, 48, 51, 54, 55, 56, 60, 61, 62, 64, 65, 68, 72, 73, 74, 75, 76, 77, 86, 87, 99, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 128], "297809": [1, 72], "658405": [1, 72], "2": [1, 2, 4, 6, 12, 17, 18, 19, 20, 21, 23, 24, 35, 36, 37, 39, 40, 41, 42, 43, 44, 47, 48, 49, 51, 55, 56, 60, 61, 65, 67, 69, 72, 73, 74, 75, 76, 78, 81, 83, 85, 86, 87, 99, 105, 107, 108, 109, 110, 111, 113, 114, 118, 119, 120, 121, 122, 123, 124, 125, 128], "468272": [1, 72], "500653": [1, 72], "3": [1, 2, 4, 19, 20, 23, 24, 25, 26, 29, 35, 36, 41, 42, 43, 44, 47, 48, 49, 50, 51, 54, 55, 56, 61, 62, 63, 64, 65, 67, 69, 75, 78, 79, 83, 89, 90, 91, 93, 94, 95, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 112, 113, 114, 115, 120, 122, 123, 124, 125], "134700": 1, "887973": 1, "4": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 61, 62, 63, 64, 65, 67, 68, 69, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 108, 109, 113, 114, 120], "337202": 1, "780797": 1, "1995": 1, "498109": 1, "889060": 1, "1996": 1, "312980": 1, "724953": 1, "1997": [1, 72], "542930": [1, 72], "583517": [1, 72], "1998": [1, 72], "871481": [1, 72], "491301": [1, 72], "1999": [1, 72], "323963": [1, 72], "719150": [1, 72], "2000": [1, 76, 81, 107], "row": [1, 35, 93, 107], "x": [1, 19, 20, 35, 67, 69, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 88, 89, 90, 91, 92, 93, 95, 96, 98, 99, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "column": [1, 4, 35, 64, 73, 89, 98, 104, 107, 120], "season": [1, 2, 3, 11, 20, 30, 32, 40, 71, 72, 75, 76, 81, 83, 88, 91, 92, 96, 98], "yr": [1, 2, 3, 10, 11, 12, 13, 14, 15, 20, 30, 32, 34, 40, 42, 44, 46, 48, 50, 55, 61, 71, 72, 75, 76], "mnth": [1, 2, 10, 11, 12, 13, 14, 15, 20, 30, 32, 34, 40, 42, 44, 46, 48, 50, 55, 61, 72, 75, 76], "hr": [1, 2, 3, 6, 11, 12, 13, 15, 20, 30, 32, 34, 40, 42, 44, 46, 48, 50, 55, 69, 71, 72, 75, 76, 78, 79, 80, 81, 82, 83, 88, 91, 92, 96, 98, 100, 101, 103], "holidai": [1, 2, 72, 75, 82], "weekdai": [1, 2, 12, 20, 34, 72, 75, 76, 91], "workingdai": [1, 2, 11, 42, 72, 75, 76, 81, 82, 88, 91, 96], "weathersit": [1, 2, 13, 72, 75, 76, 78], "6": [1, 2, 4, 19, 20, 21, 22, 23, 24, 36, 41, 42, 44, 47, 48, 51, 56, 61, 62, 63, 64, 65, 68, 72, 75, 76, 78, 79, 80, 86, 90, 94, 99, 100, 103, 105, 107, 112, 113, 114, 115, 122, 123], "17374": 1, "12": [1, 2, 8, 19, 20, 25, 26, 36, 51, 62, 64, 72, 75, 86, 89, 102, 105], "19": [1, 36, 51], "17375": 1, "20": [1, 21, 22, 27, 28, 36, 41, 43, 51, 62, 64, 76, 83, 89, 90, 93, 94, 95, 100, 101, 102, 104, 105, 107, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "17376": 1, "21": [1, 36, 51, 72, 105], "17377": [1, 72], "22": [1, 8, 36, 51, 72, 86], "17378": [1, 72], "23": [1, 2, 36, 51, 56, 72, 75, 86, 109, 111, 114, 119, 121, 123, 125], "temp": [1, 2, 3, 6, 10, 11, 12, 13, 14, 15, 20, 30, 32, 34, 40, 42, 44, 46, 48, 50, 55, 61, 71, 72, 75, 76, 92], "atemp": [1, 2, 7, 12, 13, 20, 30, 42, 44, 48, 69, 72, 78, 80, 82, 83, 88, 91, 96, 100, 103], "hum": [1, 2, 20, 72, 75, 76, 80, 83, 88, 92, 96], "windspe": [1, 2, 20, 72, 75, 91], "cnt": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 20, 30, 32, 34, 40, 42, 44, 46, 48, 50, 55, 61, 69, 71, 72, 73, 75, 78, 79, 80, 81, 82, 83, 88, 91, 92, 95, 96, 98, 100, 101, 103, 104], "24": [1, 6, 36, 43, 51, 52, 56, 57, 72, 79, 105], "2879": [1, 43, 72], "81": [1, 72], "0000": [1, 2, 20, 35, 41, 43, 72, 75], "16": [1, 19, 20, 23, 24, 25, 26, 36, 51, 54, 72, 88, 89, 91, 94, 96], "2727": [1, 72], "80": [1, 43, 72], "40": [1, 2, 35, 36, 51, 56, 72, 75, 93, 101, 103, 118, 119], "32": [1, 36, 51, 57, 72, 82, 86, 99, 108, 109], "75": [1, 43, 104], "13": [1, 2, 19, 20, 31, 36, 37, 51, 64], "26": [1, 36, 72], "2576": [1, 72], "60": [1, 41, 42, 64, 72], "1642": [1, 72], "119": 1, "89": 1, "90": [1, 51, 56, 64, 69, 72, 101], "56": [1, 72], "1343": [1, 72], "61": [1, 51, 56, 72], "65": [1, 36, 72, 79], "49": [1, 72], "17379": [1, 2, 72], "total": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 73, 92, 93, 95, 98, 102, 109, 111, 114, 119, 120, 121, 122, 123, 124, 125], "time": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 64, 76, 82, 83, 86, 89, 93, 101, 113, 114], "script": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56], "minut": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56], "708": [], "second": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 67, 69, 71, 73, 75, 83, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104, 113, 114], "python": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 78, 83, 86, 89, 90, 93, 95, 96, 105], "sourc": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56], "plot_0_data_load": [1, 8], "py": [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 105], "jupyt": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 74, 86], "notebook": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 61, 62, 65, 86], "ipynb": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 61, 62, 63, 64, 65], "galleri": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56], "gener": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 67, 72, 73, 76, 78, 79, 82, 83, 86, 87, 88, 89, 91, 93, 94, 95, 96, 98, 99, 100, 102, 104, 107, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 121, 123, 125, 128], "sphinx": [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56], "show": [2, 3, 5, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 63, 64, 67, 68, 69, 71, 74, 76, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 112, 113, 114, 115, 122, 123], "result": [2, 4, 5, 41, 42, 43, 44, 45, 46, 66, 67, 68, 73, 74, 76, 78, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 95, 96, 99, 100, 101, 103, 104, 107, 108, 109, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "us": [2, 3, 4, 5, 6, 41, 42, 44, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106], "silent": [2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 107], "data_summari": [2, 10, 11, 12, 13, 14, 15, 19, 20, 23, 25, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 61, 62, 63, 64, 65, 75, 86, 107], "feature_typ": [2, 75, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "feature_exclud": [2, 10, 11, 12, 13, 14, 15, 19, 20, 23, 25, 29, 30, 31, 32, 33, 34, 35, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 75, 107], "name": [2, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 63, 64, 67, 69, 75, 76, 77, 78, 79, 81, 83, 85, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "n_miss": [2, 75], "mean": [2, 35, 36, 67, 68, 73, 74, 75, 76, 78, 80, 82, 83, 89, 90, 92, 93, 95, 96, 98, 99, 100, 101, 102, 103, 107, 108, 109, 110, 111, 113, 114, 118, 119, 120, 121, 122, 123, 124, 125], "std": [2, 35, 36, 75, 107], "min": [2, 73, 75, 107, 113, 114, 122, 123], "q1": [2, 75], "median": [2, 62, 75, 89, 90, 94, 102, 121], "537775": [2, 75], "438776": [2, 75], "00": [2, 8, 16, 37, 52, 57, 75, 104], "7": [2, 4, 19, 20, 36, 41, 42, 43, 44, 51, 55, 56, 61, 62, 63, 64, 65, 75, 76, 85, 88, 89, 96, 100, 101, 102, 103, 105, 108, 109], "11": [2, 19, 20, 36, 45, 49, 51, 61, 62, 64, 75, 80, 89, 105], "546752": [2, 75], "914405": [2, 75], "003683": [2, 75], "005771": [2, 75], "496987": [2, 75], "192556": [2, 75], "02": [2, 8, 37, 75], "3400": [2, 75], "5000": [2, 41, 44, 75, 76, 108, 109, 113, 114], "475775": 2, "171850": 2, "3333": [2, 41, 43], "4848": [2, 42], "5": [2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 54, 55, 56, 61, 62, 63, 64, 65, 67, 68, 69, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107, 113, 114, 118, 119, 120, 121], "627229": [2, 75], "192930": [2, 75], "4800": [2, 75], "6300": [2, 75], "190098": [2, 75], "122340": [2, 75], "1045": [2, 75], "1940": [2, 75], "189": [2, 75], "463088": [2, 75], "181": [2, 75], "387599": [2, 75], "142": [2, 75], "q3": [2, 75], "max": [2, 73, 74, 75, 77, 88, 89, 93, 101, 107, 108, 109, 110, 111, 112, 113, 114, 115, 120, 121, 122, 123, 124, 125], "10": [2, 10, 19, 20, 23, 24, 25, 26, 31, 32, 36, 37, 39, 41, 45, 46, 49, 50, 51, 54, 55, 61, 62, 64, 65, 67, 69, 75, 76, 77, 79, 80, 82, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 100, 101, 102, 104, 107, 108, 109, 112, 113, 114, 115, 120, 121, 122, 123], "18": [2, 36, 51, 55, 75, 79, 86, 120, 121], "6600": [2, 75], "6212": [2, 42], "7800": [2, 75], "2537": [2, 75], "8507": [2, 75], "281": [2, 75], "977": [2, 75], "n_uniqu": [2, 75], "top1": [2, 75], "top2": [2, 75], "top3": [2, 75], "4496": [2, 75], "4409": [2, 75], "4242": [2, 75], "8734": [2, 75], "8645": [2, 75], "16879": [2, 75], "500": [2, 28, 75, 83, 107, 118, 119], "11865": [2, 75], "5514": [2, 75], "11413": [2, 75], "4544": [2, 75], "1419": [2, 75], "n_other": [2, 75], "4232": [2, 75], "html": [2, 76, 99], "valu": [2, 4, 27, 28, 51, 64, 67, 69, 71, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "shape": [2, 88, 90, 91, 95, 96, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "tab": [2, 63, 64], "children": 2, "output": [2, 76, 78, 80, 81, 83, 90, 93, 96, 99, 113, 114, 120, 121], "layout": 2, "height": 2, "350px": 2, "selected_index": 2, "titl": [2, 88, 89, 91, 95, 96], "numer": [2, 19, 20, 64, 67, 69, 71, 75, 78, 81, 92, 98, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "attribut": [2, 64, 65, 80, 83, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "categor": [2, 20, 64, 71, 73, 75, 78, 81, 92, 98, 99, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "169": 2, "plot_1_data_summari": [2, 8], "plot": [3, 5, 7, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 45, 46, 49, 50, 67, 68, 69, 70, 74, 78, 79, 80, 82, 84, 86, 89, 92, 94, 99, 101, 102, 103, 107, 112, 113, 114, 115, 120, 121, 122, 123, 125], "data_prepar": [3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 61, 62, 63, 64, 65, 73, 76, 85, 86, 107], "histogram": [3, 41, 42, 43, 44, 45, 46, 49, 50, 54, 55, 71, 88, 90, 91, 95, 96, 100, 104, 107, 122, 123, 124, 125], "densiti": [3, 49, 50, 71, 78, 104, 107, 113, 114], "univari": [3, 70, 95, 107], "uni_featur": [3, 11, 12, 13, 15, 20, 21, 22, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 71, 78, 79, 81, 83, 88, 90, 91, 92, 93, 95, 96, 107], "figsiz": [3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 67, 68, 69, 76, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 112, 113, 114, 115, 120, 121, 122, 123], "bar": [3, 67, 69, 71, 76, 78, 81, 83, 90, 92, 95, 98], "scatter": [3, 15, 71, 83, 98, 107], "bivari": [3, 70, 107], "bi_featur": [3, 11, 13, 30, 32, 34, 35, 36, 71, 78, 81, 88, 91, 93, 96, 107], "box": [3, 58, 71, 86, 88, 93, 94, 96, 103, 128], "stack": [3, 71, 110, 111], "correl": [3, 5, 6, 61, 62, 70, 71, 78, 81, 83, 95, 98, 107], "heatmap": [3, 25, 26, 71, 107], "multivari": [3, 70, 81, 107], "multi_typ": [3, 71, 107], "correlation_heatmap": [3, 71, 107], "graph": [3, 71], "correlation_graph": [3, 71, 107], "938": [], "plot_2_data_eda": [3, 8], "displai": [4, 71, 74, 77, 83, 88, 89, 91, 92, 95, 96, 98, 101, 102, 103, 104, 107, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123], "task_typ": [4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 73, 85, 107], "regress": [4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 18, 37, 38, 52, 53, 57, 61, 62, 66, 67, 72, 73, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 93, 94, 95, 96, 97, 100, 102, 103, 104, 107, 109, 110, 111, 114, 115, 117, 119, 120, 121, 123, 128], "sample_weight": [4, 73, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "none": [4, 48, 50, 54, 55, 67, 69, 73, 89, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "split_method": [4, 73, 107], "random": [4, 6, 70, 73, 74, 80, 82, 98, 100, 102, 103, 107, 108, 109, 110, 111, 113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125], "test_ratio": [4, 73, 107], "random_st": [4, 73, 85, 107, 108, 109, 110, 111, 113, 114, 117, 118, 119, 120, 121, 122, 123, 124, 125], "config": [4, 70, 107], "exclud": [4, 61, 63, 64, 65, 73, 78, 107, 113, 114], "variabl": [4, 63, 64, 65, 67, 69, 71, 72, 73, 76, 77, 79, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 104, 107], "weight": [4, 27, 28, 63, 73, 80, 83, 92, 93, 98, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "task": [4, 46, 67, 69, 73, 82, 83, 86, 92, 94, 97, 100, 104, 107], "type": [4, 51, 71, 73, 75, 77, 86, 95, 99, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "split": [4, 25, 26, 59, 73, 74, 78, 86, 89, 94, 95, 96, 101, 104, 107, 108, 109, 110, 111, 120, 121, 122, 123, 124, 125], "method": [4, 5, 6, 47, 48, 61, 64, 66, 67, 69, 70, 73, 76, 77, 78, 81, 82, 83, 86, 90, 94, 95, 96, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "ratio": [4, 64, 73, 99, 100, 101, 102, 104, 107, 113, 114, 118, 119], "state": [4, 72, 73, 83, 86, 93, 99, 107, 108, 109, 117], "train": [4, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 59, 60, 67, 68, 69, 70, 76, 77, 80, 81, 82, 83, 86, 87, 98, 99, 100, 101, 102, 104, 107, 108, 109, 110, 111, 113, 114, 118, 119, 120, 121, 122, 123, 128], "energi": [4, 73], "distanc": [4, 5, 6, 7, 45, 46, 49, 50, 54, 55, 64, 70, 74, 78, 107, 120, 121], "000586": [4, 73], "327": 4, "plot_3_data_prepar": [4, 8], "analysi": [5, 61, 62, 63, 64, 70, 79, 82, 86, 101, 107, 128], "check": [0, 8, 17, 61, 62, 64, 74, 102, 107, 120, 121], "score": [5, 45, 74, 78, 82, 83, 86, 91, 98, 99, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "distribut": [5, 7, 45, 46, 49, 50, 61, 62, 64, 71, 73, 74, 76, 77, 83, 86, 92, 93, 98, 101, 102, 103, 105, 107, 122, 123], "outlier_detect": [5, 74], "pca": [5, 74, 107], "cblof": [5, 74, 107], "data_quality_check": [5, 74, 107], "score_distribut": [5, 74, 107], "threshold": [5, 6, 41, 42, 43, 44, 45, 46, 51, 54, 55, 64, 67, 69, 72, 74, 76, 86, 97, 98, 100, 101, 104, 107, 113, 114, 118, 119], "999": [5, 74], "marginal_outlier_distribut": [5, 74, 107], "strategi": [5, 6, 76, 107, 110, 111, 120, 121], "tsne_comparison": [5, 74, 107], "313": 12, "plot_4_data_qu": [5, 8], "four": [6, 74, 76, 78, 86, 92, 102, 107, 120], "built": [6, 70, 76, 83, 93, 96, 100, 104, 107], "data": [3, 6, 7, 8, 10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 67, 69, 71, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 128], "pearson": [6, 71, 76, 107], "feature_select": [6, 61, 62, 76, 86, 107], "cor": [6, 76, 107], "corr_algorithm": [6, 76, 107], "spearman": [6, 76, 107], "dcor": [6, 76, 105, 107], "permut": [6, 9, 16, 17, 62, 65, 76, 84, 86, 107, 120, 121], "pfi": [6, 10, 61, 76, 84, 86, 107], "95": [6, 76], "condit": [6, 9, 16, 17, 70, 71, 74, 83, 84, 96, 102, 104, 107], "independ": [6, 70, 74, 81, 83, 93, 95, 107], "rcit": [6, 107], "001": [6, 35, 36, 76, 93, 113, 114, 118, 119], "n_forward_phas": [6, 76, 107], "kernel_s": [6, 76, 107], "100": [6, 11, 15, 25, 26, 27, 41, 42, 44, 48, 49, 50, 51, 76, 83, 85, 89, 95, 99, 100, 104, 107, 112, 113, 114, 115, 122, 123, 124, 125], "where": [6, 73, 74, 76, 77, 78, 81, 83, 86, 88, 89, 92, 93, 94, 95, 96, 98, 99, 100, 102, 104, 109, 111, 114, 119, 120, 121, 123, 125], "markov": [6, 76], "boundari": [6, 72, 76, 98, 107], "i": [6, 59, 61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "non": [6, 64, 74, 76, 81, 90, 96, 98, 108, 109, 112, 115, 116, 117, 120, 121], "empti": [6, 76, 107, 113, 114], "preset": [6, 76, 107], "390": 6, "plot_5_feature_select": [6, 8], "shift": [7, 45, 46, 64, 77, 101, 103, 107], "psi": [7, 45, 46, 49, 50, 64, 77, 101, 102, 107], "twosample_test": [7, 77, 107], "metric": [7, 41, 42, 43, 44, 47, 48, 51, 54, 55, 56, 63, 64, 66, 67, 69, 70, 82, 86, 97, 98, 100, 101, 102, 103, 104, 107, 108, 110, 113, 118, 120, 122, 124], "psi_bucket": [7, 77, 101, 102, 107], "uniform": [7, 51, 77, 99, 103, 107, 108, 109, 122, 123], "wd1": [7, 49, 50, 77, 101, 102, 107], "k": [7, 67, 69, 74, 76, 77, 78, 82, 86, 88, 89, 91, 96, 101, 102, 107], "singl": [7, 41, 42, 43, 44, 67, 68, 69, 71, 76, 78, 81, 83, 89, 92, 93, 100, 102, 104, 107, 112, 115, 120, 121], "quantil": [7, 47, 48, 51, 64, 67, 69, 72, 75, 77, 78, 99, 101, 102, 103, 107, 108, 109], "740": 7, "plot_6_twosample_test": [7, 8], "39": [52, 86, 105], "586": [], "execut": [8, 16, 37, 52, 57, 76, 86], "auto_examples_data": 8, "file": [8, 16, 37, 52, 57, 85, 107, 113, 114], "mb": [1, 3, 5, 8, 11, 16, 37, 51, 52, 56, 57], "06": [88, 91, 96], "partial": [9, 16, 17, 76, 84, 86, 107, 113, 114, 125], "depend": [9, 16, 17, 76, 79, 84, 86, 92, 95, 107, 125, 126], "individu": [9, 16, 17, 78, 80, 82, 83, 84, 92, 101, 104, 107, 113, 114], "expect": [9, 16, 17, 69, 83, 84, 89, 101, 103, 109, 111, 114, 119, 121, 123, 125], "accumul": [9, 16, 17, 76, 84, 86, 95, 96, 107, 119], "local": [9, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 61, 81, 83, 86, 87, 98, 107, 112, 113, 114, 115, 119, 120, 121, 122, 123, 128], "effect": [9, 16, 17, 21, 22, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 61, 62, 65, 79, 80, 81, 83, 84, 86, 92, 93, 102, 107, 108, 109, 110, 111, 112, 113, 114, 115, 119, 120, 121, 122, 123], "interpret": [9, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 58, 60, 76, 78, 84, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125, 128], "model": [9, 10, 11, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 56, 57, 58, 59, 60, 67, 68, 69, 72, 73, 74, 76, 78, 79, 81, 82, 84, 98, 99, 100, 101, 102, 103, 104, 107, 128], "agnost": [9, 16, 17, 61, 62, 65, 78, 81, 84, 86, 101, 102], "explan": [9, 16, 17, 61, 62, 65, 66, 81, 84, 86, 107], "shaplei": [9, 16, 17, 84], "addit": [9, 16, 17, 67, 69, 78, 80, 84, 86, 87, 88, 89, 91, 94, 95, 96, 98, 100, 102, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 128], "xgb2regressor": [10, 11, 12, 14, 15, 30, 40, 42, 44, 46, 50, 96, 107], "model_train": [10, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 61, 62, 63, 64, 65, 85, 88, 89, 90, 91, 92, 93, 94, 95, 96, 107], "xgb2": [10, 11, 12, 14, 15, 17, 29, 30, 38, 39, 40, 41, 42, 43, 44, 46, 49, 50, 52, 54, 55, 64, 67, 69, 79, 80, 81, 82, 83, 86, 88, 91, 96, 98, 99, 100, 101, 102, 104, 107, 124], "model_explain": [10, 11, 12, 13, 14, 15, 61, 62, 65, 78, 79, 80, 81, 82, 83, 86, 107], "n_repeat": [10, 82, 107], "574": [3, 8, 10], "plot_0_pfi": [10, 16], "n_estim": [11, 27, 28, 49, 50, 51, 85, 95, 96, 122, 123, 124, 125], "1d": [11, 13, 62, 65, 77, 86, 96, 107], "pdp": [11, 61, 62, 65, 78, 79, 83, 84, 86, 107], "original_scal": [11, 12, 13, 14, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 49, 50, 54, 55, 78, 79, 80, 81, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 104, 107, 120, 121], "2d": [11, 13, 62, 65, 74, 81, 86, 96, 107], "pdp_size": [11, 81, 107], "10000": [11, 81, 100, 113, 114, 118, 119], "36": [11, 16, 36, 76], "179": [11, 16], "estim": [1, 3, 5, 11, 51, 56, 78, 81, 83, 88, 89, 90, 91, 92, 95, 96, 98, 101, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "memori": [1, 3, 5, 11, 51, 56, 113, 114, 118, 119], "usag": [1, 3, 5, 11, 51, 56, 70, 76, 84, 89, 95, 96, 97, 98, 99], "31": [3, 11, 16, 36], "plot_1_pdp": [11, 16], "ic": [12, 72, 84, 107], "plot_2_ic": [12, 16], "reludnnregressor": [13, 36, 93, 107], "reludnn": [13, 35, 47, 78, 93, 118, 119], "al": [13, 61, 62, 65, 74, 83, 84, 86, 107], "17": [13, 19, 36, 51, 61, 69, 78, 79, 80, 81, 82, 83, 88, 91, 92, 95, 96, 98, 100, 101, 103, 104, 105, 120, 121], "598": 13, "plot_3_al": [13, 16], "lime": [14, 61, 62, 65, 84, 86, 105, 107], "without": [14, 19, 20, 35, 36, 83, 89, 92], "center": [14, 19, 20, 35, 36, 73, 76, 78, 80, 93, 107, 112, 113, 114, 115, 122, 123], "sample_id": [14, 15, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 80, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 107], "fals": [14, 19, 20, 35, 36, 39, 40, 74, 80, 92, 93, 98, 99, 104, 107, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123], "783": 14, "plot_4_lim": [14, 16], "shap": [15, 61, 62, 65, 84, 86, 105, 107], "waterfal": 15, "shap_waterfal": [15, 83, 107], "shap_fi": [15, 83, 107], "sample_s": [15, 83, 107, 113, 114], "shap_summari": [15, 83, 107], "shap_scatt": [15, 83, 107], "9": [8, 15, 19, 20, 25, 36, 41, 44, 51, 52, 56, 61, 62, 64, 65, 79, 89, 90, 94, 95, 100, 102, 103, 105], "493": 15, "plot_5_shap": [15, 16], "auto_examples_explain": 16, "000": [8, 16, 52, 55, 57, 65, 67, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "glm": [17, 18, 37, 55, 56, 62, 64, 67, 68, 69, 80, 86, 90, 92, 93, 95, 107, 117, 122, 123], "logist": [17, 18, 37, 86, 92], "taiwan": [17, 18, 37, 65, 110, 113, 118], "credit": [17, 18, 37, 51, 64, 65, 72, 99, 107, 110, 113, 118], "linear": [17, 18, 35, 36, 37, 74, 76, 80, 81, 83, 86, 87, 89, 90, 91, 107, 116, 117, 128], "bike": [17, 18, 37, 61, 69, 72, 88, 91, 95, 96, 98, 100, 101, 103, 104, 107, 109, 114, 117], "share": [17, 18, 37, 72, 88, 91, 96, 98, 107, 109, 114, 117], "gam": [17, 18, 37, 45, 63, 67, 69, 86, 88, 90, 95, 96, 101, 107, 112, 113, 114, 115], "classif": [17, 18, 19, 37, 38, 51, 52, 53, 56, 57, 63, 64, 65, 66, 69, 72, 73, 80, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 102, 103, 104, 107, 108, 110, 112, 113, 118, 120, 121, 122, 124, 128], "california": [17, 18, 37, 72, 88, 89, 94, 95, 102, 107, 111, 115, 121, 123], "hous": [17, 18, 37, 62, 72, 88, 89, 94, 95, 102, 107, 111, 115, 121, 123], "tree": [17, 18, 25, 26, 37, 41, 42, 43, 44, 54, 55, 67, 69, 74, 80, 81, 83, 86, 87, 88, 90, 95, 96, 100, 104, 107, 108, 109, 110, 111, 120, 121, 122, 123, 124, 125, 128], "taiwancredit": [17, 18, 19, 25, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 54, 60, 67, 69, 72, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104, 107, 120, 128], "fig": [17, 18, 37, 48, 54, 67, 69, 86, 89, 103, 107, 110, 111, 112, 113, 114, 115, 122, 123], "xgb": [17, 18, 37, 41, 42, 64, 74, 76, 91, 95, 96, 102, 104, 107, 122, 123, 124, 125], "ebm": [17, 18, 37, 56, 65, 68, 86, 88, 91, 107, 109], "gami": [17, 18, 37, 86, 87, 88, 96, 107, 113, 114, 128], "net": [17, 18, 37, 86, 87, 88, 92, 107, 113, 114, 120, 121, 128], "relu": [17, 18, 37, 62, 65, 86, 87, 91, 107, 113, 114, 118, 119, 128], "dnn": [17, 18, 37, 62, 65, 86, 93, 107, 118, 119], "friedman": [17, 18, 37, 63, 72, 107, 119, 121], "accuraci": [17, 38, 52, 54, 55, 66, 76, 83, 86, 97, 99, 101, 104, 107, 108, 110, 113, 118, 120, 122, 124, 128], "weakspot": [17, 38, 52, 86, 97, 100, 101, 107, 128], "overfit": [17, 38, 52, 54, 55, 66, 76, 86, 88, 90, 93, 94, 95, 97, 98, 104, 107, 128], "reliabl": [17, 38, 52, 54, 55, 66, 78, 86, 97, 98, 104, 107, 112, 128], "robust": [17, 38, 52, 54, 55, 66, 86, 88, 97, 102, 107, 111, 118, 128], "resili": [17, 38, 52, 54, 55, 66, 86, 97, 107, 128], "fair": [17, 38, 52, 53, 57, 60, 66, 72, 86, 97, 107, 108, 116, 124, 128], "all": [17, 19, 20, 48, 64, 65, 67, 69, 74, 76, 78, 79, 82, 83, 88, 89, 90, 91, 92, 93, 96, 98, 99, 102, 103, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "auto_examples_python": 17, "zip": 17, "auto_examples_jupyt": 17, "glmclassifi": [19, 56, 68, 92, 107], "limit_b": [19, 23, 25, 29, 31, 33, 35, 39, 41, 43, 45, 47, 49, 54], "sex": [19, 23, 25, 29, 31, 33, 35, 39, 41, 43, 45, 47, 49, 54], "educ": [19, 23, 25, 29, 31, 33, 35, 39, 41, 43, 45, 47, 49, 54], "marriag": [19, 23, 25, 29, 31, 33, 35, 39, 41, 43, 45, 47, 49, 54], "ag": [19, 23, 25, 29, 31, 33, 35, 39, 41, 43, 45, 47, 49, 54, 63], "flagdefault": [19, 23, 25, 29, 31, 33, 35, 39, 41, 43, 45, 47, 49, 54, 65, 67, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "evalu": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 64, 67, 69, 76, 80, 82, 83, 86, 91, 98, 101, 102, 103, 104, 107], "predict": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 45, 59, 67, 69, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 118, 119, 120, 121, 122, 123, 124, 125], "perform": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 49, 50, 64, 68, 74, 82, 86, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 107, 113, 114, 118, 119, 120, 121], "model_diagnos": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 61, 62, 65, 86, 92, 98, 100, 101, 102, 103, 104, 107], "accuracy_t": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 92, 98, 107], "acc": [19, 21, 23, 25, 27, 29, 31, 33, 35, 39, 41, 43, 51, 54, 64, 67, 69, 86, 98, 99, 100, 102, 103, 104, 107], "auc": [19, 21, 23, 25, 27, 29, 31, 33, 35, 39, 41, 47, 54, 69, 82, 86, 93, 98, 100, 102, 103, 104, 107], "recal": [19, 21, 23, 25, 27, 29, 31, 33, 35, 39, 86, 98, 99, 107], "precis": [19, 21, 23, 25, 27, 29, 31, 33, 35, 39, 74, 86, 98, 99, 107], "f1": [19, 21, 23, 25, 27, 29, 31, 33, 35, 39, 51, 54, 64, 86, 98, 99, 100, 102, 103, 104, 107], "8083": 19, "7375": 19, "2579": 19, "6834": 19, "3745": 19, "8150": 19, "7356": 19, "2583": 19, "6936": 19, "3764": 19, "gap": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 44, 86, 98, 100, 104, 107, 120, 121], "0067": [19, 33], "0019": [19, 44], "0004": [19, 34, 36, 100], "0102": [19, 42], "coeffici": [19, 20, 76, 80, 83, 86, 90, 93, 95, 107, 109, 111, 114, 119, 121, 123, 125], "model_interpret": [19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 61, 62, 65, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 107], "glm_coef_plot": [19, 20, 92, 107], "tabl": [19, 20, 39, 40, 63, 64, 76, 92, 99, 100, 103, 104, 107], "glm_coef_tabl": [19, 20, 92, 107], "pay_amt3": 19, "6906": 19, "pay_amt1": [19, 65, 93], "6464": 19, "pay_amt2": [19, 104], "5927": 19, "pay_amt4": 19, "4080": 19, "pay_amt6": 19, "3255": 19, "pay_amt5": 19, "3122": 19, "bill_amt5": 19, "1892": 19, "pay_4": 19, "0329": 19, "8": [19, 20, 26, 36, 41, 42, 43, 44, 51, 56, 57, 61, 62, 63, 64, 65, 68, 79, 83, 88, 91, 99, 100, 103, 104, 105, 107, 108, 109, 112, 113, 114, 115, 122, 123], "bill_amt1": [19, 41, 43, 47, 65], "0168": 19, "bill_amt2": [19, 47], "1473": 19, "pay_2": [19, 41, 104], "bill_amt3": [19, 47], "6271": 19, "pay_5": 19, "6885": 19, "bill_amt4": 19, "7107": 19, "14": [19, 20, 36, 41, 51, 64], "bill_amt6": 19, "8201": 19, "15": [19, 20, 36, 51, 64, 83, 108, 109], "pay_3": [19, 35, 93], "8883": 19, "pay_6": 19, "0435": 19, "pay_1": [19, 29, 31, 33, 35, 39, 41, 43, 45, 49, 54, 65, 67, 93, 98, 101, 102, 104], "2420": 19, "global_fi": [19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 88, 90, 91, 92, 93, 95, 96, 107], "local_fi": [19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 88, 90, 91, 92, 93, 95, 96, 107], "origin": [19, 20, 45, 51, 74, 76, 78, 80, 81, 82, 83, 89, 95, 98, 99, 100, 101, 107, 112, 113, 114, 115, 120, 121, 122, 123], "scale": [19, 20, 62, 81, 89, 95, 98, 100, 103, 107, 112, 113, 114, 115, 120, 121, 122, 123], "089": [19, 37], "plot_0_glm_cl": [19, 37], "glmregressor": [20, 55, 92, 107], "mse": [20, 22, 24, 26, 28, 30, 32, 34, 36, 40, 48, 55, 69, 82, 86, 98, 100, 101, 102, 103, 104, 107], "mae": [20, 22, 24, 26, 28, 30, 32, 34, 36, 40, 42, 44, 55, 69, 86, 98, 100, 102, 103, 104, 107], "r2": [20, 22, 24, 26, 28, 30, 32, 34, 36, 40, 48, 55, 69, 98, 100, 102, 103, 104, 107], "0225": 20, "1105": 20, "3467": 20, "1090": 20, "3593": 20, "0015": [20, 35, 100], "0127": 20, "2133": 20, "weathersit_2": 20, "0274": 20, "holiday_1": 20, "0250": 20, "season_2": [20, 92], "0038": 20, "workingday_0": 20, "holiday_0": 20, "season_0": 20, "weathersit_0": 20, "workingday_1": 20, "0035": [20, 36, 41], "weathersit_1": 20, "0104": 20, "0125": 20, "season_1": [20, 92], "0193": 20, "0365": 20, "season_3": [20, 92], "0659": 20, "weathersit_3": 20, "0727": 20, "1742": 20, "4082": [20, 44], "546": [20, 37], "plot_0_glm_reg": [20, 37], "gamclassifi": [21, 45, 90, 107], "spline_ord": [21, 22, 90, 112, 115], "n_spline": [21, 22, 90, 112, 115], "lam": [21, 22, 90, 112, 115], "8363": 21, "9226": 21, "8428": 21, "8346": 21, "8387": 21, "8475": 21, "9306": 21, "8542": 21, "8325": 21, "8432": 21, "0112": [21, 33], "0080": [21, 24], "0113": 21, "0021": [21, 41, 42, 44], "0045": 21, "global": [21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 61, 81, 86, 87, 107, 112, 113, 114, 115, 120, 121, 128], "global_effect_plot": [21, 22, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 88, 90, 91, 93, 95, 96, 107], "669": [21, 37], "plot_1_gam_cl": [21, 37], "gamregressor": [22, 90, 107], "californiahousing_trim2": [22, 24, 26, 28, 62, 72, 107], "medhousev": [22, 24, 26, 28, 62, 85, 89, 90, 94, 102], "0145": 22, "0867": 22, "7453": 22, "0152": [22, 42], "0883": 22, "7257": 22, "0007": [22, 23, 29, 33, 36, 39, 98], "0017": 22, "0196": 22, "medinc": [22, 28, 89, 90, 95], "312": [22, 37], "plot_1_gam_reg": [22, 37], "treeclassifi": [23, 54, 83, 94, 107], "max_depth": [23, 24, 25, 26, 48, 49, 51, 55, 64, 85, 89, 94, 104, 110, 111, 120, 121, 124, 125], "8248": 23, "7716": 23, "3740": 23, "6985": 23, "4872": 23, "8255": 23, "7605": 23, "3601": 23, "6827": 23, "4715": 23, "0111": 23, "0140": 23, "0157": 23, "start": [23, 24, 72, 76, 89, 93, 94, 95, 107], "root": [23, 24, 25, 26, 67, 74, 89, 94, 107, 120, 121], "node": [23, 24, 74, 83, 89, 93, 94, 95, 96, 107, 108, 109, 110, 111, 120, 121, 122, 123, 124, 125], "tree_glob": [23, 24, 25, 26, 89, 94, 107], "depth": [23, 24, 25, 26, 74, 86, 87, 88, 89, 94, 99, 101, 107, 110, 111, 120, 121, 122, 123, 124, 125, 128], "th": [23, 74, 76, 78, 81, 83, 89, 90, 93, 95], "tree_loc": [23, 24, 25, 26, 89, 94, 107], "536": [23, 37], "plot_2_tree_cl": [23, 37], "treeregressor": [24, 83, 94, 107], "0184": 24, "0979": 24, "6762": 24, "0212": 24, "1059": 24, "6178": 24, "0028": [24, 25], "0584": 24, "338": [24, 37, 43], "plot_2_tree_reg": [24, 37], "figsclassifi": [25, 54, 89, 107], "max_it": [25, 26, 48, 88, 89, 110, 111, 112, 115], "8246": 25, "7891": 25, "3828": 25, "6908": 25, "4926": 25, "8218": [25, 31], "7637": 25, "3562": 25, "6638": 25, "4636": [25, 44], "0255": 25, "0266": 25, "0270": [25, 42], "0290": 25, "figs_heatmap": [25, 26, 89, 107], "tree_idx": [25, 26, 89, 107, 120, 121], "first": [25, 26, 62, 63, 64, 69, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 113, 114, 120, 121], "814": [25, 37], "plot_3_figs_cl": [25, 37], "figsregressor": [26, 48, 89, 107], "0103": 26, "0705": 26, "8196": 26, "0114": 26, "0739": 26, "7941": 26, "0012": [26, 34, 42], "0034": [26, 41], "0256": 26, "987": [26, 37], "plot_3_figs_reg": [26, 37], "xgb1classifi": [27, 95, 107], "max_bin": [27, 28, 88, 95, 96, 104, 108, 109, 122, 123, 124, 125], "min_bin_s": [27, 28, 95, 122, 123], "01": [8, 27, 28, 37, 88, 95, 108, 109, 113, 114, 122, 123], "xgb1": [27, 28, 95, 96, 107], "8512": 27, "9311": 27, "8342": 27, "8663": 27, "8499": 27, "8450": 27, "9028": 27, "8281": 27, "8457": 27, "8368": 27, "0062": [27, 31], "0283": [27, 42], "0060": [27, 34], "0206": [27, 44], "0131": [27, 28], "evid": [27, 28, 107, 122, 123], "xgb1_woe": [27, 28, 95, 107], "inform": [27, 28, 67, 71, 72, 75, 86, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104, 107, 113, 114, 120, 122, 123], "xgb1_iv": [27, 28, 95, 107], "822": [27, 37], "plot_4_xgb1_cl": [27, 37], "xgb1regressor": [28, 95, 107], "0816": 28, "7704": 28, "0136": 28, "0822": 28, "7546": 28, "0005": [28, 30, 36, 40, 62, 98], "0006": [28, 32, 42, 44], "0159": [28, 44], "798": [28, 37], "plot_4_xgb1_reg": [28, 37], "xgb2classifi": [29, 39, 41, 43, 49, 51, 54, 96, 107], "8223": [29, 39, 98], "7970": [29, 39, 98], "3617": [29, 39, 98], "6924": [29, 39, 98], "4751": [29, 39, 98], "8288": [29, 39, 98], "7732": [29, 39, 98], "3624": [29, 39, 98], "7015": [29, 39, 98], "4779": [29, 39, 98], "0066": [29, 39, 44, 98], "0237": [29, 39, 98], "0091": [29, 39, 98], "0027": [29, 39, 98], "global_ei": [29, 30, 31, 32, 33, 34, 88, 91, 96, 107], "local_ei": [29, 30, 31, 32, 33, 34, 88, 91, 96, 107], "817": [29, 37], "plot_5_xgb2_cl": [29, 37], "0087": [30, 40, 44, 98], "0649": [30, 40, 98], "7469": [30, 40, 98], "0092": [30, 40, 98], "0668": [30, 40, 98], "7368": [30, 40, 98], "0018": [30, 40, 98], "0101": [30, 40, 98], "830": [30, 37], "plot_5_xgb2_reg": [30, 37], "explainableboostingclassifi": [31, 56, 68, 88, 107], "interact": [31, 32, 61, 62, 65, 78, 79, 81, 83, 86, 92, 93, 100, 108, 109, 110, 111, 113, 114], "7885": [31, 43], "3680": 31, "6854": 31, "4789": 31, "8280": 31, "7764": 31, "3716": 31, "6896": [31, 41], "4830": 31, "0121": 31, "0036": [31, 35], "0042": 31, "0040": [31, 36], "591": [31, 37], "plot_6_ebm_cl": [31, 37], "explainableboostingregressor": [32, 88, 107], "0072": 32, "0589": 32, "7920": 32, "0078": 32, "0615": 32, "7782": 32, "0026": 32, "0138": [32, 36], "727": [32, 37], "plot_6_ebm_reg": [32, 37], "gaminetclassifi": [33, 91, 107], "8191": 33, "7751": 33, "3577": 33, "6768": 33, "4681": 33, "8258": 33, "7697": 33, "3554": 33, "6881": 33, "4687": 33, "0054": [33, 44], "0023": [33, 36], "53": [33, 37, 76], "428": [33, 37], "plot_7_gaminet_cl": [33, 37], "gaminetregressor": [34, 91, 107], "0056": 34, "0526": 34, "8372": 34, "0538": 34, "8289": 34, "0083": 34, "48": [34, 36, 37], "387": [34, 37], "plot_7_gaminet_reg": [34, 37], "matplotlib": [35, 105, 112, 113, 114, 115, 122, 123], "pyplot": [35, 112, 113, 114, 115, 122, 123], "plt": [35, 112, 113, 114, 115, 122, 123], "reludnnclassifi": [35, 47, 93, 107], "hidden_layer_s": [35, 36, 93, 118, 119], "l1_reg": [35, 36, 93, 118, 119], "0002": [35, 36, 42, 93], "learning_r": [35, 36, 88, 93, 108, 109, 110, 111, 113, 114, 118, 119], "8200": [35, 86], "7723": 35, "3619": 35, "6793": 35, "4722": 35, "8300": 35, "7708": 35, "3655": 35, "7064": 35, "4817": 35, "0100": [35, 41, 43], "0271": 35, "0095": 35, "llm": [35, 36, 107], "llm_summari": [35, 36, 93, 107], "count": [35, 36, 61, 69, 78, 79, 80, 81, 82, 83, 88, 91, 92, 93, 95, 96, 98, 99, 100, 101, 103, 104, 107, 118, 119], "respons": [35, 36, 39, 61, 62, 63, 64, 65, 67, 69, 72, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "6535": 35, "1053": 35, "3069": 35, "6037": 35, "7349": 35, "4166": 35, "1066": 35, "3086": 35, "6477": 35, "6261": 35, "1307": 35, "2295": 35, "4207": 35, "5999": 35, "5003": 35, "1158": 35, "3100": 35, "4627": 35, "7819": 35, "7348": 35, "903": 35, "1595": 35, "3663": 35, "6118": 35, "5528": 35, "300": 35, "nan": [35, 36, 41], "7364": 35, "301": 35, "5529": 35, "302": 35, "7370": 35, "303": [35, 42], "7244": 35, "304": 35, "7134": 35, "305": 35, "parallel": [35, 36, 107, 108, 109, 113, 114], "coordin": [35, 36, 107], "llm_pc": [35, 36, 93, 107], "violin": [35, 36, 107], "llm_violin": [35, 36, 93, 107], "one": [35, 36, 61, 63, 64, 71, 74, 76, 78, 81, 82, 86, 88, 91, 92, 93, 95, 96, 100, 101, 102, 104, 105, 108, 109, 113, 114, 120, 121], "44": [35, 37, 43, 79], "045": [35, 37], "plot_8_reludnn_cl": [35, 37], "0192": 36, "9784": 36, "0009": 36, "0199": 36, "9709": 36, "0075": 36, "215": [36, 76, 86], "4711": 36, "1584": 36, "0309": 36, "207": 36, "4700": 36, "1648": 36, "0327": 36, "185": 36, "4592": 36, "1754": 36, "0324": [36, 91], "148": [36, 42, 44, 100], "4698": 36, "1601": 36, "0003": 36, "0340": 36, "126": 36, "3969": 36, "1574": 36, "0186": 36, "106": 36, "3815": 36, "1582": 36, "0218": 36, "6136": 36, "1315": 36, "0013": 36, "0783": 36, "62": [36, 41, 51, 56, 63], "6301": 36, "1698": 36, "0008": [36, 42, 65, 92], "0750": 36, "3266": 36, "1242": 36, "0542": 36, "45": [36, 43, 82], "2920": 36, "1354": [36, 41, 104], "0551": 36, "43": 36, "6213": [36, 43], "1345": 36, "6046": 36, "1563": 36, "37": [36, 46], "2811": 36, "1128": 36, "0560": 36, "5604": 36, "1171": [36, 100], "0014": 36, "0784": 36, "35": 36, "2250": 36, "1211": 36, "0288": 36, "2636": 36, "1341": 36, "0604": 36, "5663": 36, "1579": 36, "0037": 36, "5213": 36, "1795": 36, "0010": 36, "0441": 36, "5491": 36, "1967": 36, "0451": 36, "6115": 36, "1256": 36, "5365": 36, "1195": 36, "4459": 36, "1685": 36, "0024": 36, "2393": 36, "1061": 36, "0342": 36, "3573": 36, "1770": 36, "0404": 36, "4821": 36, "1186": 36, "0135": 36, "25": [36, 41, 47, 51, 104], "5134": 36, "0839": 36, "0016": [36, 42, 44], "0625": [36, 43], "0238": 36, "27": 36, "4321": 36, "1450": 36, "0164": 36, "28": 36, "4558": 36, "0107": 36, "0240": 36, "29": [36, 51, 56], "1400": 36, "0890": 36, "0302": 36, "30": [8, 36, 43, 64, 65, 67, 77, 86, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "2187": 36, "1037": 36, "0203": 36, "0751": 36, "1801": 36, "0305": 36, "0385": 36, "5209": 36, "0884": 36, "33": [36, 56, 64], "6258": 36, "0943": 36, "34": 36, "4773": [36, 44], "0875": 36, "x2": [36, 63, 72, 107], "210": [36, 37], "plot_8_reludnn_reg": [36, 37], "03": [37, 42], "51": [8, 37], "945": 37, "auto_examples_model": 37, "09": 37, "08": 37, "07": [37, 83, 91], "05": [37, 42, 43, 44, 54, 55, 67, 69, 100, 118, 119], "04": [37, 42, 83], "confus": [39, 98, 107], "matrix": [39, 74, 76, 78, 93, 96, 98, 103, 107, 109, 110, 111, 114, 118, 119, 120, 121, 123, 125], "roc": [39, 98, 107], "accuracy_plot": [39, 54, 55, 67, 69, 98, 107], "residu": [39, 40, 86, 88, 89, 91, 101, 102, 103, 107, 109, 111, 114, 119, 121, 123, 125], "respect": [39, 40, 73, 76, 77, 80, 83, 89, 93, 98, 99, 101, 103, 107, 113, 114], "accuracy_residu": [39, 40, 98, 107], "target_featur": [39, 40, 45, 46, 49, 50, 98, 101, 102, 107], "use_test": [39, 40, 41, 42, 43, 98, 100, 104, 107], "flagdefault_predict": 39, "765": 39, "plot_0_accuracy_cl": [39, 52], "cnt_predict": [40, 98], "278": 40, "plot_0_accuracy_reg": [40, 52], "base": [41, 42, 43, 44, 63, 67, 68, 69, 73, 75, 76, 77, 78, 80, 81, 82, 83, 86, 90, 91, 94, 95, 96, 98, 99, 101, 102, 103, 107, 108, 109, 110, 111, 113, 114, 120, 121, 122, 123, 124, 125], "slice_method": [41, 42, 43, 44, 54, 55, 67, 69, 100, 104, 107], "slice_featur": [41, 42, 43, 44, 54, 55, 67, 69, 100, 104, 107], "min_sampl": [41, 42, 43, 44, 100, 104, 107], "return_data": [41, 42, 43, 44, 45, 46, 51, 56, 68, 80, 88, 90, 91, 92, 95, 96, 99, 100, 101, 104, 107], "test_acc": [41, 43, 104], "train_acc": [41, 43, 104], "1265": [41, 104], "5090": [41, 104], "6957": 41, "0061": 41, "2500": 41, "191": [41, 104], "800": [41, 104], "6911": 41, "6787": 41, "0123": 41, "1111": [41, 43], "2222": [41, 43], "268": [41, 42, 104], "956": [41, 104], "7276": 41, "7176": 41, "3750": 41, "6250": 41, "322": [41, 104], "7205": 41, "7171": 41, "5556": 41, "351": [41, 104], "1430": [41, 104], "6125": 41, "6147": 41, "7500": 41, "82": [41, 104], "360": [41, 104], "6220": 41, "0030": [41, 42, 44], "set": [41, 42, 43, 47, 54, 55, 61, 62, 63, 64, 65, 67, 69, 70, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "4444": [41, 43], "test_auc": 41, "train_auc": 41, "752": 41, "2936": 41, "6444": 41, "7049": 41, "0605": 41, "3521": 41, "13975": 41, "6348": 41, "6958": 41, "0610": 41, "513": 41, "2154": 41, "5452": 41, "0896": 41, "5750": 41, "7060": 41, "1310": 41, "6410": 41, "4000": 41, "6786": 41, "121": 41, "7000": [41, 43], "6364": [41, 42], "0636": 41, "2778": 41, "582": 41, "2407": 41, "7268": 41, "7084": 41, "0185": 41, "1667": [41, 43], "6862": 41, "6798": 41, "0063": [41, 42], "4705": 41, "6824": 41, "488": 41, "1817": 41, "7377": 41, "7342": 41, "900": 41, "plot_1_weakspot_cl": [41, 52], "test_ms": [42, 44, 100], "train_ms": [42, 44, 100], "445": [42, 44, 100], "1736": [42, 44, 100], "0226": [42, 44], "0205": [42, 44], "290": 42, "1168": 42, "0277": 42, "0938e": 42, "85": 42, "377": 42, "0207": 42, "0200": 42, "3215e": 42, "8851e": 42, "155": 42, "538": 42, "0153": 42, "1004e": 42, "97": [42, 51, 56], "365": 42, "0108": 42, "7190e": 42, "test_ma": [42, 44], "train_ma": [42, 44], "1175": 42, "1122": 42, "0053": 42, "1026": 42, "4077": 42, "0931": 42, "0919": 42, "3261": [42, 44], "3696": [42, 44], "135": [42, 44, 100], "592": [42, 44, 100], "1947": 42, "1677": 42, "2826": [42, 44], "579": [42, 44, 100], "1130": 42, "1062": 42, "0068": 42, "8478": 42, "1630": 42, "6382": 42, "0827": 42, "0825": 42, "4545": 42, "1110": 42, "0753": 42, "0634": 42, "0119": 42, "6667": 42, "1239": 42, "0841": 42, "0778": 42, "5152": 42, "5303": 42, "127": 42, "452": 42, "0746": 42, "0738": 42, "6818": 42, "7273": 42, "146": 42, "555": 42, "0787": 42, "0803": 42, "74": 42, "307": 42, "0736": 42, "0756": 42, "0020": 42, "5909": 42, "294": 42, "1282": 42, "0790": 42, "0820": 42, "9848": [42, 44], "196": 42, "882": [42, 44], "0744": 42, "0808": 42, "474": 42, "plot_1_weakspot_reg": [42, 52], "3781": 43, "41": 43, "131": 43, "7561": 43, "8473": 43, "0912": 43, "7167": 43, "8037": 43, "117": 43, "6333": 43, "7350": 43, "1017": 43, "2814": 43, "3685": 43, "7083": 43, "8133": 43, "1050": 43, "9237": 43, "9558": 43, "69": 43, "5797": 43, "6893": 43, "1096": 43, "6715": 43, "73": 43, "6500": 43, "7808": 43, "1308": 43, "7632": 43, "7953": 43, "92": 43, "6000": 43, "7717": 43, "1717": 43, "1073": 43, "3453": 43, "296": 43, "8480": 43, "0480": 43, "9831": 43, "8182": 43, "1182": 43, "52": [3, 8, 43, 76], "198": 43, "8283": 43, "0398": [43, 44], "7228": 43, "7332": 43, "299": 43, "6933": 43, "7559": 43, "9807": 43, "8000": 43, "1000": [43, 89, 113, 114, 118, 119], "794": 43, "plot_2_overfit_cl": [43, 52], "1020": 44, "0146": 44, "0139": 44, "6636": 44, "103": 44, "366": 44, "0391": 44, "0325": 44, "2318": 44, "173": 44, "645": 44, "0260": 44, "1803": 44, "122": 44, "461": 44, "0058": 44, "1364": 44, "5606": 44, "240": 44, "0093": 44, "0077": 44, "197": [44, 86, 100], "4924": 44, "1649": 44, "6580": 44, "062": 44, "057": 44, "005": 44, "0495": 44, "0098": 44, "0177": 44, "255": 44, "plot_2_overfit_reg": [44, 52], "calcul": [45, 46, 67, 73, 74, 76, 77, 78, 80, 82, 83, 88, 89, 90, 91, 92, 93, 95, 96, 99, 100, 101, 102, 104, 107, 113, 114, 120, 121], "each": [45, 46, 65, 67, 68, 69, 71, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "between": [45, 46, 49, 50, 64, 68, 71, 73, 74, 76, 77, 78, 79, 81, 82, 83, 88, 90, 91, 92, 95, 96, 98, 100, 101, 102, 103, 104, 107, 120, 121], "un": [45, 46, 107], "reliability_dist": [45, 46, 101, 107], "distance_metr": [45, 46, 49, 50, 101, 102, 107], "bandwidth": [45, 46, 54, 55, 79, 107], "against": [45, 46, 49, 50, 67, 69, 88, 91, 96, 98, 103, 105, 107], "given": [45, 46, 76, 80, 83, 88, 89, 91, 93, 95, 96, 99, 100, 101, 104, 107, 108, 110, 112, 113, 114, 115, 118, 120, 122, 123, 124], "reliability_margin": [45, 46, 101, 107], "bin": [45, 46, 51, 54, 55, 64, 67, 69, 77, 78, 86, 88, 95, 96, 97, 100, 101, 102, 104, 107, 108, 109, 122, 123, 124, 125], "calibr": [45, 67, 107], "probabl": [45, 67, 81, 83, 93, 98, 101, 102, 103, 107, 108, 110, 113, 118, 119, 120, 122, 124], "v": [45, 62, 65, 76, 77, 107, 109, 111, 114, 119, 121, 123, 125], "reliability_calibr": [45, 101, 107], "diagram": [45, 54, 94, 107, 120, 121], "reliability_perf": [45, 54, 67, 101, 107], "brier": [45, 107], "reliability_t": [45, 46, 101, 107], "1258": 45, "1276": 45, "059": 45, "plot_3_reliability_cl": [45, 52], "empir": [46, 73, 77, 96, 101, 107], "coverag": [46, 55, 107], "averag": [46, 64, 69, 73, 74, 76, 78, 79, 80, 81, 82, 83, 89, 92, 93, 94, 95, 98, 100, 101, 104, 107, 113, 114], "alpha": [46, 47, 48, 49, 50, 54, 55, 67, 69, 101, 102, 103, 107, 120, 121], "8892": 46, "2373": 46, "051": 46, "plot_3_reliability_reg": [46, 52], "default": [47, 54, 55, 61, 62, 63, 64, 65, 67, 69, 72, 76, 81, 82, 83, 86, 88, 89, 93, 94, 98, 100, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "robustness_perf": [47, 48, 54, 55, 67, 69, 103, 107], "custom": [47, 48, 51, 54, 59, 61, 62, 65, 90, 99, 107, 110, 111, 113, 114, 122, 123], "perturn": [47, 48], "perturb_featur": [47, 48, 54, 67, 69, 103, 107], "size": [47, 48, 64, 67, 69, 74, 76, 81, 86, 93, 94, 95, 100, 103, 104, 107, 108, 109, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123], "perturb_s": [47, 48, 67, 69, 103, 107], "perturb_method": [47, 48, 67, 69, 103, 107], "worst": [47, 48, 49, 50, 54, 55, 101, 102, 107], "percent": [47, 48, 54, 55], "robustness_perf_worst": [47, 48, 54, 55, 67, 69, 103, 107], "448": 47, "plot_4_robustness_cl": [47, 52], "being": [48, 78, 82, 83, 86, 95, 99, 101, 102], "perturb": [48, 54, 67, 69, 80, 86, 107], "224": 48, "plot_4_robustness_reg": [48, 52], "scenario": [49, 50, 54, 55, 86, 102], "resilience_perf": [49, 50, 54, 55, 67, 69, 102, 107], "resilience_method": [49, 50, 54, 55, 67, 69, 102, 107], "hard": [49, 50, 67, 69, 93, 98, 102, 107, 118, 119], "outer": [49, 50, 67, 69, 73, 102, 107, 108, 109], "cluster": [49, 50, 67, 69, 73, 89, 102, 107], "margin": [49, 50, 74, 80, 83, 86, 91, 92, 93, 107, 113, 114], "resilience_dist": [49, 50, 54, 55, 102, 107], "noneimmut": 49, "immu_featur": [49, 50, 54, 55, 67, 69, 102, 107], "n_cluster": [49, 50, 67, 69, 102, 107], "resilience_shift_histogram": [49, 50, 102, 107], "resilience_shift_dens": [49, 50, 102, 107], "229": 49, "plot_5_resilience_cl": [49, 52], "immut": [50, 102, 107], "009": 50, "plot_5_resilience_reg": [50, 52], "simucredit": [51, 56, 64, 68, 72, 107], "race": [51, 56, 63, 64, 68, 99], "gender": [51, 56, 64, 68, 99], "approv": [51, 56, 64], "mono_increasing_list": [51, 95, 96, 113, 114, 122, 123, 124, 125], "mortgag": [51, 64, 72, 99, 107], "balanc": [51, 56, 64, 68, 95, 99, 107, 120], "mono_decreasing_list": [51, 95, 113, 114, 122, 123, 124, 125], "amount": [51, 64, 99], "past": [51, 64, 99], "due": [51, 64, 76, 77, 86, 90, 93, 96, 99, 103, 104], "util": [51, 64, 89, 98, 107], "delinqu": [51, 64], "inquiri": [51, 64], "open": [51, 64, 86], "trade": [51, 64, 99, 107], "xgb2_monoton": [51, 99], "metrics_result": [51, 56, 68, 99], "model_fair": [51, 64, 99, 107], "air": [51, 56, 64, 68, 99, 107], "group_categori": [51, 56, 68, 99, 107], "reference_group": [51, 56, 68, 99, 107], "protected_group": [51, 56, 68, 99, 107], "favorable_threshold": [51, 56, 68, 99, 107], "performance_metr": [51, 99, 107], "group": [51, 56, 63, 64, 80, 93, 99, 101, 107], "index": [51, 56, 77, 78, 89, 93, 107, 108, 109, 113, 114, 120, 121], "categori": [51, 56, 63, 64, 71, 78, 92, 99, 103, 107, 113, 114], "refer": [51, 56, 58, 63, 64, 72, 78, 81, 89, 90, 92, 95, 99, 101, 104, 107, 120, 121], "protect": [51, 56, 63, 64, 99, 107], "603728": 51, "745063": 51, "segment": [51, 56, 63, 64, 66, 71, 72, 86, 97, 104, 107], "segmented_result": [51, 56, 68, 99], "segmented_featur": [51, 56, 68, 99, 107], "segmented_bin": [51, 56, 68, 99, 107], "lower": [51, 56, 64, 79, 90, 101, 104], "bound": [51, 56, 88, 98, 104], "upper": [51, 56, 72, 76, 88, 104, 107], "306": [51, 56], "451200": 51, "663992": 51, "601": [51, 56], "477974": 51, "640716": 51, "47": [51, 56], "1027": [51, 56], "623723": 51, "657706": 51, "1864": [51, 56], "639482": 51, "776867": 51, "94": [51, 56], "20384": [51, 56], "87": [51, 56], "849147": 51, "815034": 51, "binning_result": [51, 99, 122, 123], "binning_dict": [51, 99, 107], "id": [51, 89, 92, 94], "configur": [51, 79, 107], "715171": 51, "000368": 51, "003484": 51, "505151": 51, "000873": 51, "998020": 51, "506629": 51, "003422": 51, "979733": 51, "511253": 51, "003826": 51, "940766": 51, "522427": 51, "580318": 51, "988035": 51, "360787": 51, "584574": 51, "975176": 51, "364127": 51, "591296": 51, "934952": 51, "373758": 51, "600570": 51, "839246": 51, "400689": 51, "419545": 51, "011075": 51, "397111": 51, "423988": 51, "997716": 51, "400796": 51, "442289": 51, "959378": 51, "410201": 51, "469471": 51, "865747": 51, "437757": 51, "460530": 51, "996881": 51, "421800": 51, "463408": 51, "987163": 51, "424344": 51, "480924": 51, "951194": 51, "433464": 51, "506623": 51, "868160": 51, "457202": 51, "472251": 51, "999380": 51, "411107": 51, "476458": 51, "988062": 51, "414268": 51, "489755": 51, "954747": 51, "422231": 51, "509819": 51, "878128": 51, "444284": 51, "thresholding_result": [51, 99], "331291": 51, "883245": 51, "6765": 51, "892292": 51, "433": [51, 52], "plot_6_fair": [51, 52], "auto_examples_test": 52, "model_compar": [54, 55, 61, 62, 65, 67, 69, 86, 107], "historgram": [54, 55, 67, 69], "slice": [54, 55, 67, 69, 86, 100, 102, 104, 107], "reliability_bandwidth": [54, 55, 67, 69, 107], "565": 54, "plot_0_compare_classif": [54, 57], "xgboost": [55, 64, 74, 86, 87, 99, 104, 105, 107, 128], "xgbregressor": 55, "xgb7": [55, 64, 67, 69], "reliability_coverag": [55, 69, 107], "plot_0_compare_regress": [55, 57], "model_fairness_compar": [56, 64, 68, 107], "glm_air": 56, "ebm_air": 56, "712368": 56, "647789": 56, "832585": 56, "781610": 56, "825086": 56, "439287": 56, "901729": 56, "703873": 56, "689973": 56, "545624": 56, "745220": 56, "642129": 56, "633800": 56, "687002": 56, "591785": 56, "701057": 56, "613486": 56, "721803": 56, "602803": 56, "826708": 56, "748971": 56, "890700": 56, "714674": 56, "835029": 56, "151": [56, 57], "plot_1_compare_fair": [56, 57], "auto_examples_testing_compar": 57, "comparison": [57, 58, 60, 70, 86, 107, 108, 110, 116, 117, 120, 128], "welcom": 58, "scikit": [58, 72, 74, 76, 79, 81, 82, 86, 92, 93, 99, 105, 107, 116, 117, 120, 121], "learn": [58, 61, 62, 65, 66, 69, 72, 74, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 113, 114, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "instal": [58, 76, 86, 126], "api": [58, 63, 67, 69, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105], "class": [58, 64, 92, 98, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "pipelin": [58, 85, 86, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 128], "post": [58, 61, 62, 65, 82, 86, 107, 128], "hoc": [58, 61, 62, 65, 82, 86, 107, 128], "explain": [58, 60, 74, 78, 79, 80, 81, 82, 83, 86, 87, 95, 98, 107, 108, 109, 128], "outcom": [58, 60, 86, 99, 107], "user": [58, 71, 74, 76, 86, 89, 96, 98, 99, 103, 104, 106], "guid": [58, 86, 98, 106], "introduct": [58, 76, 93, 128], "black": [58, 86, 88, 93, 96, 128], "case": [58, 63, 64, 80, 82, 89, 92, 95, 98, 102, 103, 108, 109, 120, 121, 128], "studi": [58, 128], "conclus": [], "frequent": 58, "ask": 58, "question": 58, "how": [59, 61, 62, 65, 67, 69, 73, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103, 104], "can": [59, 62, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 111, 114, 119, 120, 121, 123, 125], "read": [59, 86], "regist": [59, 61, 63, 64, 65, 86, 89, 91, 92, 107, 128], "my": 59, "own": [59, 72, 120], "frame": 59, "get": [59, 64, 69, 73, 74, 75, 76, 77, 78, 80, 83, 88, 89, 90, 91, 92, 93, 95, 96, 99, 101, 103, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "chapter": 60, "includ": [60, 62, 65, 67, 69, 71, 72, 73, 76, 77, 86, 88, 90, 91, 94, 95, 96, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "multipl": [60, 66, 71, 83, 86, 89, 91, 95, 101, 104, 107], "low": [60, 61, 62, 64, 65, 68, 72, 82, 83, 86, 90, 94, 98, 107], "experiment": [60, 86, 107], "intepret": 60, "diagnost": [58, 60, 66, 98, 107, 128], "benchmark": 60, "californiah": [60, 90, 128], "simul": [60, 72, 80, 83, 90, 95, 99, 103, 107, 128], "ml": [60, 72, 86, 107], "": [60, 61, 67, 73, 76, 78, 79, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "descript": [60, 72, 86, 107], "demonstr": [61, 62, 63, 64, 65, 67, 69, 76, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104], "its": [61, 62, 65, 68, 69, 74, 75, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103, 104, 113, 114, 120], "mode": [61, 62, 65, 67, 72, 82, 86, 107, 113, 114, 120], "develop": [61, 62, 65, 69, 72, 78, 79, 80, 81, 82, 83, 86, 88, 91, 92, 93, 95, 96, 98, 100, 101, 103, 104, 107], "machin": [61, 62, 65, 66, 69, 72, 76, 78, 79, 80, 81, 82, 83, 86, 87, 89, 91, 92, 94, 95, 96, 98, 99, 100, 101, 103, 104, 107, 128], "uci": [61, 65, 67, 69, 72, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103, 104, 107], "repositori": [61, 65, 67, 69, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103, 104], "which": [61, 62, 65, 67, 68, 69, 72, 74, 76, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 108, 110, 111, 113, 114, 118, 120, 121, 122, 123, 124, 125], "consist": [61, 62, 65, 69, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103, 104, 109, 111, 114, 119, 121, 123, 125], "389": [61, 69, 78, 79, 80, 81, 82, 83, 88, 91, 92, 95, 96, 98, 100, 101, 103, 104], "hourli": [61, 69, 78, 79, 80, 81, 82, 83, 88, 91, 92, 95, 96, 98, 100, 101, 103, 104], "rental": [61, 69, 78, 79, 80, 81, 82, 83, 88, 91, 92, 95, 96, 98, 100, 101, 103, 104], "capit": [61, 69, 78, 79, 80, 81, 82, 83, 88, 91, 92, 95, 96, 98, 100, 101, 103, 104], "system": [61, 69, 78, 79, 80, 81, 82, 83, 86, 88, 91, 92, 95, 96, 98, 100, 101, 103, 104], "see": [61, 62, 65, 68, 69, 74, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 120, 121], "detail": [61, 62, 65, 67, 69, 73, 74, 76, 84, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 99, 101, 106, 120, 121], "here": [61, 62, 65, 68, 71, 74, 75, 76, 78, 79, 81, 82, 88, 89, 90, 91, 92, 95, 96, 99, 100, 102], "The": [61, 62, 63, 64, 65, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "continu": [61, 62, 69, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 113, 114], "problem": [61, 62, 63, 64, 65, 67, 69, 72, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 120], "click": [61, 62, 63, 64, 65, 72, 105], "link": [61, 62, 63, 64, 65, 68, 71, 72, 73, 74, 75, 76, 77, 92, 99, 108, 109], "googl": [61, 62, 63, 64, 65, 72, 107], "colab": [61, 62, 63, 64, 65], "choos": [61, 62, 63, 64, 65, 72, 73, 74, 95, 103, 110, 111, 120, 121], "option": [67, 69, 77, 82, 83, 86, 93, 95, 100, 101, 102, 103, 104, 105, 107, 108, 109, 112, 113, 114, 115, 120, 121, 122, 123], "top": [75, 76, 77, 80, 88, 90, 91, 92, 93, 95, 96, 102, 113, 114], "percentag": 76, "98": [72, 107], "exploratori": [61, 62, 63, 64, 70, 107, 128], "need": [61, 74, 76, 77, 78, 79, 81, 83, 86, 89, 95, 96, 98, 99, 100, 101, 105], "specif": [61, 62, 65, 79, 81, 82, 86, 91, 93, 94, 95, 96, 98, 99, 106, 107, 120, 121], "inher": [61, 62, 65, 86, 91, 93, 96, 107], "pairwis": [61, 62, 65, 76, 78, 86, 88, 91, 96, 113, 114], "640": [62, 89, 90, 94, 102], "fetch": [62, 89, 90, 94, 102], "sklearn": [62, 76, 85, 86, 89, 90, 92, 94, 99, 101, 102, 107, 120, 121], "three": [62, 67, 71, 73, 76, 86, 91, 92, 98, 99, 100, 102, 103, 104], "version": [62, 86, 101, 108, 109, 111, 114, 119, 120, 121, 123, 125], "_raw": 62, "_trim1": 62, "trim": [62, 72], "onli": [62, 65, 74, 75, 77, 80, 82, 83, 86, 88, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 111, 113, 114, 120, 121], "aveoccup": [62, 72, 89, 90, 95, 107], "_trim2": 62, "averoom": [62, 72, 95, 107], "avebedrm": [62, 72, 107], "popul": [62, 72, 77, 80, 92, 95, 104, 107], "price": [62, 90], "per": [62, 78, 83, 88, 93, 108, 109, 113, 114, 122, 123, 124, 125], "block": [62, 113, 114], "log": [62, 81, 92, 95, 113, 114, 120], "Then": [62, 76, 85, 93, 102, 104], "l1": [62, 92, 93, 116, 117, 118, 119, 121, 122, 123, 124, 125], "reigster": 62, "integr": [63, 80, 81, 86, 88, 92, 93], "sola": [63, 72, 105, 107], "ai": [63, 72, 86, 105, 107], "solassimu1": [63, 72, 107], "modifi": [63, 72, 88, 107], "demo": [63, 100, 104, 107, 113, 114], "covari": [63, 72, 74, 76, 86, 103, 107], "ar": [63, 67, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "x5": [63, 72, 107], "label": [63, 67, 72, 98, 104, 107, 108, 109, 110, 111, 113, 118, 119, 120, 121, 122, 124], "binari": [63, 64, 65, 67, 69, 72, 76, 80, 81, 82, 83, 86, 90, 92, 93, 94, 95, 97, 102, 103, 107, 110, 111], "rest": [63, 72, 78, 79, 82, 88, 89, 91, 95, 101, 102, 103, 107], "demograph": [63, 64, 72, 99, 107], "contribut": [63, 72, 73, 79, 80, 82, 83, 90, 92, 95, 107, 108, 109, 112, 115, 122, 123], "minor": [63, 88], "major": 63, "grei": [63, 64], "color": [63, 64, 89], "when": [63, 64, 73, 74, 76, 78, 79, 80, 82, 83, 89, 91, 92, 93, 94, 96, 98, 100, 102, 103, 104, 107, 109, 111, 112, 113, 114, 115, 118, 119, 120, 121, 123, 125], "finish": 63, "suggest": [63, 78, 81, 83, 86, 90, 92, 98, 102], "procudur": 63, "add": [63, 64, 67, 69, 86, 96, 103, 107], "By": [63, 67, 69, 76, 77, 79, 80, 82, 86, 88, 89, 90, 92, 93, 94, 95, 98, 100, 101, 102, 103, 104, 120, 121], "enter": 63, "button": [63, 64, 72], "switch": [63, 95, 104], "other": [63, 65, 74, 75, 76, 78, 79, 81, 83, 86, 89, 90, 91, 92, 95, 101, 104], "view": [63, 68, 76, 81, 82, 83, 88, 89, 91, 94, 98], "breakdown": 63, "model_fairness_sola": [63, 107], "we": [64, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 113, 114], "decis": [64, 72, 74, 80, 83, 86, 87, 89, 99, 104, 107, 120, 121, 128], "hypothes": 64, "statu": [64, 104, 118, 119], "well": [64, 67, 69, 76, 89, 90, 92, 94, 95, 96, 98, 100, 101, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "indic": [64, 67, 78, 79, 81, 82, 83, 88, 89, 90, 91, 92, 93, 95, 96, 98, 102, 103, 104, 107, 108, 109, 113, 114, 120, 121, 122, 123, 124, 125], "20k": 64, "num": 64, "applic": [64, 72, 76, 86, 107], "last": [64, 67, 73, 76, 78, 102, 105, 113, 114, 118, 119], "month": 64, "card": [64, 65, 67, 72, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104, 107], "minimum": [64, 74, 86, 95, 98, 100, 104, 105, 108, 109, 110, 111, 120, 121, 122, 123, 124, 125], "requir": [64, 67, 69, 74, 76, 78, 81, 83, 86, 88, 92, 96, 98, 100, 101, 103, 104, 108, 109, 110, 111, 113, 118, 119, 120, 121, 122, 123, 124, 125], "payment": [64, 65], "wa": [64, 74, 102], "appli": [64, 67, 69, 83, 93, 95, 103, 120, 121], "account": [64, 83, 95], "date": 64, "ordin": [64, 73, 95, 107], "current": [64, 105, 120, 121], "dai": [64, 78, 79, 81, 88, 91, 98], "so": [64, 80, 82, 83, 89, 90, 92, 96, 99, 100, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "number": [64, 67, 73, 74, 75, 76, 77, 78, 82, 83, 88, 89, 90, 93, 95, 98, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "sum": [64, 73, 74, 76, 77, 86, 87, 88, 90, 91, 92, 93, 95, 96, 104, 107, 108, 109, 110, 111, 114, 119, 120, 121, 123, 125, 128], "divid": [64, 71, 74, 78, 88, 91, 94, 96, 98, 104], "limit": [64, 76, 77, 78, 81, 89, 90, 93, 94], "cannot": [64, 76, 92, 99, 101], "kind": [64, 73, 99], "should": [64, 76, 78, 81, 82, 86, 93, 98, 99, 100, 101, 104, 107, 108, 109, 112, 113, 114, 115, 120, 121, 122, 123], "nearli": [64, 72, 107], "depth2": 64, "manual": [64, 86, 90, 95, 113, 114], "depth7": 64, "xgbclassifi": 64, "To": [64, 73, 74, 76, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 120, 121], "e": [64, 76, 77, 78, 79, 81, 83, 86, 88, 89, 90, 91, 92, 93, 95, 96, 98, 100, 102, 103, 104, 107], "g": [64, 76, 83, 86, 88, 89, 90, 91, 92, 95, 96, 101, 104], "favor": [64, 91, 107], "defaut": 64, "If": [64, 74, 78, 81, 85, 89, 92, 95, 99, 101, 104, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "find": [64, 88, 91, 93, 95, 98, 100, 101, 102, 120, 121], "higher": [64, 81, 89, 90, 98, 101], "debias": 64, "unfair": [64, 68, 99], "mitig": [64, 76, 100], "an": [64, 67, 68, 69, 71, 74, 75, 76, 78, 79, 80, 81, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 118, 119, 120, 121, 124, 125], "repeat": [64, 76, 80, 82, 96, 112, 115], "mani": [64, 78, 86, 92, 93, 98, 120, 121], "differ": [64, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 86, 88, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 120, 121], "clear": [64, 78], "could": [64, 72, 74, 75, 83, 91, 113, 114], "remov": [64, 74, 75, 76, 82, 83, 92, 93, 96, 99, 107, 120, 121], "record": [64, 67, 69, 79, 82, 103, 104, 122, 123], "adjust": [64, 78, 94, 99, 101, 120], "vari": [64, 79, 80, 102, 103, 120, 121], "For": [64, 67, 69, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 104, 107, 109, 111, 113, 114, 119, 120, 121, 123, 125], "both": [64, 69, 71, 73, 76, 78, 79, 82, 83, 86, 88, 89, 90, 91, 92, 95, 96, 113, 114, 120], "good": [64, 88, 93, 98, 102, 104], "client": [65, 67, 72, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104, 107], "200504": 65, "200509": 65, "subject": [65, 76, 86, 92, 104, 113, 114, 122, 123, 124, 125], "slight": 65, "preprocess": [65, 67, 72, 88, 89, 92, 96, 98, 100, 101, 103, 104, 107], "histori": [65, 113, 114], "keep": [65, 78, 82, 93, 103, 109, 111, 114, 119, 121, 123, 125], "while": [65, 76, 78, 79, 82, 83, 86, 88, 89, 90, 91, 92, 93, 95, 98, 99, 100, 102, 103, 120, 121], "l1_regular": 65, "compar": [66, 67, 68, 69, 74, 76, 77, 78, 80, 86, 89, 90, 91, 92, 95, 98, 99, 100, 101, 102, 104, 107], "section": [67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 83, 93, 94, 98, 99, 103], "variou": [67, 69, 83, 86, 88, 91, 92, 98, 102, 104, 105, 107], "perspect": [67, 69, 88], "done": [67, 69, 78, 80, 96, 100, 101, 102, 104], "function": [67, 69, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 101, 103, 106, 108, 109, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "consid": [67, 69, 81, 82, 83, 86, 91, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 108, 109, 110, 111, 120, 121], "chosen": [67, 69, 89, 90, 91, 95, 104, 107, 120, 121], "chart": [67, 69, 71, 81, 92, 98], "below": [67, 69, 74, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107], "As": [67, 76, 77, 78, 82, 83, 88, 90, 91, 92, 93, 94, 95, 96, 98, 101, 102, 103, 104, 107, 113, 114], "legend": 67, "have": [67, 68, 69, 77, 78, 79, 81, 82, 83, 85, 86, 88, 89, 90, 91, 93, 94, 98, 100, 101, 102, 103, 104, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "similar": [67, 68, 69, 74, 76, 78, 79, 80, 83, 88, 89, 90, 91, 93, 95, 96, 98, 100, 101, 102, 104, 113, 114], "ha": [67, 77, 78, 80, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 100, 102, 107, 120, 121], "slightli": [67, 76, 88, 91, 96, 102], "better": [67, 68, 71, 74, 79, 82, 88, 93, 94, 95, 98, 99, 101, 102, 104], "under": [67, 69, 74, 76, 86, 92, 98, 102, 103, 104, 107, 110, 111, 120, 121], "region": [67, 69, 86, 93, 100, 104, 107], "detect": [67, 69, 74, 86, 88, 100, 104, 107, 108, 109], "algorithm": [67, 69, 74, 76, 84, 86, 88, 89, 93, 94, 96, 97, 107, 110, 111, 120, 121, 122, 123, 124, 125], "found": [67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 88, 89, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 120, 121], "keyword": [67, 69, 76, 78, 80, 81, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 101, 102], "follow": [67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 107, 120, 121], "argument": [67, 69, 76, 77, 80, 81, 82, 83, 89, 91, 95, 98, 100, 101, 103, 104, 120, 121], "instead": [67, 69, 76, 78, 81, 83, 86, 88, 89, 92, 95, 96, 98, 101, 102, 104, 109, 111, 114, 119, 120, 121, 123, 125], "string": [67, 69, 107, 113, 114, 120, 121], "repres": [67, 69, 71, 73, 74, 76, 78, 79, 80, 81, 83, 89, 90, 92, 93, 94, 95, 96, 98, 102, 103, 104, 118, 119], "illustr": [67, 69, 78, 79, 81, 83, 95, 96, 98, 102, 103], "metricmetr": [67, 69], "interv": [67, 69, 78, 93, 101], "classfic": 67, "quantifi": [67, 83, 101], "squar": [67, 74, 76, 92, 93, 98, 104, 109, 111, 114, 117, 119, 121, 123, 125], "hat": [67, 76, 78, 79, 81, 88, 89, 90, 91, 95, 96, 98, 101], "p": [67, 77, 81, 83, 95, 99, 101, 103, 107], "henc": [67, 74, 76, 88, 93, 95, 103], "prediciton": [67, 69, 79], "invert": [67, 69], "shown": [67, 76, 77, 78, 83, 88, 89, 91, 92, 93, 94, 96, 98, 101, 103], "actual": [67, 88, 90, 91, 93, 94, 95, 96, 98, 102, 113, 114], "input": [67, 69, 72, 74, 78, 79, 80, 81, 82, 83, 91, 92, 93, 98, 102, 103, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "normal": [67, 69, 74, 76, 83, 89, 90, 92, 93, 95, 96, 103, 107, 110, 111, 113, 114, 120, 121], "nois": [67, 69, 80, 86, 103, 107], "step": [67, 69, 72, 74, 76, 82, 83, 88, 89, 91, 93, 94, 95, 96, 100, 102, 103, 104, 107, 110, 111], "In": [67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 108, 110, 113, 114, 118, 120, 122, 124], "abov": [67, 69, 76, 78, 81, 82, 83, 88, 90, 91, 93, 95, 96, 98, 101, 102, 103, 104], "On": [67, 69, 78, 89, 103, 104], "axi": [67, 69, 80, 83, 88, 89, 91, 92, 93, 95, 96, 101, 102, 103, 104, 107], "y": [67, 69, 73, 76, 80, 83, 85, 88, 89, 90, 91, 92, 93, 95, 96, 98, 99, 101, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "best": [67, 69, 95, 96, 98, 109, 110, 111, 113, 114, 119, 120, 121, 123, 125], "proport": [67, 69, 77, 92, 98, 101, 103, 120], "unperturb": [67, 69], "also": [67, 69, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 101, 102, 103, 113, 114, 120, 121], "most": [67, 69, 76, 79, 80, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 100, 105, 107, 113, 114], "resilience_perf_worst": [67, 69], "kmean": [67, 69, 73, 74, 102, 107], "high": [67, 69, 72, 76, 78, 79, 80, 81, 82, 83, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103, 104, 107, 120, 121], "compris": [67, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "april": [67, 86, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "2005": [67, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "septemb": [67, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "more": [67, 68, 74, 76, 79, 81, 82, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 120, 121], "taiwancreditdata": [67, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "websit": [67, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "directli": [67, 82, 83, 88, 92, 93, 95, 96, 98, 100, 101, 102, 103, 104, 105, 107], "although": [67, 68, 78, 88, 91, 92, 96, 98, 100, 101, 103, 104], "some": [67, 76, 81, 82, 88, 90, 91, 92, 93, 95, 96, 98, 100, 101, 102, 103, 104, 107, 109, 111, 113, 114, 119, 121, 123, 125], "serv": [67, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "introduc": [68, 72, 73, 76, 83, 90, 93, 99, 101], "modul": [68, 72, 73, 76, 85, 86, 92, 94, 99, 105, 107, 113, 114], "becaus": [68, 74, 78, 80, 92, 95, 98, 102, 109, 111, 114, 119, 121, 123, 125], "complex": [68, 81, 88, 89, 90, 93, 94, 95, 104, 120, 121], "much": [68, 73, 78, 79, 83, 89, 92, 98, 102, 103], "But": [68, 74, 120, 121], "you": [68, 72, 73, 75, 76, 80, 83, 85, 86, 88, 90, 91, 92, 94, 95, 96, 99, 102, 103, 105, 107, 108, 110, 113, 118, 120, 121, 122, 124], "than": [68, 74, 75, 76, 78, 79, 80, 81, 83, 86, 89, 90, 92, 93, 95, 96, 98, 100, 101, 102, 103, 104, 107, 110, 111, 113, 114, 120, 121], "got": [68, 74, 105], "especi": [68, 76, 89, 90, 92, 110, 111, 120, 121], "larg": [68, 76, 80, 83, 89, 92, 93, 98, 100, 102, 113, 114, 118, 119], "area": [68, 90, 98, 99, 102], "That": [68, 74, 78, 98, 102, 103, 104, 120, 121], "peopl": [68, 96], "boxplot": 69, "mark": [69, 76, 92, 93, 102], "circl": 69, "thei": [69, 74, 76, 81, 83, 86, 88, 92, 95, 96, 99, 102, 120, 121], "outperform": 69, "absolut": [69, 76, 77, 83, 92, 93, 98, 107, 121], "purpos": [69, 76, 78, 81, 83, 86, 92, 96, 99, 101, 102, 104], "outsid": [69, 78, 81, 101, 107], "extern": [70, 107], "statist": [70, 76, 77, 79, 86, 92, 93, 107], "support": [71, 72, 73, 74, 78, 83, 86, 95, 96, 99, 102, 103, 105, 107, 110, 111, 120, 121], "understand": [71, 73, 79, 86, 90, 92, 93, 95], "graphic": [71, 79, 86], "represent": [71, 90, 91, 93, 96, 110, 111], "frequenc": [71, 75, 101, 120], "relationship": [71, 74, 76, 78, 79, 81, 82, 83, 90, 92, 93, 95, 98, 101, 103], "combin": [71, 76, 83, 89, 92], "collect": [71, 74, 89, 95, 96], "point": [71, 74, 76, 78, 80, 83, 90, 93, 95, 98, 103, 104, 107, 110, 111, 113, 114, 120, 121, 122, 123, 124, 125], "dimension": [71, 74, 92], "within": [71, 73, 89, 94, 96, 103, 107, 113, 114, 120, 121], "There": [71, 72, 86, 92, 99], "approach": [71, 72, 76, 83, 86, 89, 92, 100, 102, 103], "usual": [72, 78, 82, 83, 86, 89, 99, 102, 104, 107], "whole": [72, 104], "put": [72, 83, 85], "sever": [72, 74, 83, 91, 95, 107, 120, 121], "classic": 72, "gaussian": [72, 74, 76, 92, 103, 107], "spheric": [72, 107], "archiv": [72, 107], "edu": [72, 107], "californiahousing_raw": [72, 85, 107], "crash": [72, 107], "cours": [72, 107], "californiahousing_trim1": [72, 107], "trime": [72, 107], "A": [72, 76, 81, 86, 90, 92, 93, 98, 102, 103, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 123, 125], "solasai": [72, 107], "dispar": [72, 86, 98, 99, 107], "solashmda": [72, 107], "2018": [72, 83, 86, 107], "home": [72, 89, 90, 94, 102, 107], "disclosur": [72, 107], "act": [72, 107], "hmda": [72, 107], "about": [72, 78, 86, 107], "everi": [72, 107, 112, 115, 120], "unit": [72, 92, 93, 107], "easili": [72, 74, 86, 89], "just": [72, 78, 83], "upload": 72, "new": [72, 74, 86, 89, 90, 101, 120, 121], "wrap": [72, 76], "allow": [73, 81, 83, 90, 95, 107, 112, 115, 120, 121], "procedur": [73, 76, 95], "like": [73, 74, 78, 86, 88, 91, 93, 98, 99, 104, 107, 108, 109, 110, 111, 113, 114, 118, 119, 120, 121, 122, 123, 124, 125], "And": [73, 74, 98, 99, 113, 114], "seed": [73, 107, 110, 111, 113, 114, 122, 123, 124, 125], "decid": [73, 74, 107], "besid": 73, "euclidean": [73, 76, 102, 107], "farthest": 73, "awai": 73, "after": [73, 74, 78, 85, 86, 93, 99, 100, 105, 112, 113, 114, 115, 122, 123], "do": [73, 78, 82, 83, 92, 100, 101, 102, 104, 120, 121], "list": [73, 76, 86, 91, 93, 99, 100, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "relat": [73, 74, 76, 77, 89, 91, 95, 96, 101, 102, 105, 107, 120, 121], "overal": [73, 76, 78, 86, 89, 92, 94, 102, 122, 123], "measur": [73, 74, 76, 77, 82, 92, 95, 98, 101, 102, 120, 121], "edf": 73, "ed": 73, "2t": 73, "n": [73, 74, 76, 78, 81, 83, 98, 99, 101, 120, 121], "d": [73, 76, 90, 92, 93], "observ": [73, 74, 76, 79, 81, 88, 89, 90, 91, 92, 96, 98, 99, 101, 103], "term": [73, 80, 83, 86, 89, 90, 92, 93, 96, 108, 109, 110, 111, 112, 122, 123, 124, 125], "cross": [73, 76], "befor": [73, 76, 92, 108, 109, 113, 114, 118, 119, 120, 121, 124], "did": 73, "encod": [73, 86, 92, 95, 107], "scaler": [73, 112, 113, 114, 115, 122, 123], "transform": [73, 74, 76, 83, 90, 93, 95, 103], "process": [74, 75, 80, 81, 86, 89, 93, 94, 95, 96, 99, 100, 104, 108, 109, 120, 121], "valid": [74, 76, 86, 91, 101, 108, 109, 113, 114, 118, 119, 120, 121], "kei": [74, 81, 88, 90, 91, 95, 99, 103], "characterist": 74, "match": [74, 105], "what": [74, 120, 121], "anticip": 74, "prior": 74, "consumpt": 74, "focu": [74, 79, 92, 100, 104], "help": [74, 76, 81, 83, 90, 92, 93, 95, 98, 102], "locat": 74, "randomli": [74, 80, 82, 83, 120, 121], "maximum": [74, 76, 77, 88, 89, 94, 95, 96, 108, 109, 112, 115, 120, 121, 122, 123, 124, 125], "sinc": [74, 86, 89, 95, 103, 108, 110, 113, 118, 120, 122, 124], "recurs": [74, 81, 93, 94], "partit": [74, 79, 81, 120, 121, 122, 123, 124, 125], "structur": [74, 83, 86, 88, 91, 93], "equival": [74, 76, 93, 96, 102, 104], "path": [74, 83, 86, 89, 94, 107, 113, 114, 120, 121], "length": [74, 93, 108, 109, 112, 115], "termin": [74, 86, 121], "over": [74, 76, 78, 83, 88, 91, 96, 103, 118, 119], "our": [74, 79, 80, 82, 86, 89, 98, 101, 104], "produc": [74, 79, 101, 104], "notic": [74, 98], "shorter": 74, "anomali": 74, "particular": [74, 76, 83, 86, 90, 92, 93, 94, 95, 96, 101, 102], "highli": [74, 76, 78, 81, 83, 94, 95], "packag": [74, 76, 78, 79, 80, 81, 83, 86, 88, 89, 90, 92, 93, 95, 96, 105], "org": [76, 99], "stabl": [76, 90, 92, 95, 99], "ensembl": [74, 83, 89, 90, 100, 104], "isolationforest": [74, 107], "It": [74, 76, 77, 78, 80, 83, 86, 88, 89, 90, 91, 92, 94, 95, 96, 98, 101, 102, 104, 107, 113, 114, 118, 119, 120, 121], "extratreeregressor": 74, "less": [74, 78, 79, 81, 83, 90, 95, 98, 100, 101, 102, 103, 104, 107, 120, 121], "log_": 74, "build": 74, "liu": [74, 76], "et": [74, 86], "2008": 74, "propos": [74, 88, 89, 96], "he": [74, 86], "xu": 74, "deng": 74, "2002": 74, "uniqu": [74, 75, 86, 93, 95, 96, 99, 104, 120, 121], "merit": 74, "captur": [74, 76, 80, 88, 90, 91, 92], "formula": [74, 76, 78, 83, 93, 101], "broken": [74, 82], "down": [74, 78, 83], "dbscan": 74, "intra": 74, "larger": [74, 78, 79, 82, 89, 90, 92, 93, 98, 100, 107, 112, 113, 114, 115], "them": [74, 76, 89, 90, 95, 99, 102, 103, 104, 120, 121], "centroid": 74, "inter": 74, "smaller": [74, 76, 89, 93, 94, 95, 98, 101, 102, 103, 104, 107, 113, 114, 120, 121], "nearest": [74, 100, 103], "multipli": [74, 101, 120], "use_weight": 74, "clustering_method": 74, "mixtur": [74, 76], "reduct": [74, 83, 120, 121, 122, 123, 124, 125], "implement": [74, 76, 79, 80, 89, 92, 93, 101, 102, 110, 111], "spars": [74, 92, 120, 121], "mahalanobi": 74, "error": [74, 86, 98, 102, 104, 105, 107, 121], "reconstruct": 74, "equal": [74, 83, 88, 90, 92, 93, 98, 99, 101, 102, 104, 107, 110, 111, 112, 113, 114, 115, 120, 121], "zero": [74, 76, 78, 82, 88, 89, 90, 92, 93, 96, 98, 108, 109, 120, 121], "standard": [74, 75, 76, 78, 86, 88, 92, 99, 107, 113, 114], "princip": [], "md": 74, "sqrt": [76, 101, 120, 121], "zi": [], "lambda_i": 76, "ith": [118, 119], "eigenvalu": 74, "varianc": [74, 83, 88, 89, 90, 91, 92, 95, 96, 98, 103, 113, 114, 121], "space": [74, 76, 77, 89, 90, 99, 104, 107], "give": [74, 82, 93, 95, 106, 113, 114], "u": [74, 78, 81, 82, 95, 101, 103, 104, 105, 109, 111, 114, 119, 121, 123, 125], "desir": [74, 95, 101], "regressor": [107, 109, 111, 114, 115, 117, 119, 121, 123, 125], "x_": [78, 79, 81, 88, 90, 91, 93, 95, 96, 101, 112, 113, 114, 115, 122, 123], "old": [], "x_new": [], "x_old": [], "absorb": [74, 92], "advantag": [74, 76, 86, 88, 89], "call": [74, 76, 78, 81, 86, 88, 92, 93, 95, 98, 105, 108, 109, 111, 114, 119, 121, 123, 125], "iter": [74, 76, 82, 88, 89, 93, 96, 107, 110, 111, 112, 113, 114, 115, 118, 119], "stop": [74, 76, 86, 89, 107, 108, 109, 110, 111, 113, 114, 118, 119, 120, 121], "until": [74, 88, 96, 120, 121], "certain": [74, 81, 83, 91], "met": 74, "wai": [74, 76, 83, 86, 90, 91, 93, 96, 107], "handl": [74, 76, 102], "sensit": [74, 83, 92, 93, 98, 99], "homogen": 74, "increas": [74, 76, 79, 82, 83, 86, 88, 90, 91, 92, 93, 95, 96, 102, 103, 113, 114, 122, 123, 124, 125], "improv": [74, 86, 95, 102, 104, 108, 109, 118, 119, 120, 121], "proper": 74, "defin": [74, 76, 79, 81, 82, 83, 93, 99, 101, 102, 107, 109, 111, 114, 119, 120, 121, 123, 125], "whether": [74, 76, 81, 89, 95, 107, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125], "visual": [74, 78, 79, 81, 86, 88, 89, 91, 92, 93, 96], "od": 74, "t": [74, 76, 77, 85, 107, 113, 114, 118, 119, 120, 121], "sne": [74, 107], "deduc": 74, "dimens": [74, 104], "summar": [75, 89, 98, 107], "basic": [75, 107], "meta": 75, "info": 75, "chang": [75, 76, 77, 79, 80, 86, 92, 93, 99, 102, 103], "provid": [75, 77, 79, 81, 82, 83, 86, 89, 91, 92, 93, 94, 95, 98, 102, 103, 104, 108, 109, 120, 121], "miss": [75, 83, 88], "deviat": [75, 99, 107, 113, 114], "third": [75, 93, 100, 102, 113, 114], "quanil": [], "highest": [75, 78, 83], "frequeci": [], "aim": [76, 78], "subset": [76, 79, 81, 94, 101, 108, 110, 113, 118, 120, 122, 124], "relev": [76, 79, 92, 94], "comput": [76, 78, 79, 81, 82, 83, 93, 95, 98, 99, 100, 101, 103, 107, 113, 114, 118, 119, 120, 121], "burden": 76, "avoid": [76, 92, 93, 100, 113, 114, 118, 119], "moreov": [76, 78, 83, 98], "reduc": [74, 76, 78, 82, 83, 89, 93, 96], "benefici": 76, "enhanc": [76, 86, 93, 98], "would": [76, 92, 93, 94, 98, 100, 102, 104, 109, 111, 113, 114, 119, 120, 121, 123, 125], "briefli": [76, 90, 93, 101, 103], "note": [76, 77, 78, 80, 81, 82, 83, 88, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 104, 107, 109, 111, 113, 114, 119, 120, 121, 123, 125], "treat": [76, 86, 102, 104], "howev": [76, 79, 80, 81, 82, 83, 86, 88, 89, 90, 92, 93, 95, 96, 98, 101, 104], "treatment": 76, "veri": [76, 78, 80, 82, 91, 100, 102, 113, 114, 118, 119], "rigour": 76, "mathemat": 76, "begin": [76, 77, 78, 79, 81, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 101, 102], "align": [76, 77, 78, 79, 81, 83, 88, 89, 90, 91, 92, 93, 95, 96, 98, 99, 101], "rho_": 76, "frac": [76, 77, 78, 81, 83, 95, 96, 98, 99, 101, 109, 111, 114, 119, 121, 123, 125], "sum_": [76, 78, 81, 83, 89, 93, 98, 99], "left": [76, 83, 88, 89, 91, 96, 98, 110, 111, 120, 121], "x_i": 76, "right": [76, 80, 83, 88, 89, 91, 92, 95, 96, 98, 110, 111, 120, 121], "y_i": 76, "rang": [76, 78, 89, 90, 93, 95, 96, 98, 99, 100, 102, 107], "sign": [76, 98], "denot": [76, 79, 82, 83, 93, 104], "direct": [76, 90, 92, 95], "magnitud": [76, 86, 92], "strength": [76, 90, 92, 93, 95, 107, 112, 113, 114, 115, 116, 117], "correspond": [76, 83, 88, 89, 90, 91, 92, 93, 95, 96, 100, 103, 104, 107, 118, 119, 120, 121], "straightforward": [76, 80, 81, 104], "greater": [76, 79, 98, 100, 101, 104, 107, 110, 111, 113, 114, 120, 121], "specifi": [76, 77, 78, 81, 82, 83, 86, 88, 89, 91, 92, 93, 95, 96, 98, 100, 101, 102, 103, 104, 107, 120, 122, 123, 124, 125], "These": [76, 104], "up": [76, 78, 86, 96, 100, 104, 107, 120, 121], "line": [76, 79, 86, 93, 98, 99, 101, 102, 104, 107], "command": [76, 86, 92, 105], "figur": [76, 77, 86, 88, 90, 91, 93, 95, 96, 101, 103, 107, 112, 113, 114, 115, 120, 121, 122, 123], "blue": [76, 83, 89], "orang": 76, "posit": [76, 88, 90, 91, 92, 93, 96, 98, 99, 107, 112, 113, 114, 115], "neg": [76, 78, 82, 88, 90, 91, 92, 95, 96, 98, 99, 109, 111, 112, 114, 115, 116, 117, 119, 120, 121, 123, 125], "contain": [76, 82, 89, 90, 92, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "bottom": [76, 80, 88, 90, 91, 95, 98], "text": 76, "highlight": [76, 94], "easi": [76, 86, 94, 107], "mai": [76, 78, 79, 80, 81, 83, 86, 88, 89, 90, 92, 93, 94, 95, 98, 99, 102, 103, 105, 106, 107, 109, 110, 111, 114, 119, 120, 121, 123, 125], "deal": [76, 98, 103, 113, 114, 118, 119], "complic": [76, 89, 93, 102], "rank": [76, 82, 86, 92, 95, 102, 107], "r_": 76, "mathrm": [76, 79, 81, 95], "r": [76, 86, 93, 98, 99, 109, 111, 113, 114, 119, 121, 123, 125], "d_i": 76, "describ": [76, 78, 81, 103], "monoton": [76, 81, 91, 93, 95, 96, 99, 102, 113, 114, 122, 123, 124, 125], "perfect": 76, "occur": [76, 96], "assum": [76, 81, 82, 83, 85, 90, 92, 93, 94, 101, 103, 113, 114], "except": [76, 83, 90, 96, 109, 111, 114, 119, 121, 123, 125], "replac": [76, 83, 99], "pair": [76, 96, 99, 113, 114, 120], "vector": [76, 78, 83, 93, 96, 118, 119], "advanc": [76, 86], "a_": 76, "j": [76, 78, 83, 88, 90, 91, 92, 95, 96], "x_j": [76, 88, 92], "x_k": 76, "quad": 76, "ldot": [76, 83, 90, 92, 93, 101, 102], "b_": 76, "y_j": 76, "y_k": 76, "matric": 76, "_": [76, 77, 78, 79, 81, 88, 91, 96, 98, 101], "cdot": [76, 92, 98], "b": [76, 77, 86, 93, 101, 102, 103, 113, 114], "arithmet": 76, "product": [76, 113, 114], "dcov": 76, "final": [74, 76, 78, 79, 82, 83, 88, 90, 91, 93, 95, 96, 98, 101, 103, 122, 123], "dvar": 76, "operatornam": 76, "determin": [76, 77, 81, 83, 89, 90, 98, 100, 101, 104, 107, 109, 111, 114, 118, 119, 121, 123, 125], "alwai": [76, 90, 98, 100, 109, 111, 114, 119, 120, 121, 123, 125], "don": [76, 77, 85, 120, 121], "take": [76, 83, 86, 88, 91, 95, 96, 100], "li": [76, 86, 96], "flexibl": [76, 82, 86, 90, 91, 95, 104], "computation": 76, "expens": [76, 107], "make": [76, 79, 80, 82, 86, 88, 90, 91, 92, 93, 94, 96, 98, 113, 114, 122, 123, 124, 125], "scalabl": [76, 113, 114], "big": 76, "downsampl": [76, 83, 100], "statsmodel": [76, 105], "altern": [76, 77, 78, 83, 103, 120, 121], "automat": [76, 86, 95, 107, 108, 109, 120], "speed": 76, "consider": 76, "compos": 76, "fit": [74, 76, 78, 79, 80, 81, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 128], "sort": [76, 102, 103], "descend": [76, 93, 102], "order": [76, 78, 86, 90, 92, 93, 95, 102, 104, 112, 113, 114, 115, 120], "pre": [76, 83, 86, 101, 108, 109], "inspect": [76, 86, 99, 120, 121], "permutation_import": [76, 82, 120, 121], "potenti": [76, 90, 121], "concern": 76, "noisi": [76, 103], "thu": [76, 89], "incorrect": [76, 98, 103, 104], "identifi": [76, 79, 83, 86, 90, 92, 95, 96, 98, 100, 102, 103, 104, 107], "minim": [76, 107, 120, 121], "power": [76, 86, 93, 94, 95], "probabilist": 76, "incorpor": [76, 91], "z": [76, 83, 93, 96], "goal": [76, 83, 86], "perp": 76, "mid": 76, "kcit": 76, "zhang2012": 76, "kernel": [76, 83, 109, 111, 114, 119, 121, 123, 125], "work": [76, 81, 83, 86, 95, 99, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "arbitrari": [76, 86, 92, 101, 107, 128], "strobl2019": 76, "fast": [76, 86, 87, 88, 91, 93, 107, 110, 111, 128], "approxim": [76, 81, 83, 88, 89, 91, 95, 98, 102], "fourier": [76, 107], "reproduc": 76, "hibert": 76, "therefor": [76, 78, 80, 83, 92, 93, 103], "null": [76, 98], "hypothesi": 76, "sigma_": 76, "sigma": [76, 93, 99], "_f": 76, "gamma": [76, 95, 96, 122, 123, 124, 125], "asymptot": 76, "z_i": 76, "lindsai": 76, "pilla": 76, "basak": 76, "lpb": 76, "lindsayl2000": 76, "cdf": 76, "finit": 76, "borboudakis2019": 76, "elimin": 76, "conduct": 76, "further": [74, 76, 91, 95, 100, 101, 106, 122, 123, 124, 125], "delet": 76, "insignific": 76, "predefin": 76, "remain": [76, 79, 80, 83, 92, 93, 103], "candid": [76, 91], "p_valu": 76, "among": [76, 83, 92, 99, 120, 121], "signific": [76, 82, 83, 86, 88, 91, 100, 101, 102], "ad": [76, 96, 98, 103, 113, 114], "phase": [76, 118, 119], "charact": 76, "recommend": [76, 93], "yu2020": 76, "twice": 76, "paramet": [76, 78, 79, 80, 82, 83, 86, 88, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "temporarili": 76, "temporari": 76, "perman": 76, "formul": [76, 87], "fewer": [76, 113, 114], "seven": 76, "deep": [76, 86, 89, 93, 94, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "capabl": [76, 86, 92], "causal": [76, 101], "level": [76, 83, 86, 88, 91, 96, 101, 103], "disadvantag": 76, "rel": [76, 88, 90, 92, 93, 95, 98, 102, 120, 121], "sequenti": [76, 113, 114], "kun": 76, "zhang": [76, 86], "jona": 76, "peter": [76, 86], "dominik": 76, "janz": 76, "bernhard": 76, "schoelkopf": 76, "2012": 76, "discoveri": [76, 86], "arxiv": [76, 83, 86], "preprint": [76, 83, 86], "1202": 76, "3775": 76, "eric": 76, "strobl": 76, "shyam": 76, "visweswaran": 76, "2019": [76, 86], "parametr": [76, 90], "journal": [76, 79, 86], "infer": [76, 95, 113, 114, 118, 119, 120, 121], "bruce": 76, "ramani": 76, "prasanta": 76, "moment": [76, 83], "theori": 76, "annal": 76, "institut": 76, "pp": [76, 86], "230": 76, "giorgo": 76, "borboudaki": 76, "ioanni": 76, "tsamardino": 76, "research": [76, 86, 88], "276": 76, "314": [8, 76], "kui": 76, "yu": [76, 86], "xianji": 76, "guo": 76, "lin": 76, "jiuyong": 76, "hao": [76, 86], "wang": [76, 86], "zhaolong": 76, "ling": 76, "xindong": 76, "wu": [76, 86], "2020": [76, 86], "acm": [76, 86], "survei": 76, "csur": 76, "stabil": [77, 107], "extent": 77, "bucket": [77, 99, 107], "q": [77, 101, 103], "ln": 77, "fidx": 77, "wasserstein": [77, 107], "absolu": [77, 98, 102, 103, 104], "cumul": 77, "wd_": 77, "kolmogorov": [77, 107], "smirnov": [77, 107], "scipi": [77, 105], "stat": 77, "wasserstein_dist": 77, "ks_2samp": 77, "largest": [77, 80, 88, 90, 91, 92, 93, 95, 96, 101, 102, 103, 120, 121], "atamp": 77, "apley2016": [78, 86], "impact": [78, 83, 95, 96, 99, 107], "Its": [78, 98], "bias": [78, 93, 104], "overcom": 78, "offer": [78, 83, 93, 94, 102], "quicker": 78, "unbias": 78, "definit": [78, 88, 91, 93], "interest": [78, 79, 80, 81, 86, 98, 100, 101, 104, 107], "let": [78, 79, 90, 93, 103], "n_": [78, 93, 99], "z_": [74, 78], "uncent": [78, 80, 92], "h": [78, 88, 91, 96], "k_": 78, "f": [78, 79, 81, 82, 83, 90, 91, 95, 96, 101], "textbf": [78, 88, 89, 90, 91, 92, 93, 95, 96], "tag": [78, 81, 83, 88, 89, 90, 91, 92, 93, 95, 96, 98], "finlli": 78, "faster": [78, 81, 88, 89], "too": [78, 83, 93, 95, 112, 115, 120, 121], "small": [78, 83, 88, 89, 91, 93, 98, 103], "might": [78, 94], "accur": [78, 86, 94, 95, 98, 101], "hand": [78, 86, 89], "curv": [78, 98, 101, 102], "adit": 78, "pleas": [78, 79, 82, 83, 91, 93, 106], "paper": [78, 86], "pyal": 78, "strongli": 78, "across": [78, 79, 83, 92, 98, 102, 120, 121], "extrapol": [78, 81], "beyond": [78, 86], "envelop": [78, 81], "fix": [78, 83, 104, 105, 113, 114, 120, 121], "move": 78, "anoth": [78, 95, 102], "unreli": [78, 101], "lead": [78, 80, 86, 88, 90, 92, 95, 101, 103], "word": [78, 101], "tell": [78, 89, 95, 101, 103], "peak": [78, 88, 91, 96, 98, 102], "rush": [78, 88, 91, 98, 101], "hour": [78, 88, 91, 92, 96, 98, 101], "around": [78, 79, 88, 91, 96, 98, 100, 102, 104], "draw": [78, 83, 88, 89, 90, 91, 95, 96, 102, 107], "reach": 78, "previou": [78, 79, 98, 102], "creat": [78, 80, 93, 102, 120, 121], "sepcif": 78, "onc": [78, 89, 94, 96], "element": [78, 80, 98, 103, 118, 119, 120, 121], "light": [78, 89], "rain": 78, "etc": [78, 95, 108, 109], "heavi": 78, "significantli": [78, 80, 92, 98, 103], "simpl": [78, 93, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "still": [78, 79, 88, 91, 93, 95, 96, 100, 102, 104], "technic": 78, "substract": [78, 96, 107], "lighter": 78, "shade": [78, 89], "darker": [78, 89], "quit": [78, 88, 95, 96], "must": [78, 80, 103, 112, 115, 116, 117], "mind": 78, "dure": [78, 79, 80, 81, 89, 91, 95, 98, 101, 120, 121], "g2015": 79, "instanc": [79, 80, 83, 88, 89, 92, 98, 102, 103, 104, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "predictor": [74, 79, 80, 81, 82, 86, 88, 90, 91, 92, 96, 104], "complement": [79, 81], "c": [79, 81, 93, 101, 103, 105], "document": [79, 82], "avail": [79, 81, 83, 86, 95, 98, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "snippet": 79, "global_ic": 79, "constant": [79, 88, 90, 92, 95, 96, 98, 109, 111, 114, 119, 121, 123, 125], "examin": 79, "ani": [79, 82, 83, 86, 88, 89, 90, 96, 110, 111, 120, 121], "pattern": [79, 86, 88, 90, 93, 103], "apart": 79, "period": 79, "goldstein": 79, "alex": 79, "adam": [79, 113, 114], "kapeln": 79, "justin": 79, "bleich": 79, "emil": 79, "pitkin": 79, "2015": [79, 86], "ribeiro2016": [80, 86], "tool": [80, 81, 83, 86, 98, 107], "doe": [80, 82, 100, 104, 120, 121], "surrog": [80, 83, 102, 107], "lasso": [80, 86, 92, 117], "assign": [80, 92, 94, 99], "proxim": 80, "predict_proba": [80, 107, 108, 110, 112, 113, 118, 120, 122, 124], "close": [80, 88, 92, 93, 98, 101], "greatli": [80, 83], "judgment": 80, "sens": 80, "partiular": 80, "uncerterd": 80, "crucial": [80, 94, 104], "subtract": [80, 92, 96], "itself": [80, 92, 108, 109], "unchang": [80, 82, 92, 103], "essenti": [80, 92, 98, 102], "rather": [80, 92, 104], "becom": [80, 83, 86, 89, 90, 92, 98, 102, 104], "neglig": [80, 92], "am": [80, 88, 91], "now": [80, 92], "mainli": [80, 92], "intercept": [80, 89, 92, 93, 95, 96, 110, 111, 117, 122, 123], "hastie2015": [81, 86], "assumpt": [81, 90, 92, 95], "classificaiton": 81, "odd": [81, 92, 107], "suppos": [81, 83, 120], "x_c": 81, "context": [81, 83, 94, 96, 103], "mathbb": [81, 88, 89, 90, 91, 92, 93, 95, 96], "int": [81, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125], "dx_": 81, "commonli": [81, 94, 95, 96], "brute": 81, "obtain": [81, 83, 88, 93, 95, 100, 101, 113, 114, 120, 121, 122, 123], "partial_depend": 81, "few": [81, 95], "inlcud": 81, "inaccur": [81, 101], "far": 81, "inconsist": 81, "ones": [81, 91], "accomplish": 81, "trigger": [81, 92, 93, 95, 108, 109, 110, 111, 113, 114], "want": [81, 83, 85, 89, 92, 96, 99, 102], "tend": [81, 86, 90, 92, 93, 96], "substanti": 81, "joint": 81, "speedup": 81, "subsampl": [81, 83, 107], "entir": [81, 83, 94, 98, 102], "daytim": 81, "nighttim": 81, "influenc": [82, 90, 109, 111, 114, 119, 121, 123, 125], "loss": [82, 89, 95, 101, 107, 113, 114, 118, 119, 121, 122, 123, 124, 125], "l": [82, 93], "typic": [82, 92], "l2001": 82, "shuffl": 82, "drop": [82, 92, 103, 104], "assess": [82, 90, 98, 100, 101, 103, 104], "relianc": 82, "reveal": [82, 88, 96], "fulli": [82, 86], "either": [82, 86, 88, 89, 94, 96, 98, 108, 109, 120, 121], "futur": [82, 85, 128], "releas": 82, "next": [82, 89, 90, 94, 95, 98, 101], "degrad": [82, 86, 103], "invov": 82, "possibl": [82, 83, 92, 98, 99, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "achiev": [82, 91, 93, 95], "truncat": [82, 112, 115, 120, 121], "algoritm": 82, "alreadi": [82, 85, 93], "site": 82, "repetit": [82, 103, 107], "valuabl": [82, 95, 98], "insight": [82, 91, 102], "appear": [82, 95, 98, 102], "seem": [82, 83], "surpris": 82, "breiman": 82, "2001": 82, "forest": 82, "lundberg2017": [83, 86], "lundberg2018": 83, "concept": 83, "sport": 83, "analogi": 83, "won": 83, "soccer": 83, "game": 83, "winner": 83, "bonu": 83, "fairli": 83, "team": 83, "member": 83, "know": [83, 92, 120, 121], "five": 83, "player": 83, "who": 83, "plai": 83, "role": [83, 88, 96], "victori": 83, "recogn": 83, "come": [83, 86], "success": [83, 93], "imlbook": 83, "shapblog": 83, "possess": 83, "attract": 83, "properti": [83, 93, 120, 121], "missing": 83, "decompos": [83, 96], "prime": 83, "phi_0": 83, "phi_j": 83, "z_j": 83, "coalit": 83, "off": [83, 93, 98, 99, 107], "phi_": 83, "shap_": 83, "otherwis": [83, 89, 95, 100, 104, 107, 122, 123], "subseteq": 83, "val": 83, "cup": 83, "return": [83, 90, 100, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "factor": [83, 95], "accept": 83, "problemat": 83, "worth": [83, 89], "sole": 83, "affect": [83, 92, 100], "common": [83, 90, 92, 100], "background": 83, "mere": 83, "former": [83, 103], "challeng": [83, 98, 102], "practic": [83, 88, 89, 93, 100], "latter": [83, 103, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "break": 83, "interven": 83, "intervent": 83, "inspir": 83, "particularli": [83, 86], "ignor": [83, 100, 104, 105, 107, 120, 121], "unlik": [83, 89], "guarante": 83, "lot": 83, "linearshap": 83, "treeshap": 83, "paragraph": 83, "benefit": 83, "coef": 83, "design": [83, 91, 102, 128], "leaf": [83, 89, 95, 96, 108, 109, 110, 111, 120, 121, 122, 123, 124, 125], "explicitli": 83, "present": [83, 98], "went": 83, "exactli": [83, 90, 95], "bit": [83, 96, 100], "slower": [83, 89], "ll": 83, "i_j": 83, "consum": 83, "place": 83, "red": [83, 89, 101, 102, 104], "had": 83, "greatest": 83, "pdf": 83, "spap": 83, "lundberg": [83, 86], "scott": [83, 86], "m": [83, 86], "gabriel": 83, "erion": 83, "su": [83, 86], "lee": [83, 86], "1802": 83, "03888": 83, "object": [85, 90, 92, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "lightgbm": 85, "lgbmregressor": 85, "lgbm2": 85, "lgbm_2": 85, "abl": [85, 89, 90], "extract": [85, 93, 96, 112, 113, 114, 115, 122, 123], "model_sav": [85, 107], "ch_lgmb_2": 85, "pkl": [85, 107], "pickl": [85, 107], "make_pipelin": [85, 107], "lgmb_2_load": 85, "model_select": 85, "train_test_split": 85, "train_x": [85, 107], "test_x": [85, 107], "train_i": [85, 107], "test_i": [85, 107], "test_siz": 85, "lgbm7": 85, "ravel": 85, "lgmb_7": 85, "pi": [86, 93], "pai": 86, "em": 86, "el": 86, "access": 86, "workflow": [86, 92, 93, 95, 107, 120, 121], "grow": [86, 89, 120, 121], "weak": [86, 100, 104], "uncertainti": [86, 101], "exist": [86, 88, 89, 91, 92, 96, 98, 104, 107], "mlop": 86, "platform": [86, 105], "assur": 86, "enabl": [86, 94, 95, 98, 104], "furthermor": [86, 89], "comprehens": [86, 98], "bank": 86, "project": 86, "supervis": [86, 94, 104], "increasingli": 86, "domain": 86, "consequ": [86, 101], "lack": 86, "difficult": 86, "trust": 86, "emerg": 86, "pedregosa2011": 86, "kokhlikyan2020": 86, "klaise2021": 86, "baniecki2021": 86, "li2022": 86, "known": [86, 92, 93, 94, 101, 120, 121], "pitfal": 86, "rudin2019": 86, "molnar2020": 86, "yang2021a": 86, "yang2021b": [86, 91], "sudjianto2020": [86, 93], "interpretml": 86, "nori2013": [86, 88], "microsoft": [86, 88], "promot": 86, "boost": [86, 87, 89, 95, 107, 108, 109, 122, 123, 124, 125, 128], "ga2m": 86, "lou2013": [86, 88], "One": [86, 105], "sudjianto2021": 86, "discuss": [86, 94, 103], "meantim": 86, "chung2019": 86, "pycaret": 86, "tensorflow": 86, "finra": 86, "toolkit": 86, "same": [86, 88, 89, 91, 93, 96, 98, 99, 102, 103, 107, 108, 109, 120], "Such": [86, 93, 103], "sometim": 86, "demand": [86, 98], "risk": [86, 95], "manag": [86, 107], "routin": 86, "exercis": 86, "conceptu": [86, 90], "sound": 86, "angl": 86, "been": [86, 89, 90, 93, 94], "adopt": 86, "launch": 86, "2022": 86, "interfac": [86, 107], "panel": [86, 98], "widget": 86, "dashboard": 86, "lab": 86, "conveni": 86, "data_qu": 86, "choic": [86, 92, 93], "parameter": 86, "action": 86, "through": [86, 89, 91, 93, 120, 121], "cell": 86, "autom": 86, "appropri": [86, 94], "registr": [86, 107], "mandatori": 86, "unifi": 86, "glass": 86, "section_3": 86, "section_4": 86, "cover": [86, 101], "intern": [86, 118, 119, 120, 121], "aspect": [86, 91], "even": [86, 89, 93, 102, 120, 121], "though": 86, "simplif": 86, "regard": 86, "worthwhil": 86, "mention": [86, 98, 100, 104], "enough": [86, 93, 106], "backend": 86, "simplic": 86, "2023": 86, "ell_1": 86, "ell_2": 86, "regular": [86, 90, 91, 92, 93, 113, 114, 118, 119, 122, 123, 124, 125], "spline": [86, 90, 95, 112, 113, 114, 115], "serven2018": 86, "greedi": [86, 87, 107, 110, 111, 128], "tan2022": [86, 89], "extrem": [86, 89, 93], "gradient": [86, 88, 93, 122, 123, 124, 125], "chen2015": 86, "lengerich2020": [86, 95, 96], "network": [86, 87, 90, 91, 113, 114, 118, 119, 128], "aletheia": [86, 93, 118, 119], "unwrapp": [86, 118, 119], "sparsif": 86, "brief": [86, 93], "popular": [86, 92], "identif": 86, "techniqu": [86, 95, 104], "underfit": [86, 88], "accord": [86, 93, 95, 99, 102, 103, 107, 113, 114], "quantif": 86, "conform": [86, 101, 107], "wang2023": 86, "cui2023": 86, "out": [86, 93, 102, 104, 113, 114, 118, 119], "de": [86, 93], "bia": [86, 93, 118, 119], "art": 86, "expand": [86, 120, 121], "track": 86, "report": 86, "fabian": 86, "pedregosa": 86, "ga\u00ebl": 86, "varoquaux": 86, "alexandr": 86, "gramfort": 86, "vincent": 86, "michel": 86, "bertrand": 86, "thirion": 86, "olivi": 86, "grisel": 86, "mathieu": 86, "blondel": 86, "prettenhof": 86, "ron": 86, "weiss": 86, "dubourg": 86, "jake": 86, "vanderpla": 86, "passo": 86, "david": 86, "cournapeau": 86, "matthieu": 86, "brucher": 86, "perrot": 86, "\u00e9douard": 86, "duchesnai": 86, "2011": 86, "2825": 86, "2830": 86, "narin": 86, "kokhlikyan": 86, "vivek": 86, "miglani": 86, "miguel": 86, "martin": 86, "edward": 86, "bilal": 86, "alsallakh": 86, "jonathan": 86, "reynold": 86, "alexand": 86, "melnikov": 86, "natalia": 86, "kliushkina": 86, "carlo": 86, "araya": 86, "siqi": 86, "yan": 86, "orion": 86, "reblitz": 86, "richardson": 86, "captum": 86, "librari": 86, "pytorch": [86, 118, 119], "2009": 86, "07896": 86, "jani": 86, "klais": 86, "arnaud": 86, "van": 86, "looveren": 86, "giovanni": 86, "vacanti": 86, "alexandru": 86, "coca": 86, "2021": 86, "alibi": 86, "8194": 86, "hubert": 86, "baniecki": 86, "wojciech": 86, "kretowicz": 86, "piotr": 86, "piatyszek": 86, "jakub": 86, "wisniewski": 86, "przemyslaw": 86, "biecek": 86, "dalex": 86, "9759": 86, "9765": 86, "xuhong": 86, "haoyi": 86, "xiong": 86, "xingjian": 86, "xuanyu": 86, "zeyu": 86, "chen": 86, "deje": 86, "dou": 86, "interpretdl": 86, "paddlepaddl": 86, "cynthia": 86, "rudin": 86, "stake": 86, "natur": 86, "ntellig": 86, "206": 86, "christoph": 86, "molnar": 86, "gunnar": 86, "k\u00f6nig": 86, "julia": 86, "herbing": 86, "timo": 86, "freiesleben": 86, "susann": 86, "dandl": 86, "christian": 86, "scholbeck": 86, "giusepp": 86, "casalicchio": 86, "moritz": 86, "gross": 86, "wentrup": 86, "bernd": 86, "bischl": 86, "xxai": 86, "workshop": 86, "held": 86, "conjunct": 86, "icml": 86, "juli": 86, "vienna": 86, "austria": 86, "revis": 86, "extend": [86, 89], "68": 86, "cham": 86, "springer": 86, "publish": 86, "harsha": 86, "nori": 86, "samuel": 86, "jenkin": 86, "paul": 86, "koch": 86, "rich": 86, "caruana": 86, "framework": [86, 101], "1909": 86, "09223": 86, "yin": 86, "lou": 86, "johann": 86, "gehrk": 86, "gile": 86, "hooker": 86, "2013": 86, "intellig": 86, "proceed": 86, "19th": 86, "sigkdd": 86, "confer": 86, "knowledg": 86, "mine": 86, "623": 86, "631": 86, "agu": 86, "sudjianto": 86, "aijun": 86, "2111": 86, "01743": 86, "yeounoh": 86, "chung": 86, "tim": 86, "kraska": 86, "neokli": 86, "polyzoti": 86, "ki": 86, "hyun": 86, "tae": 86, "steven": 86, "euijong": 86, "whang": 86, "finder": 86, "ieee": 86, "35th": 86, "engin": 86, "icd": 86, "1550": 86, "1553": 86, "daniel": 86, "w": [86, 93, 113, 114], "aplei": 86, "jingyu": 86, "zhu": 86, "2016": 86, "1612": 86, "08468": 86, "marco": 86, "tulio": 86, "ribeiro": 86, "sameer": 86, "singh": 86, "guestrin": 86, "why": [86, 95], "classifi": [86, 92, 98, 102, 107, 108, 110, 112, 113, 116, 118, 120], "22nd": 86, "2017": 86, "neural": [86, 87, 90, 91, 128], "trevor": 86, "hasti": 86, "robert": 86, "tibshirani": 86, "wainwright": 86, "sparsiti": [86, 91], "crc": 86, "press": 86, "serv\u00e9n": 86, "charli": 86, "brummitt": 86, "pygam": [86, 90, 105, 112, 115], "zenodo": 86, "doi": 86, "5281": 86, "1208723": 86, "shuo": 86, "tan": 86, "chandan": 86, "keyan": 86, "nasseri": 86, "abhineet": 86, "agarw": 86, "2201": 86, "11931": 86, "benjamin": 86, "lengerich": 86, "sarah": 86, "chun": 86, "june": 86, "purifi": [86, 96], "anova": [86, 96, 108, 109, 122, 123, 124, 125], "effici": 86, "recov": 86, "artifici": 86, "2402": 86, "2412": 86, "pmlr": 86, "tianqi": 86, "tong": 86, "william": 86, "knauth": 86, "rahul": 86, "zebin": 86, "yang": 86, "unwrap": [86, 93], "04041": 86, "shiji": 86, "cui": 86, "runz": 86, "hot": [86, 92, 95], "2304": 86, "13761": 86, "yaqun": 86, "tbd": 86, "architectur": [86, 113, 114], "constraint": [86, 91, 95, 96, 104, 110, 111, 113, 114, 122, 123, 124, 125], "transact": 86, "2610": 86, "2621": 86, "recognit": 86, "120": 86, "108192": 86, "mu": [88, 89, 90, 91, 92, 95, 96], "limits_": [88, 91, 95, 96], "h_": [88, 91, 95, 96], "f_": [88, 89, 90, 91, 96], "jk": [88, 91, 96], "shallow": [88, 94], "round": [88, 103, 108, 109], "fashion": [88, 120, 121], "cut": [88, 107], "pick": 88, "converg": [88, 93, 96, 112, 115], "piecewis": [88, 90, 91, 95, 96], "superior": [88, 96], "hyperparamet": [88, 89, 90, 91, 92, 93, 94, 95, 96], "sacrific": 88, "rate": [88, 93, 98, 99, 107, 108, 109, 110, 111, 113, 114, 118, 119, 122, 123, 124, 125], "256": [88, 108, 109, 122, 123, 124, 125], "outlier": [88, 107], "togeth": [88, 90, 91, 92, 93, 101, 110, 111, 113, 114], "pm": [88, 91], "somehow": 88, "correct": [88, 104, 105], "positv": 88, "night": 88, "spring": 88, "domin": [88, 96], "part": [88, 89, 96], "0818": 88, "complet": [88, 91], "similarli": [88, 89, 93, 96, 101], "almost": 88, "contrast": [88, 89, 92, 95, 96, 98], "recent": [89, 105], "cart": 89, "special": [89, 93, 95], "f_k": 89, "mathbf": 89, "manner": [89, 107], "pseudo": 89, "express": [89, 90, 93, 96, 113, 114], "form": [89, 92, 93, 94, 96, 98, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "search": [89, 99, 120, 121], "whichev": 89, "author": 89, "imodel": [89, 110, 111], "re": [89, 95, 110, 111], "integ": [89, 108, 109, 120, 121], "unlimit": [89, 120, 121], "criteria": [89, 120, 121], "control": [89, 90, 93, 94, 95, 99, 102, 120, 121], "hardli": 89, "gain": [89, 120], "along": [89, 104], "leat": 89, "scheme": 89, "hierarch": 89, "dendrogram": 89, "subplot": [89, 93, 98], "middl": [89, 98], "deeper": 89, "splite": [89, 110, 111], "rightmost": 89, "convei": 89, "dark": 89, "necessari": [89, 98], "decsion_tre": 89, "distinguish": [89, 91, 98, 104, 107], "addtion": 89, "099": 89, "094": 89, "extens": 90, "primari": 90, "equat": [90, 93, 120, 121], "unknown": 90, "smooth": [90, 91, 98, 110, 111, 112, 115, 120, 121], "varieti": 90, "ensur": [90, 94, 95, 96, 102], "degre": [90, 100], "polynomi": 90, "quadrat": 90, "cubic": 90, "knot": 90, "anchor": 90, "With": [90, 92, 95], "intric": 90, "poorer": 90, "penalti": [90, 92, 93, 112, 115], "prevent": [90, 100], "encourag": 90, "simpler": [90, 93, 95], "generaliz": 90, "smoother": 90, "convers": 90, "rougher": 90, "slope": 90, "flat": 90, "steep": 90, "sharp": 90, "incom": 90, "_j": [90, 95], "datafram": [90, 92, 107], "latitud": [90, 95], "lontitud": [90, 95], "strongest": 90, "drive": 90, "3804": 90, "reformul": 91, "disentangl": [91, 93], "feedforward": [91, 93], "subnetwork": [91, 113, 114], "hidden": [91, 93, 113, 114, 118, 119], "layer": [91, 93, 113, 114, 118, 119], "parsimoni": [91, 96], "hered": [91, 113, 114], "least": [91, 93, 95, 110, 111, 117, 120, 121], "parent": 91, "clariti": [91, 113, 114], "mutual": 91, "purif": [91, 96, 112, 113, 114, 115, 122, 123], "constrain": [91, 95], "decreas": [91, 95, 102, 110, 111, 113, 114, 120, 121, 122, 123, 124, 125], "impos": [91, 113, 114, 118, 119], "gaminet": 91, "prune": [91, 96, 113, 114, 120, 121], "trivial": [91, 93, 96], "retrain": 91, "simultan": 91, "fine": [91, 113, 114], "tune": [91, 95, 107, 113, 114], "activ": [91, 93, 96, 113, 114, 118, 119], "saturdai": 91, "sundai": 91, "mondai": 91, "fridai": 91, "compon": [91, 93, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "aggreg": [91, 92, 96, 112, 113, 114, 115, 122, 123], "w_1": 92, "x_1": 92, "w_2": 92, "x_2": 92, "w_d": 92, "x_d": 92, "ident": [92, 93, 98, 101, 120, 121], "logit": 92, "l2": [92, 116, 117, 121, 122, 123, 124, 125], "l1_regularz": [92, 116, 117], "penal": [92, 93, 113, 114], "l2_regularz": [92, 116, 117], "shrink": [92, 93], "toward": [92, 93], "closer": 92, "variant": [92, 95], "linear_model": 92, "linearregress": 92, "constrainst": 92, "ridg": [92, 117], "elasticnet": [92, 117], "elast": 92, "logisticregress": 92, "hold": 92, "binomi": 92, "address": [92, 104], "issu": [92, 113, 114, 118, 119], "associ": [92, 120], "opposit": 92, "temperatur": [92, 96], "humid": 92, "involv": [92, 95, 102], "convert": [92, 120, 121], "separ": [92, 95, 98], "dummi": 92, "season_4": 92, "multicollinear": 92, "overparameter": 92, "fourth": 92, "nonlinear": [92, 93], "print": 92, "screen": [92, 113, 114], "export": 92, "w_j": 92, "behavior": 92, "longer": 92, "stem": 92, "unstabl": [92, 93], "turn": [92, 95, 113, 114], "field": [93, 101], "rectifi": 93, "remark": 93, "appeal": 93, "excel": 93, "intrins": 93, "overview": 93, "neuron": 93, "chi": 93, "mbox": 93, "eta": [93, 95, 96, 122, 123, 124, 125], "sigmoid": [93, 113, 114], "despit": 93, "said": 93, "equiv": 93, "n_l": 93, "exhibit": 93, "simplifi": [93, 95], "tild": 93, "oper": [93, 94], "tupl": [93, 107, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "poor": 93, "1e": [93, 107, 108, 109, 113, 114, 118, 119], "descent": 93, "unpen": 93, "float": [93, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "critic": [93, 101], "unnecessarili": 93, "long": [93, 112, 115, 120, 121], "wherea": 93, "5153": 93, "105570": 93, "584421": 93, "735054": 93, "static": 93, "wide": [93, 98], "roughli": 93, "vice": 93, "versa": 93, "impli": 93, "upon": [93, 98, 103], "eleg": 93, "belong": [93, 99], "diagon": [93, 98], "decomposit": [93, 95], "uniformli": [93, 113, 114], "sin": 93, "epsilon": 93, "n_featur": [93, 107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "influenti": 94, "render": 94, "wrapper": [94, 96, 112, 115, 116, 117, 120, 121], "decisiontreeregressor": 94, "often": 94, "suffer": 94, "rule": [94, 110, 111], "criterion": [94, 120, 121], "branch": [94, 110, 111, 120, 121], "easier": [94, 95], "suitabl": 95, "restrict": 95, "stump": 95, "deriv": [95, 113, 114], "stage": [95, 108, 109, 113, 114, 118, 119], "adapt": 95, "interpretabilti": 95, "optim": [95, 98, 107, 113, 114, 122, 123], "optbin": [95, 105, 122, 123], "woe": 95, "refit": [95, 122, 123], "firstli": 95, "arrang": 95, "format": 95, "taken": 95, "inherit": 95, "tree_method": [95, 96, 104, 122, 123, 124, 125], "reg_lambda": [95, 96, 122, 123, 124, 125], "reg_alpha": [95, 96, 122, 123, 124, 125], "constraient": 95, "feature_nam": [95, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "correctli": [95, 98, 108, 110, 113, 118, 120, 122, 124], "max_n_bin": 95, "strike": 95, "difficulti": 95, "fit_method": 95, "addition": [95, 96, 98, 102], "iv": 95, "aid": 95, "accompani": 95, "trend": 95, "plateau": 95, "geograph": 95, "longtitud": 95, "amplifi": 95, "resons": 95, "pariws": 96, "restructur": 96, "proce": 96, "enforc": [96, 112, 115], "feel": 96, "celsiu": 96, "50": [96, 103, 108, 109, 118, 119], "comfort": 96, "outdoor": 96, "cooler": 96, "hotter": 96, "willing": 96, "ride": 96, "bicycl": 96, "0606": 96, "summat": 96, "plu": [96, 98], "contribt": 96, "sklearn_metr": 98, "y_": [98, 101, 112, 113, 114, 115, 122, 123], "character": 98, "ideal": [98, 101], "width": [98, 99, 101], "band": 98, "residual_plot": 98, "analyz": [98, 101], "appar": 98, "notabl": [98, 102], "heterogen": 98, "reason": [98, 104], "evenli": 98, "noteworthi": 98, "_predict": 98, "variat": [98, 103], "made": [98, 99], "imbalanc": 98, "alon": 98, "whose": 98, "guess": 98, "harmon": 98, "2tp": 98, "fp": [98, 99], "fn": [98, 99], "resembl": 98, "scatterplot": 98, "lowess": 98, "thorough": 98, "mislabel": 98, "abil": [98, 101, 102], "tpr": 98, "fpr": 98, "tradeoff": 98, "irrelev": 98, "imparti": 99, "were": 99, "ethnic": 99, "sexual": 99, "orient": 99, "disabl": [99, 107], "advers": [99, 107], "tp_": 99, "fn_": 99, "tp": 99, "smd": [99, 107], "outcome_x": 99, "fp_": 99, "span": 99, "dictionari": [99, 110, 111, 112, 115, 120, 121], "accuracy_scor": 99, "f1_score": 99, "dash": 99, "ax": 99, "fail": 100, "unseen": [100, 101], "dein": 100, "neighbor": 100, "cost": [100, 113, 114, 120, 121], "chose": [100, 104], "slcing": [100, 104], "avaibl": [100, 104], "previous": [100, 104], "warn": [100, 104, 120, 121], "messag": [100, 104, 105], "biksshar": 100, "017079": 100, "015575": 100, "001504": 100, "285": 100, "005226": 100, "004305": 100, "000921": 100, "1743": 100, "006050": 100, "005585": 100, "000465": 100, "7am": 100, "9am": 100, "0171": 100, "0156": 100, "seen": 100, "pure": [100, 120, 121], "2am": 100, "55": [100, 102], "326087": 100, "369565": 100, "98480": 100, "036693": 100, "029954": 100, "006739": 100, "282609": 100, "013106": 100, "011935": 100, "001172": 100, "000000": [100, 104], "065217": 100, "55305": 100, "831": 100, "001208": 100, "000855": 100, "000353": 100, "trustworthi": 101, "healthcar": 101, "financ": 101, "safeti": 101, "crqr": 101, "exchang": 101, "epsilon_": 101, "s_": 101, "construct": 101, "confid": 101, "gbdt": 101, "88705": 101, "232974": 101, "88": [101, 104], "233": 101, "2563": 101, "wise": 101, "conclud": 101, "discret": [101, 103], "dot": [101, 102, 104, 107], "matur": 101, "isoton": 101, "maintain": 102, "unexpect": [102, 103], "situat": 102, "likelihood": 102, "bad": [102, 107], "mostli": 102, "akin": 102, "steadili": 102, "declin": 102, "unsupervis": [102, 104], "necessarili": 102, "lowest": 102, "whihc": 102, "thought": 102, "recalcul": 102, "moder": 102, "encount": 103, "drift": 103, "aris": [103, 104], "alter": 103, "underli": [103, 120, 121], "showcas": 103, "leverag": 103, "lambda": [103, 118, 119], "var": 103, "sai": [103, 104], "86": 103, "invers": [103, 120], "ten": 103, "encapsul": 103, "look": [103, 107, 120, 121], "wors": [103, 109, 111, 114, 119, 121, 123, 125], "poorli": 103, "underperform": 104, "inadequ": 104, "inappropri": 104, "insuffici": 104, "performacn": 104, "filter": 104, "hisotogram": 104, "connect": 104, "merg": 104, "min_samples_leaf": [104, 108, 109, 110, 111, 120, 121], "n_estimaor": 104, "hist": [104, 122, 123, 124, 125], "granular": 104, "723": 104, "boolean": [104, 110, 111], "annot": 104, "695652": 104, "689587": 104, "006065": 104, "test_metr": 104, "train_metr": 104, "No": [104, 105, 118, 119], "250000": 104, "691099": 104, "678750": 104, "012349": 104, "111111": 104, "222222": 104, "727612": 104, "717573": 104, "010039": 104, "375000": 104, "625000": 104, "720497": 104, "717134": 104, "003362": 104, "333333": 104, "555556": 104, "612536": 104, "614685": 104, "002150": 104, "750000": 104, "621951": 104, "003049": 104, "o": 105, "py37": 105, "py38": 105, "py39": 105, "py310": 105, "win": 105, "linux": 105, "maco": 105, "environ": 105, "pip": 105, "ipywidget": 105, "joblib": 105, "ipython": 105, "numpi": [105, 108, 109, 110, 111, 113, 114, 118, 119, 122, 123, 124, 125], "seaborn": 105, "xlrd": 105, "torch": [105, 113, 114], "natsort": 105, "psutil": 105, "dill": 105, "ortool": 105, "momentchi2": 105, "possbl": 105, "upgrad": 105, "reinstal": 105, "try": 105, "conda": 105, "forg": 105, "runtimeerror": 105, "traceback": 105, "compil": 105, "0x10": 105, "0xf": 105, "restart": 105, "runtim": 105, "guidelin": 106, "highcode_onli": 107, "str": [107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "bool": [107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "css": 107, "ingest": 107, "union": 107, "pass": [107, 112, 115, 120, 121], "program": 107, "preview": 107, "unicod": 107, "train_idx": 107, "test_idx": 107, "wheter": 107, "arrai": [107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "n_samples_train": 107, "n_samples_test": 107, "kmeanstre": 107, "dict": [107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "99": 107, "forward": 107, "backward": 107, "use": 107, "earli": [107, 108, 109, 110, 111, 113, 114, 118, 119], "fbedk": 107, "get_data": 107, "ndarrai": [107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "n_sampl": [107, 108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "workfolw": 107, "Not": 107, "get_feature_nam": 107, "get_feature_typ": 107, "get_model": 107, "modelpipelin": 107, "get_model_config": 107, "get_raw_data": 107, "datatupl": 107, "train_sample_weight": 107, "test_sample_weight": 107, "target_nam": 107, "get_target_nam": 107, "normalize_strategi": 107, "encode_strategi": 107, "excluded_featur": 107, "style": 107, "minmax": 107, "unit_norm": 107, "one_hot": 107, "xndarrai": 107, "param": [107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "insid": 107, "whther": 107, "testdataresult": [107, 112, 113, 114, 115, 120, 121, 122, 123], "diagnos": 107, "repeatit": 107, "metric_threshold": 107, "favorable_class": 107, "thresholding_bin": 107, "by_weight": 107, "binar": 107, "segement": 107, "rsmd": 107, "categorical_feature_nam": 107, "savedmodel": 107, "save": [107, 113, 114, 128], "self": [107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "get_all_supported_model": 107, "model_tun": 107, "max_interaction_bin": [108, 109], "outer_bag": [108, 109], "inner_bag": [108, 109], "validation_s": [108, 109], "early_stopping_round": [108, 109], "early_stopping_toler": [108, 109], "0001": [108, 109, 113, 114], "max_round": [108, 109], "max_leav": [108, 109], "n_job": [108, 109, 113, 114], "quantile_human": [108, 109], "bag": [108, 109], "inner": [108, 109], "toler": [108, 109, 113, 114], "dictat": [108, 109], "smallest": [108, 109], "delta": [108, 109], "job": [108, 109], "cpu": [108, 109, 113, 114, 118, 119], "decision_funct": [108, 109, 110, 112, 113, 118, 122, 124], "arg": [108, 109, 112, 115, 116, 122, 123], "get_param": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "subobject": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "map": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "model_unwrapp": [108, 109, 118, 119, 124, 125], "np": [108, 109, 110, 111, 112, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 125], "placehold": [108, 109], "unp": [108, 109, 118, 119, 124, 125], "ebmexplain": [108, 109], "multi": [108, 110, 113, 118, 119, 120, 122, 124], "harsh": [108, 110, 113, 118, 120, 122, 124], "n_output": [108, 109, 110, 111, 113, 114, 118, 119, 120, 121, 122, 123, 124, 125], "set_param": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "nest": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "__": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "updat": [108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "y_true": [109, 111, 114, 119, 121, 123, 125], "y_pred": [109, 111, 114, 119, 121, 123, 125], "arbitrarili": [109, 111, 114, 119, 121, 123, 125], "disregard": [109, 111, 114, 119, 121, 123, 125], "precomput": [109, 111, 114, 119, 121, 123, 125], "n_samples_fit": [109, 111, 114, 119, 121, 123, 125], "multioutput": [109, 111, 114, 119, 120, 121, 123, 125], "uniform_averag": [109, 111, 114, 119, 121, 123, 125], "r2_score": [109, 111, 114, 119, 121, 123, 125], "multioutputregressor": [109, 111, 114, 119, 121, 123, 125], "splitter": [110, 111, 120, 121], "min_impurity_decreas": [110, 111, 120, 121], "concis": [110, 111], "csinva": [110, 111], "leav": [110, 111, 120, 121], "induc": [110, 111, 120, 121], "impur": [110, 111, 120, 121], "feature_names_": [110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "feature_types_": [110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "n_features_in_": [110, 111, 113, 114, 118, 119, 120, 121, 122, 123, 124, 125], "intercept_": [110, 111, 122, 123], "trees_": [110, 111], "n_tree_": [110, 111], "n_iter_": [110, 111], "iteract": [110, 111], "early_stop_": [110, 111], "tree_importance_": [110, 111], "explain_tre": [110, 111], "get_tree_diag": [110, 111, 120, 121], "get_tree_heatmap": [110, 111], "global_explain": [110, 111, 112, 113, 114, 115], "global_interpret": [110, 111, 112, 113, 114, 115, 120, 121, 122, 123], "interpret_local_tre": [110, 111, 120, 121], "local_explain": [110, 111], "plot_feature_importance_heatmap": [110, 111], "plot_local_tre": [110, 111, 120, 121], "plot_tree_diag": [110, 111, 120, 121], "get_binary_matrix": [110, 111], "get_binary_represent": [110, 111], "get_depth": [110, 111, 120, 121], "get_depths_interact": [110, 111], "pred": [110, 111, 113, 114, 118, 119, 122, 123, 124, 125], "pred_proba": [110, 113, 118, 122, 124], "proba": [110, 113, 120, 122, 124], "update_tree_import": [110, 111], "stronger": [112, 115], "solver": [112, 115], "get_interaction_effect": [112, 113, 114, 115, 122, 123], "interpret_effect": [112, 113, 114, 115, 122, 123], "interpret_ei": [112, 113, 114, 115, 122, 123], "interpret_local_ei": [112, 113, 114, 115, 122, 123], "plot_ei": [112, 113, 114, 115, 122, 123], "plot_interaction_effect": [112, 113, 114, 115, 122, 123], "plot_local_ei": [112, 113, 114, 115, 122, 123], "plot_main_effect": [112, 113, 114, 115, 122, 123], "get_main_effect": [112, 113, 114, 115, 122, 123], "truncate_dict": [112, 115, 120, 121], "interpret_fi": [112, 113, 114, 115, 122, 123], "interpret_local_fi": [112, 113, 114, 115, 122, 123], "local_feature_explain": [112, 113, 114, 115, 122, 123], "plot_fi": [112, 113, 114, 115, 122, 123], "interpret_result": [112, 113, 114, 115, 120, 121, 122, 123], "max_show": [112, 113, 114, 115, 122, 123], "return_fig": [112, 113, 114, 115, 120, 121, 122, 123], "plot_local_fi": [112, 113, 114, 115, 122, 123], "interact_num": [113, 114], "subnet_size_main_effect": [113, 114], "subnet_size_interact": [113, 114], "activation_func": [113, 114], "max_epoch": [113, 114, 118, 119], "early_stop_thr": [113, 114], "auto": [113, 114, 120, 121, 122, 123, 124, 125], "batch_siz": [113, 114, 118, 119], "batch_size_infer": [113, 114, 118, 119], "max_iter_per_epoch": [113, 114], "val_ratio": [113, 114, 118, 119], "warm_start": [113, 114], "gam_sample_s": [113, 114], "mlp_sample_s": [113, 114], "reg_clar": [113, 114], "loss_threshold": [113, 114], "reg_mono": [113, 114], "mono_sample_s": [113, 114], "include_interaction_list": [113, 114], "boundary_clip": [113, 114], "verbos": [113, 114, 118, 119], "devic": [113, 114, 118, 119], "tanh": [113, 114], "epoch": [113, 114, 118, 119], "batch": [113, 114, 118, 119], "init": [113, 114], "clip": [113, 114], "reshuffl": [113, 114], "ratiom": [113, 114], "rough": [113, 114], "tensor": [113, 114], "teacher": [113, 114], "sub": [113, 114], "achiv": [113, 114], "spacec": [113, 114], "feature_name1": [113, 114], "feature_name2": [113, 114], "core": [113, 114], "hardwar": [113, 114], "net_": [113, 114, 118, 119], "data_dict_density_": [113, 114], "err_train_main_effect_training_": [113, 114], "err_val_main_effect_training_": [113, 114], "err_train_interaction_training_": [113, 114], "err_val_interaction_training_": [113, 114], "err_train_tuning_": [113, 114], "err_val_tuning_": [113, 114], "interaction_list_": [113, 114], "active_main_effect_index_": [113, 114], "active_interaction_index_": [113, 114], "main_effect_val_loss_": [113, 114], "interaction_val_loss_": [113, 114], "time_cost_": [113, 114], "clarity_": [113, 114], "monotonicity_": [113, 114], "is_fitted_": [113, 114, 118, 119, 122, 123, 124, 125], "n_interactions_": [113, 114], "dummy_values_": [113, 114], "cfeature_num_": [113, 114], "nfeature_num_": [113, 114], "cfeature_names_": [113, 114], "nfeature_names_": [113, 114], "cfeature_index_list_": [113, 114], "nfeature_index_list_": [113, 114], "num_classes_list_": [113, 114], "mu_list_": [113, 114], "std_list_": [113, 114], "min_value_": [113, 114, 122, 123], "max_value_": [113, 114, 122, 123], "mono_increasing_list_index_": [113, 114], "mono_decreasing_list_index_": [113, 114], "include_interaction_list_index_": [113, 114], "training_generator_": [113, 114], "fasttensordataload": [113, 114], "validation_generator_": [113, 114], "warm_init_main_effect_data_": [113, 114], "warm": [113, 114], "warm_init_interaction_data_": [113, 114], "main_effect_norm_": [113, 114], "interaction_norm_": [113, 114], "feature_importance_": [113, 114, 122, 123, 124, 125], "data_dict_global_": [113, 114], "certify_mono": [113, 114], "certifi": [113, 114], "satisfi": [113, 114], "mono_statu": [113, 114], "main_effect": [113, 114], "softmax": [113, 118, 119, 124], "fine_tune_select": [113, 114], "main_effect_list": [113, 114], "interaction_list": [113, 114], "lr": [113, 114], "unselect": [113, 114], "norm": [113, 114], "get_aggregate_output": [113, 114], "get_clarity_loss": [113, 114], "clarity_loss": [113, 114], "get_effect_import": [113, 114], "get_feature_import": [113, 114], "get_global_effect": [122, 123], "main_grid_s": [113, 114], "interact_grid_s": [113, 114], "grid": [113, 114], "get_interaction_raw_output": [113, 114], "n_interact": [113, 114], "get_main_effect_raw_output": [113, 114], "get_mono_loss": [113, 114], "mono_loss": [113, 114], "folder": [113, 114], "disk": [113, 114], "local_effect_explain": [113, 114], "partial_deriv": [113, 114], "plote": [113, 114], "update_effect_import": [113, 114], "update_feature_import": [113, 114, 122, 123], "kwarg": 116, "regularz": [116, 117], "ordinari": 117, "dropout_prob": [118, 119], "n_epoch_no_chang": [118, 119], "iht": [118, 119], "phase_epoch": [118, 119], "perceptron": [118, 119], "dropout": [118, 119], "doesn": [118, 119], "early_stop": [118, 119], "cuda": [118, 119], "statit": [118, 119], "coefs_": [118, 119], "len": [118, 119], "intercepts_": [118, 119], "no_improved_count_": [118, 119], "train_epoch_loss_": [118, 119], "valid_epoch_loss_": [118, 119], "get_raw_output": [118, 119], "unwrapperclassifi": 118, "funciton": [118, 119], "unwrapperregressor": 119, "min_samples_split": [120, 121], "min_weight_fraction_leaf": [120, 121], "max_featur": [120, 121], "max_leaf_nod": [120, 121], "ccp_alpha": [120, 121], "docstr": [120, 121], "gini": [120, 121], "entropi": 120, "log_loss": 120, "shannon": 120, "fraction": [120, 121, 122, 123], "ceil": [120, 121], "log2": [120, 121], "randomst": [120, 121], "determinist": [120, 121], "behaviour": [120, 121], "n_t": [120, 121], "n_t_r": [120, 121], "right_impur": [120, 121], "n_t_l": [120, 121], "left_impur": [120, 121], "child": [120, 121], "class_weight": 120, "class_label": 120, "multilabel": 120, "n_class": 120, "bincount": 120, "subtre": [120, 121], "classes_": 120, "feature_importances_": [120, 121], "max_features_": [120, 121], "n_classes_": 120, "n_outputs_": [120, 121], "tree_": [120, 121], "check_input": [120, 121], "dtype": [120, 121], "float32": [120, 121], "csr_matrix": [120, 121], "bypass": [120, 121], "unless": [120, 121], "x_leav": [120, 121], "datapoint": [120, 121], "node_count": [120, 121], "possibli": [120, 121], "cost_complexity_pruning_path": [120, 121], "minimal_cost_complexity_prun": [120, 121], "csc_matrix": [120, 121], "carri": [120, 121], "ccp_path": [120, 121], "bunch": [120, 121], "decision_path": [120, 121], "n_node": [120, 121], "csr": [120, 121], "goe": [120, 121], "brought": [120, 121], "mislead": [120, 121], "cardin": [120, 121], "get_n_leav": [120, 121], "n_leav": [120, 121], "useless": [120, 121], "predict_log_proba": 120, "squared_error": 121, "friedman_ms": 121, "absolute_error": 121, "poisson": 121, "devianc": 121, "refit_method": [122, 123], "max_bin_s": [122, 123], "true_to_data": [122, 123], "xgboostclassifi": [122, 124], "exact": [122, 123, 124, 125], "approx": [122, 123, 124, 125], "gpu_hist": [122, 123, 124, 125], "split_info_": [122, 123, 124, 125], "n_splits_raw_": [122, 123, 124, 125], "totoal": [122, 123, 124, 125], "n_splits_": [122, 123, 124, 125], "xgb_params_": [122, 123, 124, 125], "effects_": [122, 123], "get_binning_result": [122, 123], "global_visualize_dict": [122, 123], "interpret_iv": [122, 123], "include_intercept": [122, 123], "plot_iv": [122, 123], "plot_wo": [122, 123], "xgboostregressor": [123, 125], "xgbunwrapperclassifi": 124, "xgbunwrapperregressor": 125, "quick": 126, "troubleshoot": 126, "suit": [58, 128], "plan": 128, "referec": [], "binning_list": [], "248": [1, 8], "46": [5, 8], "492": [5, 8], "116": [5, 8], "lambda_": 74, "leve": 74, "wrt": [108, 109, 110, 111, 113, 114, 118, 119, 120, 121, 122, 123, 124, 125], "get_global_effects_": [113, 114], "fit_intercept": 117, "n_features_": [120, 121], "deprec": [120, 121]}, "objects": {"piml": [[107, 0, 1, "", "Experiment"]], "piml.Experiment": [[107, 1, 1, "", "data_loader"], [107, 1, 1, "", "data_prepare"], [107, 1, 1, "", "data_quality_check"], [107, 1, 1, "", "data_summary"], [107, 1, 1, "", "eda"], [107, 1, 1, "", "feature_select"], [107, 1, 1, "", "get_data"], [107, 1, 1, "", "get_feature_names"], [107, 1, 1, "", "get_feature_types"], [107, 1, 1, "", "get_model"], [107, 1, 1, "", "get_model_config"], [107, 1, 1, "", "get_raw_data"], [107, 1, 1, "", "get_target_name"], [107, 1, 1, "", "make_pipeline"], [107, 1, 1, "", "model_compare"], [107, 1, 1, "", "model_diagnose"], [107, 1, 1, "", "model_explain"], [107, 1, 1, "", "model_fairness"], [107, 1, 1, "", "model_fairness_compare"], [107, 1, 1, "", "model_fairness_solas"], [107, 1, 1, "", "model_interpret"], [107, 1, 1, "", "model_save"], [107, 1, 1, "", "model_train"], [107, 1, 1, "", "model_tune"], [107, 1, 1, "", "register"], [107, 1, 1, "", "twosample_test"]], "piml.models": [[108, 0, 1, "", "ExplainableBoostingClassifier"], [109, 0, 1, "", "ExplainableBoostingRegressor"], [110, 0, 1, "", "FIGSClassifier"], [111, 0, 1, "", "FIGSRegressor"], [112, 0, 1, "", "GAMClassifier"], [113, 0, 1, "", "GAMINetClassifier"], [114, 0, 1, "", "GAMINetRegressor"], [115, 0, 1, "", "GAMRegressor"], [116, 0, 1, "", "GLMClassifier"], [117, 0, 1, "", "GLMRegressor"], [118, 0, 1, "", "ReluDNNClassifier"], [119, 0, 1, "", "ReluDNNRegressor"], [120, 0, 1, "", "TreeClassifier"], [121, 0, 1, "", "TreeRegressor"], [122, 0, 1, "", "XGB1Classifier"], [123, 0, 1, "", "XGB1Regressor"], [124, 0, 1, "", "XGB2Classifier"], [125, 0, 1, "", "XGB2Regressor"]], "piml.models.ExplainableBoostingClassifier": [[108, 1, 1, "", "decision_function"], [108, 1, 1, "", "fit"], [108, 1, 1, "", "get_params"], [108, 1, 1, "", "model_unwrapper"], [108, 1, 1, "", "predict"], [108, 1, 1, "", "predict_proba"], [108, 1, 1, "", "score"], [108, 1, 1, "", "set_params"]], "piml.models.ExplainableBoostingRegressor": [[109, 1, 1, "", "decision_function"], [109, 1, 1, "", "fit"], [109, 1, 1, "", "get_params"], [109, 1, 1, "", "model_unwrapper"], [109, 1, 1, "", "predict"], [109, 1, 1, "", "score"], [109, 1, 1, "", "set_params"]], "piml.models.FIGSClassifier": [[110, 1, 1, "", "decision_function"], [110, 1, 1, "", "fit"], [110, 1, 1, "", "get_binary_matrix"], [110, 1, 1, "", "get_binary_representation"], [110, 1, 1, "", "get_depths"], [110, 1, 1, "", "get_depths_interactions"], [110, 1, 1, "", "get_params"], [110, 1, 1, "", "predict"], [110, 1, 1, "", "predict_proba"], [110, 1, 1, "", "score"], [110, 1, 1, "", "set_params"], [110, 1, 1, "", "update_tree_importance"]], "piml.models.FIGSRegressor": [[111, 1, 1, "", "fit"], [111, 1, 1, "", "get_binary_matrix"], [111, 1, 1, "", "get_binary_representation"], [111, 1, 1, "", "get_depths"], [111, 1, 1, "", "get_depths_interactions"], [111, 1, 1, "", "get_params"], [111, 1, 1, "", "predict"], [111, 1, 1, "", "score"], [111, 1, 1, "", "set_params"], [111, 1, 1, "", "update_tree_importance"]], "piml.models.GAMClassifier": [[112, 1, 1, "", "fit"], [112, 1, 1, "", "get_main_effect"], [112, 1, 1, "", "get_params"], [112, 1, 1, "", "global_interpret"], [112, 1, 1, "", "interpret_fi"], [112, 1, 1, "", "interpret_local_fi"], [112, 1, 1, "", "local_feature_explain"], [112, 1, 1, "", "plot_fi"], [112, 1, 1, "", "plot_local_fi"], [112, 1, 1, "", "set_params"]], "piml.models.GAMINetClassifier": [[113, 1, 1, "", "certify_mono"], [113, 1, 1, "", "decision_function"], [113, 1, 1, "", "fine_tune_selected"], [113, 1, 1, "", "fit"], [113, 1, 1, "", "get_aggregate_output"], [113, 1, 1, "", "get_clarity_loss"], [113, 1, 1, "", "get_effect_importance"], [113, 1, 1, "", "get_feature_importance"], [113, 1, 1, "", "get_global_effects_"], [113, 1, 1, "", "get_interaction_raw_output"], [113, 1, 1, "", "get_main_effect"], [113, 1, 1, "", "get_main_effect_raw_output"], [113, 1, 1, "", "get_mono_loss"], [113, 1, 1, "", "get_params"], [113, 1, 1, "", "interpret_fi"], [113, 1, 1, "", "interpret_local_fi"], [113, 1, 1, "", "load"], [113, 1, 1, "", "local_effect_explain"], [113, 1, 1, "", "local_feature_explain"], [113, 1, 1, "", "partial_derivatives"], [113, 1, 1, "", "plot_fi"], [113, 1, 1, "", "plot_local_fi"], [113, 1, 1, "", "predict"], [113, 1, 1, "", "predict_proba"], [113, 1, 1, "", "save"], [113, 1, 1, "", "score"], [113, 1, 1, "", "set_params"], [113, 1, 1, "", "update_effect_importance"], [113, 1, 1, "", "update_feature_importance"]], "piml.models.GAMINetRegressor": [[114, 1, 1, "", "certify_mono"], [114, 1, 1, "", "fine_tune_selected"], [114, 1, 1, "", "fit"], [114, 1, 1, "", "get_aggregate_output"], [114, 1, 1, "", "get_clarity_loss"], [114, 1, 1, "", "get_effect_importance"], [114, 1, 1, "", "get_feature_importance"], [114, 1, 1, "", "get_global_effects_"], [114, 1, 1, "", "get_interaction_raw_output"], [114, 1, 1, "", "get_main_effect"], [114, 1, 1, "", "get_main_effect_raw_output"], [114, 1, 1, "", "get_mono_loss"], [114, 1, 1, "", "get_params"], [114, 1, 1, "", "interpret_fi"], [114, 1, 1, "", "interpret_local_fi"], [114, 1, 1, "", "load"], [114, 1, 1, "", "local_effect_explain"], [114, 1, 1, "", "local_feature_explain"], [114, 1, 1, "", "partial_derivatives"], [114, 1, 1, "", "plot_fi"], [114, 1, 1, "", "plot_local_fi"], [114, 1, 1, "", "predict"], [114, 1, 1, "", "save"], [114, 1, 1, "", "score"], [114, 1, 1, "", "set_params"], [114, 1, 1, "", "update_effect_importance"], [114, 1, 1, "", "update_feature_importance"]], "piml.models.GAMRegressor": [[115, 1, 1, "", "fit"], [115, 1, 1, "", "get_main_effect"], [115, 1, 1, "", "get_params"], [115, 1, 1, "", "global_interpret"], [115, 1, 1, "", "interpret_fi"], [115, 1, 1, "", "interpret_local_fi"], [115, 1, 1, "", "local_feature_explain"], [115, 1, 1, "", "plot_fi"], [115, 1, 1, "", "plot_local_fi"], [115, 1, 1, "", "set_params"]], "piml.models.GLMClassifier": [[116, 1, 1, "", "get_params"], [116, 1, 1, "", "set_params"]], "piml.models.GLMRegressor": [[117, 1, 1, "", "get_params"], [117, 1, 1, "", "set_params"]], "piml.models.ReluDNNClassifier": [[118, 1, 1, "", "decision_function"], [118, 1, 1, "", "fit"], [118, 1, 1, "", "get_params"], [118, 1, 1, "", "get_raw_output"], [118, 1, 1, "", "model_unwrapper"], [118, 1, 1, "", "predict"], [118, 1, 1, "", "predict_proba"], [118, 1, 1, "", "score"], [118, 1, 1, "", "set_params"]], "piml.models.ReluDNNRegressor": [[119, 1, 1, "", "fit"], [119, 1, 1, "", "get_params"], [119, 1, 1, "", "get_raw_output"], [119, 1, 1, "", "model_unwrapper"], [119, 1, 1, "", "predict"], [119, 1, 1, "", "score"], [119, 1, 1, "", "set_params"]], "piml.models.TreeClassifier": [[120, 1, 1, "", "apply"], [120, 1, 1, "", "cost_complexity_pruning_path"], [120, 1, 1, "", "decision_path"], [120, 2, 1, "", "feature_importances_"], [120, 1, 1, "", "fit"], [120, 1, 1, "", "get_depth"], [120, 1, 1, "", "get_n_leaves"], [120, 1, 1, "", "get_params"], [120, 1, 1, "", "get_tree_diag"], [120, 1, 1, "", "global_interpret"], [120, 1, 1, "", "interpret_local_tree"], [120, 2, 1, "", "n_features_"], [120, 1, 1, "", "plot_local_tree"], [120, 1, 1, "", "plot_tree_diag"], [120, 1, 1, "", "predict"], [120, 1, 1, "", "predict_log_proba"], [120, 1, 1, "", "predict_proba"], [120, 1, 1, "", "score"], [120, 1, 1, "", "set_params"]], "piml.models.TreeRegressor": [[121, 1, 1, "", "apply"], [121, 1, 1, "", "cost_complexity_pruning_path"], [121, 1, 1, "", "decision_path"], [121, 2, 1, "", "feature_importances_"], [121, 1, 1, "", "fit"], [121, 1, 1, "", "get_depth"], [121, 1, 1, "", "get_n_leaves"], [121, 1, 1, "", "get_params"], [121, 1, 1, "", "get_tree_diag"], [121, 1, 1, "", "global_interpret"], [121, 1, 1, "", "interpret_local_tree"], [121, 2, 1, "", "n_features_"], [121, 1, 1, "", "plot_local_tree"], [121, 1, 1, "", "plot_tree_diag"], [121, 1, 1, "", "predict"], [121, 1, 1, "", "score"], [121, 1, 1, "", "set_params"]], "piml.models.XGB1Classifier": [[122, 1, 1, "", "decision_function"], [122, 1, 1, "", "fit"], [122, 1, 1, "", "get_main_effect"], [122, 1, 1, "", "get_params"], [122, 1, 1, "", "interpret_fi"], [122, 1, 1, "", "interpret_iv"], [122, 1, 1, "", "interpret_local_fi"], [122, 1, 1, "", "local_feature_explain"], [122, 1, 1, "", "plot_fi"], [122, 1, 1, "", "plot_iv"], [122, 1, 1, "", "plot_local_fi"], [122, 1, 1, "", "plot_woe"], [122, 1, 1, "", "predict"], [122, 1, 1, "", "predict_proba"], [122, 1, 1, "", "score"], [122, 1, 1, "", "set_params"], [122, 1, 1, "", "update_feature_importance"]], "piml.models.XGB1Regressor": [[123, 1, 1, "", "fit"], [123, 1, 1, "", "get_main_effect"], [123, 1, 1, "", "get_params"], [123, 1, 1, "", "interpret_fi"], [123, 1, 1, "", "interpret_iv"], [123, 1, 1, "", "interpret_local_fi"], [123, 1, 1, "", "local_feature_explain"], [123, 1, 1, "", "plot_fi"], [123, 1, 1, "", "plot_iv"], [123, 1, 1, "", "plot_local_fi"], [123, 1, 1, "", "plot_woe"], [123, 1, 1, "", "predict"], [123, 1, 1, "", "score"], [123, 1, 1, "", "set_params"], [123, 1, 1, "", "update_feature_importance"]], "piml.models.XGB2Classifier": [[124, 1, 1, "", "decision_function"], [124, 1, 1, "", "fit"], [124, 1, 1, "", "get_params"], [124, 1, 1, "", "model_unwrapper"], [124, 1, 1, "", "predict"], [124, 1, 1, "", "predict_proba"], [124, 1, 1, "", "score"], [124, 1, 1, "", "set_params"]], "piml.models.XGB2Regressor": [[125, 1, 1, "", "fit"], [125, 1, 1, "", "get_params"], [125, 1, 1, "", "model_unwrapper"], [125, 1, 1, "", "predict"], [125, 1, 1, "", "score"], [125, 1, 1, "", "set_params"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"]}, "titleterms": {"data": [0, 1, 2, 4, 5, 17, 61, 62, 63, 64, 65, 70, 72, 73, 74, 75, 85, 101, 106], "pipelin": [0, 17, 70, 106], "loader": [], "summari": [2, 75, 83, 93], "eda": 3, "prepar": [4, 61, 62, 63, 64, 65, 73], "qualiti": [5, 74], "featur": [6, 10, 76, 82, 83, 88, 89, 90, 91, 92, 93, 95, 96, 103], "select": [6, 76], "two": [7, 77, 78, 81, 100, 104], "sampl": [7, 67, 69, 77, 103], "test": [7, 17, 38, 51, 61, 62, 63, 64, 65, 73, 76, 77, 103, 106], "comput": [8, 16, 37, 52, 57], "time": [8, 16, 37, 52, 57], "post": [9, 17, 84, 106], "hoc": [9, 17, 84, 106], "explain": [9, 17, 61, 62, 65, 84, 88, 106], "permut": [10, 82], "import": [10, 76, 82, 83, 88, 89, 90, 91, 92, 93, 95, 96, 105], "partial": [11, 81], "depend": [11, 81, 83, 105], "plot": [11, 71, 77, 81, 83, 88, 90, 91, 93, 95, 96, 98, 100, 104], "individu": [12, 79], "condit": [12, 76, 79], "expect": [12, 79], "accumul": [13, 78], "local": [13, 14, 74, 78, 80, 84, 88, 89, 90, 91, 92, 93, 94, 95, 96], "effect": [13, 78, 88, 90, 91, 95, 96], "interpret": [14, 17, 18, 61, 62, 65, 80, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 106], "model": [14, 17, 18, 53, 54, 55, 61, 62, 63, 64, 65, 66, 80, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "agnost": [14, 80], "explan": [14, 15, 80, 83], "shaplei": [15, 83], "addit": [15, 83, 90], "exampl": [17, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "outcom": [17, 38, 61, 62, 65, 106], "comparison": [17, 53, 54, 55, 56, 61, 62, 64, 65, 66, 67, 68, 69, 74, 77, 102], "glm": [19, 20], "logist": 19, "regress": [19, 20, 22, 24, 26, 28, 30, 32, 34, 36, 40, 42, 44, 46, 48, 50, 55, 69, 92, 98, 101], "taiwan": [19, 25, 29, 31, 33, 35, 67, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "credit": [19, 25, 29, 31, 33, 35, 67, 88, 89, 91, 92, 93, 94, 96, 98, 100, 101, 102, 103, 104], "linear": [20, 92, 93], "bike": [20, 30, 32, 34, 78, 79, 80, 81, 82, 83, 92], "share": [20, 30, 32, 34, 78, 79, 80, 81, 82, 83, 92], "gam": [21, 22], "classif": [21, 23, 25, 27, 29, 31, 33, 35, 39, 41, 43, 45, 47, 49, 54, 67, 98, 101], "cocircl": [21, 27, 90, 95], "california": [22, 24, 26, 28, 90], "hous": [22, 24, 26, 28, 90], "tree": [23, 24, 89, 94], "taiwancredit": [23, 65], "fig": [25, 26], "xgb": [27, 28, 29, 30], "1": [27, 28, 63, 67, 69, 78, 79, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103, 104], "2": [29, 30, 64, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 100, 101, 102, 103, 104], "ebm": [31, 32], "gami": [33, 34, 91], "net": [33, 34, 91], "relu": [35, 36, 93], "dnn": [35, 36], "friedman": [36, 93], "accuraci": [39, 40, 67, 69, 98], "weakspot": [41, 42, 104], "overfit": [43, 44, 67, 69, 100], "reliabl": [45, 46, 67, 69, 101], "robust": [47, 48, 67, 69, 103], "resili": [49, 50, 67, 69, 102], "fair": [51, 56, 63, 64, 68, 99], "xgb2": 51, "tabl": [58, 93, 98, 101], "Of": 58, "content": 58, "frequent": 59, "ask": 59, "question": 59, "case": 60, "studi": [60, 63, 64], "bikeshar": [61, 69, 88, 91, 95, 96, 98, 100, 101, 103, 104], "load": [1, 61, 62, 63, 64, 65, 72, 85, 105], "train": [61, 62, 63, 64, 65, 73, 85, 88, 89, 90, 91, 92, 93, 94, 95, 96], "intepret": [61, 62, 65], "diagnost": [61, 62, 65, 86, 97], "benchmark": [61, 62, 65], "californiah": [62, 89, 94, 102], "simul": [63, 64], "ml": [63, 64], "": [63, 64], "descript": 64, "score": [67, 69, 101], "auc": 67, "f1": 67, "bandwidth": [67, 69, 101], "diagram": [67, 89, 101], "perforform": [67, 69], "perform": [67, 69, 102], "worst": [67, 69, 103], "metric": [68, 77, 99], "segment": [68, 99], "mean": 69, "squar": 69, "error": 69, "absolu": 69, "r": 69, "coverag": [69, 101], "conclus": [], "exploratori": 71, "analysi": [71, 74], "univari": 71, "bivari": 71, "multivari": 71, "full": [71, 72, 73, 74, 75, 76, 77], "built": 72, "dataset": 72, "extern": 72, "config": 73, "set": 73, "distanc": [73, 76, 77, 101, 102], "method": 74, "isol": 74, "forest": 74, "cluster": 74, "base": 74, "outlier": 74, "factor": 74, "principl": [], "compon": 74, "kmeanstre": 74, "statist": 75, "correl": 76, "random": 76, "independ": 76, "rcit": 76, "forward": 76, "backward": 76, "earli": 76, "drop": 76, "fbedk": 76, "refer": [76, 79, 82, 83, 86, 106], "usag": [77, 78, 79, 80, 81, 82, 83, 100, 102, 103, 104], "margin": [77, 101, 102], "densiti": [77, 102], "al": 78, "algorithm": [78, 79, 80, 81, 82, 83, 100, 102, 103, 104], "detail": [78, 79, 80, 81, 82, 83, 100, 102, 103, 104], "One": [78, 81, 100, 104], "wai": [78, 81, 100, 104], "ic": 79, "lime": 80, "pdp": 81, "pfi": 82, "shap": 83, "exact": 83, "solut": 83, "kernelshap": 83, "specif": 83, "The": 83, "waterfal": 83, "global": [84, 88, 89, 90, 91, 92, 93, 94, 95, 96], "black": 85, "box": 85, "regist": 85, "save": 85, "fit": 85, "arbitrari": 85, "introduct": 86, "toolbox": 86, "design": 86, "suit": [86, 97], "futur": 86, "plan": 86, "boost": 88, "machin": 88, "main": [88, 90, 91, 95, 96], "interact": [88, 91, 96], "contribut": [88, 91, 93, 96], "fast": 89, "greedi": 89, "sum": 89, "heatmap": 89, "gener": [90, 92], "coeffici": 92, "origin": 92, "scale": 92, "option": 92, "center": 92, "neural": 93, "network": 93, "formul": 93, "llm": 93, "parallel": 93, "coordin": 93, "violin": 93, "profil": 93, "pairwis": 93, "decis": 94, "xgboost": [95, 96], "depth": [95, 96], "weight": 95, "evid": 95, "inform": 95, "valu": 95, "task": [98, 101], "residu": 98, "binari": [98, 101], "bin": 99, "threshold": 99, "un": 101, "classifi": 101, "calibr": 101, "brier": 101, "histogram": 102, "perturb": 103, "For": 103, "numer": 103, "categor": 103, "variabl": 103, "whole": 103, "instal": 105, "quick": 105, "troubleshoot": 105, "could": 105, "find": 105, "version": 105, "satisfi": 105, "requir": 105, "piml": [105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "cannot": 105, "uninstal": 105, "llvmlite": 105, "librari": 105, "libxgboost": 105, "so": 105, "colab": 105, "api": 106, "experi": [106, 107], "class": 106, "high": 106, "code": 106, "us": [107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125], "explainableboostingclassifi": 108, "explainableboostingregressor": 109, "figsclassifi": 110, "figsregressor": 111, "gamclassifi": 112, "gaminetclassifi": 113, "gaminetregressor": 114, "gamregressor": 115, "glmclassifi": 116, "glmregressor": 117, "reludnnclassifi": 118, "reludnnregressor": 119, "treeclassifi": 120, "treeregressor": 121, "xgb1classifi": 122, "xgb1regressor": 123, "xgb2classifi": 124, "xgb2regressor": 125, "welcom": 126, "scikit": 126, "learn": 126, "user": 128, "guid": 128, "check": 5, "princip": 74}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.intersphinx": 1, "sphinx": 57}, "alltitles": {"Data Pipeline": [[0, "data-pipeline"], [17, "data-pipeline"], [70, "data-pipeline"], [106, "data-pipeline"]], "Data Load": [[1, "data-load"], [72, "data-load"]], "Data Summary": [[2, "data-summary"], [75, "data-summary"]], "EDA": [[3, "eda"]], "Data Prepare": [[4, "data-prepare"], [73, "data-prepare"]], "Data Quality Check": [[5, "data-quality-check"]], "Feature Selection": [[6, "feature-selection"], [76, "feature-selection"]], "Two Sample Test": [[7, "two-sample-test"], [77, "two-sample-test"]], "Computation times": [[8, "computation-times"], [16, "computation-times"], [37, "computation-times"], [52, "computation-times"], [57, "computation-times"]], "Post hoc Explainability": [[9, "post-hoc-explainability"], [17, "post-hoc-explainability"]], "Permutation Feature Importance": [[10, "permutation-feature-importance"]], "Partial Dependence Plot": [[11, "partial-dependence-plot"]], "Individual Conditional Expectation": [[12, "individual-conditional-expectation"]], "Accumulated Local Effects": [[13, "accumulated-local-effects"]], "Local Interpretable Model-Agnostic Explanation": [[14, "local-interpretable-model-agnostic-explanation"]], "SHapley Additive exPlanations": [[15, "shapley-additive-explanations"]], "Examples": [[17, "examples"], [67, "examples"], [68, "examples"], [69, "examples"], [78, "examples"], [79, "examples"], [80, "examples"], [81, "examples"], [83, "examples"], [88, "examples"], [89, "examples"], [91, "examples"], [92, "examples"], [93, "examples"], [94, "examples"], [95, "examples"], [96, "examples"], [98, "examples"], [99, "examples"], [100, "examples"], [101, "examples"], [102, "examples"], [103, "examples"], [104, "examples"]], "Interpretable Models": [[17, "interpretable-models"], [18, "interpretable-models"], [86, "interpretable-models"], [87, "interpretable-models"], [106, "interpretable-models"]], "Outcome Testing": [[17, "outcome-testing"], [38, "outcome-testing"], [106, "outcome-testing"]], "Model Comparison": [[17, "model-comparison"], [53, "model-comparison"], [66, "model-comparison"]], "GLM Logistic Regression (Taiwan Credit)": [[19, "glm-logistic-regression-taiwan-credit"]], "GLM Linear Regression (Bike Sharing)": [[20, "glm-linear-regression-bike-sharing"]], "GAM Classification (CoCircles)": [[21, "gam-classification-cocircles"]], "GAM Regression (California Housing)": [[22, "gam-regression-california-housing"]], "Tree Classification (TaiwanCredit)": [[23, "tree-classification-taiwancredit"]], "Tree Regression (California Housing)": [[24, "tree-regression-california-housing"]], "FIGS Classification (Taiwan Credit)": [[25, "figs-classification-taiwan-credit"]], "FIGS Regression (California Housing)": [[26, "figs-regression-california-housing"]], "XGB-1 Classification (CoCircles)": [[27, "xgb-1-classification-cocircles"]], "XGB-1 Regression (California Housing)": [[28, "xgb-1-regression-california-housing"]], "XGB-2 Classification (Taiwan Credit)": [[29, "xgb-2-classification-taiwan-credit"]], "XGB-2 Regression (Bike Sharing)": [[30, "xgb-2-regression-bike-sharing"]], "EBM Classification (Taiwan Credit)": [[31, "ebm-classification-taiwan-credit"]], "EBM Regression (Bike Sharing)": [[32, "ebm-regression-bike-sharing"]], "GAMI-Net Classification (Taiwan Credit)": [[33, "gami-net-classification-taiwan-credit"]], "GAMI-Net Regression (Bike Sharing)": [[34, "gami-net-regression-bike-sharing"]], "ReLU DNN Classification (Taiwan Credit)": [[35, "relu-dnn-classification-taiwan-credit"]], "ReLU DNN Regression (Friedman)": [[36, "relu-dnn-regression-friedman"]], "Accuracy: Classification": [[39, "accuracy-classification"]], "Accuracy: Regression": [[40, "accuracy-regression"]], "WeakSpot: Classification": [[41, "weakspot-classification"]], "WeakSpot: Regression": [[42, "weakspot-regression"]], "Overfit: Classification": [[43, "overfit-classification"]], "Overfit: Regression": [[44, "overfit-regression"]], "Reliability: Classification": [[45, "reliability-classification"]], "Reliability: Regression": [[46, "reliability-regression"]], "Robustness: Classification": [[47, "robustness-classification"]], "Robustness:  Regression": [[48, "robustness-regression"]], "Resilience:  Classification": [[49, "resilience-classification"]], "Resilience - Regression": [[50, "resilience-regression"]], "Fairness Test: XGB2": [[51, "fairness-test-xgb2"]], "Model Comparison: Classification": [[54, "model-comparison-classification"]], "Model Comparison: Regression": [[55, "model-comparison-regression"]], "Fairness Comparison": [[56, "fairness-comparison"], [68, "fairness-comparison"]], "Table Of Contents": [[58, "table-of-contents"]], "Frequently Asked Questions": [[59, "frequently-asked-questions"]], "Case Studies": [[60, "case-studies"]], "BikeSharing Data": [[61, "BikeSharing-Data"]], "Load and Prepare Data": [[61, "Load-and-Prepare-Data"], [62, "Load-and-Prepare-Data"], [63, "Load-and-Prepare-Data"], [65, "Load-and-Prepare-Data"]], "Train Intepretable Models": [[61, "Train-Intepretable-Models"], [62, "Train-Intepretable-Models"], [65, "Train-Intepretable-Models"]], "Interpretability and Explainability": [[61, "Interpretability-and-Explainability"], [62, "Interpretability-and-Explainability"], [65, "Interpretability-and-Explainability"]], "Model Diagnostics and Outcome Testing": [[61, "Model-Diagnostics-and-Outcome-Testing"], [62, "Model-Diagnostics-and-Outcome-Testing"], [65, "Model-Diagnostics-and-Outcome-Testing"]], "Model Comparison and Benchmarking": [[61, "Model-Comparison-and-Benchmarking"], [62, "Model-Comparison-and-Benchmarking"], [65, "Model-Comparison-and-Benchmarking"]], "CaliforniaHousing Data": [[62, "CaliforniaHousing-Data"]], "Fairness Simulation Study 1": [[63, "Fairness-Simulation-Study-1"]], "Train ML Model(s)": [[63, "Train-ML-Model(s)"], [64, "Train-ML-Model(s)"]], "Fairness Testing": [[63, "Fairness-Testing"], [64, "Fairness-Testing"]], "Fairness Simulation Study 2": [[64, "Fairness-Simulation-Study-2"]], "Data Description": [[64, "Data-Description"]], "Load and Prepare data": [[64, "Load-and-Prepare-data"]], "Fairness Testing Comparison": [[64, "Fairness-Testing-Comparison"]], "TaiwanCredit Data": [[65, "TaiwanCredit-Data"]], "Comparison for Classification": [[67, "comparison-for-classification"]], "Accuracy Comparison": [[67, "accuracy-comparison"], [69, "accuracy-comparison"]], "Accuracy Score": [[67, "accuracy-score"]], "AUC Score": [[67, "auc-score"]], "F1 Score": [[67, "f1-score"]], "Overfit Comparison": [[67, "overfit-comparison"], [69, "overfit-comparison"]], "Reliability Comparison": [[67, "reliability-comparison"], [69, "reliability-comparison"]], "Bandwidth Comparison": [[67, "bandwidth-comparison"], [69, "bandwidth-comparison"]], "Reliability Diagram Comparison": [[67, "reliability-diagram-comparison"]], "Robustness Comparison": [[67, "robustness-comparison"], [69, "robustness-comparison"]], "Robustness Perforformance": [[67, "robustness-perforformance"], [69, "robustness-perforformance"]], "Robustness Performance on Worst Samples": [[67, "robustness-performance-on-worst-samples"], [69, "robustness-performance-on-worst-samples"]], "Resilience Comparison": [[67, "resilience-comparison"], [69, "resilience-comparison"]], "Resilience Perforformance": [[67, "resilience-perforformance"], [69, "resilience-perforformance"]], "Resilience Performance on Worst Samples": [[67, "resilience-performance-on-worst-samples"], [69, "resilience-performance-on-worst-samples"]], "Examples 1: Taiwan Credit": [[67, null]], "Metric": [[68, "metric"]], "Segmented": [[68, "segmented"]], "Example": [[68, null], [71, null], [72, null], [73, null], [75, null], [76, null], [77, null], [82, "example"], [90, "example"], [99, null], [74, null]], "Comparison for Regression": [[69, "comparison-for-regression"]], "Mean Squared Error": [[69, "mean-squared-error"]], "Mean Absoluate Error": [[69, "mean-absoluate-error"]], "R-squared Score": [[69, "r-squared-score"]], "Coverage Comparison": [[69, "coverage-comparison"]], "Example 1: BikeSharing": [[69, null], [88, null], [91, null], [95, null], [96, null], [98, null], [100, null], [101, null], [103, null], [104, null]], "Exploratory Analysis": [[71, "exploratory-analysis"]], "Univariate Plots": [[71, "univariate-plots"]], "Bivariate Plots": [[71, "bivariate-plots"]], "Multivariate Plots": [[71, "multivariate-plots"]], "Full Example": [[71, "full-example"], [72, "full-example"], [73, "full-example"], [75, "full-example"], [76, "full-example"], [77, "full-example"], [74, "full-example"]], "Built-in Dataset": [[72, "built-in-dataset"]], "External Dataset": [[72, "external-dataset"]], "Config setting": [[73, "config-setting"]], "Train Test Distance": [[73, "train-test-distance"]], "Summary Statistics": [[75, "summary-statistics"]], "Correlations": [[76, "correlations"]], "Distance Correlation": [[76, "distance-correlation"]], "Feature Importance": [[76, "feature-importance"], [88, "feature-importance"], [90, "feature-importance"], [91, "feature-importance"], [92, "feature-importance"], [95, "feature-importance"], [96, "feature-importance"]], "Randomized Conditional Independence Test": [[76, "randomized-conditional-independence-test"]], "RCIT Test": [[76, "rcit-test"]], "Forward-Backward selection with Early Dropping (FBEDk):": [[76, "forward-backward-selection-with-early-dropping-fbedk"]], "References": [[76, null], [79, null], [82, null], [83, null], [86, null]], "Distance Metrics": [[77, "distance-metrics"]], "Usage": [[77, "usage"], [78, "usage"], [79, "usage"], [80, "usage"], [81, "usage"], [82, "usage"], [83, "usage"], [100, "usage"], [102, "usage"], [103, "usage"], [104, "usage"]], "Distance Metric Plot": [[77, "distance-metric-plot"]], "Marginal Density Comparison": [[77, "marginal-density-comparison"], [102, "marginal-density-comparison"]], "ALE (Accumulated Local Effects)": [[78, "ale-accumulated-local-effects"]], "Algorithm Details": [[78, "algorithm-details"], [79, "algorithm-details"], [80, "algorithm-details"], [81, "algorithm-details"], [82, "algorithm-details"], [83, "algorithm-details"], [100, "algorithm-details"], [102, "algorithm-details"], [103, "algorithm-details"], [104, "algorithm-details"]], "One-way ALE": [[78, "one-way-ale"]], "Two-way ALE": [[78, "two-way-ale"]], "Example 1: Bike Sharing": [[78, null], [79, null], [80, null], [81, null], [82, null], [83, null], [92, null]], "ICE (Individual Conditional Expectation)": [[79, "ice-individual-conditional-expectation"]], "LIME (Local Interpretable Model-Agnostic Explanation)": [[80, "lime-local-interpretable-model-agnostic-explanation"]], "PDP (Partial Dependence Plot)": [[81, "pdp-partial-dependence-plot"]], "One-way PDPs": [[81, "one-way-pdps"]], "Two-way PDPs": [[81, "two-way-pdps"]], "PFI (Permutation Feature Importance)": [[82, "pfi-permutation-feature-importance"]], "SHAP (SHapley Additive exPlanations)": [[83, "shap-shapley-additive-explanations"]], "Exact Solution": [[83, "exact-solution"]], "KernelSHAP": [[83, "kernelshap"]], "Algorithms for specific models": [[83, "algorithms-for-specific-models"]], "The Waterfall plot": [[83, "the-waterfall-plot"]], "SHAP Feature importance": [[83, "shap-feature-importance"]], "SHAP Summary plot": [[83, "shap-summary-plot"]], "SHAP Dependence Plot": [[83, "shap-dependence-plot"]], "Post-hoc Explainability": [[84, "post-hoc-explainability"], [106, "post-hoc-explainability"]], "Global Explainability": [[84, "global-explainability"]], "Local Explainability": [[84, "local-explainability"]], "Black-box Models": [[85, "black-box-models"]], "Train and Register Models": [[85, "train-and-register-models"]], "Save Fitted Models": [[85, "save-fitted-models"]], "Load and Register Fitted Models": [[85, "load-and-register-fitted-models"]], "Register Arbitrary Models and Data": [[85, "register-arbitrary-models-and-data"]], "Introduction": [[86, "introduction"], [86, "id1"]], "Toolbox Design": [[86, "toolbox-design"]], "Diagnostic Suite": [[86, "diagnostic-suite"], [97, "diagnostic-suite"]], "Future Plan": [[86, "future-plan"]], "Explainable Boosting Machines": [[88, "explainable-boosting-machines"]], "Model Training": [[88, "model-training"], [89, "model-training"], [90, "model-training"], [91, "model-training"], [92, "model-training"], [93, "model-training"], [94, "model-training"], [95, "model-training"], [96, "model-training"]], "Global Interpretation": [[88, "global-interpretation"], [89, "global-interpretation"], [90, "global-interpretation"], [91, "global-interpretation"], [92, "global-interpretation"], [93, "global-interpretation"], [94, "global-interpretation"], [95, "global-interpretation"], [96, "global-interpretation"]], "Main Effect Plot": [[88, "main-effect-plot"], [90, "main-effect-plot"], [91, "main-effect-plot"], [95, "main-effect-plot"], [96, "main-effect-plot"]], "Interaction Plot": [[88, "interaction-plot"], [91, "interaction-plot"], [96, "interaction-plot"]], "Effect Importance": [[88, "effect-importance"], [91, "effect-importance"], [96, "effect-importance"]], "Local Interpretation": [[88, "local-interpretation"], [89, "local-interpretation"], [90, "local-interpretation"], [91, "local-interpretation"], [92, "local-interpretation"], [93, "local-interpretation"], [94, "local-interpretation"], [95, "local-interpretation"], [96, "local-interpretation"]], "Local Effect Contribution": [[88, "local-effect-contribution"], [91, "local-effect-contribution"], [96, "local-effect-contribution"]], "Local Feature Contribution": [[88, "local-feature-contribution"], [91, "local-feature-contribution"], [96, "local-feature-contribution"]], "Examples 2: Taiwan Credit": [[88, null], [89, null], [91, null], [93, null], [94, null], [96, null], [98, null], [100, null], [101, null], [102, null], [103, null], [104, null]], "Fast Interpretable Greedy-tree Sums": [[89, "fast-interpretable-greedy-tree-sums"]], "Feature Importance Heatmap": [[89, "feature-importance-heatmap"]], "Tree Diagram": [[89, "tree-diagram"]], "Example 1: CaliforniaHousing": [[89, null], [94, null], [102, null]], "Generalized Additive Model": [[90, "generalized-additive-model"]], "Example 1: California Housing": [[90, null]], "Example 2: CoCircles": [[90, null], [95, null]], "GAMI-Net": [[91, "gami-net"]], "Generalized Linear Models": [[92, "generalized-linear-models"]], "Regression Coefficients": [[92, "regression-coefficients"]], "Original Scale Option": [[92, "original-scale-option"]], "Centered Option": [[92, "centered-option"]], "Example 2: Taiwan Credit": [[92, null]], "ReLU Neural Network": [[93, "relu-neural-network"]], "Model Formulation": [[93, "model-formulation"]], "Local Linear Models": [[93, "local-linear-models"]], "LLM Summary Table": [[93, "llm-summary-table"]], "Parallel Coordinate Plot": [[93, "parallel-coordinate-plot"]], "LLM Violin Plot": [[93, "llm-violin-plot"]], "Feature Importance Plot": [[93, "feature-importance-plot"]], "LLM profile plot": [[93, "llm-profile-plot"]], "LLM pairwise plot": [[93, "llm-pairwise-plot"]], "Local Feature Contribution plot": [[93, "local-feature-contribution-plot"]], "Example 1: Friedman": [[93, null]], "Decision Tree": [[94, "decision-tree"]], "XGBoost Depth 1": [[95, "xgboost-depth-1"]], "Weight of Evidence Plot": [[95, "weight-of-evidence-plot"]], "Information Value Plot": [[95, "information-value-plot"]], "XGBoost Depth 2": [[96, "xgboost-depth-2"]], "Accuracy": [[98, "accuracy"]], "Regression Tasks": [[98, "regression-tasks"]], "Accuracy Table": [[98, "accuracy-table"], [98, "id1"]], "Residual Plot": [[98, "residual-plot"], [98, "id2"]], "Binary Classification": [[98, "binary-classification"]], "Accuracy Plot": [[98, "accuracy-plot"]], "Fairness": [[99, "fairness"]], "Fairness Metric": [[99, "fairness-metric"]], "Fairness Segmented": [[99, "fairness-segmented"]], "Fairness Binning": [[99, "fairness-binning"]], "Fairness Thresholding": [[99, "fairness-thresholding"]], "Overfit": [[100, "overfit"]], "One-way Overfit Plot": [[100, "one-way-overfit-plot"]], "Two-way Overfit Plot": [[100, "two-way-overfit-plot"]], "Reliability": [[101, "reliability"]], "Reliability for Regression Tasks": [[101, "reliability-for-regression-tasks"]], "Coverage and Bandwidth Table": [[101, "coverage-and-bandwidth-table"]], "Distance of Reliable and Un-reliable Data": [[101, "distance-of-reliable-and-un-reliable-data"], [101, "id1"]], "Marginal Bandwidth": [[101, "marginal-bandwidth"], [101, "id2"]], "Reliability for Binary Classification": [[101, "reliability-for-binary-classification"]], "Classifier Calibration": [[101, "classifier-calibration"]], "Reliability Diagram": [[101, "reliability-diagram"]], "Brier Score Table": [[101, "brier-score-table"]], "Resilience": [[102, "resilience"]], "Resilience Performance": [[102, "resilience-performance"]], "Resilience Distance": [[102, "resilience-distance"]], "Marginal Histogram Comparison": [[102, "marginal-histogram-comparison"]], "Robustness": [[103, "robustness"]], "Perturbation For Numerical Features": [[103, "perturbation-for-numerical-features"]], "Perturbation for Categorical Variable": [[103, "perturbation-for-categorical-variable"]], "Robustness on whole test sample": [[103, "robustness-on-whole-test-sample"]], "Robustness on worst test samples": [[103, "robustness-on-worst-test-samples"]], "WeakSpot": [[104, "weakspot"]], "One-way WeakSpot Plot": [[104, "one-way-weakspot-plot"]], "Two-way WeakSpot Plot": [[104, "two-way-weakspot-plot"]], "Installation": [[105, "installation"]], "Quick Install": [[105, "quick-install"]], "Dependencies": [[105, "dependencies"]], "Troubleshooting": [[105, "troubleshooting"]], "Could not find a version that satisfies the requirement PiML": [[105, "could-not-find-a-version-that-satisfies-the-requirement-piml"]], "Cannot uninstall \u201cllvmlite\u201d.": [[105, "cannot-uninstall-llvmlite"]], "Library \u201clibxgboost.so\u201d not loaded": [[105, "library-libxgboost-so-not-loaded"]], "Cannot import PiML on Colab": [[105, "cannot-import-piml-on-colab"]], "API Reference": [[106, "api-reference"]], "Experiment Class": [[106, "experiment-class"]], "High Code APIs": [[106, "high-code-apis"]], "Model Classes": [[106, "model-classes"]], "piml.Experiment": [[107, "piml-experiment"]], "Examples using piml.Experiment": [[107, "examples-using-piml-experiment"]], "piml.models.ExplainableBoostingClassifier": [[108, "piml-models-explainableboostingclassifier"]], "Examples using piml.models.ExplainableBoostingClassifier": [[108, "examples-using-piml-models-explainableboostingclassifier"]], "piml.models.ExplainableBoostingRegressor": [[109, "piml-models-explainableboostingregressor"]], "Examples using piml.models.ExplainableBoostingRegressor": [[109, "examples-using-piml-models-explainableboostingregressor"]], "piml.models.FIGSClassifier": [[110, "piml-models-figsclassifier"]], "Examples using piml.models.FIGSClassifier": [[110, "examples-using-piml-models-figsclassifier"]], "piml.models.FIGSRegressor": [[111, "piml-models-figsregressor"]], "Examples using piml.models.FIGSRegressor": [[111, "examples-using-piml-models-figsregressor"]], "piml.models.GAMClassifier": [[112, "piml-models-gamclassifier"]], "Examples using piml.models.GAMClassifier": [[112, "examples-using-piml-models-gamclassifier"]], "piml.models.GAMINetClassifier": [[113, "piml-models-gaminetclassifier"]], "Examples using piml.models.GAMINetClassifier": [[113, "examples-using-piml-models-gaminetclassifier"]], "piml.models.GAMINetRegressor": [[114, "piml-models-gaminetregressor"]], "Examples using piml.models.GAMINetRegressor": [[114, "examples-using-piml-models-gaminetregressor"]], "piml.models.GAMRegressor": [[115, "piml-models-gamregressor"]], "Examples using piml.models.GAMRegressor": [[115, "examples-using-piml-models-gamregressor"]], "piml.models.GLMClassifier": [[116, "piml-models-glmclassifier"]], "Examples using piml.models.GLMClassifier": [[116, "examples-using-piml-models-glmclassifier"]], "piml.models.GLMRegressor": [[117, "piml-models-glmregressor"]], "Examples using piml.models.GLMRegressor": [[117, "examples-using-piml-models-glmregressor"]], "piml.models.ReluDNNClassifier": [[118, "piml-models-reludnnclassifier"]], "Examples using piml.models.ReluDNNClassifier": [[118, "examples-using-piml-models-reludnnclassifier"]], "piml.models.ReluDNNRegressor": [[119, "piml-models-reludnnregressor"]], "Examples using piml.models.ReluDNNRegressor": [[119, "examples-using-piml-models-reludnnregressor"]], "piml.models.TreeClassifier": [[120, "piml-models-treeclassifier"]], "Examples using piml.models.TreeClassifier": [[120, "examples-using-piml-models-treeclassifier"]], "piml.models.TreeRegressor": [[121, "piml-models-treeregressor"]], "Examples using piml.models.TreeRegressor": [[121, "examples-using-piml-models-treeregressor"]], "piml.models.XGB1Classifier": [[122, "piml-models-xgb1classifier"]], "Examples using piml.models.XGB1Classifier": [[122, "examples-using-piml-models-xgb1classifier"]], "piml.models.XGB1Regressor": [[123, "piml-models-xgb1regressor"]], "Examples using piml.models.XGB1Regressor": [[123, "examples-using-piml-models-xgb1regressor"]], "piml.models.XGB2Classifier": [[124, "piml-models-xgb2classifier"]], "Examples using piml.models.XGB2Classifier": [[124, "examples-using-piml-models-xgb2classifier"]], "piml.models.XGB2Regressor": [[125, "piml-models-xgb2regressor"]], "Examples using piml.models.XGB2Regressor": [[125, "examples-using-piml-models-xgb2regressor"]], "Welcome to scikit-learn": [[126, "welcome-to-scikit-learn"]], "User Guide": [[128, "user-guide"]], "Data Quality": [[74, "data-quality"]], "Method": [[74, "method"]], "Isolation Forest": [[74, "isolation-forest"]], "Cluster-Based Local Outlier Factor": [[74, "cluster-based-local-outlier-factor"]], "Principal Component Analysis": [[74, "principal-component-analysis"]], "KmeansTree": [[74, "kmeanstree"]], "Analysis and Comparison": [[74, "analysis-and-comparison"]]}, "indexentries": {}})