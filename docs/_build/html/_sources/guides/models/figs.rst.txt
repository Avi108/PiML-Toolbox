.. Places parent toc into the sidebar

:parenttoc: True

.. include:: ../../includes/big_toc_css.rst

==========================================
Fast Interpretable Greedy-tree Sums
==========================================

Fast Interpretable Greedy-tree Sums (FIGS) is a recently proposed machine-learning algorithm that extends classification and regression trees (CART), by growing a sum of multiple trees [T2022]_. At each iteration, FIGS may grow any existing tree it has already started or start a new tree, and it greedily selects whichever rule reduces the total unexplained variance (or an alternative splitting criterion) the most. Therefore, the search space of FIGS is much larger than that of CART, and also its predictive performance.


Model Training
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

PiML provides a re-implementation of the FIGS by the imodels package, which is much faster and with more interpretation functionalities, see `FIGSRegressor`_ and `FIGSClassifier`_.

.. _FIGSRegressor: ../../modules/generated/piml.models.FIGSRegressor.html

.. _FIGSClassifier: ../../modules/generated/piml.models.FIGSClassifier.html


The training of FIGS is similar to that of the other interpretable models.

.. jupyter-input::

    from piml.models import FIGSRegressor
    exp.model_train(model=FIGSRegressor(max_iter=100, max_depth=4), name='FIGS')

In our implementation, `max_iter` and `max_depth` are the two most important hyperparameters.

- `max_iter`: an integer limiting the max number of split iterations, by default 20.
 
- `max_depth`: an integer limiting the max depth of the tree, by default None, which means unlimited of max tree depth.

Both of them are stopping criteria, and we can use them collectively to control the complexity of overall model and each single tree. For instance, if without any limit on `max_depth`, the fitted trees can be extremely deep, and the results can be hardly interpretable. On the other hand, if without any limit on `max_iter`, then the overall model can become even more complicated than ensemble tree models.


Global Interpretation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Similar to decision trees, the FIGS model can be globally interpreted using tree diagrams. The main difference lies in that the FIGS model may have multiple trees, and hence we would need to specify which tree to show.

.. jupyter-input::
     
     exp.model_interpret(model='FIGS', show="tree_global", root=0, tree_idx=0,
                         depth=3, original_scale=True, figsize=(20, 6))

.. figure:: ../../auto_examples/models/images/sphx_glr_plot_3_figs_reg_001.png
   :target: ../../auto_examples/models/plot_3_figs_reg.html
   :align: center
   :scale: 50%

Here, we introduce the `tree_idx` argument, which is the index of the tree to show. We also have `root` and `depth` arguments, which have the same definition as the `Decsion_Trees`_.

.. _Decsion_Trees: decision_tree.html#model-interpretation


Local Interpretation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

As we use the keyword ``tree_Local``, the decision path of a selected sample will be shown within the tree diagram. The usage of the rest parameters is the same as the tree diagram plot.

.. jupyter-input::

    exp.model_interpret(model='FIGS', show="tree_local", sample_id=0, tree_idx=0, root=0,
                        depth=3, original_scale=True, figsize=(20, 6))

.. figure:: ../../auto_examples/models/images/sphx_glr_plot_3_figs_reg_003.png
   :target: ../../auto_examples/models/plot_3_figs_reg.html
   :align: center
   :scale: 50%


Examples
^^^^^^^^^^^^^^^^^^^^^

.. topic:: Example 1: CaliforniaHousing_trim2

  The example below demonstrates how to use PiML with its high-code APis for the California Housing dataset from the UCI repository, which consists of 20,640 samples and 9 features, fetched by sklearn.datasets. The response variable MedHouseVal (Median Home Value) is continuous and is a regression problem.

 * :ref:`sphx_glr_auto_examples_models_plot_3_figs_reg.py`

.. topic:: Examples 2: Taiwan Credit

   The second example below demonstrates how to use PiML's high-code APIs for the TaiwanCredit dataset from the UCI repository. This dataset comprises the credit card details of 30,000 clients in Taiwan from April 2005 to September 2005, and more information can be found on the TaiwanCreditData website. The `FlagDefault` variable serves as the response for this classification problem.

 * :ref:`sphx_glr_auto_examples_models_plot_3_figs_cls.py`


.. topic:: References

     .. [T2022] Yan Shuo Tan, Chandan Singh, Keyan Nasseri, Abhineet Agarwal, and Bin Yu (2022).
				`Fast interpretable greedy-tree sums (FIGS). <https://arxiv.org/pdf/2201.11931.pdf>`_, arXiv preprint arXiv:2201.11931.